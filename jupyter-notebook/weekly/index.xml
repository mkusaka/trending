<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-11T01:40:11Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>apache/superset</title>
    <updated>2025-05-11T01:40:11Z</updated>
    <id>tag:github.com,2025-05-11:/apache/superset</id>
    <link href="https://github.com/apache/superset" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Apache Superset is a Data Visualization and Data Exploration Platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Superset&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://opensource.org/license/apache-2-0&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/superset/releases/latest&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/v/release/apache/superset?sort=semver&#34; alt=&#34;Latest Release on Github&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/apache/superset/actions&#34;&gt;&lt;img src=&#34;https://github.com/apache/superset/actions/workflows/superset-python-unittest.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://badge.fury.io/py/apache_superset&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/apache_superset.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/github/apache/superset&#34;&gt;&lt;img src=&#34;https://codecov.io/github/apache/superset/coverage.svg?branch=master&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/apache_superset&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/pyversions/apache_superset.svg?maxAge=2592000&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://bit.ly/join-superset-slack&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-join-orange.svg?sanitize=true&#34; alt=&#34;Get on Slack&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://superset.apache.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-apache.org-blue.svg?sanitize=true&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;picture width=&#34;500&#34;&gt; &#xA; &lt;source width=&#34;600&#34; media=&#34;(prefers-color-scheme: dark)&#34; src=&#34;https://superset.apache.org/img/superset-logo-horiz-dark.svg&#34; alt=&#34;Superset logo (dark)&#34;&gt; &#xA; &lt;img width=&#34;600&#34; src=&#34;https://superset.apache.org/img/superset-logo-horiz-apache.svg?sanitize=true&#34; alt=&#34;Superset logo (light)&#34;&gt; &#xA;&lt;/picture&gt; &#xA;&lt;p&gt;A modern, enterprise-ready business intelligence web application.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#why-superset&#34;&gt;&lt;strong&gt;Why Superset?&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#supported-databases&#34;&gt;&lt;strong&gt;Supported Databases&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#installation-and-configuration&#34;&gt;&lt;strong&gt;Installation and Configuration&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/apache/superset/raw/master/RELEASING/README.md#release-notes-for-recent-releases&#34;&gt;&lt;strong&gt;Release Notes&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#get-involved&#34;&gt;&lt;strong&gt;Get Involved&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#contributor-guide&#34;&gt;&lt;strong&gt;Contributor Guide&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/apache/superset/master/#resources&#34;&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/apache/superset/raw/master/RESOURCES/INTHEWILD.md&#34;&gt;&lt;strong&gt;Organizations Using Superset&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Why Superset?&lt;/h2&gt; &#xA;&lt;p&gt;Superset is a modern data exploration and data visualization platform. Superset can replace or augment proprietary business intelligence tools for many teams. Superset integrates well with a variety of data sources.&lt;/p&gt; &#xA;&lt;p&gt;Superset provides:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;strong&gt;no-code interface&lt;/strong&gt; for building charts quickly&lt;/li&gt; &#xA; &lt;li&gt;A powerful, web-based &lt;strong&gt;SQL Editor&lt;/strong&gt; for advanced querying&lt;/li&gt; &#xA; &lt;li&gt;A &lt;strong&gt;lightweight semantic layer&lt;/strong&gt; for quickly defining custom dimensions and metrics&lt;/li&gt; &#xA; &lt;li&gt;Out of the box support for &lt;strong&gt;nearly any SQL&lt;/strong&gt; database or data engine&lt;/li&gt; &#xA; &lt;li&gt;A wide array of &lt;strong&gt;beautiful visualizations&lt;/strong&gt; to showcase your data, ranging from simple bar charts to geospatial visualizations&lt;/li&gt; &#xA; &lt;li&gt;Lightweight, configurable &lt;strong&gt;caching layer&lt;/strong&gt; to help ease database load&lt;/li&gt; &#xA; &lt;li&gt;Highly extensible &lt;strong&gt;security roles and authentication&lt;/strong&gt; options&lt;/li&gt; &#xA; &lt;li&gt;An &lt;strong&gt;API&lt;/strong&gt; for programmatic customization&lt;/li&gt; &#xA; &lt;li&gt;A &lt;strong&gt;cloud-native architecture&lt;/strong&gt; designed from the ground up for scale&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Screenshots &amp;amp; Gifs&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Video Overview&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;!-- File hosted here https://github.com/apache/superset-site/raw/lfs/superset-video-4k.mp4 --&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/user-attachments/assets/b37388f7-a971-409c-96a7-90c4e31322e6&#34;&gt;superset-video-1080p.webm&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;strong&gt;Large Gallery of Visualizations&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;kbd&gt;&lt;img title=&#34;Gallery&#34; src=&#34;https://superset.apache.org/img/screenshots/gallery.jpg&#34;&gt;&lt;/kbd&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Craft Beautiful, Dynamic Dashboards&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;kbd&gt;&lt;img title=&#34;View Dashboards&#34; src=&#34;https://superset.apache.org/img/screenshots/slack_dash.jpg&#34;&gt;&lt;/kbd&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;No-Code Chart Builder&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;kbd&gt;&lt;img title=&#34;Slice &amp;amp; dice your data&#34; src=&#34;https://superset.apache.org/img/screenshots/explore.jpg&#34;&gt;&lt;/kbd&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Powerful SQL Editor&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;kbd&gt;&lt;img title=&#34;SQL Lab&#34; src=&#34;https://superset.apache.org/img/screenshots/sql_lab.jpg&#34;&gt;&lt;/kbd&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Supported Databases&lt;/h2&gt; &#xA;&lt;p&gt;Superset can query data from any SQL-speaking datastore or data engine (Presto, Trino, Athena, &lt;a href=&#34;https://superset.apache.org/docs/configuration/databases&#34;&gt;and more&lt;/a&gt;) that has a Python DB-API driver and a SQLAlchemy dialect.&lt;/p&gt; &#xA;&lt;p&gt;Here are some of the major database solutions that are supported:&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/redshift.png&#34; alt=&#34;redshift&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/google-biquery.png&#34; alt=&#34;google-biquery&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/snowflake.png&#34; alt=&#34;snowflake&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/trino.png&#34; alt=&#34;trino&#34; border=&#34;0&#34; width=&#34;150&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/presto.png&#34; alt=&#34;presto&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/databricks.png&#34; alt=&#34;databricks&#34; border=&#34;0&#34; width=&#34;160&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/druid.png&#34; alt=&#34;druid&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/firebolt.png&#34; alt=&#34;firebolt&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/timescale.png&#34; alt=&#34;timescale&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/rockset.png&#34; alt=&#34;rockset&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/postgresql.png&#34; alt=&#34;postgresql&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/mysql.png&#34; alt=&#34;mysql&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/mssql-server.png&#34; alt=&#34;mssql-server&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/ibm-db2.svg?sanitize=true&#34; alt=&#34;db2&#34; border=&#34;0&#34; width=&#34;220&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/sqlite.png&#34; alt=&#34;sqlite&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/sybase.png&#34; alt=&#34;sybase&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/mariadb.png&#34; alt=&#34;mariadb&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/vertica.png&#34; alt=&#34;vertica&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/oracle.png&#34; alt=&#34;oracle&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/firebird.png&#34; alt=&#34;firebird&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/greenplum.png&#34; alt=&#34;greenplum&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/clickhouse.png&#34; alt=&#34;clickhouse&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/exasol.png&#34; alt=&#34;exasol&#34; border=&#34;0&#34; width=&#34;160&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/monet-db.png&#34; alt=&#34;monet-db&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/apache-kylin.png&#34; alt=&#34;apache-kylin&#34; border=&#34;0&#34; width=&#34;80&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/hologres.png&#34; alt=&#34;hologres&#34; border=&#34;0&#34; width=&#34;80&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/netezza.png&#34; alt=&#34;netezza&#34; border=&#34;0&#34; width=&#34;80&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/pinot.png&#34; alt=&#34;pinot&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/teradata.png&#34; alt=&#34;teradata&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/yugabyte.png&#34; alt=&#34;yugabyte&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/databend.png&#34; alt=&#34;databend&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/starrocks.png&#34; alt=&#34;starrocks&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/doris.png&#34; alt=&#34;doris&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/oceanbase.svg?sanitize=true&#34; alt=&#34;oceanbase&#34; border=&#34;0&#34; width=&#34;220&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/sap-hana.png&#34; alt=&#34;oceanbase&#34; border=&#34;0&#34; width=&#34;220&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/denodo.png&#34; alt=&#34;denodo&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/ydb.svg?sanitize=true&#34; alt=&#34;ydb&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;img src=&#34;https://superset.apache.org/img/databases/tdengine.png&#34; alt=&#34;TDengine&#34; border=&#34;0&#34; width=&#34;200&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;A more comprehensive list of supported databases&lt;/strong&gt; along with the configuration instructions can be found &lt;a href=&#34;https://superset.apache.org/docs/configuration/databases&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Want to add support for your datastore or data engine? Read more &lt;a href=&#34;https://superset.apache.org/docs/frequently-asked-questions#does-superset-work-with-insert-database-engine-here&#34;&gt;here&lt;/a&gt; about the technical requirements.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and Configuration&lt;/h2&gt; &#xA;&lt;p&gt;Try out Superset&#39;s &lt;a href=&#34;https://superset.apache.org/docs/quickstart/&#34;&gt;quickstart&lt;/a&gt; guide or learn about &lt;a href=&#34;https://superset.apache.org/docs/installation/architecture/&#34;&gt;the options for production deployments&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get Involved&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Ask and answer questions on &lt;a href=&#34;https://stackoverflow.com/questions/tagged/apache-superset&#34;&gt;StackOverflow&lt;/a&gt; using the &lt;strong&gt;apache-superset&lt;/strong&gt; tag&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://bit.ly/join-superset-slack&#34;&gt;Join our community&#39;s Slack&lt;/a&gt; and please read our &lt;a href=&#34;https://github.com/apache/superset/raw/master/CODE_OF_CONDUCT.md#slack-community-guidelines&#34;&gt;Slack Community Guidelines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lists.apache.org/list.html?dev@superset.apache.org&#34;&gt;Join our dev@superset.apache.org Mailing list&lt;/a&gt;. To join, simply send an email to &lt;a href=&#34;mailto:dev-subscribe@superset.apache.org&#34;&gt;dev-subscribe@superset.apache.org&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;If you want to help troubleshoot GitHub Issues involving the numerous database drivers that Superset supports, please consider adding your name and the databases you have access to on the &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1U1qxiLvOX0kBTUGME1AHHi6Ywel6ECF8xk_Qy-V9R8c/edit#gid=0&#34;&gt;Superset Database Familiarity Rolodex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Join Superset&#39;s Town Hall and &lt;a href=&#34;https://preset.io/blog/the-superset-operational-model-wants-you/&#34;&gt;Operational Model&lt;/a&gt; recurring meetings. Meeting info is available on the &lt;a href=&#34;https://superset.apache.org/community&#34;&gt;Superset Community Calendar&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributor Guide&lt;/h2&gt; &#xA;&lt;p&gt;Interested in contributing? Check out our &lt;a href=&#34;https://github.com/apache/superset/raw/master/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; to find resources around contributing along with a detailed guide on how to set up a development environment.&lt;/p&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apache/superset/raw/master/RESOURCES/INTHEWILD.md&#34;&gt;Superset &#34;In the Wild&#34;&lt;/a&gt; - open a PR to add your org to the list!&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apache/superset/raw/master/RESOURCES/FEATURE_FLAGS.md&#34;&gt;Feature Flags&lt;/a&gt; - the status of Superset&#39;s Feature Flags.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apache/superset/raw/master/RESOURCES/STANDARD_ROLES.md&#34;&gt;Standard Roles&lt;/a&gt; - How RBAC permissions map to roles.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/apache/superset/wiki&#34;&gt;Superset Wiki&lt;/a&gt; - Tons of additional community resources: best practices, community content and other information.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/orgs/apache/projects/170&#34;&gt;Superset SIPs&lt;/a&gt; - The status of Superset&#39;s SIPs (Superset Improvement Proposals) for both consensus and implementation status.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Understanding the Superset Points of View&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://preset.io/blog/dataset-centric-visualization/&#34;&gt;The Case for Dataset-Centric Visualization&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://preset.io/blog/understanding-superset-semantic-layer/&#34;&gt;Understanding the Superset Semantic Layer&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Getting Started with Superset&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://superset.apache.org/docs/installation/docker-compose#installing-superset-locally-using-docker-compose&#34;&gt;Superset in 2 Minutes using Docker Compose&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://superset.apache.org/docs/configuration/databases#installing-database-drivers&#34;&gt;Installing Database Drivers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/blog/building-database-connector/&#34;&gt;Building New Database Connectors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://superset.apache.org/docs/using-superset/creating-your-first-dashboard/&#34;&gt;Create Your First Dashboard&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/blog/tutorial-contributing-code-to-apache-superset/&#34;&gt;Comprehensive Tutorial for Contributing Code to Apache Superset &lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://preset.io/resources/&#34;&gt;Resources to master Superset by Preset&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Deploying Superset&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://hub.docker.com/r/apache/superset&#34;&gt;Official Docker image&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/apache/superset/tree/master/helm/superset&#34;&gt;Helm Chart&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Recordings of Past &lt;a href=&#34;https://preset.io/events&#34;&gt;Superset Community Events&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/events/mixed-time-series-visualization-in-superset-workshop/&#34;&gt;Mixed Time Series Charts&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/events/how-the-bing-team-heavily-customized-superset-for-their-internal-data/&#34;&gt;How the Bing Team Customized Superset for the Internal Self-Serve Data &amp;amp; Analytics Platform&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/events/2021-04-13-visualizing-mongodb-and-pinot-data-using-trino/&#34;&gt;Live Demo: Visualizing MongoDB and Pinot Data using Trino&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/events/introduction-to-the-superset-api/&#34;&gt;Introduction to the Superset API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/events/2021-02-16-building-a-database-connector-for-superset/&#34;&gt;Building a Database Connector for Superset&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Visualizations&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://superset.apache.org/docs/contributing/creating-viz-plugins/&#34;&gt;Creating Viz Plugins&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://medium.com/nmc-techblog/apache-superset-manage-custom-viz-plugins-in-production-9fde1a708e55&#34;&gt;Managing and Deploying Custom Viz Plugins&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://preset.io/blog/2021-4-1-why-echarts/&#34;&gt;Why Apache Superset is Betting on Apache ECharts&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://superset.apache.org/docs/rest-api&#34;&gt;Superset API&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Repo Activity&lt;/h2&gt; &#xA;&lt;a href=&#34;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats?repo_id=39464018&#34; target=&#34;_blank&#34; align=&#34;center&#34;&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&amp;amp;image_size=auto&amp;amp;color_scheme=dark&#34; width=&#34;655&#34; height=&#34;auto&#34;&gt; &#xA;  &lt;img alt=&#34;Performance Stats of apache/superset - Last 28 days&#34; src=&#34;https://next.ossinsight.io/widgets/official/compose-last-28-days-stats/thumbnail.png?repo_id=39464018&amp;amp;image_size=auto&amp;amp;color_scheme=light&#34; width=&#34;655&#34; height=&#34;auto&#34;&gt; &#xA; &lt;/picture&gt; &lt;/a&gt; &#xA;&lt;!-- Made with [OSS Insight](https://ossinsight.io/) --&gt; &#xA;&lt;!-- telemetry/analytics pixel: --&gt; &#xA;&lt;img referrerpolicy=&#34;no-referrer-when-downgrade&#34; src=&#34;https://static.scarf.sh/a.png?x-pxid=bc1c90cd-bc04-4e11-8c7b-289fb2839492&#34;&gt;</summary>
  </entry>
  <entry>
    <title>huggingface/agents-course</title>
    <updated>2025-05-11T01:40:11Z</updated>
    <id>tag:github.com,2025-05-11:/huggingface/agents-course</id>
    <link href="https://github.com/huggingface/agents-course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains the Hugging Face Agents Course.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://hf.co/learn/agents-course&#34; target=&#34;_blank&#34;&gt;The Hugging Face Agents Course&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;If you like the course, &lt;strong&gt;don&#39;t hesitate to ⭐ star this repository&lt;/strong&gt;. This helps us to &lt;strong&gt;make the course more visible 🤗&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;img src=&#34;https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/please_star.gif&#34; alt=&#34;Star the repo&#34;&gt; &#xA;&lt;h2&gt;Content&lt;/h2&gt; &#xA;&lt;p&gt;The course is divided into 4 units. These will take you from &lt;strong&gt;the basics of agents to a final assignment with a benchmark&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Sign up here (it&#39;s free) 👉 &lt;a href=&#34;https://bit.ly/hf-learn-agents&#34; target=&#34;_blank&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://bit.ly/hf-learn-agents&#34;&gt;https://bit.ly/hf-learn-agents&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can access the course here 👉 &lt;a href=&#34;https://hf.co/learn/agents-course&#34; target=&#34;_blank&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://hf.co/learn/agents-course&#34;&gt;https://hf.co/learn/agents-course&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Unit&lt;/th&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/en/unit0/introduction&#34;&gt;Welcome to the Course&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Welcome, guidelines, necessary tools, and course overview.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/en/unit1/introduction&#34;&gt;Introduction to Agents&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Definition of agents, LLMs, model family tree, and special tokens.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1 Bonus&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/bonus-unit1/introduction&#34;&gt;Fine-tuning an LLM for Function-calling&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to fine-tune an LLM for Function-Calling&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/introduction&#34;&gt;Frameworks for AI Agents&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Overview of &lt;code&gt;smolagents&lt;/code&gt;, &lt;code&gt;LangGraph&lt;/code&gt; and &lt;code&gt;LlamaIndex&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/smolagents/introduction&#34;&gt;The Smolagents Framework&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to build effective agents using the &lt;code&gt;smolagents&lt;/code&gt; library, a lightweight framework for creating capable AI agents.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/llama-index/introduction&#34;&gt;The LlamaIndex Framework&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to build LLM-powered agents over your data using indexes and workflows using the &lt;code&gt;LlamaIndex&lt;/code&gt; toolkit.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit2/langgraph/introduction&#34;&gt;The LangGraph Framework&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to build production-ready applications using the &lt;code&gt;LangGraph&lt;/code&gt; framework giving you control tools over the flow of your agent.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2 Bonus&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/bonus-unit2/introduction&#34;&gt;Observability and Evaluation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to trace and evaluate your agents.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit3/agentic-rag/introduction&#34;&gt;Use Case for Agentic RAG&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn how to use Agentic RAG to help agents respond to different use cases using various frameworks.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/learn/agents-course/unit4/introduction&#34;&gt;Final Project - Create, Test and Certify Your Agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Automated evaluation of agents and leaderboard with student results.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Prerequisites&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Basic knowledge of Python&lt;/li&gt; &#xA; &lt;li&gt;Basic knowledge of LLMs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution Guidelines&lt;/h2&gt; &#xA;&lt;p&gt;If you want to contribute to this course, you&#39;re welcome to do so. Feel free to open an issue or join the discussion in the &lt;a href=&#34;https://discord.gg/UrrTSsSyjb&#34;&gt;Discord&lt;/a&gt;. For specific contributions, here are some guidelines:&lt;/p&gt; &#xA;&lt;h3&gt;Small typo and grammar fixes&lt;/h3&gt; &#xA;&lt;p&gt;If you find a small typo or grammar mistake, please fix it yourself and submit a pull request. This is very helpful for students.&lt;/p&gt; &#xA;&lt;h3&gt;New unit&lt;/h3&gt; &#xA;&lt;p&gt;If you want to add a new unit, &lt;strong&gt;please create an issue in the repository, describe the unit, and why it should be added&lt;/strong&gt;. We will discuss it and if it&#39;s a good addition, we can collaborate on it.&lt;/p&gt; &#xA;&lt;h2&gt;Citing the project&lt;/h2&gt; &#xA;&lt;p&gt;To cite this repository in publications:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{agents-course,&#xA;  author = {Burtenshaw, Ben and Thomas, Joffrey and Simonini, Thomas and Paniego, Sergio},&#xA;  title = {The Hugging Face Agents Course},&#xA;  year = {2025},&#xA;  howpublished = {\url{https://github.com/huggingface/agents-course}},&#xA;  note = {GitHub repository},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/PhiCookBook</title>
    <updated>2025-05-11T01:40:11Z</updated>
    <id>tag:github.com,2025-05-11:/microsoft/PhiCookBook</id>
    <link href="https://github.com/microsoft/PhiCookBook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is a Phi Family of SLMs book for getting started with Phi Models. Phi a family of open sourced AI models developed by Microsoft. Phi models are the most capable and cost-effective small language models (SLMs) available, outperforming models of the same size and next size up across a variety of language, reasoning, coding, and math benchmarks&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Phi Cookbook: Hands-On Examples with Microsoft&#39;s Phi Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://codespaces.new/microsoft/phicookbook&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open and use the samples in GitHub Codespaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?style=for-the-badge&amp;amp;label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode&#34; alt=&#34;Open in Dev Containers&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/microsoft/phicookbook.svg?sanitize=true&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/microsoft/phicookbook.svg?sanitize=true&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg?sanitize=true&#34; alt=&#34;GitHub pull-requests&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&#34; alt=&#34;PRs Welcome&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&amp;amp;label=Watch&#34; alt=&#34;GitHub watchers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&amp;amp;label=Fork&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/microsoft/phicookbook?style=social&amp;amp;label=Star&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://dcbadge.vercel.app/api/server/ByRwuEEgH4&#34; alt=&#34;Azure AI Community Discord&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Phi is a series of open source AI models developed by Microsoft.&lt;/p&gt; &#xA;&lt;p&gt;Phi is currently the most powerful and cost-effective small language model (SLM), with very good benchmarks in multi-language, reasoning, text/chat generation,coding, images, audio and other scenarios.&lt;/p&gt; &#xA;&lt;p&gt;You can deploy Phi to the cloud or to edge devices, and you can easily build generative AI applications with limited computing power.&lt;/p&gt; &#xA;&lt;p&gt;Follow these steps to get started using these resource :&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;: Click &lt;a href=&#34;https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&amp;amp;label=Fork&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;: &lt;code&gt;git clone https://github.com/microsoft/PhiCookBook.git&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;&lt;strong&gt;Join The Microsoft AI Discord Community and meet experts and fellow developers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/imgs/cover.png&#34; alt=&#34;cover&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🌐 Multi-Language Support&lt;/h2&gt; &#xA;&lt;h3&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/fr/README.md&#34;&gt;French&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/es/README.md&#34;&gt;Spanish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/de/README.md&#34;&gt;German&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ru/README.md&#34;&gt;Russian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ar/README.md&#34;&gt;Arabic&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/fa/README.md&#34;&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ur/README.md&#34;&gt;Urdu&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/zh/README.md&#34;&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/mo/README.md&#34;&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/hk/README.md&#34;&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/tw/README.md&#34;&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ja/README.md&#34;&gt;Japanese&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ko/README.md&#34;&gt;Korean&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/hi/README.md&#34;&gt;Hindi&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Supported via CLI&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/bn/README.md&#34;&gt;Bengali&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/mr/README.md&#34;&gt;Marathi&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ne/README.md&#34;&gt;Nepali&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/pa/README.md&#34;&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/pt/README.md&#34;&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/br/README.md&#34;&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/it/README.md&#34;&gt;Italian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/pl/README.md&#34;&gt;Polish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/tr/README.md&#34;&gt;Turkish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/el/README.md&#34;&gt;Greek&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/th/README.md&#34;&gt;Thai&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/sv/README.md&#34;&gt;Swedish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/da/README.md&#34;&gt;Danish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/no/README.md&#34;&gt;Norwegian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/fi/README.md&#34;&gt;Finnish&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/nl/README.md&#34;&gt;Dutch&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/he/README.md&#34;&gt;Hebrew&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/vi/README.md&#34;&gt;Vietnamese&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/id/README.md&#34;&gt;Indonesian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ms/README.md&#34;&gt;Malay&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/tl/README.md&#34;&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/sw/README.md&#34;&gt;Swahili&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/hu/README.md&#34;&gt;Hungarian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/cs/README.md&#34;&gt;Czech&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/sk/README.md&#34;&gt;Slovak&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/ro/README.md&#34;&gt;Romanian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/bg/README.md&#34;&gt;Bulgarian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/sr/README.md&#34;&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/hr/README.md&#34;&gt;Croatian&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/translations/sl/README.md&#34;&gt;Slovenian&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Introduction&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.PhiFamily.md&#34;&gt;Welcome to the Phi Family&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.EnvironmentSetup.md&#34;&gt;Setting up your environment&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.Understandingtech.md&#34;&gt;Understanding Key Technologies&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.AISafety.md&#34;&gt;AI Safety for Phi Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.Hardwaresupport.md&#34;&gt;Phi Hardware Support&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.Edgeandcloud.md&#34;&gt;Phi Models &amp;amp; Availability across platforms&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/01/01.Guidance.md&#34;&gt;Using Guidance-ai and Phi&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/marketplace/models&#34;&gt;GitHub Marketplace Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.azure.com&#34;&gt;Azure AI Model Catalog&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Inference Phi in different environment&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/01.HF.md&#34;&gt;Hugging face&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/02.GitHubModel.md&#34;&gt;GitHub Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/03.AzureAIFoundry.md&#34;&gt;Azure AI Foundry Model Catalog&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/04.Ollama.md&#34;&gt;Ollama&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/05.AITK.md&#34;&gt;AI Toolkit VSCode (AITK)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/02/06.NVIDIA.md&#34;&gt;NVIDIA NIM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Inference Phi Family&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/iOS_Inference.md&#34;&gt;Inference Phi in iOS&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Android_Inference.md&#34;&gt;Inference Phi in Android&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Jetson_Inference.md&#34;&gt;Inference Phi in Jetson&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/AIPC_Inference.md&#34;&gt;Inference Phi in AI PC&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/MLX_Inference.md&#34;&gt;Inference Phi with Apple MLX Framework&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Local_Server_Inference.md&#34;&gt;Inference Phi in Local Server&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Remote_Interence.md&#34;&gt;Inference Phi in Remote Server using AI Toolkit&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Rust_Inference.md&#34;&gt;Inference Phi with Rust&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Vision_Inference.md&#34;&gt;Inference Phi--Vision in Local&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/03/Kaito_Inference.md&#34;&gt;Inference Phi with Kaito AKS, Azure Containers(official support)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/04/QuantifyingPhi.md&#34;&gt;Quantifying Phi Family&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md&#34;&gt;Quantizing Phi-3.5 / 4 using llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md&#34;&gt;Quantizing Phi-3.5 / 4 using Generative AI extensions for onnxruntime&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md&#34;&gt;Quantizing Phi-3.5 / 4 using Intel OpenVINO&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md&#34;&gt;Quantizing Phi-3.5 / 4 using Apple MLX Framework&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Evaluation Phi&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/05/ResponsibleAI.md&#34;&gt;Response AI&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/05/AIFoundry.md&#34;&gt;Azure AI Foundry for Evaluation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/01.Introduction/05/Promptflow.md&#34;&gt;Using Promptflow for Evaluation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;RAG with Azure AI Search&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/PhiCookBook/raw/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb&#34;&gt;How to use Phi-4-mini and Phi-4-multimodal(RAG) with Azure AI Search&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Phi application development samples&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Text &amp;amp; Chat Applications&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md&#34;&gt;Chat With Phi-4-mini ONNX Model&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime/&#34;&gt;Chat with Phi-4 local ONNX Model .NET&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK/&#34;&gt;Chat .NET Console App with Phi-4 ONNX using Sementic Kernel&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;Phi-3 / 3.5 Samples &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat&#34;&gt;Local Chatbot in the browser using Phi3, ONNX Runtime Web and WebGPU&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md&#34;&gt;OpenVino Chat&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md&#34;&gt;Multi Model - Interactive Phi-3-mini and OpenAI Whisper&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md&#34;&gt;MLFlow - Building a wrapper and using Phi-3 with MLFlow&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/Olive/tree/main/examples/phi3&#34;&gt;Model Optimization - How to optimize Phi-3-min model for ONNX Runtime Web with Olive&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/&#34;&gt;WinUI3 App with Phi-3 mini-4k-instruct-onnx&lt;/a&gt; -&lt;a href=&#34;https://github.com/microsoft/ai-powered-notes-winui3-sample&#34;&gt;WinUI3 Multi Model AI Powered Notes App Sample&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md&#34;&gt;Fine-tune and Integrate custom Phi-3 models with Prompt flow&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md&#34;&gt;Fine-tune and Integrate custom Phi-3 models with Prompt flow in Azure AI Foundry&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md&#34;&gt;Evaluate the Fine-tuned Phi-3 / Phi-3.5 Model in Azure AI Foundry Focusing on Microsoft&#39;s Responsible AI Principles&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb&#34;&gt;Phi-3.5-mini-instruct language prediction sample (Chinese/English)&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md&#34;&gt;Phi-3.5-Instruct WebGPU RAG Chatbot&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md&#34;&gt;Using Windows GPU to create Prompt flow solution with Phi-3.5-Instruct ONNX&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md&#34;&gt;Using Microsoft Phi-3.5 tflite to create Android app&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi301/&#34;&gt;Q&amp;amp;A .NET Example using local ONNX Phi-3 model using the Microsoft.ML.OnnxRuntime&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi302/&#34;&gt;Console chat .NET app with Semantic Kernel and Phi-3&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Azure AI Inference SDK Code Based Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/02.Code/Phi4/GenProjectCode/README.md&#34;&gt;Generate project code using Phi-4-multimodal&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;Phi-3 / 3.5 Samples &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/02.Code/Phi3/VSCodeExt/README.md&#34;&gt;Build your own Visual Studio Code GitHub Copilot Chat with Microsoft Phi-3 Family&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md&#34;&gt;Create your own Visual Studio Code Chat Copilot Agent with Phi-3.5 by GitHub Models&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Advanced Reasoning Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md&#34;&gt;Phi-4-mini-reasoning or Phi-4-reasoning Samples&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/olive_ft_phi_4_reasoning_with_medicaldata.ipynb&#34;&gt;Fine-tuning Phi-4-mini-reasoning with Microsoft Olive&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/mlx_ft_phi_4_reasoning_with_medicaldata.ipynb&#34;&gt;Fine-tuning Phi-4-mini-reasoning with Apple MLX&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/02.Code/Phi4r/github_models_inference.ipynb&#34;&gt;Phi-4-mini-reasoning with GitHub Models&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/02.Code/Phi4r/azure_models_inference.ipynb&#34;&gt;Phi-4-mini-reasoning with Azure AI Foundry Models&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Demos&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;Phi-4-mini demos hosted on Hugging Face Spaces&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;Phi-4-multimodal demos hosted on Hugginge Face Spaces&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Vision Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi4/CreateFrontend/README.md&#34;&gt;Use Phi-4-multimodal to read images and generate code&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;Phi-3 / 3.5 Samples &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓]&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb&#34;&gt;Phi-3-vision-Image text to text&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html&#34;&gt;Phi-3-vision-ONNX&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓]&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb&#34;&gt;Phi-3-vision CLIP Embedding&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/jennifermarsman/PhiRecycling/&#34;&gt;DEMO: Phi-3 Recycling&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html&#34;&gt;Phi-3-vision - Visual language assistant - with Phi3-Vision and OpenVINO&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md&#34;&gt;Phi-3 Vision Nvidia NIM&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md&#34;&gt;Phi-3 Vision OpenVino&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓]&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb&#34;&gt;Phi-3.5 Vision multi-frame or multi-image sample&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi303/&#34;&gt;Phi-3 Vision Local ONNX Model using the Microsoft.ML.OnnxRuntime .NET&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi304/&#34;&gt;Menu based Phi-3 Vision Local ONNX Model using the Microsoft.ML.OnnxRuntime .NET&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Audio Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/05.Audio/Phi4/Transciption/README.md&#34;&gt;Extracting audio transcripts using Phi-4-multimodal&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/05.Audio/Phi4/Siri/demo.ipynb&#34;&gt;Phi-4-multimodal Audio Sample&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/05.Audio/Phi4/Translate/demo.ipynb&#34;&gt;Phi-4-multimodal Speech Translation Sample&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio/&#34;&gt;.NET console application using Phi-4-multimodal Audio to analyze an audio file and generate transcript&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;MOE Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-3 / 3.5 Samples &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb&#34;&gt;Phi-3.5 Mixture of Experts Models (MoEs) Social Media Sample&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb&#34;&gt;Building a Retrieval-Augmented Generation (RAG) Pipeline with NVIDIA NIM Phi-3 MOE, Azure AI Search, and LlamaIndex&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Function Calling Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md&#34;&gt;Using Function Calling With Phi-4-mini&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/07.FunctionCalling/Phi4/Multiagents/Phi_4_mini_multiagent.ipynb&#34;&gt;Using Function Calling to create multi-agents With Phi-4-mini&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/07.FunctionCalling/Phi4/Ollama/ollama_functioncalling.ipynb&#34;&gt;Using Function Calling with Ollama&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Multimodal Mixing Samples&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Phi-4 Samples 🆕 &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;[📓] &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb&#34;&gt;Using Phi-4-multimodal as a Technology journalist&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images/&#34;&gt;.NET console application using Phi-4-multimodal to analyze images&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fine-tuning Phi Samples&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Scenarios.md&#34;&gt;Fine-tuning Scenarios&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_vs_RAG.md&#34;&gt;Fine-tuning vs RAG&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/LetPhi3gotoIndustriy.md&#34;&gt;Fine-tuning Let Phi-3 become an industry expert&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/Finetuning_VSCodeaitoolkit.md&#34;&gt;Fine-tuning Phi-3 with AI Toolkit for VS Code&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/Introduce_AzureML.md&#34;&gt;Fine-tuning Phi-3 with Azure Machine Learning Service&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Lora.md&#34;&gt;Fine-tuning Phi-3 with Lora&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Qlora.md&#34;&gt;Fine-tuning Phi-3 with QLora&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_AIFoundry.md&#34;&gt;Fine-tuning Phi-3 with Azure AI Foundry&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_MLSDK.md&#34;&gt;Fine-tuning Phi-3 with Azure ML CLI/SDK&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_MicrosoftOlive.md&#34;&gt;Fine-tuning with Microsoft Olive&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/olive-lab/readme.md&#34;&gt;Fine-tuning with Microsoft Olive Hands-On Lab&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Phi-3-visionWandB.md&#34;&gt;Fine-tuning Phi-3-vision with Weights and Bias&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_MLX.md&#34;&gt;Fine-tuning Phi-3 with Apple MLX Framework&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Vision.md&#34;&gt;Fine-tuning Phi-3-vision (official support)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/03.FineTuning/FineTuning_Kaito.md&#34;&gt;Fine-Tuning Phi-3 with Kaito AKS , Azure Containers(official Support)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/2U1/Phi3-Vision-Finetune&#34;&gt;Fine-Tuning Phi-3 and 3.5 Vision&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Hands on Lab&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/aitour-exploring-cutting-edge-models&#34;&gt;Exploring cutting-edge models: LLMs, SLMs, local development and more&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/azure/Ignite_FineTuning_workshop&#34;&gt;Unlocking NLP Potential: Fine-Tuning with Microsoft Olive&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Academic Research Papers and Publications&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.05463&#34;&gt;Textbooks Are All You Need II: phi-1.5 technical report&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2404.14219&#34;&gt;Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.08905&#34;&gt;Phi-4 Technical Report&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2503.01743&#34;&gt;Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2501.02342&#34;&gt;Optimizing Small Language Models for In-Vehicle Function-Calling&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2501.01588&#34;&gt;(WhyPHI) Fine-Tuning PHI-3 for Multiple-Choice Question Answering: Methodology, Results, and Challenges&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf&#34;&gt;Phi-4-reasoning Technical Report&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-4-mini-reasoning/blob/main/Phi-4-Mini-Reasoning.pdf&#34;&gt;Phi-4-mini-reasoning Technical Report&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Using Phi Models&lt;/h2&gt; &#xA;&lt;h3&gt;Phi on Azure AI Foundry&lt;/h3&gt; &#xA;&lt;p&gt;You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the models and customizing Phi for your scenarios using the &lt;a href=&#34;https://aka.ms/phi3-azure-ai&#34;&gt;Azure AI Foundry Azure AI Model Catalog&lt;/a&gt; you can learn more at Getting Started with &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.QuickStart/AzureAIFoundry_QuickStart.md&#34;&gt;Azure AI Foundry&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Playground&lt;/strong&gt; Each model has a dedicated playground to test the model &lt;a href=&#34;https://aka.ms/try-phi3&#34;&gt;Azure AI Playground&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Phi on GitHub Models&lt;/h3&gt; &#xA;&lt;p&gt;You can learn how to use Microsoft Phi and how to build E2E solutions in your different hardware devices. To experience Phi for yourself, start by playing with the model and customizing Phi for your scenarios using the &lt;a href=&#34;https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo&#34;&gt;GitHub Model Catalog&lt;/a&gt; you can learn more at Getting Started with &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.QuickStart/GitHubModel_QuickStart.md&#34;&gt;GitHub Model Catalog&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Playground&lt;/strong&gt; Each model has a dedicated &lt;a href=&#34;https://raw.githubusercontent.com/microsoft/PhiCookBook/main/md/02.QuickStart/GitHubModel_QuickStart.md&#34;&gt;playground to test the model&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Phi on Hugging Face&lt;/h3&gt; &#xA;&lt;p&gt;You can also find the model on the &lt;a href=&#34;https://huggingface.co/microsoft&#34;&gt;Hugging Face&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Playground&lt;/strong&gt; &lt;a href=&#34;https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct&#34;&gt;Hugging Chat playground&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Responsible AI&lt;/h2&gt; &#xA;&lt;p&gt;Microsoft is committed to helping our customers use our AI products responsibly, sharing our learnings, and building trust-based partnerships through tools like Transparency Notes and Impact Assessments. Many of these resources can be found at &lt;a href=&#34;https://aka.ms/RAI&#34;&gt;https://aka.ms/RAI&lt;/a&gt;. Microsoft’s approach to responsible AI is grounded in our AI principles of fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.&lt;/p&gt; &#xA;&lt;p&gt;Large-scale natural language, image, and speech models - like the ones used in this sample - can potentially behave in ways that are unfair, unreliable, or offensive, in turn causing harms. Please consult the &lt;a href=&#34;https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text&#34;&gt;Azure OpenAI service Transparency note&lt;/a&gt; to be informed about risks and limitations.&lt;/p&gt; &#xA;&lt;p&gt;The recommended approach to mitigating these risks is to include a safety system in your architecture that can detect and prevent harmful behavior. &lt;a href=&#34;https://learn.microsoft.com/azure/ai-services/content-safety/overview&#34;&gt;Azure AI Content Safety&lt;/a&gt; provides an independent layer of protection, able to detect harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes text and image APIs that allow you to detect material that is harmful. Within Azure AI Foundry, the Content Safety service allows you to view, explore and try out sample code for detecting harmful content across different modalities. The following &lt;a href=&#34;https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&amp;amp;pivots=programming-language-rest&#34;&gt;quickstart documentation&lt;/a&gt; guides you through making requests to the service.&lt;/p&gt; &#xA;&lt;p&gt;Another aspect to take into account is the overall application performance. With multi-modal and multi-models applications, we consider performance to mean that the system performs as you and your users expect, including not generating harmful outputs. It&#39;s important to assess the performance of your overall application using &lt;a href=&#34;https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in&#34;&gt;Performance and Quality and Risk and Safety evaluators&lt;/a&gt;. You also have the ability to create and evaluate with &lt;a href=&#34;https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators&#34;&gt;custom evaluators&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can evaluate your AI application in your development environment using the &lt;a href=&#34;https://microsoft.github.io/promptflow/index.html&#34;&gt;Azure AI Evaluation SDK&lt;/a&gt;. Given either a test dataset or a target, your generative AI application generations are quantitatively measured with built-in evaluators or custom evaluators of your choice. To get started with the azure ai evaluation sdk to evaluate your system, you can follow the &lt;a href=&#34;https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk&#34;&gt;quickstart guide&lt;/a&gt;. Once you execute an evaluation run, you can &lt;a href=&#34;https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results&#34;&gt;visualize the results in Azure AI Foundry&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>