<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-06-29T01:41:21Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google-gemini/gemma-cookbook</title>
    <updated>2025-06-29T01:41:21Z</updated>
    <id>tag:github.com,2025-06-29:/google-gemini/gemma-cookbook</id>
    <link href="https://github.com/google-gemini/gemma-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of guides and examples for the Gemma open models from Google.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to the Gemma Cookbook&lt;/h1&gt; &#xA;&lt;p&gt;This is a collection of guides and examples for &lt;a href=&#34;https://ai.google.dev/gemma/&#34;&gt;Google Gemma&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Get started with the Gemma models&lt;/h2&gt; &#xA;&lt;p&gt;Gemma is a family of lightweight, generative artificial intelligence (AI) open models, built from the same research and technology used to create the Gemini models. The Gemma model family includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gemma&lt;br&gt; The core models of the Gemma family. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/core/model_card&#34;&gt;Gemma&lt;/a&gt;&lt;br&gt; For a variety of text generation tasks and can be further tuned for specific use cases&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/core/model_card_2&#34;&gt;Gemma 2&lt;/a&gt;&lt;br&gt; Higher-performing and more efficient, available in 2B, 9B, 27B parameter sizes&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/core/model_card_3&#34;&gt;Gemma 3&lt;/a&gt;&lt;br&gt; Longer context window and handling text and image input, available in 1B, 4B, 12B and 27B parameter sizes&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/gemma-3n/model_card&#34;&gt;Gemma 3n&lt;/a&gt; &lt;br&gt; Designed for efficient execution on low-resource devices. Handling text, image, video, and audio input, available in E2B and E4B parameter sizes&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Gemma variants &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/codegemma&#34;&gt;CodeGemma&lt;/a&gt;&lt;br&gt; Fine-tuned for a variety of coding tasks&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/paligemma/model-card&#34;&gt;PaliGemma&lt;/a&gt;&lt;br&gt; Vision Language Model&lt;br&gt; For a deeper analysis of images and provide useful insights&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/paligemma/model-card-2&#34;&gt;PaliGemma 2&lt;/a&gt;&lt;br&gt; VLM which incorporates the capabilities of the Gemma 2 models&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/recurrentgemma&#34;&gt;RecurrentGemma&lt;/a&gt;&lt;br&gt; Based on &lt;a href=&#34;https://arxiv.org/abs/2402.19427&#34;&gt;Griffin&lt;/a&gt; architecture&lt;br&gt; For a variety of text generation tasks&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/shieldgemma/model_card&#34;&gt;ShieldGemma&lt;/a&gt;&lt;br&gt; Fine-tuned for evaluating the safety of text prompt input and text output responses against a set of defined safety policies&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/shieldgemma/model_card_2&#34;&gt;ShieldGemma 2&lt;/a&gt;&lt;br&gt; Fine-tuned on Gemma 3&#39;s 4B IT checkpoint for image safety classification&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ai.google.dev/gemma/docs/datagemma&#34;&gt;DataGemma&lt;/a&gt;&lt;br&gt; Fine-tuned for using Data Commons to address AI hallucinations&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can find the Gemma models on the Hugging Face Hub, Kaggle, Google Cloud Vertex AI Model Garden, and &lt;a href=&#34;https://ai.nvidia.com&#34;&gt;ai.nvidia.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Notebooks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/Gemma/README.md&#34;&gt;Gemma&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/CodeGemma/README.md&#34;&gt;CodeGemma&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/PaliGemma/README.md&#34;&gt;PaliGemma&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/Workshops/README.md&#34;&gt;Workshops and technical talks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google-gemini/gemma-cookbook/main/Demos/README.md&#34;&gt;Showcase complex end-to-end use cases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/generative-ai/tree/main/open-models&#34;&gt;Gemma on Google Cloud&lt;/a&gt; : GCP open models has additional notebooks for using Gemma&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get help&lt;/h2&gt; &#xA;&lt;p&gt;Ask a Gemma cookbook-related question on the &lt;a href=&#34;https://discuss.ai.google.dev/c/gemma/10&#34;&gt;developer forum&lt;/a&gt;, or open an &lt;a href=&#34;https://github.com/google-gemini/gemma-cookbook/issues&#34;&gt;issue&lt;/a&gt; on GitHub.&lt;/p&gt; &#xA;&lt;h2&gt;Wish list&lt;/h2&gt; &#xA;&lt;p&gt;If you want to see additional cookbooks implemented for specific features/integrations, please open a new issue with &lt;a href=&#34;https://github.com/google-gemini/gemma-cookbook/issues/new?template=feature_request.yml&#34;&gt;“Feature Request” template&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you want to make contributions to the Gemma Cookbook project, you are welcome to pick any idea in the &lt;a href=&#34;https://github.com/google-gemini/gemma-cookbook/labels/wishlist&#34;&gt;“Wish List”&lt;/a&gt; and implement it.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Contributions are always welcome. Please read &lt;a href=&#34;https://github.com/google-gemini/gemma-cookbook/raw/main/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; before implementation.&lt;/p&gt; &#xA;&lt;p&gt;Thank you for developing with Gemma! We’re excited to see what you create.&lt;/p&gt; &#xA;&lt;h2&gt;Translation of this repository&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/doggy8088/gemma-cookbook&#34;&gt;Traditional Chinese&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xiaoxiong1006/gemma-cookbook&#34;&gt;Simplified Chinese&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>HandsOnLLM/Hands-On-Large-Language-Models</title>
    <updated>2025-06-29T01:41:21Z</updated>
    <id>tag:github.com,2025-06-29:/HandsOnLLM/Hands-On-Large-Language-Models</id>
    <link href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code repo for the O&#39;Reilly Book - &#34;Hands-On Large Language Models&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hands-On Large Language Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/jalammar/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Follow%20Jay-blue.svg?logo=linkedin&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/mgrootendorst/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Follow%20Maarten-blue.svg?logo=linkedin&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.deeplearning.ai/short-courses/how-transformer-llms-work/?utm_campaign=handsonllm-launch&amp;amp;utm_medium=partner&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DeepLearning.AI%20Course-NEW!-&amp;amp;labelColor=black&amp;amp;color=red.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAuMDAwMzY1MjgxIC0wLjAwMDE0MDE0MiAzMy4yOSAzMy4xNSI+Cgk8cGF0aCBkPSJNMTYuNjQzIDMzLjE0NWMtMy4yOTIgMC02LjUxLS45NzItOS4yNDYtMi43OTNhMTYuNTg4IDE2LjU4OCAwIDAxLTYuMTMtNy40MzhBMTYuNTA3IDE2LjUwNyAwIDAxLjMyIDEzLjM0YTE2LjU1IDE2LjU1IDAgMDE0LjU1NS04LjQ4NUExNi42NjUgMTYuNjY1IDAgMDExMy4zOTYuMzE4YTE2LjcxIDE2LjcxIDAgMDE5LjYxNi45NDQgMTYuNjI4IDE2LjYyOCAwIDAxNy40NyA2LjEwMyAxNi41MjIgMTYuNTIyIDAgMDEyLjgwNCA5LjIwN2MwIDQuMzk2LTEuNzUzIDguNjEtNC44NzQgMTEuNzE5YTE2LjY4IDE2LjY4IDAgMDEtMTEuNzY5IDQuODU0em0uMTI1LTYuNjI4YzYuOTA2IDAgMTIuNTE3LTUuNjk4IDEyLjUxNy0xMi43MyAwLTcuMDMtNS42MS0xMi43MjUtMTIuNTE3LTEyLjcyNS02LjkwNiAwLTEyLjUxNyA1LjY5OC0xMi41MTcgMTIuNzI1IDAgNy4wMjcgNS42MTEgMTIuNzMgMTIuNTE3IDEyLjczem0tLjEyNS0yLjkxOGMtNi4yODkgMC0xMS4zODYtNC45MjUtMTEuMzg2LTExLjAwMkM1LjI1NyA2LjUyIDEwLjM2IDEuNTkgMTYuNjQzIDEuNTljNi4yODQgMCAxMS4zODYgNC45MyAxMS4zODYgMTEuMDA3cy01LjA5NyAxMS4wMDItMTEuMzg2IDExLjAwMnptLS4yNDItNC41MDhjNC43NyAwIDguNjMzLTMuNjc5IDguNjMzLTguMjE4IDAtNC41MzgtMy44ODUtOC4yMjEtOC42MzMtOC4yMjEtNC43NDcgMC04LjYzMiAzLjY3OS04LjYzMiA4LjIyMSAwIDQuNTQzIDMuODg1IDguMjE4IDguNjMyIDguMjE4eiIgZmlsbD0iI0ZENEE2MSIvPgo8L3N2Zz4=&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Welcome! In this repository you will find the code for all examples throughout the book &lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;Hands-On Large Language Models&lt;/a&gt; written by &lt;a href=&#34;https://www.linkedin.com/in/jalammar/&#34;&gt;Jay Alammar&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/mgrootendorst/&#34;&gt;Maarten Grootendorst&lt;/a&gt; which we playfully dubbed: &lt;br&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;&#34;The Illustrated LLM Book&#34;&lt;/i&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;Through the visually educational nature of this book and with &lt;strong&gt;almost 300 custom made figures&lt;/strong&gt;, learn the practical tools and concepts you need to use Large Language Models today!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png&#34; width=&#34;50%&#34; height=&#34;50%&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;The book is available on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;Amazon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.shroffpublishers.com/books/computer-science/large-language-models/9789355425522/&#34;&gt;Shroff Publishers (India)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/&#34;&gt;O&#39;Reilly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Alammar-ebook/dp/B0DGZ46G88/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;amp;qid=&amp;amp;sr=&#34;&gt;Kindle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.barnesandnoble.com/w/hands-on-large-language-models-jay-alammar/1145185960&#34;&gt;Barnes and Noble&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/210408850-hands-on-large-language-models&#34;&gt;Goodreads&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;p&gt;We advise to run all examples through Google Colab for the easiest setup. Google Colab allows you to use a T4 GPU with 16GB of VRAM for free. All examples were mainly built and tested using Google Colab, so it should be the most stable platform. However, any other cloud provider should work.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Chapter&lt;/th&gt; &#xA;   &lt;th&gt;Notebook&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 1: Introduction to Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter01/Chapter%201%20-%20Introduction%20to%20Language%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 2: Tokens and Embeddings&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter02/Chapter%202%20-%20Tokens%20and%20Token%20Embeddings.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 3: Looking Inside Transformer LLMs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter03/Chapter%203%20-%20Looking%20Inside%20LLMs.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 4: Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter04/Chapter%204%20-%20Text%20Classification.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 5: Text Clustering and Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter05/Chapter%205%20-%20Text%20Clustering%20and%20Topic%20Modeling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 6: Prompt Engineering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter06/Chapter%206%20-%20Prompt%20Engineering.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 7: Advanced Text Generation Techniques and Tools&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter07/Chapter%207%20-%20Advanced%20Text%20Generation%20Techniques%20and%20Tools.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 8: Semantic Search and Retrieval-Augmented Generation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 9: Multimodal Large Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter09/Chapter%209%20-%20Multimodal%20Large%20Language%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 10: Creating Text Embedding Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter10/Chapter%2010%20-%20Creating%20Text%20Embedding%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 11: Fine-tuning Representation Models for Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter11/Chapter%2011%20-%20Fine-Tuning%20BERT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 12: Fine-tuning Generation Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter12/Chapter%2012%20-%20Fine-tuning%20Generation%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] You can check the &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/.setup/&#34;&gt;setup&lt;/a&gt; folder for a quick-start guide to install all packages locally and you can check the &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/.setup/conda/&#34;&gt;conda&lt;/a&gt; folder for a complete guide on how to setup your environment, including conda and PyTorch installation. Note that the depending on your OS, Python version, and dependencies your results might be slightly differ. However, they should this be similar to the examples in the book.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Reviews&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;Jay and Maarten have continued their tradition of providing beautifully illustrated and insightful descriptions of complex topics in their new book. Bolstered with working code, timelines, and references to key papers, their book is a valuable resource for anyone looking to understand the main techniques behind how Large Language Models are built.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Andrew Ng&lt;/strong&gt; - founder of &lt;a href=&#34;https://www.deeplearning.ai/&#34;&gt;DeepLearning.AI&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;This is an exceptional guide to the world of language models and their practical applications in industry. Its highly-visual coverage of generative, representational, and retrieval applications of language models empowers readers to quickly understand, use, and refine LLMs. Highly recommended!&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Nils Reimers&lt;/strong&gt; - Director of Machine Learning at Cohere | creator of &lt;a href=&#34;https://github.com/UKPLab/sentence-transformers&#34;&gt;sentence-transformers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;I can’t think of another book that is more important to read right now. On every single page, I learned something that is critical to success in this era of language models.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Josh Starmer&lt;/strong&gt; - &lt;a href=&#34;https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw&#34;&gt;StatQuest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;If you’re looking to get up to speed in everything regarding LLMs, look no further! In this wonderful book, Jay and Maarten will take you from zero to expert in the history and latest advances in large language models. With very intuitive explanations, great real-life examples, clear illustrations, and comprehensive code labs, this book lifts the curtain on the complexities of transformer models, tokenizers, semantic search, RAG, and many other cutting-edge technologies. A must read for anyone interested in the latest AI technology!&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Luis Serrano, PhD&lt;/strong&gt; - Founder and CEO of &lt;a href=&#34;https://www.youtube.com/@SerranoAcademy&#34;&gt;Serrano Academy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;Hands-On Large Language Models brings clarity and practical examples to cut through the hype of AI. It provides a wealth of great diagrams and visual aids to supplement the clear explanations. The worked examples and code make concrete what other books leave abstract. The book starts with simple introductory beginnings, and steadily builds in scope. By the final chapters, you will be fine-tuning and building your own large language models with confidence.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Leland McInnes&lt;/strong&gt; - Researcher at the Tutte Institute for Mathematics and Computing | creator of &lt;a href=&#34;https://github.com/lmcinnes/umap&#34;&gt;UMAP&lt;/a&gt; and &lt;a href=&#34;https://github.com/scikit-learn-contrib/hdbscan&#34;&gt;HDBSCAN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/bonus/&#34;&gt;Bonus content!&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;We attempted to put as much information into the book without it being overwhelming. However, even with a 400-page book there is still much to discover!&lt;/p&gt; &#xA;&lt;p&gt;We continue to create more guides that compliment the book and go more in-depth into new and &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/(bonus/)&#34;&gt;exciting topics&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state&#34;&gt;A Visual Guide to Mamba&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization&#34;&gt;A Visual Guide to Quantization&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://jalammar.github.io/illustrated-stable-diffusion/&#34;&gt;The Illustrated Stable Diffusion&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/mamba.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/quant.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/diffusion.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts&#34;&gt;A Visual Guide to Mixture of Experts&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms&#34;&gt;A Visual Guide to Reasoning LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&#34;&gt;The Illustrated DeepSeek-R1&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/moe.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/reasoning.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/deepseek.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please consider citing the book if you consider it useful for your research:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@book{hands-on-llms-book,&#xA;  author       = {Jay Alammar and Maarten Grootendorst},&#xA;  title        = {Hands-On Large Language Models},&#xA;  publisher    = {O&#39;Reilly},&#xA;  year         = {2024},&#xA;  isbn         = {978-1098150969},&#xA;  url          = {https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/},&#xA;  github       = {https://github.com/HandsOnLLM/Hands-On-Large-Language-Models}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ed-donner/agents</title>
    <updated>2025-06-29T01:41:21Z</updated>
    <id>tag:github.com,2025-06-29:/ed-donner/agents</id>
    <link href="https://github.com/ed-donner/agents" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repo for the Complete Agentic AI Engineering Course&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Master AI Agentic Engineering - build autonomous AI Agents&lt;/h2&gt; &#xA;&lt;h3&gt;6 week journey to code and deploy AI Agents with OpenAI Agents SDK, CrewAI, LangGraph, AutoGen and MCP&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/assets/autonomy.png&#34; alt=&#34;Autonomous Agent&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;If you&#39;re looking at this in Cursor, please right click on the filename in the Explorer on the left, and select &#34;Open preview&#34;, to view the formatted version.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;I couldn&#39;t be more excited to welcome you! This is the start of your 6 week adventure into the powerful, astonishing and often surreal world of Agentic AI.&lt;/p&gt; &#xA;&lt;h3&gt;Before you begin&lt;/h3&gt; &#xA;&lt;p&gt;I&#39;m here to help you be most successful! Please do reach out if I can help, either in the platform or by emailing me direct (&lt;a href=&#34;mailto:ed@edwarddonner.com&#34;&gt;ed@edwarddonner.com&lt;/a&gt;). It&#39;s always great to connect with people on LinkedIn to build up the community - you&#39;ll find me here:&lt;br&gt; &lt;a href=&#34;https://www.linkedin.com/in/eddonner/&#34;&gt;https://www.linkedin.com/in/eddonner/&lt;/a&gt;&lt;br&gt; And this is new to me, but I&#39;m also trying out X/Twitter at &lt;a href=&#34;https://x.com/edwarddonner&#34;&gt;@edwarddonner&lt;/a&gt; - if you&#39;re on X, please show me how it&#39;s done 😂&lt;/p&gt; &#xA;&lt;h3&gt;The not-so-dreaded setup instructions&lt;/h3&gt; &#xA;&lt;p&gt;Perhaps famous last words: but I really, truly hope that I&#39;ve put together an environment that will be not too horrific to set up!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Windows people, your instructions are &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-PC.md&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mac people, yours are &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-mac.md&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Linux people, yours are &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-linux.md&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Any problems, please do contact me.&lt;/p&gt; &#xA;&lt;h3&gt;Important notes for CrewAI week (Week 3)&lt;/h3&gt; &#xA;&lt;p&gt;Windows PC users: you will need to have checked the &#34;gotcha #4&#34; at the top of the &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/setup/SETUP-PC.md&#34;&gt;SETUP-PC&lt;/a&gt; instructions -- installing Microsoft Build Tools.&lt;br&gt; If you don&#39;t do this, then CrewAI will fail with an obscure error involving Chroma..&lt;/p&gt; &#xA;&lt;p&gt;Then, you will need to run this command in a Cursor Terminal in the project root directory in order to run the Crew commands:&lt;br&gt; &lt;code&gt;uv tool install crewai&lt;/code&gt;&lt;br&gt; And in case you&#39;ve used Crew before, it might be worth doing this to make sure you have the latest:&lt;br&gt; &lt;code&gt;uv tool upgrade crewai&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Then please keep in mind for Crew:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;There are two ways that you can work on the CrewAI project in week 3. Either review the code for each project while I build it, and then do &lt;code&gt;crewai run&lt;/code&gt; to see it in action. Or if you prefer to be more hands-on, then create your own Crew project from scratch to mirror mine; for example, create &lt;code&gt;my_debate&lt;/code&gt; to go alongside &lt;code&gt;debate&lt;/code&gt;, and write the code alongside me. Either approach works!&lt;/li&gt; &#xA; &lt;li&gt;Windows users: there&#39;s a new issue that was recently introduced by one of Crew&#39;s libraries. Until this is fixed, you might get a &#34;unicode&#34; error when you try to run &lt;code&gt;crewai create crew&lt;/code&gt;. If that happens, please try running this command in the Terminal first: &lt;code&gt;$env:PYTHONUTF8 = &#34;1&#34;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gemini users: in addition to a key in your &lt;code&gt;.env&lt;/code&gt; file for &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt;, you will need an identical key for &lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Super useful resources&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The course &lt;a href=&#34;https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/&#34;&gt;resources&lt;/a&gt; with videos&lt;/li&gt; &#xA; &lt;li&gt;Many essential guides in the &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/guides/01_intro.ipynb&#34;&gt;guides&lt;/a&gt; section&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/setup/troubleshooting.ipynb&#34;&gt;troubleshooting&lt;/a&gt; notebook&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;API costs - please read me!&lt;/h3&gt; &#xA;&lt;p&gt;This course does involve making calls to OpenAI and other frontier models, requiring an API key and a small spend, which we set up in the SETUP instructions. If you&#39;d prefer not to spend on API calls, there are cheaper alternatives like DeepSeek and free alternatives like using Ollama!&lt;/p&gt; &#xA;&lt;p&gt;Details are &lt;a href=&#34;https://raw.githubusercontent.com/ed-donner/agents/main/guides/09_ai_apis_and_ollama.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Be sure to monitor your API costs to ensure you are totally happy with any spend. For OpenAI, the dashboard is &lt;a href=&#34;https://platform.openai.com/usage&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;ABOVE ALL ELSE -&lt;/h3&gt; &#xA;&lt;p&gt;Be sure to have fun with the course! You could not have picked a better time to be learning about Agentic AI. I hope you enjoy every single minute! And if you get stuck at any point - &lt;a href=&#34;https://www.linkedin.com/in/eddonner/&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>