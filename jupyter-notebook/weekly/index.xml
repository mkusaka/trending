<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-23T01:57:28Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>geekyutao/Inpaint-Anything</title>
    <updated>2023-07-23T01:57:28Z</updated>
    <id>tag:github.com,2023-07-23:/geekyutao/Inpaint-Anything</id>
    <link href="https://github.com/geekyutao/Inpaint-Anything" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Inpaint anything using Segment Anything and inpainting models.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/IAM.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Inpaint Anything: Segment Anything Meets Image Inpainting&lt;/h1&gt; &#xA;&lt;p&gt;Inpaint Anything can inpaint anything in &lt;strong&gt;images&lt;/strong&gt;, &lt;strong&gt;videos&lt;/strong&gt; and &lt;strong&gt;3D scenes&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Authors: Tao Yu, Runseng Feng, Ruoyu Feng, Jinming Liu, Xin Jin, Wenjun Zeng and Zhibo Chen.&lt;/li&gt; &#xA; &lt;li&gt;Institutes: University of Science and Technology of China; Eastern Institute for Advanced Study.&lt;/li&gt; &#xA; &lt;li&gt;[&lt;a href=&#34;https://arxiv.org/abs/2304.06790&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/spaces/InpaintAI/Inpaint-Anything&#34;&gt;Website&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/InpaintAI&#34;&gt;Hugging Face Homepage&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/MainFramework.png&#34; width=&#34;100%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;TL; DR: Users can select any object in an image by clicking on it. With powerful vision models, e.g., &lt;a href=&#34;https://arxiv.org/abs/2304.02643&#34;&gt;SAM&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2109.07161&#34;&gt;LaMa&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;Stable Diffusion (SD)&lt;/a&gt;, &lt;strong&gt;Inpaint Anything&lt;/strong&gt; is able to remove the object smoothly (i.e., &lt;em&gt;Remove Anything&lt;/em&gt;). Further, prompted by user input text, Inpaint Anything can fill the object with any desired content (i.e., &lt;em&gt;Fill Anything&lt;/em&gt;) or replace the background of it arbitrarily (i.e., &lt;em&gt;Replace Anything&lt;/em&gt;).&lt;/p&gt; &#xA;&lt;h2&gt;📜 News&lt;/h2&gt; &#xA;&lt;p&gt;[2023/4/30] &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#remove-anything-video&#34;&gt;Remove Anything Video&lt;/a&gt; available! You can remove any object from a video!&lt;br&gt; [2023/4/24] &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/app&#34;&gt;Local web UI&lt;/a&gt; supported! You can run the demo website locally!&lt;br&gt; [2023/4/22] &lt;a href=&#34;https://huggingface.co/spaces/InpaintAI/Inpaint-Anything&#34;&gt;Website&lt;/a&gt; available! You can experience Inpaint Anything through the interface!&lt;br&gt; [2023/4/22] &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#remove-anything-3d&#34;&gt;Remove Anything 3D&lt;/a&gt; available! You can remove any 3D object from a 3D scene!&lt;br&gt; [2023/4/13] &lt;a href=&#34;https://arxiv.org/abs/2304.06790&#34;&gt;Technical report on arXiv&lt;/a&gt; available!&lt;/p&gt; &#xA;&lt;h2&gt;🌟 Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#remove-anything&#34;&gt;&lt;strong&gt;Remove&lt;/strong&gt; Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#fill-anything&#34;&gt;&lt;strong&gt;Fill&lt;/strong&gt; Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#replace-anything&#34;&gt;&lt;strong&gt;Replace&lt;/strong&gt; Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#remove-anything-3d&#34;&gt;Remove Anything &lt;strong&gt;3D&lt;/strong&gt;&lt;/a&gt; (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fill Anything &lt;strong&gt;3D&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Replace Anything &lt;strong&gt;3D&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/#remove-anything-video&#34;&gt;Remove Anything &lt;strong&gt;Video&lt;/strong&gt;&lt;/a&gt; (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fill Anything &lt;strong&gt;Video&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Replace Anything &lt;strong&gt;Video&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;💡 Highlights&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Any aspect ratio supported&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 2K resolution supported&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://arxiv.org/abs/2304.06790&#34;&gt;Technical report on arXiv&lt;/a&gt; available (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://huggingface.co/spaces/InpaintAI/Inpaint-Anything&#34;&gt;Website&lt;/a&gt; available (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/app&#34;&gt;Local web UI&lt;/a&gt; available (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Multiple modalities (i.e., image, video and 3D scene) supported (&lt;span style=&#34;color:red&#34;&gt;🔥NEW&lt;/span&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- ## Updates&#xA;| Date | News |&#xA;| ------ | --------&#xA;| 2023-04-12 | Release the Fill Anything feature | &#xA;| 2023-04-10 | Release the Remove Anything feature |&#xA;| 2023-04-10 | Release the first version of Inpaint Anything | --&gt; &#xA;&lt;h2&gt;&lt;span id=&#34;remove-anything&#34;&gt;📌 Remove Anything&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;!-- &lt;table&gt;&#xA;  &lt;tr&gt;&#xA;    &lt;td&gt;&lt;img src=&#34;./example/remove-anything/dog/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;    &lt;td&gt;&lt;img src=&#34;./example/remove-anything/dog/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;    &lt;td&gt;&lt;img src=&#34;./example/remove-anything/dog/inpainted_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;  &lt;/tr&gt;&#xA;&lt;/table&gt; --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/GIF/Remove-dog.gif&#34; alt=&#34;image&#34; style=&#34;width:400px;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Click&lt;/strong&gt; on an object in the image, and Inpainting Anything will &lt;strong&gt;remove&lt;/strong&gt; it instantly!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click on an object;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://segment-anything.com/&#34;&gt;Segment Anything Model&lt;/a&gt; (SAM) segments the object out;&lt;/li&gt; &#xA; &lt;li&gt;Inpainting models (e.g., &lt;a href=&#34;https://advimman.github.io/lama-project/&#34;&gt;LaMa&lt;/a&gt;) fill the &#34;hole&#34;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install torch torchvision torchaudio&#xA;python -m pip install -e segment_anything&#xA;python -m pip install -r lama/requirements.txt &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In Windows, we recommend you to first install &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;miniconda&lt;/a&gt; and open &lt;code&gt;Anaconda Powershell Prompt (miniconda3)&lt;/code&gt; as administrator. Then pip install &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/lama_requirements_windows.txt&#34;&gt;./lama_requirements_windows.txt&lt;/a&gt; instead of &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/lama%2Frequirements.txt&#34;&gt;./lama/requirements.txt&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Download the model checkpoints provided in &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/segment_anything/README.md&#34;&gt;Segment Anything&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/lama/README.md&#34;&gt;LaMa&lt;/a&gt; (e.g., &lt;a href=&#34;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth&#34;&gt;sam_vit_h_4b8939.pth&lt;/a&gt; and &lt;a href=&#34;https://disk.yandex.ru/d/ouP6l8VJ0HpMZg&#34;&gt;big-lama&lt;/a&gt;), and put them into &lt;code&gt;./pretrained_models&lt;/code&gt;. For simplicity, you can also go &lt;a href=&#34;https://drive.google.com/drive/folders/1ST0aRbDRZGli0r7OVVOQvXwtadMCuWXg?usp=sharing&#34;&gt;here&lt;/a&gt;, directly download &lt;a href=&#34;https://drive.google.com/drive/folders/1wpY-upCo4GIW4wVPnlMh_ym779lLIG2A?usp=sharing&#34;&gt;pretrained_models&lt;/a&gt;, put the directory into &lt;code&gt;./&lt;/code&gt; and get &lt;code&gt;./pretrained_models&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Specify an image and a point, and Remove Anything will remove the object at the point.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python remove_anything.py \&#xA;    --input_img ./example/remove-anything/dog.jpg \&#xA;    --coords_type key_in \&#xA;    --point_coords 200 450 \&#xA;    --point_labels 1 \&#xA;    --dilate_kernel_size 15 \&#xA;    --output_dir ./results \&#xA;    --sam_model_type &#34;vit_h&#34; \&#xA;    --sam_ckpt ./pretrained_models/sam_vit_h_4b8939.pth \&#xA;    --lama_config ./lama/configs/prediction/default.yaml \&#xA;    --lama_ckpt ./pretrained_models/big-lama&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can change &lt;code&gt;--coords_type key_in&lt;/code&gt; to &lt;code&gt;--coords_type click&lt;/code&gt; if your machine has a display device. If &lt;code&gt;click&lt;/code&gt; is set, after running the above command, the image will be displayed. (1) Use &lt;em&gt;left-click&lt;/em&gt; to record the coordinates of the click. It supports modifying points, and only last point coordinates are recorded. (2) Use &lt;em&gt;right-click&lt;/em&gt; to finish the selection.&lt;/p&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/person/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/person/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/person/inpainted_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/bridge/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/bridge/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/bridge/inpainted_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/boat/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/boat/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/boat/inpainted_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/baseball/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/baseball/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/baseball/inpainted_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;span id=&#34;fill-anything&#34;&gt;📌 Fill Anything&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;!-- &lt;table&gt;&#xA;  &lt;caption align=&#34;center&#34;&gt;Text prompt: &#34;a teddy bear on a bench&#34;&lt;/caption&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/fill-anything/sample1/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/fill-anything/sample1/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/fill-anything/sample1/filled_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;&lt;/table&gt; --&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Text prompt: &#34;a teddy bear on a bench&#34;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/GIF/Fill-sample1.gif&#34; alt=&#34;image&#34; style=&#34;width:400px;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Click&lt;/strong&gt; on an object, &lt;strong&gt;type&lt;/strong&gt; in what you want to fill, and Inpaint Anything will &lt;strong&gt;fill&lt;/strong&gt; it!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click on an object;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://segment-anything.com/&#34;&gt;SAM&lt;/a&gt; segments the object out;&lt;/li&gt; &#xA; &lt;li&gt;Input a text prompt;&lt;/li&gt; &#xA; &lt;li&gt;Text-prompt-guided inpainting models (e.g., &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;) fill the &#34;hole&#34; according to the text.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install torch torchvision torchaudio&#xA;python -m pip install -e segment_anything&#xA;python -m pip install diffusers transformers accelerate scipy safetensors&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Download the model checkpoints provided in &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/segment_anything/README.md&#34;&gt;Segment Anything&lt;/a&gt; (e.g., &lt;a href=&#34;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth&#34;&gt;sam_vit_h_4b8939.pth&lt;/a&gt;) and put them into &lt;code&gt;./pretrained_models&lt;/code&gt;. For simplicity, you can also go &lt;a href=&#34;https://drive.google.com/drive/folders/1ST0aRbDRZGli0r7OVVOQvXwtadMCuWXg?usp=sharing&#34;&gt;here&lt;/a&gt;, directly download &lt;a href=&#34;https://drive.google.com/drive/folders/1wpY-upCo4GIW4wVPnlMh_ym779lLIG2A?usp=sharing&#34;&gt;pretrained_models&lt;/a&gt;, put the directory into &lt;code&gt;./&lt;/code&gt; and get &lt;code&gt;./pretrained_models&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Specify an image, a point and text prompt, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python fill_anything.py \&#xA;    --input_img ./example/fill-anything/sample1.png \&#xA;    --coords_type key_in \&#xA;    --point_coords 750 500 \&#xA;    --point_labels 1 \&#xA;    --text_prompt &#34;a teddy bear on a bench&#34; \&#xA;    --dilate_kernel_size 50 \&#xA;    --output_dir ./results \&#xA;    --sam_model_type &#34;vit_h&#34; \&#xA;    --sam_ckpt ./pretrained_models/sam_vit_h_4b8939.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;a camera lens in the hand&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample2/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample2/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample2/filled_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;a Picasso painting on the wall&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample5/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample5/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample5/filled_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;an aircraft carrier on the sea&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample3/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample3/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample3/filled_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;a sports car on a road&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample4/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample4/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample4/filled_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;span id=&#34;replace-anything&#34;&gt;📌 Replace Anything&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;!-- &lt;table&gt;&#xA;  &lt;caption align=&#34;center&#34;&gt;Text prompt: &#34;a man in office&#34;&lt;/caption&gt;&#xA;    &lt;tr&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/replace-anything/man/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/replace-anything/man/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;      &lt;td&gt;&lt;img src=&#34;./example/replace-anything/man/replaced_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;&lt;/table&gt; --&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Text prompt: &#34;a man in office&#34;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/GIF/Replace-man.gif&#34; alt=&#34;image&#34; style=&#34;width:400px;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Click&lt;/strong&gt; on an object, &lt;strong&gt;type&lt;/strong&gt; in what background you want to replace, and Inpaint Anything will &lt;strong&gt;replace&lt;/strong&gt; it!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click on an object;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://segment-anything.com/&#34;&gt;SAM&lt;/a&gt; segments the object out;&lt;/li&gt; &#xA; &lt;li&gt;Input a text prompt;&lt;/li&gt; &#xA; &lt;li&gt;Text-prompt-guided inpainting models (e.g., &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;) replace the background according to the text.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install torch torchvision torchaudio&#xA;python -m pip install -e segment_anything&#xA;python -m pip install diffusers transformers accelerate scipy safetensors&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Download the model checkpoints provided in &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/segment_anything/README.md&#34;&gt;Segment Anything&lt;/a&gt; (e.g. &lt;a href=&#34;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth&#34;&gt;sam_vit_h_4b8939.pth&lt;/a&gt;) and put them into &lt;code&gt;./pretrained_models&lt;/code&gt;. For simplicity, you can also go &lt;a href=&#34;https://drive.google.com/drive/folders/1ST0aRbDRZGli0r7OVVOQvXwtadMCuWXg?usp=sharing&#34;&gt;here&lt;/a&gt;, directly download &lt;a href=&#34;https://drive.google.com/drive/folders/1wpY-upCo4GIW4wVPnlMh_ym779lLIG2A?usp=sharing&#34;&gt;pretrained_models&lt;/a&gt;, put the directory into &lt;code&gt;./&lt;/code&gt; and get &lt;code&gt;./pretrained_models&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Specify an image, a point and text prompt, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python replace_anything.py \&#xA;    --input_img ./example/replace-anything/dog.png \&#xA;    --coords_type key_in \&#xA;    --point_coords 750 500 \&#xA;    --point_labels 1 \&#xA;    --text_prompt &#34;sit on the swing&#34; \&#xA;    --output_dir ./results \&#xA;    --sam_model_type &#34;vit_h&#34; \&#xA;    --sam_ckpt ./pretrained_models/sam_vit_h_4b8939.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;sit on the swing&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/dog/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/dog/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/dog/replaced_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;a bus, on the center of a country road, summer&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/bus/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/bus/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/bus/replaced_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;breakfast&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000029675/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000029675/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000029675/replaced_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;caption align=&#34;center&#34;&gt;&#xA;  Text prompt: &#34;crossroad in the city&#34;&#xA; &lt;/caption&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000000724/with_points.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000000724/with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/000000000724/replaced_with_mask.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;span id=&#34;remove-anything-3d&#34;&gt;📌 Remove Anything 3D&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Remove Anything 3D can remove any object from a 3D scene! We release some results below. (Code and implementation details will be released soon.)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/horns/org.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/horns/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/horns/result.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/room/org.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/room/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-3d/room/result.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;&lt;span id=&#34;remove-anything-video&#34;&gt;📌 Remove Anything Video&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/paragliding/original.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/paragliding/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/paragliding/removed.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;With a single &lt;strong&gt;click&lt;/strong&gt; on an object in the &lt;em&gt;first&lt;/em&gt; video frame, Remove Anything Video can remove the object from the &lt;em&gt;whole&lt;/em&gt; video!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Click on an object in the first frame of a video;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://segment-anything.com/&#34;&gt;SAM&lt;/a&gt; segments the object out (with three possible masks);&lt;/li&gt; &#xA; &lt;li&gt;Select one mask;&lt;/li&gt; &#xA; &lt;li&gt;A tracking model such as &lt;a href=&#34;https://github.com/botaoye/OSTrack&#34;&gt;OSTrack&lt;/a&gt; is ultilized to track the object in the video;&lt;/li&gt; &#xA; &lt;li&gt;SAM segments the object out in each frame according to tracking results;&lt;/li&gt; &#xA; &lt;li&gt;A video inpainting model such as &lt;a href=&#34;https://github.com/researchmm/STTN&#34;&gt;STTN&lt;/a&gt; is ultilized to inpaint the object in each frame.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;Requires &lt;code&gt;python&amp;gt;=3.8&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install torch torchvision torchaudio&#xA;python -m pip install -e segment_anything&#xA;python -m pip install -r lama/requirements.txt&#xA;python -m pip install jpeg4py lmdb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;Download the model checkpoints provided in &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/segment_anything/README.md&#34;&gt;Segment Anything&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/sttn/README.md&#34;&gt;STTN&lt;/a&gt; (e.g., &lt;a href=&#34;https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth&#34;&gt;sam_vit_h_4b8939.pth&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/file/d/1ZAMV8547wmZylKRt5qR_tC5VlosXD4Wv/view&#34;&gt;sttn.pth&lt;/a&gt;), and put them into &lt;code&gt;./pretrained_models&lt;/code&gt;. Further, download &lt;a href=&#34;https://github.com/botaoye/OSTrack&#34;&gt;OSTrack&lt;/a&gt; pretrained model from &lt;a href=&#34;https://drive.google.com/drive/folders/1ttafo0O5S9DXK2PX0YqPvPrQ-HWJjhSy&#34;&gt;here&lt;/a&gt; (e.g., &lt;a href=&#34;https://drive.google.com/drive/folders/1XJ70dYB6muatZ1LPQGEhyvouX-sU_wnu&#34;&gt;vitb_384_mae_ce_32x4_ep300.pth&lt;/a&gt;) and put it into &lt;code&gt;./pytracking/pretrain&lt;/code&gt;. For simplicity, you can also go &lt;a href=&#34;https://drive.google.com/drive/folders/1ST0aRbDRZGli0r7OVVOQvXwtadMCuWXg?usp=sharing&#34;&gt;here&lt;/a&gt;, directly download &lt;a href=&#34;https://drive.google.com/drive/folders/1wpY-upCo4GIW4wVPnlMh_ym779lLIG2A?usp=sharing&#34;&gt;pretrained_models&lt;/a&gt;, put the directory into &lt;code&gt;./&lt;/code&gt; and get &lt;code&gt;./pretrained_models&lt;/code&gt;. Additionally, download &lt;a href=&#34;https://drive.google.com/drive/folders/1SERTIfS7JYyOOmXWujAva4CDQf-W7fjv?usp=sharing&#34;&gt;pretrain&lt;/a&gt;, put the directory into &lt;code&gt;./pytracking&lt;/code&gt; and get &lt;code&gt;./pytracking/pretrain&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Specify a video, a point, video FPS and mask index (indicating using which mask result of the first frame), and Remove Anything Video will remove the object from the whole video.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python remove_anything_video.py \&#xA;    --input_video ./example/video/paragliding/original_video.mp4 \&#xA;    --coords_type key_in \&#xA;    --point_coords 652 162 \&#xA;    --point_labels 1 \&#xA;    --dilate_kernel_size 15 \&#xA;    --output_dir ./results \&#xA;    --sam_model_type &#34;vit_h&#34; \&#xA;    --sam_ckpt ./pretrained_models/sam_vit_h_4b8939.pth \&#xA;    --lama_config lama/configs/prediction/default.yaml \&#xA;    --lama_ckpt ./pretrained_models/big-lama \&#xA;    --tracker_ckpt vitb_384_mae_ce_32x4_ep300 \&#xA;    --vi_ckpt ./pretrained_models/sttn.pth \&#xA;    --mask_idx 2 \&#xA;    --fps 25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;code&gt;--mask_idx&lt;/code&gt; is usually set to 2, which typically is the most confident mask result of the first frame. If the object is not segmented out well, you can try other masks (0 or 1).&lt;/p&gt; &#xA;&lt;h3&gt;Demo&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/drift-chicane/original.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/drift-chicane/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/drift-chicane/removed.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/surf/original.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/surf/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/surf/removed.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/tennis-vest/original.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/tennis-vest/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/tennis-vest/removed.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/dog-gooses/original.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/dog-gooses/mask.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything-video/dog-gooses/removed.gif&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/segment-anything&#34;&gt;Segment Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/advimman/lama&#34;&gt;LaMa&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/botaoye/OSTrack&#34;&gt;OSTrack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/researchmm/STTN&#34;&gt;STTN&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Other Interesting Repositories&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/VainF/Awesome-Anything&#34;&gt;Awesome Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Adamdad/Awesome-ComposableAI&#34;&gt;Composable AI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/IDEA-Research/Grounded-Segment-Anything&#34;&gt;Grounded SAM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this work useful for your research, please cite us:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{yu2023inpaint,&#xA;  title={Inpaint Anything: Segment Anything Meets Image Inpainting},&#xA;  author={Yu, Tao and Feng, Runseng and Feng, Ruoyu and Liu, Jinming and Jin, Xin and Zeng, Wenjun and Chen, Zhibo},&#xA;  journal={arXiv preprint arXiv:2304.06790},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://star-history.com/#geekyutao/Inpaint-Anything&amp;amp;Date&#34;&gt; &lt;img src=&#34;https://api.star-history.com/svg?repos=geekyutao/Inpaint-Anything&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt; &lt;/a&gt; &lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>camenduru/text-generation-webui-colab</title>
    <updated>2023-07-23T01:57:28Z</updated>
    <id>tag:github.com,2023-07-23:/camenduru/text-generation-webui-colab</id>
    <link href="https://github.com/camenduru/text-generation-webui-colab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A colab gradio web UI for running Large Language Models&lt;/p&gt;&lt;hr&gt;&lt;p&gt;🐣 Please follow me for new updates &lt;a href=&#34;https://twitter.com/camenduru&#34;&gt;https://twitter.com/camenduru&lt;/a&gt; &lt;br&gt; 🔥 Please join our discord server &lt;a href=&#34;https://discord.gg/k5BwmmvJJU&#34;&gt;https://discord.gg/k5BwmmvJJU&lt;/a&gt; &lt;br&gt; 🥳 Please join my patreon community &lt;a href=&#34;https://patreon.com/camenduru&#34;&gt;https://patreon.com/camenduru&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🚦 WIP 🚦&lt;/h2&gt; &#xA;&lt;h2&gt;🦒 Colab&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;colab&lt;/th&gt; &#xA;   &lt;th&gt;Info - Model Page&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/vicuna-13b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;vicuna-13b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://vicuna.lmsys.org&#34;&gt;https://vicuna.lmsys.org&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/vicuna-13B-1.1-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;vicuna-13B-1.1-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://vicuna.lmsys.org&#34;&gt;https://vicuna.lmsys.org&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/stable-vicuna-13B-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;stable-vicuna-13B-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://huggingface.co/CarperAI/stable-vicuna-13b-delta&#34;&gt;https://huggingface.co/CarperAI/stable-vicuna-13b-delta&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/gpt4-x-alpaca-13b-native-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;gpt4-x-alpaca-13b-native-4bit-128g &lt;br&gt; &lt;a href=&#34;https://huggingface.co/chavinlo/gpt4-x-alpaca&#34;&gt;https://huggingface.co/chavinlo/gpt4-x-alpaca&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/pyg-7b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;pyg-7b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&#34;&gt;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/koala-13B-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;koala-13B-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://bair.berkeley.edu/blog/2023/04/03/koala&#34;&gt;https://bair.berkeley.edu/blog/2023/04/03/koala&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/oasst-llama13b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;oasst-llama13b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://open-assistant.io&#34;&gt;https://open-assistant.io&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/wizard-lm-uncensored-7b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;wizard-lm-uncensored-7b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://github.com/nlpxucan/WizardLM&#34;&gt;https://github.com/nlpxucan/WizardLM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/mpt-storywriter-7b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;mpt-storywriter-7b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://www.mosaicml.com&#34;&gt;https://www.mosaicml.com&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/wizard-lm-uncensored-13b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;wizard-lm-uncensored-13b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://github.com/nlpxucan/WizardLM&#34;&gt;https://github.com/nlpxucan/WizardLM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/pyg-13b-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;pyg-13b-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://huggingface.co/PygmalionAI/pygmalion-13b&#34;&gt;https://huggingface.co/PygmalionAI/pygmalion-13b&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/falcon-7b-instruct-GPTQ-4bit.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;falcon-7b-instruct-GPTQ-4bit &lt;br&gt; &lt;a href=&#34;https://falconllm.tii.ae/&#34;&gt;https://falconllm.tii.ae/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/wizard-lm-13b-1.1-GPTQ-4bit-128g.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;wizard-lm-13b-1.1-GPTQ-4bit-128g &lt;br&gt; &lt;a href=&#34;https://github.com/nlpxucan/WizardLM&#34;&gt;https://github.com/nlpxucan/WizardLM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-7b-chat-GPTQ-4bit.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama-2-7b-chat-GPTQ-4bit (4bit) &lt;br&gt; &lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;https://ai.meta.com/llama/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-13b-chat-GPTQ-4bit.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama-2-13b-chat-GPTQ-4bit (4bit) &lt;br&gt; &lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;https://ai.meta.com/llama/&lt;/a&gt; &lt;br&gt; 🚦 WIP 🚦 please try llama-2-13b-chat or llama-2-7b-chat or llama-2-7b-chat-GPTQ-4bit&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-7b-chat.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama-2-7b-chat (16bit) &lt;br&gt; &lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;https://ai.meta.com/llama/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-13b-chat.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;llama-2-13b-chat (8bit) &lt;br&gt; &lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;https://ai.meta.com/llama/&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/redmond-puffin-13b-GPTQ-4bit.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;redmond-puffin-13b-GPTQ-4bit (4bit) &lt;br&gt; &lt;a href=&#34;https://huggingface.co/NousResearch/Redmond-Puffin-13B&#34;&gt;https://huggingface.co/NousResearch/Redmond-Puffin-13B&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/nous-hermes-13b-GPTQ-4bit.ipynb) | nous-hermes-13b-GPTQ-4bit (4bit) &lt;br /&gt; https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b --&gt; &#xA;&lt;h2&gt;🦒 Colab Pro&lt;/h2&gt; &#xA;&lt;p&gt;According to the Facebook Research LLaMA license (Non-commercial bespoke license), maybe we cannot use this model with a Colab Pro account. But Yann LeCun said &#34;GPL v3&#34; (&lt;a href=&#34;https://twitter.com/ylecun/status/1629189925089296386&#34;&gt;https://twitter.com/ylecun/status/1629189925089296386&lt;/a&gt;) I am a little confused. Is it possible to use this with a non-free Colab Pro account?&lt;/p&gt; &#xA;&lt;h2&gt;Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kgA7eKU1XuA&#34;&gt;https://www.youtube.com/watch?v=kgA7eKU1XuA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Text Generation Web UI&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/oobabooga/text-generation-webui&#34;&gt;https://github.com/oobabooga/text-generation-webui&lt;/a&gt; (Thanks to @oobabooga ❤)&lt;/p&gt; &#xA;&lt;h2&gt;Models License&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;License&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;vicuna-13b-GPTQ-4bit-128g&lt;/td&gt; &#xA;   &lt;td&gt;From &lt;a href=&#34;https://vicuna.lmsys.org&#34;&gt;https://vicuna.lmsys.org&lt;/a&gt;: The online demo is a research preview intended for non-commercial use only, subject to the model &lt;a href=&#34;https://github.com/facebookresearch/llama/raw/main/MODEL_CARD.md&#34;&gt;License&lt;/a&gt; of LLaMA, Terms of Use of the data generated by OpenAI, and Privacy Practices of ShareGPT. Please contact us If you find any potential violation. The code is released under the Apache License 2.0.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;gpt4-x-alpaca-13b-native-4bit-128g&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/chavinlo/alpaca-native&#34;&gt;https://huggingface.co/chavinlo/alpaca-native&lt;/a&gt; -&amp;gt; &lt;a href=&#34;https://huggingface.co/chavinlo/alpaca-13b&#34;&gt;https://huggingface.co/chavinlo/alpaca-13b&lt;/a&gt; -&amp;gt; &lt;a href=&#34;https://huggingface.co/chavinlo/gpt4-x-alpaca&#34;&gt;https://huggingface.co/chavinlo/gpt4-x-alpaca&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;llama-2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.meta.com/llama/&#34;&gt;https://ai.meta.com/llama/&lt;/a&gt; Llama 2 is available for free for research and commercial use. 🥳&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Special Thanks&lt;/h2&gt; &#xA;&lt;p&gt;Thanks to facebookresearch ❤ for &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;https://github.com/facebookresearch/llama&lt;/a&gt; &lt;br&gt; Thanks to lmsys ❤ for &lt;a href=&#34;https://huggingface.co/lmsys/vicuna-13b-delta-v0&#34;&gt;https://huggingface.co/lmsys/vicuna-13b-delta-v0&lt;/a&gt; &lt;br&gt; Thanks to anon8231489123 ❤ for &lt;a href=&#34;https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g&#34;&gt;https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/lmsys/vicuna-13b-delta-v0&#34;&gt;https://huggingface.co/lmsys/vicuna-13b-delta-v0&lt;/a&gt;) &lt;br&gt; Thanks to tatsu-lab ❤ for &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt; &lt;br&gt; Thanks to chavinlo ❤ for &lt;a href=&#34;https://huggingface.co/chavinlo/gpt4-x-alpaca&#34;&gt;https://huggingface.co/chavinlo/gpt4-x-alpaca&lt;/a&gt; &lt;br&gt; Thanks to qwopqwop200 ❤ for &lt;a href=&#34;https://github.com/qwopqwop200/GPTQ-for-LLaMa&#34;&gt;https://github.com/qwopqwop200/GPTQ-for-LLaMa&lt;/a&gt; &lt;br&gt; Thanks to tsumeone ❤ for &lt;a href=&#34;https://huggingface.co/tsumeone/gpt4-x-alpaca-13b-native-4bit-128g-cuda&#34;&gt;https://huggingface.co/tsumeone/gpt4-x-alpaca-13b-native-4bit-128g-cuda&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/chavinlo/gpt4-x-alpaca&#34;&gt;https://huggingface.co/chavinlo/gpt4-x-alpaca&lt;/a&gt;) &lt;br&gt; Thanks to transformers ❤ for &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;https://github.com/huggingface/transformers&lt;/a&gt; &lt;br&gt; Thanks to gradio-app ❤ for &lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;https://github.com/gradio-app/gradio&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ&#34;&gt;https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ&lt;/a&gt; &lt;br&gt; Thanks to Neko-Institute-of-Science ❤ for &lt;a href=&#34;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&#34;&gt;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&lt;/a&gt; &lt;br&gt; Thanks to gozfarb ❤ for &lt;a href=&#34;https://huggingface.co/gozfarb/pygmalion-7b-4bit-128g-cuda&#34;&gt;https://huggingface.co/gozfarb/pygmalion-7b-4bit-128g-cuda&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&#34;&gt;https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b&lt;/a&gt;) &lt;br&gt; Thanks to young-geng ❤ for &lt;a href=&#34;https://huggingface.co/young-geng/koala&#34;&gt;https://huggingface.co/young-geng/koala&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g&#34;&gt;https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/young-geng/koala&#34;&gt;https://huggingface.co/young-geng/koala&lt;/a&gt;) &lt;br&gt; Thanks to dvruette ❤ for &lt;a href=&#34;https://huggingface.co/dvruette/oasst-llama-13b-2-epochs&#34;&gt;https://huggingface.co/dvruette/oasst-llama-13b-2-epochs&lt;/a&gt; &lt;br&gt; Thanks to gozfarb ❤ for &lt;a href=&#34;https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g&#34;&gt;https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/dvruette/oasst-llama-13b-2-epochs&#34;&gt;https://huggingface.co/dvruette/oasst-llama-13b-2-epochs&lt;/a&gt;) &lt;br&gt; Thanks to ehartford ❤ for &lt;a href=&#34;https://huggingface.co/ehartford/WizardLM-7B-Uncensored&#34;&gt;https://huggingface.co/ehartford/WizardLM-7B-Uncensored&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ&#34;&gt;https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/ehartford/WizardLM-7B-Uncensored&#34;&gt;https://huggingface.co/ehartford/WizardLM-7B-Uncensored&lt;/a&gt;) &lt;br&gt; Thanks to mosaicml ❤ for &lt;a href=&#34;https://huggingface.co/mosaicml/mpt-7b-storywriter&#34;&gt;https://huggingface.co/mosaicml/mpt-7b-storywriter&lt;/a&gt; &lt;br&gt; Thanks to OccamRazor ❤ for &lt;a href=&#34;https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g&#34;&gt;https://huggingface.co/OccamRazor/mpt-7b-storywriter-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/mosaicml/mpt-7b-storywriter&#34;&gt;https://huggingface.co/mosaicml/mpt-7b-storywriter&lt;/a&gt;) &lt;br&gt; Thanks to ehartford ❤ for &lt;a href=&#34;https://huggingface.co/ehartford/WizardLM-13B-Uncensored&#34;&gt;https://huggingface.co/ehartford/WizardLM-13B-Uncensored&lt;/a&gt; &lt;br&gt; Thanks to ausboss ❤ for &lt;a href=&#34;https://huggingface.co/ausboss/WizardLM-13B-Uncensored-4bit-128g&#34;&gt;https://huggingface.co/ausboss/WizardLM-13B-Uncensored-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/ehartford/WizardLM-13B-Uncensored&#34;&gt;https://huggingface.co/ehartford/WizardLM-13B-Uncensored&lt;/a&gt;) &lt;br&gt; Thanks to PygmalionAI ❤ for &lt;a href=&#34;https://huggingface.co/PygmalionAI/pygmalion-13b&#34;&gt;https://huggingface.co/PygmalionAI/pygmalion-13b&lt;/a&gt; &lt;br&gt; Thanks to notstoic ❤ for &lt;a href=&#34;https://huggingface.co/notstoic/pygmalion-13b-4bit-128g&#34;&gt;https://huggingface.co/notstoic/pygmalion-13b-4bit-128g&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/PygmalionAI/pygmalion-13b&#34;&gt;https://huggingface.co/PygmalionAI/pygmalion-13b&lt;/a&gt;) &lt;br&gt; Thanks to WizardLM ❤ for &lt;a href=&#34;https://huggingface.co/WizardLM/WizardLM-13B-V1.1&#34;&gt;https://huggingface.co/WizardLM/WizardLM-13B-V1.1&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/WizardLM-13B-V1.1-GPTQ&#34;&gt;https://huggingface.co/TheBloke/WizardLM-13B-V1.1-GPTQ&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/WizardLM/WizardLM-13B-V1.1&#34;&gt;https://huggingface.co/WizardLM/WizardLM-13B-V1.1&lt;/a&gt;) &lt;br&gt; Thanks to meta-llama ❤ for &lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ&#34;&gt;https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&#34;&gt;https://huggingface.co/meta-llama/Llama-2-7b-chat-hf&lt;/a&gt;) &lt;br&gt; Thanks to meta-llama ❤ for &lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&lt;/a&gt; &lt;br&gt; Thanks to localmodels ❤ for &lt;a href=&#34;https://huggingface.co/localmodels/Llama-2-13B-Chat-GPTQ&#34;&gt;https://huggingface.co/localmodels/Llama-2-13B-Chat-GPTQ&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&#34;&gt;https://huggingface.co/meta-llama/Llama-2-13b-chat-hf&lt;/a&gt;) &lt;br&gt; Thanks to NousResearch ❤ for &lt;a href=&#34;https://huggingface.co/NousResearch/Redmond-Puffin-13B&#34;&gt;https://huggingface.co/NousResearch/Redmond-Puffin-13B&lt;/a&gt; &lt;br&gt; Thanks to TheBloke ❤ for &lt;a href=&#34;https://huggingface.co/TheBloke/Redmond-Puffin-13B-GPTQ&#34;&gt;https://huggingface.co/TheBloke/Redmond-Puffin-13B-GPTQ&lt;/a&gt; (GPTQ 4bit quantization of: &lt;a href=&#34;https://huggingface.co/NousResearch/Redmond-Puffin-13B&#34;&gt;https://huggingface.co/NousResearch/Redmond-Puffin-13B&lt;/a&gt;) &lt;br&gt;&lt;/p&gt; &#xA;&lt;!-- Thanks to NousResearch ❤ for https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b (GPTQ 4bit quantization https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ)&lt;br /&gt;  --&gt;</summary>
  </entry>
  <entry>
    <title>lyhue1991/torchkeras</title>
    <updated>2023-07-23T01:57:28Z</updated>
    <id>tag:github.com,2023-07-23:/lyhue1991/torchkeras</id>
    <link href="https://github.com/lyhue1991/torchkeras" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Pytorch❤️ Keras 😋😋&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;炼丹师，这是你的梦中情炉吗?🌹🌹&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/README_en.md&#34;&gt;English&lt;/a&gt; | 简体中文&lt;/p&gt; &#xA;&lt;p&gt;torchkeras 是一个通用的pytorch模型训练模版工具，按照如下目标进行设计和实现：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;好看&lt;/strong&gt; (代码优雅，日志美丽，自带可视化)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;好用&lt;/strong&gt; (使用方便，支持 进度条、评估指标、early-stopping等常用功能，支持tensorboard，wandb回调函数等扩展功能)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;好改&lt;/strong&gt; (修改简单，核心代码模块化，仅约200行，并提供丰富的修改使用案例)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;1，炼丹之痛 😭😭&lt;/h2&gt; &#xA;&lt;p&gt;无论是学术研究还是工业落地，pytorch几乎都是目前炼丹的首选框架。&lt;/p&gt; &#xA;&lt;p&gt;pytorch的胜出不仅在于其简洁一致的api设计，更在于其生态中丰富和强大的模型库。&lt;/p&gt; &#xA;&lt;p&gt;但是我们会发现不同的pytorch模型库提供的训练和验证代码非常不一样。&lt;/p&gt; &#xA;&lt;p&gt;torchvision官方提供的范例代码主要是一个关联了非常多依赖函数的train_one_epoch和evaluate函数，针对检测和分割各有一套。&lt;/p&gt; &#xA;&lt;p&gt;yolo系列的主要是支持ddp模式的各种风格迥异的Trainer，每个不同的yolo版本都会改动很多导致不同yolo版本之间都难以通用。&lt;/p&gt; &#xA;&lt;p&gt;抱抱脸的transformers库在借鉴了pytorch_lightning的基础上也搞了一个自己的Trainer，但与pytorch_lightning并不兼容。&lt;/p&gt; &#xA;&lt;p&gt;非常有名的facebook的目标检测库detectron2, 也是搞了一个它自己的Trainer，配合一个全局的cfg参数设置对象来训练模型。&lt;/p&gt; &#xA;&lt;p&gt;还有我用的比较多的语义分割的segmentation_models.pytorch这个库，设计了一个TrainEpoch和一个ValidEpoch来做训练和验证。&lt;/p&gt; &#xA;&lt;p&gt;在学习和使用这些不同的pytorch模型库时，尝试阅读理解和改动这些训练和验证相关的代码让我受到了一万点伤害。&lt;/p&gt; &#xA;&lt;p&gt;有些设计非常糟糕，嵌套了十几层，有些实现非常dirty，各种带下划线的私有变量满天飞。&lt;/p&gt; &#xA;&lt;p&gt;让你每次想要改动一下加入一些自己想要的功能时就感到望而却步。&lt;/p&gt; &#xA;&lt;p&gt;我不就想finetune一下模型嘛，何必拿这么多垃圾代码搞我？&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;2，梦中情炉 🤗🤗&lt;/h2&gt; &#xA;&lt;p&gt;这一切的苦不由得让我怀念起tensorflow中keras的美好了。&lt;/p&gt; &#xA;&lt;p&gt;还记得keras那compile, fit, evalute三连击吗？一切都像行云流水般自然，真正的for humans。&lt;/p&gt; &#xA;&lt;p&gt;而且你看任何用keras实现的模型库，训练和验证都几乎可以用这一套相同的接口，没有那么多莫名奇妙的野生Trainer。&lt;/p&gt; &#xA;&lt;p&gt;我能否基于pytorch打造一个接口和keras一样简洁易用，功能强大，但是实现代码非常简短易懂，便于修改的模型训练工具呢？&lt;/p&gt; &#xA;&lt;p&gt;从2020年7月左右发布1.0版本到最近发布的3.86版本，我陆陆续续在工作中一边使用一边打磨一个工具，总共提交修改了70多次。&lt;/p&gt; &#xA;&lt;p&gt;现在我感觉我细心雕琢的这个作品终于长成了我心目中接近完美的样子。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;她有一个美丽的名字：torchkeras.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;是的，她兼具torch的灵动，也有keras的优雅~&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;并且她的美丽，无与伦比~&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;她，就是我的梦中情炉~ 🤗🤗&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/data/torchkeras.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;3，使用方法 🍊🍊&lt;/h2&gt; &#xA;&lt;p&gt;安装torchkeras&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install torchkeras&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;通过使用torchkeras，你不需要写自己的pytorch模型训练循环。你只要做这样两步就可以了。&lt;/p&gt; &#xA;&lt;p&gt;(1) 创建你的模型结构net,然后把它和损失函数传入torchkeras.KerasModel构建一个model。&lt;/p&gt; &#xA;&lt;p&gt;(2) 使用model的fit方法在你的训练数据和验证数据上进行训练，训练数据和验证数据需要封装成两个DataLoader.&lt;/p&gt; &#xA;&lt;p&gt;核心使用代码就像下面这样：&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch &#xA;import torchkeras&#xA;import torchmetrics&#xA;model = torchkeras.KerasModel(net,&#xA;                              loss_fn = nn.BCEWithLogitsLoss(),&#xA;                              optimizer= torch.optim.Adam(net.parameters(),lr = 1e-4),&#xA;                              metrics_dict = {&#34;acc&#34;:torchmetrics.Accuracy(task=&#39;binary&#39;)}&#xA;                             )&#xA;dfhistory=model.fit(train_data=dl_train, &#xA;                    val_data=dl_val, &#xA;                    epochs=20, &#xA;                    patience=3, &#xA;                    ckpt_path=&#39;checkpoint.pt&#39;,&#xA;                    monitor=&#34;val_acc&#34;,&#xA;                    mode=&#34;max&#34;,&#xA;                    plot=True,&#xA;                    &#xA;                   )&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;在jupyter notebook中执行训练代码，你将看到类似下面的训练可视化图像和训练日志进度条。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/data/torchkeras_plot.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;4，主要特性 🍉🍉&lt;/h2&gt; &#xA;&lt;p&gt;torchkeras 支持以下这些功能特性，稳定支持这些功能的起始版本以及这些功能借鉴或者依赖的库的来源见下表。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;功能&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;稳定支持起始版本&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;依赖或借鉴库&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ 训练进度条&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖tqdm,借鉴keras&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ 训练评估指标&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;借鉴pytorch_lightning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ notebook中训练自带可视化&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.8.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;借鉴fastai&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ early stopping&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;借鉴keras&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ gpu training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.0.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖accelerate&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ multi-gpus training(ddp)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.6.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖accelerate&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ fp16/bf16 training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.6.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖accelerate&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ tensorboard callback&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.7.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖tensorboard&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;✅ wandb callback&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3.7.0&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;依赖wandb&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;5，基本范例 🌰🌰&lt;/h2&gt; &#xA;&lt;p&gt;以下范例是torchkeras的基础范例，演示了torchkeras的主要功能。&lt;/p&gt; &#xA;&lt;p&gt;包括基础训练，使用wandb可视化，使用wandb调参，使用tensorboard可视化，使用多GPU的ddp模式训练等。&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;example&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;kaggle链接&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;①基础范例 🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/01%EF%BC%8Ckerasmodel_example.ipynb&#34;&gt;&lt;strong&gt;basic example&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&#xA;    &lt;div&gt;&#xA;     &lt;a href=&#34;https://www.kaggle.com/lyhue1991/kerasmodel-example&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open In Kaggle&#34;&gt;&lt;/a&gt;&#xA;    &lt;/div&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;②wandb可视化 🔥🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/02%EF%BC%8Ckerasmodel_wandb_demo.ipynb&#34;&gt;&lt;strong&gt;wandb demo&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&#xA;    &lt;div&gt;&#xA;     &lt;a href=&#34;https://www.kaggle.com/lyhue1991/kerasmodel-wandb-example&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open In Kaggle&#34;&gt;&lt;/a&gt;&#xA;    &lt;/div&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;③wandb自动化调参🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/03%EF%BC%8Ckerasmodel_tuning_demo.ipynb&#34;&gt;&lt;strong&gt;wandb sweep demo&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&#xA;    &lt;div&gt;&#xA;     &lt;a href=&#34;https://www.kaggle.com/lyhue1991/torchkeras-loves-wandb-sweep&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open In Kaggle&#34;&gt;&lt;/a&gt;&#xA;    &lt;/div&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;④tensorboard可视化&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/04%EF%BC%8Ckerasmodel_tensorboard_demo.ipynb&#34;&gt;&lt;strong&gt;tensorboard example&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;⑤ddp/tpu训练范例&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.kaggle.com/code/lyhue1991/torchkeras-ddp-tpu-examples&#34;&gt;&lt;strong&gt;ddp tpu examples&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;br&gt;&#xA;    &lt;div&gt;&#xA;     &lt;a href=&#34;https://www.kaggle.com/lyhue1991/torchkeras-ddp-tpu-examples&#34;&gt;&lt;img src=&#34;https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true&#34; alt=&#34;Open In Kaggle&#34;&gt;&lt;/a&gt;&#xA;    &lt;/div&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;6，进阶范例 🔥🔥&lt;/h2&gt; &#xA;&lt;p&gt;在炼丹实践中，遇到的数据集结构或者训练推理逻辑往往会千差万别。&lt;/p&gt; &#xA;&lt;p&gt;例如我们可能会遇到多输入多输出结构，或者希望在训练过程中计算并打印一些特定的指标等等。&lt;/p&gt; &#xA;&lt;p&gt;这时候炼丹师可能会倾向于使用最纯粹的pytorch编写自己的训练循环。&lt;/p&gt; &#xA;&lt;p&gt;实际上，torchkeras提供了极致的灵活性来让炼丹师掌控训练过程的每个细节。&lt;/p&gt; &#xA;&lt;p&gt;从这个意义上说，torchkeras更像是一个训练代码模版。&lt;/p&gt; &#xA;&lt;p&gt;这个模版由低到高由StepRunner，EpochRunner 和 KerasModel 三个类组成。&lt;/p&gt; &#xA;&lt;p&gt;在绝大多数场景下，用户只需要在StepRunner上稍作修改并覆盖掉，就可以实现自己想要的训练推理逻辑。&lt;/p&gt; &#xA;&lt;p&gt;就像下面这段代码范例，这是一个多输入的例子，并且嵌入了特定的accuracy计算逻辑。&lt;/p&gt; &#xA;&lt;p&gt;这段代码的完整范例，见examples下的CRNN_CTC验证码识别。&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;import torch.nn.functional as F &#xA;from torchkeras import KerasModel&#xA;from accelerate import Accelerator&#xA;&#xA;#我们覆盖KerasModel的StepRunner以实现自定义训练逻辑。&#xA;#注意这里把acc指标的结果写在了step_losses中以便和loss一样在Epoch上求平均，这是一个非常灵活而且有用的写法。&#xA;&#xA;class StepRunner:&#xA;    def __init__(self, net, loss_fn, accelerator=None, stage = &#34;train&#34;, metrics_dict = None, &#xA;                 optimizer = None, lr_scheduler = None&#xA;                 ):&#xA;        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage&#xA;        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler&#xA;        self.accelerator = accelerator if accelerator is not None else Accelerator()&#xA;        if self.stage==&#39;train&#39;:&#xA;            self.net.train() &#xA;        else:&#xA;            self.net.eval()&#xA;    &#xA;    def __call__(self, batch):&#xA;        &#xA;        images, targets, input_lengths, target_lengths = batch&#xA;        &#xA;        #loss&#xA;        preds = self.net(images)&#xA;        preds_log_softmax = F.log_softmax(preds, dim=-1)&#xA;        loss = F.ctc_loss(preds_log_softmax, targets, input_lengths, target_lengths)&#xA;        acc = eval_acc(targets,preds)&#xA;            &#xA;&#xA;        #backward()&#xA;        if self.optimizer is not None and self.stage==&#34;train&#34;:&#xA;            self.accelerator.backward(loss)&#xA;            self.optimizer.step()&#xA;            if self.lr_scheduler is not None:&#xA;                self.lr_scheduler.step()&#xA;            self.optimizer.zero_grad()&#xA;            &#xA;            &#xA;        all_loss = self.accelerator.gather(loss).sum()&#xA;        &#xA;        #losses （or plain metric that can be averaged）&#xA;        step_losses = {self.stage+&#34;_loss&#34;:all_loss.item(),&#xA;                       self.stage+&#39;_acc&#39;:acc}&#xA;        &#xA;        #metrics (stateful metric)&#xA;        step_metrics = {}&#xA;        if self.stage==&#34;train&#34;:&#xA;            if self.optimizer is not None:&#xA;                step_metrics[&#39;lr&#39;] = self.optimizer.state_dict()[&#39;param_groups&#39;][0][&#39;lr&#39;]&#xA;            else:&#xA;                step_metrics[&#39;lr&#39;] = 0.0&#xA;        return step_losses,step_metrics&#xA;    &#xA;#覆盖掉默认StepRunner &#xA;KerasModel.StepRunner = StepRunner &#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;可以看到，这种修改实际上是非常简单并且灵活的，保持每个模块的输出与原始实现格式一致就行，中间处理逻辑根据需要灵活调整。&lt;/p&gt; &#xA;&lt;p&gt;同理，用户也可以修改并覆盖EpochRunner来实现自己的特定逻辑，但我一般很少遇到有这样需求的场景。&lt;/p&gt; &#xA;&lt;p&gt;examples目录下的范例库包括了使用torchkeras对一些非常常用的库中的模型进行训练的例子。&lt;/p&gt; &#xA;&lt;p&gt;例如：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;torchvision&lt;/li&gt; &#xA; &lt;li&gt;transformers&lt;/li&gt; &#xA; &lt;li&gt;segmentation_models_pytorch&lt;/li&gt; &#xA; &lt;li&gt;ultralytics&lt;/li&gt; &#xA; &lt;li&gt;timm&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;如果你想掌握一个东西，那么就去使用它，如果你想真正理解一个东西，那么尝试去改变它。 ———— 爱因斯坦&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;example&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;使用模型库&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;notebook&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;RL&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;强化学习——Q-Learning 🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/Q-learning.ipynb&#34;&gt;Q-learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;强化学习——DQN&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/DQN.ipynb&#34;&gt;DQN&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;CV&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;图片分类——Resnet&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/ResNet.ipynb&#34;&gt;Resnet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;语义分割——UNet&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/UNet.ipynb&#34;&gt;UNet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;目标检测——SSD&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/SSD.ipynb&#34;&gt;SSD&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;文字识别——CRNN 🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;-&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/CRNN_CTC.ipynb&#34;&gt;CRNN-CTC&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;目标检测——FasterRCNN&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;torchvision&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/FasterRCNN%E2%80%94%E2%80%94vision.ipynb&#34;&gt;FasterRCNN&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;语义分割——DeepLabV3++&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;segmentation_models_pytorch&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/Deeplabv3plus%E2%80%94%E2%80%94smp.ipynb&#34;&gt;Deeplabv3++&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;实例分割——MaskRCNN&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;detectron2&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/MaskRCNN%E2%80%94%E2%80%94detectron2.ipynb&#34;&gt;MaskRCNN&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;目标检测——YOLOv8 🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;ultralytics&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/YOLOv8%E2%80%94%E2%80%94ultralytics.ipynb&#34;&gt;YOLOv8&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;图片分类——SwinTransformer&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;timm&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/SwinTransformer%E2%80%94%E2%80%94timm.ipynb&#34;&gt;Swin&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;NLP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;文本分类——BERT🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/BERT%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;BERT&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;命名实体识别——BERT&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/BERT_NER%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;BERT_NER&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LLM微调——ChatGLM2_LoRA 🔥🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/ChatGLM2_LoRA%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;ChatGLM2_LoRA&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LLM微调——ChatGLM2_AdaLoRA 🔥🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/ChatGLM2_AdaLoRA%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;ChatGLM2_AdaLoRA&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LLM微调——ChatGLM2_QLoRA 🔥🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/ChatGLM2_QLoRA_Kaggle%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;ChatGLM2_QLoRA_Kaggle&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LLM微调——BaiChuan13B_QLoRA 🔥🔥🔥&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;transformers&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/lyhue1991/torchkeras/master/examples/BaiChuan13B_QLoRA%E2%80%94%E2%80%94transformers.ipynb&#34;&gt;BaiChuan13B_QLoRA&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;7，鼓励和联系作者 🎈🎈&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;如果本项目对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;如果在torchkeras的使用中遇到问题，可以在项目中提交issue。&lt;/p&gt; &#xA;&lt;p&gt;如果想要获得更快的反馈或者与其他torchkeras用户小伙伴进行交流，&lt;/p&gt; &#xA;&lt;p&gt;可以在公众号算法美食屋后台回复关键字：&lt;strong&gt;加群&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>