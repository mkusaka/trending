<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-04-13T02:01:28Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>MLEveryday/practicalAI-cn</title>
    <updated>2025-04-13T02:01:28Z</updated>
    <id>tag:github.com,2025-04-13:/MLEveryday/practicalAI-cn</id>
    <link href="https://github.com/MLEveryday/practicalAI-cn" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AIå®æˆ˜-practicalAI ä¸­æ–‡ç‰ˆ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AIå®æˆ˜-&lt;a href=&#34;https://github.com/LisonEvf/practicalAI-cn&#34;&gt;practicalAI&lt;/a&gt; ä¸­æ–‡ç‰ˆ&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/launch-Google%20Colab-orange.svg?sanitize=true&#34; alt=&#34;Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/LisonEvf/practicalAI-cn/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-brightgreen.svg?sanitize=true&#34; alt=&#34;MIT&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/GokuMohandas&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Author-GokuMohandas-blue.svg?sanitize=true&#34; alt=&#34;Author&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/MLEveryday/practicalAI-cn&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Fork-MLEveryday/practicalAI--cn-yellow.svg?sanitize=true&#34; alt=&#34;Fork&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;è®©ä½ æœ‰èƒ½åŠ›ä½¿ç”¨æœºå™¨å­¦ä¹ ä»æ•°æ®ä¸­è·å–æœ‰ä»·å€¼çš„è§è§£ã€‚&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ”¥ ä½¿ç”¨ &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch&lt;/a&gt; å®ç°åŸºæœ¬çš„æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ·±åº¦ç¥ç»ç½‘ç»œã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ–¥ï¸ ä¸éœ€è¦ä»»ä½•è®¾ç½®ï¼Œåœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨ &lt;a href=&#34;https://colab.research.google.com/&#34;&gt;Google Colab&lt;/a&gt; è¿è¡Œæ‰€æœ‰ç¨‹åºã€‚&lt;/li&gt; &#xA; &lt;li&gt;ğŸ“¦ ä¸ä»…ä»…æ˜¯æ•™ç¨‹ï¼Œè€Œæ˜¯å­¦ä¹ äº§å“çº§çš„é¢å‘å¯¹è±¡æœºå™¨å­¦ä¹ ç¼–ç¨‹ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Notebooks&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;åŸºç¡€&lt;/th&gt; &#xA;   &lt;th&gt;æ·±åº¦å­¦ä¹ &lt;/th&gt; &#xA;   &lt;th&gt;è¿›é˜¶&lt;/th&gt; &#xA;   &lt;th&gt;ä¸»é¢˜&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ““ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/00_Notebooks.ipynb&#34;&gt;Notebooks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ”¥ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/07_PyTorch.ipynb&#34;&gt;PyTorch&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ“š &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/14_Advanced_RNNs.ipynb&#34;&gt;é«˜çº§å¾ªç¯ç¥ç»ç½‘ç»œ Advanced RNNs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ“¸ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/15_Computer_Vision.ipynb&#34;&gt;è®¡ç®—æœºè§†è§‰ Computer Vision&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/01_Python.ipynb&#34;&gt;Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ›ï¸ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/08_Multilayer_Perceptron.ipynb&#34;&gt;å¤šå±‚æ„ŸçŸ¥ Multilayer Perceptrons&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸï¸ Highway and Residual Networks&lt;/td&gt; &#xA;   &lt;td&gt;â° æ—¶é—´åºåˆ—åˆ†æ Time Series Analysis&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ”¢ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/02_NumPy.ipynb&#34;&gt;NumPy&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ” &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/09_Data_and_Models.ipynb&#34;&gt;æ•°æ®å’Œæ¨¡å‹ Data &amp;amp; Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ”® è‡ªç¼–ç å™¨ Autoencoders&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ˜ï¸ Topic Modeling&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ¼ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/03_Pandas.ipynb&#34;&gt;Pandas&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ“¦ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/10_Object_Oriented_ML.ipynb&#34;&gt;é¢å‘å¯¹è±¡çš„æœºå™¨å­¦ä¹  Object-Oriented ML&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ­ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ Generative Adversarial Networks&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ›’ æ¨èç³»ç»Ÿ Recommendation Systems&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ“ˆ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/04_Linear_Regression.ipynb&#34;&gt;çº¿æ€§å›å½’ Linear Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ–¼ï¸ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/11_Convolutional_Neural_Networks.ipynb&#34;&gt;å·ç§¯ç¥ç»ç½‘ç»œ Convolutional Neural Networks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ ç©ºé—´å˜æ¢æ¨¡å‹ Spatial Transformer Networks&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ—£ï¸ é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ Pretrained Language Modeling&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ“Š &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/05_Logistic_Regression.ipynb&#34;&gt;é€»è¾‘å›å½’ Logistic Regression&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ“ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/12_Embeddings.ipynb&#34;&gt;åµŒå…¥å±‚ Embeddings&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ¤· å¤šä»»åŠ¡å­¦ä¹  Multitask Learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸŒ³ &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/06_Random_Forests.ipynb&#34;&gt;éšæœºæ£®æ— Random Forests&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ“— &lt;a href=&#34;https://nbviewer.jupyter.org/github/LisonEvf/practicalAI-cn/blob/master/notebooks/13_Recurrent_Neural_Networks.ipynb&#34;&gt;é€’å½’ç¥ç»ç½‘ç»œ Recurrent Neural Networks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ¯ Low Shot Learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ğŸ’¥ k-å‡å€¼èšç±» KMeans Clustering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ğŸ’ å¼ºåŒ–å­¦ä¹  Reinforcement Learning&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;æŸ¥çœ‹ notebooks&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä¸éœ€è¦è¿è¡Œ notebooksï¼Œä½¿ç”¨ Jupyter nbviewer å°±å¯ä»¥æ–¹ä¾¿åœ°æŸ¥çœ‹å®ƒä»¬ã€‚&lt;/p&gt; &#xA;&lt;p&gt;å°† &lt;code&gt;https://github.com/&lt;/code&gt; æ›¿æ¢ä¸º &lt;code&gt;https://nbviewer.jupyter.org/github/&lt;/code&gt; ï¼Œæˆ–è€…æ‰“å¼€ &lt;code&gt;https://nbviewer.jupyter.org&lt;/code&gt; å¹¶è¾“å…¥ notebook çš„ URLã€‚&lt;/p&gt; &#xA;&lt;h2&gt;è¿è¡Œ notebooks&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;åœ¨æœ¬é¡¹ç›®çš„ &lt;a href=&#34;https://raw.githubusercontent.com/MLEveryday/practicalAI-cn/master/notebooks/&#34;&gt;&lt;code&gt;notebooks&lt;/code&gt;&lt;/a&gt; æ–‡ä»¶å¤¹è·å– notebookï¼›&lt;/li&gt; &#xA; &lt;li&gt;ä½ å¯ä»¥åœ¨ Google Colabï¼ˆæ¨èï¼‰æˆ–æœ¬åœ°ç”µè„‘è¿è¡Œè¿™äº› notebookï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç‚¹å‡»ä¸€ä¸ª notebookï¼Œç„¶åæ›¿æ¢URLåœ°å€ä¸­ &lt;code&gt;https://github.com/&lt;/code&gt; ä¸º &lt;code&gt;https://colab.research.google.com/github/&lt;/code&gt; ï¼Œæˆ–è€…ä½¿ç”¨è¿™ä¸ª &lt;a href=&#34;https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo&#34;&gt;Chromeæ‰©å±•&lt;/a&gt; ä¸€é”®å®Œæˆï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç™»å½•ä½ è‡ªå·±çš„ Google è´¦æˆ·ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç‚¹å‡»å·¥å…·æ ä¸Šçš„ &lt;code&gt;å¤åˆ¶åˆ°äº‘ç«¯ç¡¬ç›˜&lt;/code&gt;ï¼Œä¼šåœ¨ä¸€ä¸ªæ–°çš„æ ‡ç­¾é¡µæ‰“å¼€ notebookï¼›&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MLEveryday/practicalAI-cn/master/images/copy_to_drive.png&#34;&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;é€šè¿‡å»æ‰æ ‡é¢˜ä¸­çš„&lt;code&gt;å‰¯æœ¬&lt;/code&gt;å®Œæˆ notebook é‡å‘½åï¼›&lt;/li&gt; &#xA; &lt;li&gt;è¿è¡Œä»£ç ã€ä¿®æ”¹ç­‰ï¼Œæ‰€æœ‰è¿™äº›éƒ½ä¼šè‡ªåŠ¨ä¿å­˜åˆ°ä½ çš„ä¸ªäºº Google Driveã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;è´¡çŒ® notebooks&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ä¿®æ”¹åä¸‹è½½ Google Colab notebook ä¸º .ipynb æ–‡ä»¶ï¼›&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MLEveryday/practicalAI-cn/master/images/download_ipynb.png&#34;&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;è½¬åˆ° &lt;a href=&#34;https://github.com/LisonEvf/practicalAI-cn/tree/master/notebooks&#34;&gt;https://github.com/LisonEvf/practicalAI-cn/tree/master/notebooks&lt;/a&gt; ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç‚¹å‡» &lt;code&gt;Upload files&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MLEveryday/practicalAI-cn/master/images/upload.png&#34;&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;ä¸Šä¼ è¿™ä¸ª .ipynb æ–‡ä»¶ï¼›&lt;/li&gt; &#xA; &lt;li&gt;å†™ä¸€ä¸ªè¯¦ç»†è¯¦ç»†çš„æäº¤æ ‡é¢˜å’Œè¯´æ˜ï¼›&lt;/li&gt; &#xA; &lt;li&gt;é€‚å½“å‘½åä½ çš„åˆ†æ”¯ï¼›&lt;/li&gt; &#xA; &lt;li&gt;ç‚¹å‡» &lt;code&gt;Propose changes&lt;/code&gt;ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/MLEveryday/practicalAI-cn/master/images/commit.png&#34;&gt; &#xA;&lt;h2&gt;è´¡çŒ®åˆ—è¡¨&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿ä»»ä½•äººå‚ä¸å’Œå®Œå–„ã€‚&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Notebook&lt;/th&gt; &#xA;   &lt;th&gt;è¯‘è€…&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;00_Notebooks.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/amusi&#34;&gt;@amusi&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;01_Python.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/amusi&#34;&gt;@amusi&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;02_NumPy.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/amusi&#34;&gt;@amusi&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;03_Pandas.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/amusi&#34;&gt;@amusi&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;04_Linear_Regression.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jasonhhao&#34;&gt;@jasonhhao&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;05_Logistic_Regression.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jasonhhao&#34;&gt;@jasonhhao&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;06_Random_Forests.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/jasonhhao&#34;&gt;@jasonhhao&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;07_PyTorch.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/amusi&#34;&gt;@amusi&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;08_Multilayer_Perceptron.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zhyongquan&#34;&gt;@zhyongquan&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09_Data_and_Models.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zhyongquan&#34;&gt;@zhyongquan&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10_Object_Oriented_ML.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/zhyongquan&#34;&gt;@zhyongquan&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;11_Convolutional_Neural_Networks.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;12_Embeddings.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/wengJJ&#34;&gt;@wengJJ&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13_Recurrent_Neural_Networks.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;14_Advanced_RNNs.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;15_Computer_Vision.ipynb&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>chiphuyen/aie-book</title>
    <updated>2025-04-13T02:01:28Z</updated>
    <id>tag:github.com,2025-04-13:/chiphuyen/aie-book</id>
    <link href="https://github.com/chiphuyen/aie-book" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[WIP] Resources for AI engineers. Also contains supporting materials for the book AI Engineering (Chip Huyen, 2025)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Engineering book and other resources&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;em&gt;This repo will be updated with more resources in the next few weeks.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/#about-the-book&#34;&gt;About the book AI Engineering&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/ToC.md&#34;&gt;Table of contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/chapter-summaries.md&#34;&gt;Chapter summaries&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/study-notes.md&#34;&gt;Study notes&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/resources.md&#34;&gt;AI engineering resources&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/prompt-examples.md&#34;&gt;Prompt examples&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/case-studies.md&#34;&gt;Case studies&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/misalignment.md&#34;&gt;Misalignment AI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/appendix.md&#34;&gt;Appendix&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fun tools:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/scripts/ai-heatmap.ipynb&#34;&gt;ChatGPT and Claude conversation heatmap generator&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;And more ...&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;About the book&lt;/h2&gt; &#xA;&lt;p&gt;The availability of foundation models has transformed AI from a specialized discipline into a powerful development tool everyone can use. This book covers the end-to-end process of adapting foundation models to solve real-world problems, encompassing tried-and-true techniques from other engineering fields and techniques emerging with foundation models.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://amzn.to/49j1cGS&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/assets/aie-cover.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt;&lt;a href=&#34;https://amzn.to/49j1cGS&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chiphuyen/aie-book/main/assets/aie-cover-back.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The book is available on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://amzn.to/49j1cGS&#34;&gt;Amazon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://oreillymedia.pxf.io/c/5719111/2146021/15173&#34;&gt;O&#39;Reilly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://amzn.to/3Vq2ryu&#34;&gt;Kindle&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;and most places where technical books are sold.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This is NOT a tutorial book, so it doesn&#39;t have a lot of code snippets.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What this book is about&lt;/h2&gt; &#xA;&lt;p&gt;This book provides a framework for adapting foundation models, which include both large language models (LLMs) and large multimodal models (LMMs), to specific applications. It not only outlines various solutions for building an AI application but also raises questions you can ask to evaluate the best solution for your needs. Here are just some of the many questions that this book can help you answer:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Should I build this AI application?&lt;/li&gt; &#xA; &lt;li&gt;How do I evaluate my application? Can I use AI to evaluate AI outputs?&lt;/li&gt; &#xA; &lt;li&gt;What causes hallucinations? How do I detect and mitigate hallucinations?&lt;/li&gt; &#xA; &lt;li&gt;What are the best practices for prompt engineering?&lt;/li&gt; &#xA; &lt;li&gt;Why does RAG work? What are the strategies for doing RAG?&lt;/li&gt; &#xA; &lt;li&gt;Whatâ€™s an agent? How do I build and evaluate an agent?&lt;/li&gt; &#xA; &lt;li&gt;When to finetune a model? When not to finetune a model?&lt;/li&gt; &#xA; &lt;li&gt;How much data do I need? How do I validate the quality of my data?&lt;/li&gt; &#xA; &lt;li&gt;How do I make my model faster, cheaper, and secure?&lt;/li&gt; &#xA; &lt;li&gt;How do I create a feedback loop to improve my application continually?&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The book will also help you navigate the overwhelming AI landscape: types of models, evaluation benchmarks, and a seemingly infinite number of use cases and application patterns.&lt;/p&gt; &#xA;&lt;p&gt;The content in this book is illustrated using actual case studies, many of which Iâ€™ve worked on, backed by ample references and extensively reviewed by experts from a wide range of backgrounds. Even though the book took two years to write, it draws from my experience working with language models and ML systems from the last decade.&lt;/p&gt; &#xA;&lt;p&gt;Like my previous book, &lt;em&gt;&lt;a href=&#34;https://amzn.to/4fXVZH2&#34;&gt;Designing Machine Learning Systems (DMLS)&lt;/a&gt;&lt;/em&gt;, this book focuses on the fundamentals of AI engineering instead of any specific tool or API. Tools become outdated quickly, but fundamentals should last longer.&lt;/p&gt; &#xA;&lt;h3&gt;Reading &lt;em&gt;AI Engineering&lt;/em&gt; (AIE) with &lt;em&gt;Designing Machine Learning Systems&lt;/em&gt; (DMLS)&lt;/h3&gt; &#xA;&lt;p&gt;AIE can be a companion to DMLS. DMLS focuses on building applications on top of traditional ML models, which involves more tabular data annotations, feature engineering, and model training. AIE focuses on building applications on top of foundation models, which involves more prompt engineering, context construction, and parameter-efficient finetuning. Both books are self-contained and modular, so you can read either book independently.&lt;/p&gt; &#xA;&lt;p&gt;Since foundation models are ML models, some concepts are relevant to working with both. If a topic is relevant to AIE but has been discussed extensively in DMLS, itâ€™ll still be covered in this book, but to a lesser extent, with pointers to relevant resources.&lt;/p&gt; &#xA;&lt;p&gt;Note that many topics are covered in DMLS but not in AIE, and vice versa. The first chapter of this book also covers the differences between traditional ML engineering and AI engineering.&lt;/p&gt; &#xA;&lt;p&gt;A real-world system often involves both traditional ML models and foundation models, so knowledge about working with both is often necessary.&lt;/p&gt; &#xA;&lt;h2&gt;Who this book is for&lt;/h2&gt; &#xA;&lt;p&gt;This book is for anyone who wants to leverage foundation models to solve real-world problems. This is a technical book, so the language of this book is geared towards technical roles, including AI engineers, ML engineers, data scientists, engineering managers, and technical product managers. This book is for you if you can relate to one of the following scenarios:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Youâ€™re building or optimizing an AI application, whether youâ€™re starting from scratch or looking to move beyond the demo phase into a production-ready stage. You may also be facing issues like hallucinations, security, latency, or costs, and need targeted solutions.&lt;/li&gt; &#xA; &lt;li&gt;You want to streamline your teamâ€™s AI development process, making it more systematic, faster, and reliable.&lt;/li&gt; &#xA; &lt;li&gt;You want to understand how your organization can leverage foundation models to improve the businessâ€™s bottom line and how to build a team to do so.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can also benefit from the book if you belong to one of the following groups:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Tool developers who want to identify underserved areas in AI engineering to position your products in the ecosystem.&lt;/li&gt; &#xA; &lt;li&gt;Researchers who want to understand better AI use cases.&lt;/li&gt; &#xA; &lt;li&gt;Job candidates seeking clarity on the skills needed to pursue a career as an AI engineer.&lt;/li&gt; &#xA; &lt;li&gt;Anyone wanting to better understand AI&#39;s capabilities and limitations, and how it might affect different roles.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;I love getting to the bottom of things, so some sections dive a bit deeper into the technical side. While many early readers like the detail, I know it might not be for everyone. Iâ€™ll give you a heads-up before things get too technical. Feel free to skip ahead if it feels a little too in the weeds!&lt;/p&gt; &#xA;&lt;h2&gt;Reviews&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;This book offers a comprehensive, well-structured guide to the essential aspects of building generative AI systems. A must-read for any professional looking to scale AI across the enterprise.&#34;&lt;/em&gt; - Vittorio Cretella, former global CIO at P&amp;amp;G and Mars&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;Chip Huyen gets generative AI. She is a remarkable teacher and writer whose work has been instrumental in helping teams bring AI into production. Drawing on her deep expertise, AI Engineering is a comprehensive and holistic guide to building generative AI applications in production.&#34;&lt;/em&gt; - Luke Metz, co-creator of ChatGPT, ex-research manager @ OpenAI&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;Every AI engineer building real-world applications should read this book. Itâ€™s a vital guide to end-to-end AI system design, from model development and evaluation to large-scale deployment and operation.&#34;&lt;/em&gt; - Andrei Lopatenko, Director Search and AI, Neuron7&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;This book serves as an essential guide for building AI products that can scale. Unlike other books that focus on tools or current trends that are constantly changing, Chip delivers timeless foundational knowledge. Whether you&#39;re a product manager or an engineer, this book effectively bridges the collaboration gap between cross-functional teams, making it a must-read for anyone involved in AI development.&#34;&lt;/em&gt; - Aileen Bui, AI Product Operations Manager, Google&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;This is the definitive segue into AI Engineering from one of the greats of ML Engineering! Chip has seen through successful projects and careers at every stage of a company and for the first time ever condensed her expertise for new AI Engineers entering the field.&#34;&lt;/em&gt; - swyx, Curator, AI.Engineer&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;AI Engineering is a practical guide that provides the most up-to-date information on AI development, making it approachable for novice and expert leaders alike. This book is an essential resource for anyone looking to build robust and scalable AI systems.&#34;&lt;/em&gt; - Vicki Reyzelman, Chief AI Solutions Architect, Mave Sparks&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;AI Engineering is a comprehensive guide that serves as an essential reference for both understanding and implementing AI systems in practice.&#34;&lt;/em&gt; - Han Lee, Director - Data Science, Moody&#39;s.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&#34;AI Engineering is an essential guide for anyone building software with Generative AI! It demystifies the technology, highlights the importance of evaluation, and shares what should be done to achieve quality before starting with costly fine-tuning.&#34;&lt;/em&gt; - Rafal Kawala, Senior AI Engineering Director, 16 years of experience working in a Fortune 500 company&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See what people are talking about the book on Twitter &lt;a href=&#34;https://twitter.com/aisysbooks/likes&#34;&gt;@aisysbooks&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgments&lt;/h2&gt; &#xA;&lt;p&gt;This book would&#39;ve taken a lot longer to write and missed many important topics if it wasn&#39;t for so many wonderful people who helped me through the process.&lt;/p&gt; &#xA;&lt;p&gt;Because the timeline for the project was tightâ€”two years for a 150,000-word book that covers so much groundâ€”I&#39;m grateful to the technical reviewers who put aside their precious time to review this book so quickly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://x.com/luke_metz&#34;&gt;Luke Metz&lt;/a&gt; is an amazing soundboard who checked my assumptions and prevented me from going down the wrong path. &lt;a href=&#34;https://www.linkedin.com/in/hanchunglee/&#34;&gt;Han-chung Lee&lt;/a&gt;, always up to date with the latest AI news and community development, pointed me toward resources that I missed. Luke and Han were the first to review my drafts before I sent them to the next round of technical reviewers, and I&#39;m forever indebted to them for tolerating my follies and mistakes.&lt;/p&gt; &#xA;&lt;p&gt;Having led AI innovation at Fortune 500 companies, &lt;a href=&#34;https://www.linkedin.com/in/vittorio-cretella/&#34;&gt;Vittorio Cretella&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/lopatenko/&#34;&gt;Andrei Lopatenko&lt;/a&gt; provided invaluable feedback that combined deep technical expertise with executive insights. &lt;a href=&#34;https://www.linkedin.com/in/vickireyzelman/&#34;&gt;Vicki Reyzelman&lt;/a&gt; helped me ground my content and keep it relevant for readers with a software engineering background.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://eugeneyan.com/&#34;&gt;Eugene Yan&lt;/a&gt;, a dear friend and amazing applied scientist, provided me with technical and emotional support. Shawn Wang (&lt;a href=&#34;https://x.com/swyx&#34;&gt;swyx&lt;/a&gt;), provided an important vibe check that helped me feel more confident about the book. &lt;a href=&#34;https://x.com/bhutanisanyam1&#34;&gt;Sanyam Bhutani&lt;/a&gt; is one of the best learners and most humble souls I know, who not only gave thoughtful written feedback but also recorded videos to explain his feedback.&lt;/p&gt; &#xA;&lt;p&gt;Kyle Krannen is a star deep learning lead who interviewed his colleagues and shared with me an amazing writeup about their finetuning process, which guided the finetuning chapter. &lt;a href=&#34;https://x.com/marksaroufim&#34;&gt;Mark Saroufim&lt;/a&gt;, an inquisitive mind who always has his pulse on the most interesting problems, introduced me to great resources on efficiency. Both Kyle and Mark&#39;s feedback was critical in writing Chapters 7 and 9.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/kittipat-bot-kampa-1b1965/&#34;&gt;Kittipat &#34;Bot&#34; Kampa&lt;/a&gt;, on top of answering my many questions, shared with me a detailed visualization of how he thinks about AI platform. I appreciate &lt;a href=&#34;https://www.linkedin.com/in/denyslinkov/&#34;&gt;Denys Linkov&lt;/a&gt;&#39;s systematic approach to evaluation and platform development. &lt;a href=&#34;https://www.linkedin.com/in/chetantekur/&#34;&gt;Chetan Tekur&lt;/a&gt; gave great examples that helped me structure AI application patterns. I&#39;d also like to thank &lt;a href=&#34;https://www.linkedin.com/in/findalexli/&#34;&gt;Alex (Shengzhi Li) Li&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/hienluu/&#34;&gt;Hien Luu&lt;/a&gt; for their thoughtful feedback on my draft on AI architecture.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/aileenbui/&#34;&gt;Aileen Bui&lt;/a&gt; is a treasure who shared unique feedback and examples from a product manager&#39;s perspective. Thanks &lt;a href=&#34;https://www.linkedin.com/in/todor-markov-4aa38a67/&#34;&gt;Todor Markov&lt;/a&gt; for the actionable advice on the RAG and Agents chapter. Thanks &lt;a href=&#34;https://www.linkedin.com/in/tal-kachman/&#34;&gt;Tal Kachman&lt;/a&gt; for jumping in at the last minute to push the finetuning chapter over the finish line.&lt;/p&gt; &#xA;&lt;p&gt;There are so many wonderful people whose company and conversations gave me ideas that guide the content of this book. I tried my best to include the names of everyone who has helped me here, but due to the inherent faultiness of human memory, I undoubtedly neglected to mention many. If I forgot to include your name, please know that it wasn&#39;t because I don&#39;t appreciate your contribution, and please kindly remind me so that I can rectify as soon as possible!&lt;/p&gt; &#xA;&lt;p&gt;Andrew Francis, Anish Nag, &lt;a href=&#34;https://www.linkedin.com/in/wgalczak/&#34;&gt;Anthony Galczak&lt;/a&gt;, &lt;a href=&#34;https://x.com/abacaj&#34;&gt;Anton Bacaj&lt;/a&gt;, BalÃ¡zs Galambosi, Charles Frye, Charles Packer, Chris Brousseau, Eric Hartford, Goku Mohandas, Hamel Husain, Harpreet Sahota, Hassan El Mghari, Huu Nguyen, Jeremy Howard, Jesse Silver, John Cook, &lt;a href=&#34;https://www.linkedin.com/in/juan-pablo-bottaro/&#34;&gt;Juan Pablo Bottaro&lt;/a&gt;, Kyle Gallatin, Lance Martin, Lucio Dery, Matt Ross, Maxime Labonne, Miles Brundage, Nathan Lambert, Omar Khattab, &lt;a href=&#34;https://www.linkedin.com/in/xphongvn/&#34;&gt;Phong Nguyen&lt;/a&gt;, Purnendu Mukherjee, Sam Reiswig, Sebastian Raschka, Shahul ES, Sharif Shameem, Soumith Chintala, Teknium, Tim Dettmers, Undi5, Val Andrei Fajardo, Vern Liang, Victor Sanh, Wing Lian, Xiquan Cui, Ying Sheng, and Kristofer.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;d like to thank all early readers who have also reached out with feedback. Douglas Bailley is a super reader who shared so much thoughtful feedback. Nutan Sahoo for suggesting an elegant way to explain perplexity.&lt;/p&gt; &#xA;&lt;p&gt;I learned so much from the online discussions with so many. Thanks to everyone who&#39;s ever answered my questions, commented on my posts, or sent me an email with your thoughts.&lt;/p&gt; &#xA;&lt;p&gt;Of course, the book wouldn&#39;t have been possible without the team at O&#39;Reilly, especially my development editors (Melissa Potter, Corbin Collins, Jill Leonard) and my production editors (Kristen Brown and Elizabeth Kelly). Liz Wheeler is the most discerning editor I&#39;ve ever worked with. Nicole Butterfield is a force who oversaw this book from an idea to a final product.&lt;/p&gt; &#xA;&lt;p&gt;This book, after all, is an accumulation of invaluable lessons I learned throughout my career. I owe these lessons to my extremely competent and patient coworkers and former coworkers. Every person I&#39;ve worked with has taught me something new about bringing ML into the world.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Chip Huyen, &lt;em&gt;AI Engineering&lt;/em&gt;. O&#39;Reilly Media, 2025.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@book{aiebook2025,  &#xA;    address = {USA},  &#xA;    author = {Chip Huyen},  &#xA;    isbn = {978-1801819312},   &#xA;    publisher = {O&#39;Reilly Media},  &#xA;    title = {{AI Engineering}},  &#xA;    year = {2025}  &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>meta-llama/llama-cookbook</title>
    <updated>2025-04-13T02:01:28Z</updated>
    <id>tag:github.com,2025-04-13:/meta-llama/llama-cookbook</id>
    <link href="https://github.com/meta-llama/llama-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Welcome to the Llama Cookbook! This is your go to guide for Building with Llama: Getting started with Inference, Fine-Tuning, RAG. We also show you how to solve end to end problems using Llama model family and using them on various provider services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama Cookbook: The Official Guide to building with Llama Models&lt;/h1&gt; &#xA;&lt;p&gt;Checkout our latest model tutorial here: &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/build_with_llama_4.ipynb&#34;&gt;Build with Llama 4 Scout&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Welcome to the official repository for helping you get started with &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/inference/&#34;&gt;inference&lt;/a&gt;, &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/finetuning&#34;&gt;fine-tuning&lt;/a&gt; and &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/end-to-end-use-cases&#34;&gt;end-to-end use-cases&lt;/a&gt; of building with the Llama Model family.&lt;/p&gt; &#xA;&lt;p&gt;This repository covers the most popular community approaches, use-cases and the latest recipes for Llama Text and Vision models.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Popular getting started links:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/build_with_llama_4.ipynb&#34;&gt;Build with Llama 4 Scout&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/inference/local_inference/README.md#multimodal-inference&#34;&gt;Multimodal Inference with Llama 3.2 Vision&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/responsible_ai/llama_guard/&#34;&gt;Inferencing using Llama Guard (Safety Model)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Popular end to end recipes:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/end-to-end-use-cases/email_agent/&#34;&gt;Email Agent&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/end-to-end-use-cases/NotebookLlama/&#34;&gt;NotebookLlama&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/end-to-end-use-cases/coding/text2sql/&#34;&gt;Text to SQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: We recently did a refactor of the repo, &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/archive-main&#34;&gt;archive-main&lt;/a&gt; is a snapshot branch from before the refactor&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Repository Structure:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/3p-integrations&#34;&gt;3P Integrations&lt;/a&gt;: Getting Started Recipes and End to End Use-Cases from various Llama providers&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/end-to-end-use-cases&#34;&gt;End to End Use Cases&lt;/a&gt;: As the name suggests, spanning various domains and applications&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/getting-started/&#34;&gt;Getting Started&lt;/a&gt;: Reference for inferencing, fine-tuning and RAG examples&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/src/&#34;&gt;src&lt;/a&gt;: Contains the src for the original llama-recipes library along with some FAQs for fine-tuning.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ:&lt;/h2&gt; &#xA;&lt;h2&gt;FAQ:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; What happened to llama-recipes? &lt;strong&gt;A:&lt;/strong&gt; We recently renamed llama-recipes to llama-cookbook.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Prompt Template changes for Multi-Modality? &lt;strong&gt;A:&lt;/strong&gt; Llama 3.2 follows the same prompt template as Llama 3.1, with a new special token &lt;code&gt;&amp;lt;|image|&amp;gt;&lt;/code&gt; representing the input image for the multimodal models. More details on the prompt templates for image reasoning, tool-calling, and code interpreter can be found &lt;a href=&#34;https://www.llama.com/docs/overview&#34;&gt;on the documentation website&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; I have some questions for Fine-Tuning, is there a section to address these? &lt;strong&gt;A:&lt;/strong&gt; Checkout the Fine-Tuning FAQ &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/main/src/docs/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Some links are broken/folders are missing: &lt;strong&gt;A:&lt;/strong&gt; We recently did a refactor of the repo, &lt;a href=&#34;https://github.com/meta-llama/llama-cookbook/tree/archive-main&#34;&gt;archive-main&lt;/a&gt; is a snapshot branch from before the refactor.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt; Where can we find details about the latest models? &lt;strong&gt;A:&lt;/strong&gt; Official &lt;a href=&#34;https://www.llama.com&#34;&gt;Llama models website&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;!-- markdown-link-check-disable --&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.1 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- markdown-link-check-enable --&gt;</summary>
  </entry>
</feed>