<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Weekly Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-21T01:56:11Z</updated>
  <subtitle>Weekly Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>s4afa451dgf415f/colab_stable_diffusion</title>
    <updated>2023-05-21T01:56:11Z</updated>
    <id>tag:github.com,2023-05-21:/s4afa451dgf415f/colab_stable_diffusion</id>
    <link href="https://github.com/s4afa451dgf415f/colab_stable_diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;strong&gt;colab_stable_diffusion_webui&lt;/strong&gt;&lt;/h1&gt; &#xA;&lt;p&gt;-&lt;a href=&#34;https://colab.research.google.com/github/s4afa451dgf415f/colab_stable_diffusion/blob/main/%E4%BA%91stable_diffusion(%E4%BF%AE%E5%A4%8D%E6%8C%96%E7%9F%BF%E5%AB%8C%E7%96%91).ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?message=Open%20in%20Colab&amp;amp;logo=googlecolab&amp;amp;labelColor=5c5c5c&amp;amp;color=0f80c1&amp;amp;label=%20&amp;amp;style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;h3&gt;关于谷歌colab&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;请确认有可以魔法上网的工具，工具用于谷歌colab的机器学习，属于合法范畴。&lt;/li&gt; &#xA; &lt;li&gt;优势：不需要显卡，手机也能用，且云端运行速度快。&lt;/li&gt; &#xA; &lt;li&gt;此项目为免费开源项目，并将持续维护更新。如果有任何广告动机请举报&lt;/li&gt; &#xA; &lt;li&gt;由于人数较多，谷歌colab每个号的时间大概为4-6小时左右，多弄几个号在云盘里主号的json给其他号添加编辑权限就实现了所有号共用&lt;/li&gt; &#xA; &lt;li&gt;一天内第一次启动过程约7分钟左右下载插件模型依赖，请耐心等待。之后如果再启动就非常快。&lt;/li&gt; &#xA; &lt;li&gt;你也可以电脑魔法上网colab，手机直接打开代码运行后给出的域名就行。&lt;/li&gt; &#xA; &lt;li&gt;谷歌运行环境为12G 内存15G显存，大显存小内存所以推荐使用半精度进行计算&lt;/li&gt; &#xA; &lt;li&gt;教程可以点击链接:&lt;a href=&#34;https://www.bilibili.com/video/BV17h4y1J79g/?spm_id_from=333.788.top_right_bar_window_history.content.click&#34;&gt;https://www.bilibili.com/video/BV17h4y1J79g/?spm_id_from=333.788.top_right_bar_window_history.content.click&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;mod管理单元中lora和checkpoint只需填下载地址即可，你也可以添加一些信息方便管理。&lt;/li&gt; &#xA; &lt;li&gt;笔记本为单线程，请保证4、单元格处于未运行状态再管理mod。&lt;/li&gt; &#xA; &lt;li&gt;mod管理时建议mod名以&#34;c站mod名（自定义中文名）&#34;的形式进行命名，这样既可以方便搜索c站的sd图，又方便在使用时在lora列表进行搜索&lt;/li&gt; &#xA; &lt;li&gt;新人不知道下哪些模型可以去推荐模型文档单元下载json文件。&lt;/li&gt; &#xA; &lt;li&gt;自定义的vae与插件请在云盘新建文件夹VAE与extensions并自行管理。&lt;/li&gt; &#xA; &lt;li&gt;晚高峰人数较多，提示连接出错或断线为正常情况，可以尝试使用ngrok管道进行加速。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;关于sd&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果图片信息读取图片“不是一张stable diffusion图片”说明作者上传的图片经过了压缩处理，请选择其他图片或者复制文字与种子手动输入&lt;/li&gt; &#xA; &lt;li&gt;采样方法推荐 DDIM 与DPM++ 2M 高清放大推荐 潜变量(bicubic)与潜变量最邻近&lt;/li&gt; &#xA; &lt;li&gt;图片可以选择输出在云盘的outputs文件夹里&lt;/li&gt; &#xA; &lt;li&gt;生成图的速度与执行代码的速度与网速无关，你就算断网几分钟他也在执行&lt;/li&gt; &#xA; &lt;li&gt;如果要使用手机进行局部绘图请使用Edge浏览器，谷歌浏览器不兼容&lt;/li&gt; &#xA; &lt;li&gt;there&#39;s not enough precision to represent the picture的解决方式是切换其他VAE，或者4、运行时勾选全精度，但生成图的速度会下降一半&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Update?&lt;/h2&gt; &#xA;&lt;h3&gt;v2.0.5(23/05/19)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;torch问题已修复&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.5 (23/05/14)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;优化了下载。用LCS算法对mod的下载进行最小化更新&lt;/li&gt; &#xA; &lt;li&gt;增加sd原版ui下暗配色为可选启动项&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.4 (23/05/12)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加openpose3d插件&lt;/li&gt; &#xA; &lt;li&gt;增加推荐mod文档下载单元格&lt;/li&gt; &#xA; &lt;li&gt;增加自定义插件和vae方法&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.4 (23/05/09)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加了不挂载云盘运行的选项&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.3 (23/05/03)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;根据大版本更新修复了脚本&lt;/li&gt; &#xA; &lt;li&gt;默认UI改回&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Automatic111&lt;/a&gt;，anapnoe为可选择&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.2 (23/04/29)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;内存泄露问题已解决&lt;/li&gt; &#xA; &lt;li&gt;优化了mod管理单元的交互，支持切换文档了&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.1 (23/04/27)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;改用了更好更适配的ui系统，来源&lt;a href=&#34;https://github.com/anapnoe/stable-diffusion-webui-ux&#34;&gt;anapnoe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;用指令一定程度解决了mod切换内存不足的问题&lt;/li&gt; &#xA; &lt;li&gt;解决了图生图某些特定尺寸无法生成的问题&lt;/li&gt; &#xA; &lt;li&gt;配置了ngrok加速&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.2.0.0 (23/04/27)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;增加了mod增删改查系统&lt;/li&gt; &#xA; &lt;li&gt;重构mod下载模块，不需要再用云盘保存mod&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.1.1.4 (23/04/24)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;更新了controlnet 1.1&lt;/li&gt; &#xA; &lt;li&gt;增加部分了自定义设置&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.1.1.3 (23/04/21)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;修复了出现怀疑挖矿提示框的问题&lt;/li&gt; &#xA; &lt;li&gt;部分单元格采用异步下载提高执行效率&lt;/li&gt; &#xA; &lt;li&gt;默认大模型换成了&lt;a href=&#34;https://civitai.com/api/download/models/33482&#34;&gt;Dark Sushi Mix&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;controlNet控制模型默认数量变为3&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.1.1.2 (23/04/17)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;修复了手机局部绘图图片width过大的问题&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;v.1.1.1 (23/04/12)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;更新了&lt;a href=&#34;https://www.bilibili.com/video/BV1tg4y137mt/?spm_id_from=333.880.my_history.page.click&amp;amp;vd_source=931a87555c05909a4816745522b3ce74&#34;&gt;CN_tag_trans&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;增加了从png_info图片秒读秒填充的功能&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>SociallyIneptWeeb/LanguageLeapAI</title>
    <updated>2023-05-21T01:56:11Z</updated>
    <id>tag:github.com,2023-05-21:/SociallyIneptWeeb/LanguageLeapAI</id>
    <link href="https://github.com/SociallyIneptWeeb/LanguageLeapAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Your Personal Multilingual AI Translator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LanguageLeapAI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docs/screenshots/LanguageLeapAI_logo.png?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LEAP across Language barriers by using AI to converse with other online users from across the globe! &lt;strong&gt;LanguageLeapAI&lt;/strong&gt; aims to provide you a real-time language AI assistant that can understand and speak your desired language fluently. &lt;em&gt;(Targeted towards English to Japanese and German as of right now)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Setup Guide: &lt;a href=&#34;https://www.youtube.com/watch?v=bN5UaEkIPGM&#34;&gt;https://www.youtube.com/watch?v=bN5UaEkIPGM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Showcase: &lt;a href=&#34;https://www.youtube.com/watch?v=UY7sRB60wZ4&#34;&gt;https://www.youtube.com/watch?v=UY7sRB60wZ4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Integration of AI Entities&lt;/h2&gt; &#xA;&lt;p&gt;This project integrates 3 free and open-source AI systems:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/whisper&#34;&gt;WhisperAI&lt;/a&gt;: General-purpose Speech Recognition Model developed by OpenAI that can perform multilingual speech recognition.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.deepl.com/translator&#34;&gt;DeepL Translator&lt;/a&gt;: Powered by neural networks and the latest AI innovations for natural-sounding translations&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://voicevox.hiroshiba.jp/&#34;&gt;Voicevox&lt;/a&gt;: Japanese Deep-Learning AI Voice Synthesizer&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;WhisperAI and Voicevox both have docker images available on DockerHub, so we will be building and running them both via a &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docker-compose.yml&#34;&gt;Docker Compose file&lt;/a&gt;. DeepL can be interacted with by signing up for a free plan and interacting with its &lt;a href=&#34;https://www.deepl.com/pro-api?cta=header-pro-api/&#34;&gt;REST API&lt;/a&gt; up to 500,000 character limit / month. If DeepL is unavailable in your country, an option to use Google Translate instead is available.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docs/screenshots/ai_integrations.png?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How it works&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;LanguageLeapAI&lt;/strong&gt; is made up of 2 main python programs.&lt;/p&gt; &#xA;&lt;h3&gt;Voice Translator&lt;/h3&gt; &#xA;&lt;p&gt;The first, &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/voice_translator.py&#34;&gt;voice_translator.py&lt;/a&gt;, records your microphone whenever a push-to-talk key is held down on the keyboard. Once this key is released, it saves your voice in an audio file which is then sent to WhisperAI&#39;s transcribe endpoint which runs Automatic Speech Recognition (ASR) on it. After a response containing your speech as text is received, this text is then translated using DeepL&#39;s REST API.&lt;/p&gt; &#xA;&lt;p&gt;The translated text is then sent to Voicevox which performs text-to-speech and generates an audio file voiced in Japanese. This file is then played to your target application&#39;s microphone input and your speakers/headphones.&lt;/p&gt; &#xA;&lt;p&gt;Since Voicevox only takes in Japanese text as input and generates speech in Japanese, the project is technically only limited to Japanese as the target language. However, Voicevox can be replaced with any other text to speech program that can speak your desired language for limitless possibilities.&lt;/p&gt; &#xA;&lt;p&gt;Thorsten has been added as a German TTS program.&lt;/p&gt; &#xA;&lt;h3&gt;Audio Subtitler&lt;/h3&gt; &#xA;&lt;p&gt;The second, &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/subtitler.py&#34;&gt;subtitler.py&lt;/a&gt;, records your application&#39;s audio output and listens in the background for any speech. Once it has detected that a phrase/sentence is complete, it saves the audio into a wav file and sends it to WhisperAI&#39;s translate endpoint which translates the speech from the target language to English.&lt;/p&gt; &#xA;&lt;p&gt;This English text is then displayed on screen using python&#39;s tkinter module, essentially acting as subtitles.&lt;/p&gt; &#xA;&lt;h2&gt;Applications&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;LanguageLeapAI&#39;s&lt;/strong&gt; target audience is for users who want to chat with another but do not speak the same language. An example is an English-speaking user playing an online game in the Japan server but wants to use voice chat despite not knowing Japanese.&lt;/p&gt; &#xA;&lt;p&gt;By running both &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/subtitler.py&#34;&gt;subtitler.py&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/voice_translator.py&#34;&gt;voice_translator.py&lt;/a&gt;, they can understand their fellow Japanese teammates by reading the english subtitles generated in real time. They can also speak English and the Japanese teammates will instead hear the translated Japanese speech generated by Voicevox.&lt;/p&gt; &#xA;&lt;p&gt;However, this is not the only application of &lt;strong&gt;LanguageLeapAI&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Only using Audio Subtitler&lt;/h3&gt; &#xA;&lt;p&gt;User simply wants to understand what is being said with no need to speak. E.g. Watching a video / stream / movie in another language without subtitles. The user can choose to not run &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/voice_translator.py&#34;&gt;voice_translator.py&lt;/a&gt; and simply use &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/subtitler.py&#34;&gt;subtitler.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Only using Voice Translator&lt;/h3&gt; &#xA;&lt;p&gt;User understands the language enough to listen and understand, but is afraid to speak the language for various reasons, e.g. Anonymity / Fear of messing up or offending. The user can choose to not run &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/subtitler.py&#34;&gt;subtitler.py&lt;/a&gt; and simply use &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/voice_translator.py&#34;&gt;voice_translator.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Setting up &lt;strong&gt;LanguageLeapAI&lt;/strong&gt; requires 3 crucial steps, so don&#39;t miss out on any of them!&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docs/INSTALLATION.md&#34;&gt;Installing Services and Dependencies&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docs/AUDIO.md&#34;&gt;Audio Routing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docs/ENV.md&#34;&gt;Writing your Environment file&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To run &lt;strong&gt;LanguageLeapAI&lt;/strong&gt;, you need to first run WhisperAI and Voicevox. They can either be run via Docker or using Google Colab.&lt;/p&gt; &#xA;&lt;h3&gt;Google Colab&lt;/h3&gt; &#xA;&lt;p&gt;If your GPU is not powerful enough, you may want to consider running WhisperAI and Voicevox using Google Colab&#39;s GPU.&lt;/p&gt; &#xA;&lt;p&gt;Upload &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/run_whisper_n_voicevox.ipynb&#34;&gt;run_whisper_n_voicevox.ipynb&lt;/a&gt; file to Google drive, open the notebook with Google Colab and simply follow the instructions!&lt;/p&gt; &#xA;&lt;p&gt;To run only whisper or voicevox on the cloud: Use either the &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/run_whisper_colab.ipynb&#34;&gt;run_whisper_colab.ipynb&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src/run_voicevox_colab.ipynb&#34;&gt;run_voicevox_colab.ipynb&lt;/a&gt; Colab files instead!&lt;/p&gt; &#xA;&lt;h3&gt;Docker&lt;/h3&gt; &#xA;&lt;h4&gt;Voicevox - JA&lt;/h4&gt; &#xA;&lt;p&gt;If you still want to run both Whisper and Voicevox on your computer, run these commands in the folder containing the &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docker-compose.yml&#34;&gt;docker-compose.yml&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;To run both WhisperAI and Voicevox:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To stop running the containers:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker-compose down&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re running Windows Subsystem for Linux (WSL) don&#39;t forget to shut it down to reclaim your ram. This should only after you have stopped the containers and are done using the program.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;wsl --shutdown&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h4&gt;TTS Thorsten - DE&lt;/h4&gt; &#xA;&lt;p&gt;If you want to run a German version of Voicevox, you need to change the docker-compose file to the corresponding &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/docker-compose-de.yml&#34;&gt;one&lt;/a&gt;. The TTS is the only thing that&#39;s changing, so make sure to also change the &lt;code&gt;TARGET_LANGUAGE_CODE&lt;/code&gt; in your &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/.env.sample&#34;&gt;.env&lt;/a&gt; file.&lt;/p&gt; &#xA;&lt;p&gt;To run both WhisperAI and Thorsten:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker-compose -f docker-compose-de.yml up -d&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To stop running the containers:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;docker-compose down&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Python Program&lt;/h3&gt; &#xA;&lt;p&gt;Run these commands in the &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/src&#34;&gt;src/&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;p&gt;To run the Audio Subtitler:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python subtitler.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To run the Voice Translator:&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;python voice_translator.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To stop the python scripts, simply press &lt;code&gt;Ctrl+C&lt;/code&gt; in the terminal.&lt;/p&gt; &#xA;&lt;h3&gt;Things to note&lt;/h3&gt; &#xA;&lt;p&gt;Some important things to keep in mind while using &lt;strong&gt;LanguageLeapAI&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Whisper&#39;s inconsistency&lt;/h4&gt; &#xA;&lt;p&gt;Do note that WhisperAI is not exactly the most accurate and will not transcribe speech correctly 100% of the time, so use at your own risk. Until OpenAI decides to improve the dataset that was used to train the Whisper models, this will have to do.&lt;/p&gt; &#xA;&lt;p&gt;Also, Whisper is not designed to handle multiple concurrent requests at once. However, for subtitles to be updated in time, multiple requests are being sent asynchronously, so some requests might return an error.&lt;/p&gt; &#xA;&lt;h4&gt;Antivirus Web Protection&lt;/h4&gt; &#xA;&lt;p&gt;If you are running Whisper and Voicevox on the cloud using Google Colab, since we are using ngrok and localtunnel to host our services, the randomised public IP address that they provide might be blacklisted by your antivirus software. If the AI seems to stop working, it may be due to your antivirus blocking the connections to these public IP addresses. You may whitelist these IP addresses or just turn off your antivirus web protection &lt;strong&gt;at your own risk&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h4&gt;Voicevox voices&lt;/h4&gt; &#xA;&lt;p&gt;There are certain terms and conditions for using the voices from Voicevox, so do read up on &lt;a href=&#34;https://voicevox.hiroshiba.jp/&#34;&gt;these&lt;/a&gt; before using a specific speaker.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The code of LanguageLeapAI is released under the MIT License. See &lt;a href=&#34;https://raw.githubusercontent.com/SociallyIneptWeeb/LanguageLeapAI/main/LICENSE&#34;&gt;LICENSE&lt;/a&gt; for further details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>google/generative-ai-docs</title>
    <updated>2023-05-21T01:56:11Z</updated>
    <id>tag:github.com,2023-05-21:/google/generative-ai-docs</id>
    <link href="https://github.com/google/generative-ai-docs" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Generative AI Documentation&lt;/h1&gt; &#xA;&lt;p&gt;These are the source files for the guide and tutorials on the &lt;a href=&#34;https://developers.generativeai.google/&#34;&gt;Generative AI developer site&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To contribute to the site documentation, please read &lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-docs/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To file an issue, please use the &lt;a href=&#34;https://github.com/google/generative-ai-docs/issues/new&#34;&gt;GitHub issue tracker&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/google/generative-ai-docs/main/LICENSE&#34;&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>