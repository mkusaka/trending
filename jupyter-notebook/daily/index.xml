<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-24T01:33:13Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>MetaGLM/glm-cookbook</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/MetaGLM/glm-cookbook</id>
    <link href="https://github.com/MetaGLM/glm-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Zhipu API series cookbook&lt;/p&gt;&lt;hr&gt;&lt;h1&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/asset/glm.png&#34; alt=&#34;glm&#34; style=&#34;height: 1.5em; vertical-align: bottom;&#34;&gt; glm-cookbook &lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/README_en.md&#34;&gt;Read this in English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;欢迎来到 GLM API 模型入门仓库📘。这是一本开源的 GLM API 入门代码教材。&lt;/p&gt; &#xA;&lt;p&gt;在这里，你会发现丰富的 &lt;strong&gt;代码示例👨‍&lt;/strong&gt;、&lt;strong&gt;实用指南🗺&lt;/strong&gt;️ 以及 &lt;strong&gt;资源链接🔗&lt;/strong&gt;，或许能帮助你轻松掌握 GLM API 的使用！&lt;/p&gt; &#xA;&lt;h2&gt;更新情况 🔥&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;🔥 2024-03-18: 仓库开始更新 &lt;a href=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/Users/zr/Code/glm-cookbook/glms&#34;&gt;智谱清言&lt;/a&gt; 基础开发者教学文档，基础提示词文档 和 智能体文档 已经在 &lt;a href=&#34;https://zhipu-ai.feishu.cn/wiki/SPyFwjSI7iOCoCksq2sc3Eb7nXd&#34;&gt;技术文档&lt;/a&gt; 推出，欢迎体验和留言，我们将继续快速迭代！&lt;/li&gt; &#xA; &lt;li&gt;🔥 2024-03-06: 仓库所在组织 &lt;a href=&#34;https://github.com/MetaGLM&#34;&gt;MetaGLM&lt;/a&gt; 更新了4门语言 (Python, Java,C#,Node.js) 的SDK，欢迎提出意见和对项目进行PR！&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;快速开始 🚀&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;要开始使用GLM API，你首先需要一个 GLM API 账户和相应的 API 密钥。 如果你还没有账户，可以在 &lt;a href=&#34;https://open.bigmodel.cn/&#34;&gt;这里&lt;/a&gt; 免费注册。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;我的代码以 &lt;strong&gt;Python, Jupyter Note&lt;/strong&gt; 为主，但同样的概念也可以应用于其他编程语言（不过这可能要你们自己实现咯）。 这些代码示例旨在帮助我（或许也能对你）如何高效地使用 GLM API 完成常见的简单任务。 推荐使用&lt;code&gt;Python 3.9 - 3.12&lt;/code&gt; 的版本（我自己是Python 3.10）。你需要安装必须的依赖，才能更好的使用 Demo。你可以使用以下命令来安装总的依赖：&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;对了，我一般使用 ✅GLM4 来完成任务，我也推荐你使用这个模型哦！&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;仓库文件 📂&lt;/h2&gt; &#xA;&lt;p&gt;我已经分类好了多个文件夹，这些文件夹都有自己的内容，你可以根据自己的需求来查看！&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;🌱&lt;code&gt;basic&lt;/code&gt; 最基础的内容，帮助你熟悉基本的 API 调用。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;👁️&lt;code&gt;vision&lt;/code&gt; 关于视觉模型和绘图模型的调用和基本应用。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🔧&lt;code&gt;finetune&lt;/code&gt; 或许可以来这里找找微调的内容？&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🎉&lt;code&gt;demo&lt;/code&gt; 一些有趣的小项目，或许可以激发点灵感。&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;🤖&lt;code&gt;agent&lt;/code&gt; 看看发布会的智能体有多厉害！&lt;/li&gt; &#xA;   &lt;li&gt;📚&lt;code&gt;data&lt;/code&gt; 运行demo所需要的数据。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;📊&lt;code&gt;glms&lt;/code&gt; 智能体 (智谱清言) 专区，即使你不会代码，也能快速上手！&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;🏠&lt;code&gt;asset&lt;/code&gt; 一些相关的图片资料&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;你可以通过以下图片快速了解本仓库构成, 我将尽快同步更新 Zhipu AI SDK的最新实验和教学内容。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/asset/plan.png&#34; alt=&#34;实现原理图&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;开源SDK&lt;/h2&gt; &#xA;&lt;p&gt;GLM-4系列SDK已经开源，如果你想直接在我们的SDK上进行修改，可以按照以下地址进行需改：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-python-v4&#34;&gt;Python SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-java-v4&#34;&gt;Java SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-csharp-v4&#34;&gt;C# SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-nodejs-v4&#34;&gt;Node.js SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;如果你有其他语言的SDK想贡献到官方仓库，欢迎提出PR。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;贡献指南 🤝&lt;/h2&gt; &#xA;&lt;p&gt;欢迎大家贡献自己的想法和代码！如果你有任何建议或想添加自己的代码，请随时提交 Pull Request 或开 Issue 讨论。 如果你喜欢这个仓库，欢迎给它一个 ⭐，这将对我有很大帮助！&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ora-io/keras2circom</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/ora-io/keras2circom</id>
    <link href="https://github.com/ora-io/keras2circom" rel="alternate"></link>
    <summary type="html">&lt;p&gt;python tool to transpile a tf.keras model into a circom circuit&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;keras2circom&lt;/h1&gt; &#xA;&lt;p&gt;keras2circom is a python tool that transpiles a tf.keras model into a circom circuit.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;First, clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/socathie/keras2circom.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, install the dependencies. You can use pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use conda, you can also create a new environment with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will also need to install circom and snarkjs. You can run the following commands to install them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash setup-circom.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Last but not least, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To use the package, you can run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py &amp;lt;model_path&amp;gt; [-o &amp;lt;output_dir&amp;gt;] [--raw]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example, to transpile the model in &lt;code&gt;models/model.h5&lt;/code&gt; into a circom circuit, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py models/model.h5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The output will be in the &lt;code&gt;output&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;If you want to transpile the model into a circom circuit with &#34;raw&#34; output, i.e. no ArgMax at the end, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py models/model.h5 --raw&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;To test the package, you can run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm test&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>lichao-sun/Mora</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/lichao-sun/Mora</id>
    <link href="https://github.com/lichao-sun/Mora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Mora: More like Sora for Generalist Video Generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mora: More like Sora for Generalist Video Generation&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;🔍 See our newest Video Generation paper: &lt;a href=&#34;http://arxiv.org/abs/2403.13248&#34;&gt;&lt;strong&gt;&#34;Mora: Enabling Generalist Video Generation via A Multi-Agent Framework&#34;&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;http://arxiv.org/abs/2403.13248&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-%F0%9F%8E%93-lightblue?style=flat-square&#34; alt=&#34;Paper&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lichao-sun/Mora&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gtihub-%F0%9F%8E%93-lightblue?style=flat-square&#34; alt=&#34;GitHub&#34;&gt;)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;📧 Please let us know if you find a mistake or have any suggestions by e-mail: &lt;a href=&#34;mailto:lis221@lehigh.edu&#34;&gt;lis221@lehigh.edu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;📰News&lt;/h2&gt; &#xA;&lt;p&gt;🚀️ Mar 20: Our paper &#34;&lt;a href=&#34;https://arxiv.org/abs/2403.13248&#34;&gt;Mora: Enabling Generalist Video Generation via A Multi-Agent Framework&lt;/a&gt;&#34; is released!&lt;/p&gt; &#xA;&lt;h2&gt;What is Mora&lt;/h2&gt; &#xA;&lt;p&gt;Mora is a multi-agent framework designed to facilitate generalist video generation tasks, leveraging a collaborative approach with multiple visual agents. It aims to replicate and extend the capabilities of OpenAI&#39;s Sora. &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task.jpg&#34; alt=&#34;Task&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;🎥Demo (1024×576 resolution, 12 seconds and more!)&lt;/h2&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo1.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo2.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo3.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo4.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Mora: A Multi-Agent Framework for Video Generation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/method.jpg&#34; alt=&#34;test image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Agent Collaboration&lt;/strong&gt;: Utilizes several advanced visual AI agents, each specializing in different aspects of the video generation process, to achieve high-quality outcomes across various tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Broad Spectrum of Tasks&lt;/strong&gt;: Capable of performing text-to-video generation, text-conditional image-to-video generation, extending generated videos, video-to-video editing, connecting videos, and simulating digital worlds, thereby covering an extensive range of video generation applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open-Source and Extendable&lt;/strong&gt;: Mora’s open-source nature fosters innovation and collaboration within the community, allowing for continuous improvement and customization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Proven Performance&lt;/strong&gt;: Experimental results demonstrate Mora&#39;s ability to achieve performance that is close to that of Sora in various tasks, making it a compelling open-source alternative for the video generation domain.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;h3&gt;Text-to-video generation&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input prompt&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Output video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A vibrant coral reef teeming with life under the crystal-clear blue ocean, with colorful fish swimming among the coral, rays of sunlight filtering through the water, and a gentle current moving the sea plants. &lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_1.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A majestic mountain range covered in snow, with the peaks touching the clouds and a crystal-clear lake at its base, reflecting the mountains and the sky, creating a breathtaking natural mirror.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_2.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In the middle of a vast desert, a golden desert city appears on the horizon, its architecture a blend of ancient Egyptian and futuristic elements.The city is surrounded by a radiant energy barrier, while in the air, seve&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_3.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Text-conditional image-to-video generation&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input prompt&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input image&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora generated Video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora generated Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Monster Illustration in the flat design style of a diverse family of monsters. The group includes a furry brown monster, a sleek black monster with antennas, a spotted green monster, and a tiny polka-dotted monster, all interacting in a playful environment. &lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/input1.jpg&#34; width=&#34;600&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task2_demo1.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/sora_demo1.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;An image of a realistic cloud that spells “SORA”.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/input2.jpg&#34; width=&#34;600&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task2_demo2.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/sora_demo2.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Extend generated video&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Original video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora extended video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora extended video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;./image/original video.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/mora_task3.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task3_sora.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Video-to-video editing&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Instruction&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Original video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora edited Video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora edited Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Change the setting to the 1920s with an old school car. make sure to keep the red color.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_original.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_mora_1920.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_sora_1920.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Put the video in space with a rainbow road&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_original.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_mora_rainbow.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_sora_rainbow.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Connect videos&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input previous video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input next video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Output connect Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora1.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora2.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora1.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora2.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Simulate digital worlds&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora simulating video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora simulating video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_mora1.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_sora1.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_mora2.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_sora2.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Code will be released as soon as possible!&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{yuan2024mora,&#xA;  title={Mora: Enabling Generalist Video Generation via A Multi-Agent Framework},&#xA;  author={Yuan, Zhengqing and Chen, Ruoxi and Li, Zhaoxu and Jia, Haolong and He, Lifang and Wang, Chi and Sun, Lichao},&#xA;  journal={arXiv preprint arXiv:2403.13248},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{liu2024sora,&#xA;  title={Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models},&#xA;  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},&#xA;  journal={arXiv preprint arXiv:2402.17177},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{openai2024sorareport,&#xA;  title={Video generation models as world simulators},&#xA;  author={OpenAI},&#xA;  year={2024},&#xA;  howpublished={https://openai.com/research/video-generation-models-as-world-simulators},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>