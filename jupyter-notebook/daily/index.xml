<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-24T01:27:50Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google-deepmind/gemma</title>
    <updated>2024-02-24T01:27:50Z</updated>
    <id>tag:github.com,2024-02-24:/google-deepmind/gemma</id>
    <link href="https://github.com/google-deepmind/gemma" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open weights LLM from Google DeepMind.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gemma&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;Gemma&lt;/a&gt; is a family of open-weights Large Language Model (LLM) by &lt;a href=&#34;https://deepmind.google/&#34;&gt;Google DeepMind&lt;/a&gt;, based on Gemini research and technology.&lt;/p&gt; &#xA;&lt;p&gt;This repository contains an inference implementation and examples, based on the &lt;a href=&#34;https://github.com/google/flax&#34;&gt;Flax&lt;/a&gt; and &lt;a href=&#34;https://github.com/google/jax&#34;&gt;JAX&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Learn more about Gemma&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://ai.google.dev/gemma/technical-report&#34;&gt;Gemma technical report&lt;/a&gt; details the models&#39; capabilities.&lt;/li&gt; &#xA; &lt;li&gt;For tutorials, reference implementations in other ML frameworks, and more, visit &lt;a href=&#34;https://ai.google.dev/gemma&#34;&gt;https://ai.google.dev/gemma&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;To install Gemma you need to use Python 3.10 or higher.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install JAX for CPU, GPU or TPU. Follow instructions at &lt;a href=&#34;https://jax.readthedocs.io/en/latest/installation.html&#34;&gt;the JAX website&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Run&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv gemma-demo&#xA;. gemma-demo/bin/activate&#xA;pip install git+https://github.com/google-deepmind/gemma.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Downloading the models&lt;/h3&gt; &#xA;&lt;p&gt;The model checkpoints are available through Kaggle at &lt;a href=&#34;http://kaggle.com/models/google/gemma&#34;&gt;http://kaggle.com/models/google/gemma&lt;/a&gt;. Select one of the &lt;strong&gt;Flax&lt;/strong&gt; model variations, click the â¤“ button to download the model archive, then extract the contents to a local directory. The archive contains both the model weights and the tokenizer, for example the 2b Flax variation contains:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;2b/              # Directory containing model weights&#xA;tokenizer.model  # Tokenizer&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running the unit tests&lt;/h3&gt; &#xA;&lt;p&gt;To run the unit tests, install the optional &lt;code&gt;[test]&lt;/code&gt; dependencies (e.g. using &lt;code&gt;pip install -e .[test]&lt;/code&gt; from the root of the source tree), then:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pytest .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the tests in &lt;code&gt;sampler_test.py&lt;/code&gt; are skipped by default since no tokenizer is distributed with the Gemma sources. To run these tests, download a tokenizer following the instructions above, and update the &lt;code&gt;_VOCAB&lt;/code&gt; constant in &lt;code&gt;sampler_test.py&lt;/code&gt; with the path to &lt;code&gt;tokenizer.model&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;To run the example sampling script, pass the paths to the weights directory and tokenizer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python examples/sampling.py -- \&#xA;  --path_checkpoint=/path/to/archive/contents/2b/ \&#xA;  --path_tokenizer=/path/to/archive/contents/tokenizer.model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are also several Colab notebook tutorials:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colab.sandbox.google.com/github/google-deepmind/gemma/blob/main/colabs/sampling_tutorial.ipynb&#34;&gt;&lt;code&gt;colabs/sampling_tutorial.ipynb&lt;/code&gt;&lt;/a&gt; contains a &lt;a href=&#34;http://colab.google&#34;&gt;Colab&lt;/a&gt; notebook with a sampling example.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colab.sandbox.google.com/github/google-deepmind/gemma/blob/main/colabs/fine_tuning_tutorial.ipynb&#34;&gt;&lt;code&gt;colabs/fine_tuning_tutorial.ipynb&lt;/code&gt;&lt;/a&gt; contains a &lt;a href=&#34;http://colab.google&#34;&gt;Colab&lt;/a&gt; with a basic tutorial on how to fine tune Gemma for a task, such as English to French translation.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://colab.sandbox.google.com/github/google-deepmind/gemma/blob/main/colabs/gsm8k_eval.ipynb&#34;&gt;&lt;code&gt;colabs/gsm8k_eval.ipynb&lt;/code&gt;&lt;/a&gt; is a &lt;a href=&#34;http://colab.google&#34;&gt;Colab&lt;/a&gt; with a reference GSM8K eval implementation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run these notebooks you will need to download a local copy of the weights and tokenizer (see above), and update the &lt;code&gt;ckpt_path&lt;/code&gt; and &lt;code&gt;vocab_path&lt;/code&gt; variables with the corresponding paths.&lt;/p&gt; &#xA;&lt;h2&gt;System Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Gemma can run on a CPU, GPU and TPU. For GPU, we recommend a 8GB+ RAM on GPU for the 2B checkpoint and 24GB+ RAM on GPU for the 7B checkpoint.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We are open to bug reports, pull requests (PR), and other contributions. Please see &lt;a href=&#34;https://raw.githubusercontent.com/google-deepmind/gemma/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on PRs.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright 2024 DeepMind Technologies Limited&lt;/p&gt; &#xA;&lt;p&gt;This code is licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at &lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This is not an official Google product.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>epfl-nlp/cs-552-modern-nlp</title>
    <updated>2024-02-24T01:27:50Z</updated>
    <id>tag:github.com,2024-02-24:/epfl-nlp/cs-552-modern-nlp</id>
    <link href="https://github.com/epfl-nlp/cs-552-modern-nlp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repository for EPFL&#39;s CS-552: Modern NLP class&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CS-552: Modern Natural Language Processing&lt;/h1&gt; &#xA;&lt;h3&gt;Course Description&lt;/h3&gt; &#xA;&lt;p&gt;Natural language processing is ubiquitous in modern intelligent technologies, serving as a foundation for language translators, virtual assistants, search engines, and many more. In this course, we cover the foundations of modern methods for natural language processing, such as word embeddings, recurrent neural networks, transformers, and pretraining, and how they can be applied to important tasks in the field, such as machine translation and text classification. We also cover issues with these state-of-the-art approaches (such as robustness, interpretability, sensitivity), identify their failure modes in different NLP applications, and discuss analysis and mitigation techniques for these issues.&lt;/p&gt; &#xA;&lt;h4&gt;Quick access links:&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/epfl-nlp/cs-552-modern-nlp/main/#class&#34;&gt;Platforms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/epfl-nlp/cs-552-modern-nlp/main/#lectures&#34;&gt;Lecture Schedule&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/epfl-nlp/cs-552-modern-nlp/main/#exercises&#34;&gt;Exercise Schedule&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/epfl-nlp/cs-552-modern-nlp/main/#evaluation&#34;&gt;Grading&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/epfl-nlp/cs-552-modern-nlp/main/#contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a name=&#34;class&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Class&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Platform&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Where &amp;amp; when&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Lectures&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Wednesdays: 11:15-13:00&lt;/strong&gt; [&lt;a href=&#34;https://plan.epfl.ch/?room=%3DSTCC%20-%20Cloud%20C&amp;amp;dim_floor=0&amp;amp;lang=en&amp;amp;dim_lang=en&amp;amp;tree_groups=centres_nevralgiques%2Cmobilite_acces_grp%2Censeignement%2Ccommerces_et_services&amp;amp;tree_group_layers_centres_nevralgiques=information_epfl%2Cguichet_etudiants&amp;amp;tree_group_layers_mobilite_acces_grp=metro&amp;amp;tree_group_layers_enseignement=&amp;amp;tree_group_layers_commerces_et_services=&amp;amp;baselayer_ref=grp_backgrounds&amp;amp;map_x=2532938&amp;amp;map_y=1152803&amp;amp;map_zoom=11&#34;&gt;STCC - Cloud C&lt;/a&gt;] &amp;amp; &lt;strong&gt;Thursdays: 13:15-14:00&lt;/strong&gt; [&lt;a href=&#34;https://plan.epfl.ch/?room=%3DCE%201%206&amp;amp;dim_floor=1&amp;amp;lang=en&amp;amp;dim_lang=en&amp;amp;tree_groups=centres_nevralgiques%2Cmobilite_acces_grp%2Censeignement%2Ccommerces_et_services&amp;amp;tree_group_layers_centres_nevralgiques=information_epfl%2Cguichet_etudiants&amp;amp;tree_group_layers_mobilite_acces_grp=metro&amp;amp;tree_group_layers_enseignement=&amp;amp;tree_group_layers_commerces_et_services=&amp;amp;baselayer_ref=grp_backgrounds&amp;amp;map_x=2533400&amp;amp;map_y=1152502&amp;amp;map_zoom=13&#34;&gt;CE16&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Exercises Session&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Thursdays: 14:15-16:00&lt;/strong&gt; [&lt;a href=&#34;https://plan.epfl.ch/?room=%3DCE%201%201&amp;amp;dim_floor=1&amp;amp;lang=en&amp;amp;dim_lang=en&amp;amp;tree_groups=centres_nevralgiques%2Cmobilite_acces_grp%2Censeignement%2Ccommerces_et_services&amp;amp;tree_group_layers_centres_nevralgiques=information_epfl%2Cguichet_etudiants&amp;amp;tree_group_layers_mobilite_acces_grp=metro&amp;amp;tree_group_layers_enseignement=&amp;amp;tree_group_layers_commerces_et_services=&amp;amp;baselayer_ref=grp_backgrounds&amp;amp;map_x=2533297&amp;amp;map_y=1152521&amp;amp;map_zoom=13&#34;&gt;CE11&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project Assistance &lt;br&gt;(not every week)&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Wednesdays: 13:15-14:00&lt;/strong&gt; [&lt;a href=&#34;https://plan.epfl.ch/?room=%3DSTCC%20-%20Cloud%20C&amp;amp;dim_floor=0&amp;amp;lang=en&amp;amp;dim_lang=en&amp;amp;tree_groups=centres_nevralgiques%2Cmobilite_acces_grp%2Censeignement%2Ccommerces_et_services&amp;amp;tree_group_layers_centres_nevralgiques=information_epfl%2Cguichet_etudiants&amp;amp;tree_group_layers_mobilite_acces_grp=metro&amp;amp;tree_group_layers_enseignement=&amp;amp;tree_group_layers_commerces_et_services=&amp;amp;baselayer_ref=grp_backgrounds&amp;amp;map_x=2532938&amp;amp;map_y=1152803&amp;amp;map_zoom=11&#34;&gt;STCC - Cloud C&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;QA Forum &amp;amp; Annoucements&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ed Forum [&lt;a href=&#34;https://edstem.org/eu/courses/1159/discussion/&#34;&gt;link&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Grades&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Moodle [&lt;a href=&#34;https://moodle.epfl.ch/course/view.php?id=17143&#34;&gt;link&lt;/a&gt;]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;All lectures will be given in person and live streamed on Zoom. The link to the Zoom is available on the Ed Forum (pinned post). Beware that, in the event of a technical failure during the lecture, continuing to accompany the lecture live via zoom might not be possible.&lt;/p&gt; &#xA;&lt;p&gt;Recording of the lectures will be made available on SwitchTube. We will reuse some of last year&#39;s recordings and we may record a few new lectures in case of different lecture contents.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;lectures&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Lecture Schedule&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Week&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Date&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Topic&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Instructor&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;21 Feb &lt;br&gt;22 Feb&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Introduction | Building a simple neural classifier &lt;br&gt;Neural LMs: word embeddings [&lt;a href=&#34;https://github.com/epfl-nlp/cs-552-modern-nlp/tree/main/Lectures/Week%201&#34;&gt;slides&lt;/a&gt;]&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;28 Feb &lt;br&gt;29 Feb&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;LM basics | Neural LMs: Fixed Context Models &lt;br&gt;Neural LMs: RNNs, Backpropagation, Vanishing Gradients; LSTMs&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;6 Mar &lt;br&gt;7 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Seq2seq + decoding + attention | Transformers&lt;br&gt;Transformers + Greedy Decoding; GPT&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;13 Mar &lt;br&gt;14 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Pretraining: ELMo, BERT, MLM, task generality | Transfer Learning: Introduction &lt;br&gt;Pretraining S2S: BART, T5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;20 Mar &lt;br&gt;21 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Transfer Learning: Dataset Biases &lt;br&gt;Generation: Task&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;27 Mar &lt;br&gt;28 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Generation: Decoding and Training &lt;br&gt;Generation: Evaluation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;em&gt;&lt;strong&gt;EASTER BREAK&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;10 Apr &lt;br&gt;11 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;In-context Learning - GPT-3 + Prompts | Instruction Tuning&lt;br&gt;Project Description&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;17 Apr &lt;br&gt;18 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ethics in NLP: Bias / Fairness and Toxicity, Privacy, Disinformation &lt;br&gt;&lt;strong&gt;No class&lt;/strong&gt; (Project work; A1 Grade Review Session)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Anna Sotnikova&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;24 Apr &lt;br&gt;25 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Scaling laws | Model Compression &lt;br&gt;&lt;strong&gt;No class&lt;/strong&gt; (Project work; A1 Grade Review Session)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut &lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 10&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;1 May &lt;br&gt;2 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Tokenization: BPE, WP, Char-based | Multilingual LMs &lt;br&gt;Guest Lecture: Kayo Yin&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Negar Foroutan &lt;br&gt; Kayo Yin&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 11&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;8 May &lt;br&gt;9 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Syntactic and Semantic Tasks (NER) | Interpretability: BERTology &lt;br&gt;&lt;strong&gt;No class&lt;/strong&gt; (Project work; A2 Grade Review Session)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Gail Weiss&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 12&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;15 May &lt;br&gt;16 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Reading Comprehension | Retrieval-augmented LMs &lt;br&gt;&lt;strong&gt;No class&lt;/strong&gt; (Project work; A2 Grade Review Session)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 13&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;22 May &lt;br&gt;23 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Multimodality: L &amp;amp; V &lt;br&gt;Looking forward&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Syrielle Montariol &lt;br&gt;Antoine Bosselut&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 14&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;29 May &lt;br&gt;30 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;No class&lt;/strong&gt; (Project work; A3 Grade Review Session)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a name=&#34;exercises&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Exercise Schedule&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Week&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Date&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Topic&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Instructor&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 1&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;22 Feb&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Setup + Word embeddings [&lt;a href=&#34;https://github.com/epfl-nlp/cs-552-modern-nlp/tree/main/Exercises/Week%201%20-%20Word%20Embeddings&#34;&gt;code&lt;/a&gt;]&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Mete Ismayilzada&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 2&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;29 Feb&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Word embeddings review &lt;br&gt; Language and Sequence-to-sequence models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Mete Ismayilzada &lt;br&gt;Badr AlKhamissi&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 3&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;7 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Language and Sequence-to-sequence models review &lt;br&gt; Attention + Transformers &lt;br&gt; Assignment 1 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Badr AlKhamissi &lt;br&gt;Simin Fan&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;14 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Attention + Transformers review &lt;br&gt;Pretraining and Transfer Learning Pt. 1 &lt;br&gt; Assignment 1 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simin Fan &lt;br&gt; Badr AlKhamissi&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 5&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;21 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Pretraining and Transfer Learning Pt. 1 review &lt;br&gt;Transfer Learning Pt. 2 &lt;br&gt; Assignment 2 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simin Fan&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 6&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;28 Mar&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Transfer Learning Pt. 2 review &lt;br&gt;Text Generation &lt;br&gt; Assignment 2 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simin Fan &lt;br&gt;Deniz Bayazit&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 8&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;4 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;em&gt;&lt;strong&gt;EASTER BREAK&lt;/strong&gt;&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 7&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;11 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Text Generation review &lt;br&gt;In-context Learning &lt;br&gt; Assignment 3 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Badr AlKhamissi &lt;br&gt; Deniz Bayazit &lt;br&gt; Mete Ismayilzada&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 9&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;18 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;In-context Learning review &lt;br&gt; Assignment 3 Q&amp;amp;A&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Badr AlKhamissi &lt;br&gt; Deniz Bayazit &lt;br&gt; Mete Ismayilzada&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 10&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;25 Apr&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 11&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;2 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 12&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;9 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project &lt;br&gt; Milestone 1 Feedback&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 13&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;16 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 14&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;23 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Week 15&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;30 May&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Project &lt;br&gt; Milestone 2 Feedback&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TA meetings on-demand&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Exercises Session format:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TAs will provide a small discussion over the &lt;strong&gt;last week&#39;s exercises&lt;/strong&gt;, answering any questions and explaining the solutions. &lt;em&gt;(10-15mins)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;TAs will present &lt;strong&gt;this week&#39;s exercise&lt;/strong&gt;. &lt;em&gt;(5mins)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Students will be solving this week&#39;s exercises and TAs will provide answers and clarification if needed.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;: Please make sure you have already done the setup prerequisites to run the coding parts of the exercises. You can find the instructions &lt;a href=&#34;https://github.com/epfl-nlp/cs-552-modern-nlp/tree/main/Exercises/Setup&#34;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;evaluation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Grading:&lt;/h2&gt; &#xA;&lt;p&gt;Your grade in the course will be computed according to the following guidelines:&lt;/p&gt; &#xA;&lt;h3&gt;Assignments (40%):&lt;/h3&gt; &#xA;&lt;p&gt;There will be three assignments throughout the course. They will be released and due according to the following schedule:&lt;/p&gt; &#xA;&lt;h4&gt;Assignment 1 (10%)&lt;/h4&gt; &#xA;&lt;!-- Link for the assignment [here][1a]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Released: 26 February 2024&lt;/li&gt; &#xA; &lt;li&gt;Due: 17 March 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade released: 14 April 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade review sessions: 18 and 25 April 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Assignment 2 (15%)&lt;/h4&gt; &#xA;&lt;!-- Link for the assignment [here][2a]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Released: 18 March 2024&lt;/li&gt; &#xA; &lt;li&gt;Due: 7 April 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade released: 5 May 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade review sessions: 9 and 16 May 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Assignment 3 (15%)&lt;/h4&gt; &#xA;&lt;!-- Link for the assignment [here][3a]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Released: 1 April 2024&lt;/li&gt; &#xA; &lt;li&gt;Due: 21 April 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade released: 19 May 2024&lt;/li&gt; &#xA; &lt;li&gt;Grade review sessions: 29 and 30 May 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Assignment releases will be announced on Ed.&lt;/p&gt; &#xA;&lt;h3&gt;Project (60%):&lt;/h3&gt; &#xA;&lt;p&gt;The project will be divided into 2 milestones and a final submission. Each milestone will be worth 15% of the final grade with the remaining 30% being allocated to the final report. Each team will be supervised by one of the course TAs or AEs.&lt;/p&gt; &#xA;&lt;p&gt;More details on the content of the project and the deliverables of each milestone will be released at a later date.&lt;/p&gt; &#xA;&lt;!-- Registration details can be found in the announcement [here][1p]. --&gt; &#xA;&lt;h4&gt;Milestone 1 (15%):&lt;/h4&gt; &#xA;&lt;!-- - Milestone 1 parameters can be found in the [project description][2p]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Due: 5 May 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Milestone 2 (15%):&lt;/h4&gt; &#xA;&lt;!-- - Milestone 2 parameters can be found in the [project description][2p]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Due: 26 May 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Final Deliverable (30%):&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The final report, code, and date will be due on June 14th. Students are welcome to turn in their materials ahead of time, as soon as the semester ends.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- - More details can be found in the [project description][2p]. --&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Due: 14 June 2024&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Late Days Policy&lt;/h3&gt; &#xA;&lt;p&gt;All assignments and milestones are due at 23:59 on their due date. As we understand that circumstances can make it challenging to abide by these due dates, you will receive 6 late days over the course of the semester to be allocated to the assignments and project milestones as you see fit. No further extensions will be granted. The only exception to this rule is for the final report, code, and data. No extensions will be granted beyond June 14th.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;contact&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contacts&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Lecturer&lt;/strong&gt;: &lt;a href=&#34;https://people.epfl.ch/antoine.bosselut&#34;&gt;Antoine Bosselut&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Teaching assistants&lt;/strong&gt;: &lt;a href=&#34;https://people.epfl.ch/badr.alkhamissi&#34;&gt;Badr AlKhamissi&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/deniz.bayazit?lang=en&#34;&gt;Deniz Bayazit&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/beatriz.borges&#34;&gt;Beatriz Borges&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/zeming.chen?lang=en&#34;&gt;Zeming (Eric) Chen&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/simin.fan?lang=en&#34;&gt;Simin Fan&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/negar.foroutan&#34;&gt;Negar Foroutan Eghlidi&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/silin.gao?lang=en&#34;&gt;Silin Gao&lt;/a&gt;, &lt;a href=&#34;https://people.epfl.ch/mahammad.ismayilzada&#34;&gt;Mete Ismayilzada&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please contact us for any organizational questions or questions related to the course content.&lt;/p&gt; &#xA;&lt;!-- [2s]: --&gt; &#xA;&lt;!-- [3s]: --&gt; &#xA;&lt;!-- [4s]: --&gt; &#xA;&lt;!-- [5s]: --&gt; &#xA;&lt;!-- [6s]: --&gt; &#xA;&lt;!-- [7s]: --&gt; &#xA;&lt;!-- [8s]: --&gt; &#xA;&lt;!-- [9s]: --&gt; &#xA;&lt;!-- [10s]: --&gt; &#xA;&lt;!-- [11s]: --&gt; &#xA;&lt;!-- [12s]: --&gt; &#xA;&lt;!-- [13s]: --&gt; &#xA;&lt;!-- [14s]: --&gt; &#xA;&lt;!-- [2e]: --&gt; &#xA;&lt;!-- [3e]: --&gt; &#xA;&lt;!-- [4e]: --&gt; &#xA;&lt;!-- [5e]: --&gt; &#xA;&lt;!-- [6e]: --&gt; &#xA;&lt;!-- [7e]: --&gt; &#xA;&lt;!-- [8e]: --&gt; &#xA;&lt;!-- [1a]: --&gt; &#xA;&lt;!-- [2a]: --&gt; &#xA;&lt;!-- [3a]: --&gt; &#xA;&lt;!-- [1p]: --&gt; &#xA;&lt;!-- [2p]: --&gt; &#xA;&lt;!-- [1r]: --&gt; &#xA;&lt;!-- [2r]: --&gt; &#xA;&lt;!-- [3r]: --&gt; &#xA;&lt;!-- [4r]: --&gt; &#xA;&lt;!-- [5r]: --&gt; &#xA;&lt;!-- [6r]: --&gt; &#xA;&lt;!-- [7r]: --&gt; &#xA;&lt;!-- [8r]: --&gt; &#xA;&lt;!-- [9r]: --&gt; &#xA;&lt;!-- [10r]: --&gt; &#xA;&lt;!-- [11r]: --&gt; &#xA;&lt;!-- [12r]: --&gt; &#xA;&lt;!-- [13r]: --&gt; &#xA;&lt;!-- [14r]: --&gt;</summary>
  </entry>
</feed>