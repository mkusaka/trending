<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-05T01:34:31Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yudianzheng/SketchVideo</title>
    <updated>2023-12-05T01:34:31Z</updated>
    <id>tag:github.com,2023-12-05:/yudianzheng/SketchVideo</id>
    <link href="https://github.com/yudianzheng/SketchVideo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[arXiv 2023] Sketch Video Synthesis&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Sketch Video Synthesis&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yudianzheng/&#34;&gt;Yudian Zheng&lt;/a&gt; Â· &lt;a href=&#34;http://vinthony.github.io/&#34;&gt;Xiaodong Cun&lt;/a&gt; Â· &lt;a href=&#34;https://menghanxia.github.io/&#34;&gt;Menghan Xia&lt;/a&gt; Â· &lt;a href=&#34;https://www.cis.um.edu.mo/~cmpun/&#34;&gt;Chi-Man Pun&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2311.15306&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/ArXiv-2311.15306-red&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://sketchvideo.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=cVQERKS3Iqg&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Youtube-Video-blue&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;ðŸ—º Showcases&lt;/h3&gt; &#xA;&lt;div&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/yudianzheng/SketchVideo/main/gif/teaser.gif&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;ðŸ’¡ Abstract&lt;/h3&gt; &#xA;&lt;p&gt;Understanding semantic intricacies and high-level concepts is essential in image sketch generation, and this challenge becomes even more formidable when applied to the domain of videos. To address this, we propose a novel optimization-based framework for sketching videos represented by the frame-wise BÃ©zier Curves. In detail, we first propose a cross-frame stroke initialization approach to warm up the location and the width of each curve. Then, we optimize the locations of these curves by utilizing a semantic loss based on CLIP features and a newly designed consistency loss using the self-decomposed 2D atlas network. Built upon these design elements, the resulting sketch video showcases impressive visual abstraction and temporal coherence. Furthermore, by transforming a video into SVG lines through the sketching process, our method unlocks applications in sketch-based video editing and video doodling, enabled through video composition, as exemplified in the teaser.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;ðŸš© Getting Start&lt;/h3&gt; &#xA;&lt;p&gt;if you only want to optimize the example, run (1) and (5).&lt;/p&gt; &#xA;&lt;h5&gt;(1) build up the environment:&lt;/h5&gt; &#xA;&lt;p&gt;the total training need projects of layer &lt;strong&gt;neural layer atlas&lt;/strong&gt; and &lt;strong&gt;diffvg&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# install all and train from beginning&#xA;sh scripts/install.sh&#xA;# install diffvg(optimize the example)&#xA;sh scripts/install_diffvg.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;(2) download Dataset or take your own data(less than 70 frames,and extract masks), put on the folder &lt;data&gt;:&lt;/data&gt;&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget https://data.vision.ee.ethz.ch/csergi/share/davis/DAVIS-2017-Unsupervised-trainval-Full-Resolution.zip&#xA; &#xA;unzip DAVIS-2017-Unsupervised-trainval-Full-Resolution.zip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or using the examples data(car-turn) and extract the masks.&lt;/p&gt; &#xA;&lt;h5&gt;(3) process/crop the data:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh scripts/process_dataset.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;(4) build up atlas:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh scripts/operate_atlas.sh &amp;lt;video_name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;(5)compute our method:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh scripts/operate_clipavideo.sh &amp;lt;video_name&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Look at arguments.txt to see more arguments&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{zheng2023sketch,&#xA;      title={Sketch Video Synthesis}, &#xA;      author={Yudian Zheng and Xiaodong Cun and Menghan Xia and Chi-Man Pun},&#xA;      year={2023},&#xA;      eprint={2311.15306},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Acknowledgements&lt;/h3&gt; &#xA;&lt;p&gt;The code is borrowed heavily from &lt;a href=&#34;https://github.com/yael-vinker/CLIPasso&#34;&gt;CLIPasso&lt;/a&gt; and &lt;a href=&#34;https://github.com/yael-vinker/SceneSketch&#34;&gt;CLIPScene&lt;/a&gt;, thanks for their wonderful work!&lt;/p&gt;</summary>
  </entry>
</feed>