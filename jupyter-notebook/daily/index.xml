<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-23T01:36:25Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>chandrikadeb7/Face-Mask-Detection</title>
    <updated>2022-11-23T01:36:25Z</updated>
    <id>tag:github.com,2022-11-23:/chandrikadeb7/Face-Mask-Detection</id>
    <link href="https://github.com/chandrikadeb7/Face-Mask-Detection" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Face Mask Detection system based on computer vision and deep learning using OpenCV and Tensorflow/Keras&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Face Mask Detection&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://github.com/Vrushti24/Face-Mask-Detection/raw/logo/Logo/facemaskdetection.ai%20%40%2051.06%25%20(CMYK_GPU%20Preview)%20%2018-02-2021%2018_33_18%20(2).png&#34; width=&#34;200&#34; height=&#34;200&#34;&gt; &#xA; &lt;h4&gt;Face Mask Detection System built with OpenCV, Keras/TensorFlow using Deep Learning and Computer Vision concepts in order to detect face masks in static images as well as in real-time video streams.&lt;/h4&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src=&#34;https://img.shields.io/badge/python-v3.6+-blue.svg?sanitize=true&#34; alt=&#34;Python&#34;&gt; &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&#34; alt=&#34;contributions welcome&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/chandrikadeb7/Face-Mask-Detection.svg?logo=github&#34; alt=&#34;Forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/chandrikadeb7/Face-Mask-Detection.svg?logo=github&#34; alt=&#34;Stargazers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/chandrikadeb7/Face-Mask-Detection.svg?logo=github&#34; alt=&#34;Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/chandrika-deb/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-LinkedIn-black.svg?style=flat-square&amp;amp;logo=linkedin&amp;amp;colorB=555&#34; alt=&#34;LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;img src=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/Readme_images/Demo.gif&#34; alt=&#34;Live Demo&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üëá&lt;/span&gt; Support me here!&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.buymeacoffee.com/chandrikadeb7&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png&#34; alt=&#34;Buy Me A Coffee&#34; style=&#34;height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üòá&lt;/span&gt; Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Amid the ongoing COVID-19 pandemic, there are no efficient face mask detection applications which are now in high demand for transportation means, densely populated areas, residential districts, large-scale manufacturers and other enterprises to ensure safety. The absence of large datasets of &lt;strong&gt;‚Äòwith_mask‚Äô&lt;/strong&gt; images has made this task cumbersome and challenging.&lt;/p&gt; &#xA;&lt;h2&gt;PPT and Project Report sharing costs ‚Çπ1000 ($15)&lt;/h2&gt; &#xA;&lt;p&gt;If interested, contact me at &lt;a href=&#34;mailto:chandrikadeb7@gmail.com&#34;&gt;chandrikadeb7@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;üåü &lt;a href=&#34;https://gum.co/GetFaceMask&#34;&gt;Purchase on Gumroad&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚åõ&lt;/span&gt; Project Demo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;span&gt;üé•&lt;/span&gt; &lt;a href=&#34;https://youtu.be/wYwW7gAYyxw&#34;&gt;YouTube Demo Link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üíª&lt;/span&gt; &lt;a href=&#34;https://dev.to/chandrikadeb7/face-mask-detection-my-major-project-3fj3&#34;&gt;Dev Link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://face-mask--detection-app.herokuapp.com/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vasantvohra/TrashNet/master/hr.svg?sanitize=true&#34; alt=&#34;Already deployed version&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/Readme_images/Screen%20Shot%202020-05-14%20at%208.49.06%20PM.png&#34; width=&#34;700&#34; height=&#34;400&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚ö†&lt;/span&gt; TechStack/framework used&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv.org/&#34;&gt;OpenCV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://caffe.berkeleyvision.org/&#34;&gt;Caffe-based face detector&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://keras.io/&#34;&gt;Keras&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1801.04381&#34;&gt;MobileNetV2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚≠ê&lt;/span&gt; Features&lt;/h2&gt; &#xA;&lt;p&gt;Our face mask detector doesn&#39;t use any morphed masked images dataset and the model is accurate. Owing to the use of MobileNetV2 architecture, it is&amp;nbsp;computationally efficient, thus making it easier to deploy the model to embedded systems (Raspberry Pi, Google Coral, etc.).&lt;/p&gt; &#xA;&lt;p&gt;This system can therefore be used in real-time applications which require face-mask detection for safety purposes due to the outbreak of Covid-19. This project can be integrated with embedded systems for application in airports, railway stations, offices, schools, and public places to ensure that public safety guidelines are followed.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üìÅ&lt;/span&gt; Dataset&lt;/h2&gt; &#xA;&lt;p&gt;The dataset used can be downloaded here - &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/tree/master/dataset&#34;&gt;Click to Download&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This dataset consists of&amp;nbsp;&lt;strong&gt;4095 images&lt;/strong&gt;&amp;nbsp;belonging to two classes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;with_mask: 2165 images&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;without_mask: 1930 images&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The images used were real images of faces wearing masks. The images were collected from the following sources:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Bing Search API&lt;/strong&gt; (&lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/search.py&#34;&gt;See Python script&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Kaggle datasets&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;RMFD dataset&lt;/strong&gt; (&lt;a href=&#34;https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset&#34;&gt;See here&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;üîë&lt;/span&gt; Prerequisites&lt;/h2&gt; &#xA;&lt;p&gt;All the dependencies and required libraries are included in the file &lt;code&gt;requirements.txt&lt;/code&gt; &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/requirements.txt&#34;&gt;See here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ&amp;nbsp; Installation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Change your directory to the cloned repo&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ cd Face-Mask-Detection&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Create a Python virtual environment named &#39;test&#39; and activate it&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ virtualenv test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ source test/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Now, run the following command in your Terminal/Command Prompt to install the libraries required&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ pip3 install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;span&gt;üí°&lt;/span&gt; Working&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Open terminal. Go into the cloned project directory and type the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 train_mask_detector.py --dataset dataset&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;To detect face masks in an image type the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 detect_mask_image.py --image images/pic1.jpeg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;To detect face masks in real-time video streams type the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python3 detect_mask_video.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;span&gt;üîë&lt;/span&gt; Results&lt;/h2&gt; &#xA;&lt;h4&gt;Our model gave 98% accuracy for Face Mask Detection after training via &lt;code&gt;tensorflow-gpu==2.5.0&lt;/code&gt;&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1AZ0W2QAHnM3rcj0qbTmc7c3fAMPCowQ1?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/Readme_images/Screenshot%202020-06-01%20at%209.48.27%20PM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;We got the following accuracy/loss training curve plot&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/plot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Streamlit app&lt;/h2&gt; &#xA;&lt;p&gt;Face Mask Detector webapp using Tensorflow &amp;amp; Streamlit&lt;/p&gt; &#xA;&lt;p&gt;command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ streamlit run app.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Images&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/1.PNG&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Upload Images&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/2.PNG&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;Results&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üëè&lt;/span&gt; And it&#39;s done!&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to mail me for any doubts/query &lt;span&gt;üìß&lt;/span&gt; &lt;a href=&#34;mailto:chandrikadeb7@gmail.com&#34;&gt;chandrikadeb7@gmail.com&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Internet of Things Device Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Expected Hardware&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.canakit.com/raspberry-pi-4-4gb.html&#34;&gt;Raspberry Pi 4 4GB with a case&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.arducam.com/docs/cameras-for-raspberry-pi/native-raspberry-pi-cameras/5mp-ov5647-cameras/&#34;&gt;5MP OV5647 PiCamera from Arducam&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Setup the Raspberry Pi case and Operating System by following the Getting Started section on page 3 at &lt;code&gt;documentation/CanaKit-Raspberry-Pi-Quick-Start-Guide-4.0.pdf&lt;/code&gt; or &lt;a href=&#34;https://www.canakit.com/Media/CanaKit-Raspberry-Pi-Quick-Start-Guide-4.0.pdf&#34;&gt;https://www.canakit.com/Media/CanaKit-Raspberry-Pi-Quick-Start-Guide-4.0.pdf&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;With NOOBS, use the recommended operating system&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Setup the PiCamera &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Assemble the PiCamera case from Arducam using &lt;code&gt;documentation/Arducam-Case-Setup.pdf&lt;/code&gt; or &lt;a href=&#34;https://www.arducam.com/docs/cameras-for-raspberry-pi/native-raspberry-pi-cameras/5mp-ov5647-cameras/&#34;&gt;https://www.arducam.com/docs/cameras-for-raspberry-pi/native-raspberry-pi-cameras/5mp-ov5647-cameras/&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/2&#34;&gt;Attach your PiCamera module to the Raspberry Pi and enable the camera&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Raspberry Pi App Installation &amp;amp; Execution&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Run these commands after cloning the project&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Commands&lt;/th&gt; &#xA;   &lt;th&gt;Time to completion&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;sudo apt install -y libatlas-base-dev liblapacke-dev gfortran&lt;/td&gt; &#xA;   &lt;td&gt;1min&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;sudo apt install -y libhdf5-dev libhdf5-103&lt;/td&gt; &#xA;   &lt;td&gt;1min&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pip3 install -r requirements.txt&lt;/td&gt; &#xA;   &lt;td&gt;1-3 mins&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;wget &#34;&lt;a href=&#34;https://raw.githubusercontent.com/PINTO0309/Tensorflow-bin/master/tensorflow-2.4.0-cp37-none-linux_armv7l_download.sh&#34;&gt;https://raw.githubusercontent.com/PINTO0309/Tensorflow-bin/master/tensorflow-2.4.0-cp37-none-linux_armv7l_download.sh&lt;/a&gt;&#34;&lt;/td&gt; &#xA;   &lt;td&gt;less than 10 secs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;./tensorflow-2.4.0-cp37-none-linux_armv7l_download.sh&lt;/td&gt; &#xA;   &lt;td&gt;less than 10 secs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;pip3 install tensorflow-2.4.0-cp37-none-linux_armv7l.whl&lt;/td&gt; &#xA;   &lt;td&gt;1-3 mins&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;&lt;span&gt;üèÜ&lt;/span&gt; Awards&lt;/h2&gt; &#xA;&lt;p&gt;Awarded Runners Up position in &lt;a href=&#34;https://www.amdocs.com/&#34;&gt;Amdocs Innovation India ICE Project Fair&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/nn.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üôã&lt;/span&gt; Cited by:&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://osf.io/preprints/3gph4/&#34;&gt;https://osf.io/preprints/3gph4/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-981-33-4673-4_49&#34;&gt;https://link.springer.com/chapter/10.1007/978-981-33-4673-4_49&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9312083/&#34;&gt;https://ieeexplore.ieee.org/abstract/document/9312083/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-981-33-4673-4_48&#34;&gt;https://link.springer.com/chapter/10.1007/978-981-33-4673-4_48&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/profile/Akhyar_Ahmed/publication/344173985_Face_Mask_Detector/links/5f58c00ea6fdcc9879d8e6f7/Face-Mask-Detector.pdf&#34;&gt;https://www.researchgate.net/profile/Akhyar_Ahmed/publication/344173985_Face_Mask_Detector/links/5f58c00ea6fdcc9879d8e6f7/Face-Mask-Detector.pdf&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;üëè Appreciation&lt;/h2&gt; &#xA;&lt;h3&gt;Selected in &lt;a href=&#34;https://devscript.tech/woc/&#34;&gt;Devscript Winter Of Code&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/Devscript.jpeg&#34; height=&#34;300&#34; width=&#34;300&#34;&gt; &#xA;&lt;h3&gt;Selected in &lt;a href=&#34;https://swoc.tech/project.html&#34;&gt;Script Winter Of Code&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/winter.jpeg&#34; height=&#34;300&#34; width=&#34;300&#34;&gt; &#xA;&lt;h3&gt;Seleted in &lt;a href=&#34;https://scodein.tech/&#34;&gt;Student Code-in&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/Readme_images/sci.jpeg&#34; height=&#34;300&#34; width=&#34;300&#34;&gt; &#xA;&lt;h2&gt;&lt;span&gt;üëç&lt;/span&gt; Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.pyimagesearch.com/&#34;&gt;https://www.pyimagesearch.com/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/tutorials/images/transfer_learning&#34;&gt;https://www.tensorflow.org/tutorials/images/transfer_learning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;ü§ù&lt;/span&gt; Contribution&lt;/h2&gt; &#xA;&lt;h4&gt;Please read the Contribution Guidelines &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/CONTRIBUTING.md&#34;&gt;here&lt;/a&gt;&lt;/h4&gt; &#xA;&lt;p&gt;Feel free to &lt;strong&gt;file a new issue&lt;/strong&gt; with a respective title and description on the the &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/issues&#34;&gt;Face-Mask-Detection&lt;/a&gt; repository. If you already found a solution to your problem, &lt;strong&gt;I would love to review your pull request&lt;/strong&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;ü§ù&lt;/span&gt; Our Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contributors-img.web.app/image?repo=chandrikadeb7/Face-Mask-Detection&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;&lt;span&gt;üëÄ&lt;/span&gt; Code of Conduct&lt;/h2&gt; &#xA;&lt;p&gt;You can find our Code of Conduct &lt;a href=&#34;https://raw.githubusercontent.com/chandrikadeb7/Face-Mask-Detection/master/CODE_OF_CONDUCT.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚ù§Ô∏è&lt;/span&gt; Owner&lt;/h2&gt; &#xA;&lt;p&gt;Made with &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;&amp;nbsp; by &lt;a href=&#34;https://github.com/chandrikadeb7&#34;&gt;Chandrika Deb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üëÄ&lt;/span&gt; License&lt;/h2&gt; &#xA;&lt;p&gt;MIT ¬© &lt;a href=&#34;https://github.com/chandrikadeb7/Face-Mask-Detection/raw/master/LICENSE&#34;&gt;Chandrika Deb&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>claimed-framework/component-library</title>
    <updated>2022-11-23T01:36:25Z</updated>
    <id>tag:github.com,2022-11-23:/claimed-framework/component-library</id>
    <link href="https://github.com/claimed-framework/component-library" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;{% comment %} Copyright 2018-2021 Elyra Authors&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. {% endcomment %} --&amp;gt;&lt;/p&gt; &#xA;&lt;h1&gt;Elyra Component Library - The Component Library for AI, Machine Learning, ETL, and Data Science&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;set of re-usable coarse-grained components (just a bunch of code)&lt;/li&gt; &#xA; &lt;li&gt;think of tasks, not functions (e.g., read from a database, transform data, train model, deploy model)&lt;/li&gt; &#xA; &lt;li&gt;write once, runs everywhere: Kubeflow, Apache Airflow, CLI, KNative, Docker, Kubernetes&lt;/li&gt; &#xA; &lt;li&gt;orchestrate with anything: shell script, Kubeflow, Airflow, Argo, Tekton&lt;/li&gt; &#xA; &lt;li&gt;persistence layer / queue agnostic: Cloud Object Storage, file systems, PVC, Kafka, MQTT&lt;/li&gt; &#xA; &lt;li&gt;just use Python - no other skills required (no Kubeflow component YAML, maven, Java)&lt;/li&gt; &#xA; &lt;li&gt;1st class citizen in JupyterLab and the Elyra Pipeline Editor (creating a low code / no code IDE for data science)&lt;/li&gt; &#xA; &lt;li&gt;upstream repository to IBM Watson Studio Pipelines contributed components in IBM Cloud Pak for Data&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;CLAIMED is a component library for artificial intelligence, machine learning, &#34;extract, transform, load&#34; processes, and data science. The goal is to enable low-code/no-code rapid prototyping style programming to seamlessly CI/CD into production. The library provides ready-made components for various business domains, supports multiple computer languages, works on different data flow editors and command line tools, and runs on various execution engines including Kubernetes, KNative, Kubeflow, Airflow or plain docker. To demonstrate its utility, we constructed a workflow composed exclusively of this library&#39;s components. To display the capabilities of this library, we made use of a publicly available Computed Tomography (CT) scan dataset [covidata]. We created a deep learning model, which is supposed to classify exams as either COVID-19 positive or negative. We built the pipeline with Elyra&#39;s Pipeline Visual Editor, with support for local, Airflow, and Kubeflow execution &lt;a href=&#34;https://arxiv.org/abs/2103.03281&#34;&gt;https://arxiv.org/abs/2103.03281&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/IBM/claimed/raw/master/images/elyra_pipeline.png&#34; alt=&#34;Low Code / No Code pipeline creation tool for data science&#34;&gt; &lt;em&gt;Low Code / No Code pipeline creation tool for data science&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Bring the latest and greatest libraries to the hands of everybody.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/IBM/claimed/raw/master/images/elyra_lime.png&#34; alt=&#34;AIX360/LIME highlights a poor deep learning covid classification model looking at bones only&#34;&gt; &lt;em&gt;AIX360/LIME highlights a poor deep learning covid classification model looking at bones only&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Components of this library can be exported as:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Kubeflow pipeline components&lt;/li&gt; &#xA; &lt;li&gt;Apache Airflow components&lt;/li&gt; &#xA; &lt;li&gt;Standalone graphical components for the Elyra pipeline editor&lt;/li&gt; &#xA; &lt;li&gt;Standalone components to be run from the command line&lt;/li&gt; &#xA; &lt;li&gt;Standalone components to be run as docker containers&lt;/li&gt; &#xA; &lt;li&gt;Standalone components to be run as Kubernetes Service&lt;/li&gt; &#xA; &lt;li&gt;Standalone components to be run as KNative Application or Job&lt;/li&gt; &#xA; &lt;li&gt;Components to consume from or publish to Queue Managers like Kafka or MQTT&lt;/li&gt; &#xA; &lt;li&gt;Components deployed to Kubernets wrapped into DAPR (as service or message consumer/producer)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/IBM/claimed/raw/master/images/elyra_graphical_export.png&#34; alt=&#34;Visually create pipelines from notebooks and run everywhere&#34;&gt; &lt;em&gt;Visually create pipelines from notebooks and run them everywhere&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Each notebook is following a similar format.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The first cell contains a description of the component itself.&lt;/li&gt; &#xA; &lt;li&gt;The second cell installs all dependencies using pip3.&lt;/li&gt; &#xA; &lt;li&gt;The third cell imports all dependencies.&lt;/li&gt; &#xA; &lt;li&gt;The fourth cell contains a list of dependencies, input parameters, and return values as Python comments&lt;/li&gt; &#xA; &lt;li&gt;The fifth cell reads the input parameters from environment variables.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/IBM/claimed/raw/master/images/elyra_cli_export.png&#34; alt=&#34;Export notebooks and files as runtime components for different engines&#34;&gt; &lt;em&gt;Export notebooks and files as runtime components for different engines&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;To learn more on how this library works in practice, please have a look at the following &lt;a href=&#34;https://www.youtube.com/watch?v=FuV2oG55C5s&#34;&gt;video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Related work&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/ploomber/ploomber&#34;&gt;Ploomber&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.orchest.io/&#34;&gt;Orchest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[covidata] Joseph Paul Cohen et al. &lt;em&gt;COVID-19 Image Data Collection: Prospective Predictions Are the Future&lt;/em&gt;, arXiv:2006.11988, 2020&lt;/p&gt; &#xA;&lt;h2&gt;Getting Help&lt;/h2&gt; &#xA;&lt;p&gt;We welcome your questions, ideas, and feedback. Please create an &lt;a href=&#34;https://github.com/IBM/claimed/issues&#34;&gt;issue&lt;/a&gt; or a &lt;a href=&#34;https://github.com/IBM/claimed/discussions&#34;&gt;discussion thread&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing to CLAIMED&lt;/h2&gt; &#xA;&lt;p&gt;Interested in helping make CLAIMED better? We encourage you to take a look at our &lt;a href=&#34;https://raw.githubusercontent.com/claimed-framework/component-library/master/CONTRIBUTING.md&#34;&gt;Contributing&lt;/a&gt; page.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>soyHenry/Python-Prep</title>
    <updated>2022-11-23T01:36:25Z</updated>
    <id>tag:github.com,2022-11-23:/soyHenry/Python-Prep</id>
    <link href="https://github.com/soyHenry/Python-Prep" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png&#34; alt=&#34;HenryLogo&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Prep Course&lt;/h1&gt; &#xA;&lt;p&gt;¬°Hola! Bienvenido al Prep Course para la carrera de Data Science.&lt;/p&gt; &#xA;&lt;p&gt;En este curso introductorio podr√°s aprender todo el contenido que luego ser√° evaluado en el Henry Challenge, el √∫ltimo paso para ingresar a la carrera de Data Science en Henry.&lt;/p&gt; &#xA;&lt;p&gt;¬øQu√© es el Prep Course? El Prep Course, o curso preparatorio, es un curso que dise√±amos desde Henry con la finalidad de nivelar a todos nuestros aplicantes. La idea es que con este curso puedas dar tus primeros pasos en tecnolog√≠a y as√≠ aprender esos conceptos b√°sicos que ser√°n necesarios para cuando est√©s dentro de la carrera.&lt;/p&gt; &#xA;&lt;p&gt;¬øEn qu√© consiste el Prep Course? El curso consiste en una serie de videos, material escrito y ejercicios para que puedas ir aprendiendo estos conceptos b√°sicos de Python y Matem√°tica Todo el material de Python se encuentra aqui, en este repositorio (&lt;a href=&#34;https://github.com/soyHenry/Python-Prep&#34;&gt;https://github.com/soyHenry/Python-Prep&lt;/a&gt;). Una vez que hayas terminado de estudiarlo, podr√°s continuar con el contenido de matem√°tica que se encuentra en: math.prep.soyhenry.com Podr√°s ir avanzando con el contenido a tu ritmo y de manera asincr√≥nica (es decir, en los horarios y tiempos que tu prefieras). Cuando hayas finalizado, podr√°s inscribirte para realizar el Henry Challenge.&lt;/p&gt; &#xA;&lt;p&gt;¬øQu√© es el Henry Challenge? Es un examen donde evaluamos los conceptos que se aprenden en el Prep Course. El examen tiene la finalidad de asegurarnos que realmente se han aprendido estos conceptos, dado que tenerlos bien claro es la clave de √©xito para que puedas avanzar bien dentro de la carrera. El examen se realiza los d√≠as s√°bados cada dos semanas, previa inscripci√≥n en el siguiente enlace (&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdzlBPk6hNHK6IlyIHIjvg4ehYhi5Wn39t4Vo9q9fVW0zid0w/viewform&#34;&gt;https://docs.google.com/forms/d/e/1FAIpQLSdzlBPk6hNHK6IlyIHIjvg4ehYhi5Wn39t4Vo9q9fVW0zid0w/viewform&lt;/a&gt;). Podr√°s rendirlo todas las veces que quieras. Para m√°s informaci√≥n, puedes ir a la secci√≥n del challenge.&lt;/p&gt; &#xA;&lt;p&gt;¬øQu√© puedo hacer si tengo dudas? Contamos con Slack: una plataforma de comunicaci√≥n donde podr√°s ponerte en contacto con nuestra comunidad que siempre te ayudar√° a resolver todas tus dudas. Encontrar√°s acceso a slack desde los mails que recibiste al aplicar a la carrera. M√°s adelante te explicaremos c√≥mo usar la herramienta.&lt;/p&gt; &#xA;&lt;p&gt;Entonces, ¬øqu√© debo hacer ahora para avanzar con el proceso? Debes comenzar a ver todos los videos, el material escrito y a hacer los ejercicios, siguiendo el orden postulado aqu√≠ en el curso. Una vez que hayas finalizado, pasar√°s al material de matem√°tica y luego podr√°s realizar el Henry Challenge.&lt;/p&gt; &#xA;&lt;p&gt;Cualquier duda, nos puedes escribir a &lt;a href=&#34;mailto:admisiones@soyhenry.com&#34;&gt;admisiones@soyhenry.com&lt;/a&gt; ¬°Muchos √©xitos!&lt;/p&gt; &#xA;&lt;h2&gt;Open House&lt;/h2&gt; &#xA;&lt;p&gt;En este video podr√°s conocer m√°s sobre Henry, la carrera de Data Science y el proceso de admisi√≥n.&lt;/p&gt; &#xA;&lt;div class=&#34;iframeContainer&#34;&gt;&#xA;  &amp;lt;iframe src=&#34;https://player.vimeo.com/video/682041440&#34; allow=&#34;autoplay; fullscreen&#34; allowfullscreen&amp;gt;&amp;lt;/iframe&amp;gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;El Henry Challenge se realiza los sabados, cada dos semanas. Puedes encontrar las nuevas fechas e inscribirte aqui: &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSdzlBPk6hNHK6IlyIHIjvg4ehYhi5Wn39t4Vo9q9fVW0zid0w/viewform&#34;&gt;https://docs.google.com/forms/d/e/1FAIpQLSdzlBPk6hNHK6IlyIHIjvg4ehYhi5Wn39t4Vo9q9fVW0zid0w/viewform&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Los proximos inicios de la carrera se iran publicando en la landing de Data Science: &lt;a href=&#34;https://www.soyhenry.com/carrera-data-science&#34;&gt;https://www.soyhenry.com/carrera-data-science&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Si tienes mas dudas sobre Henry, la carrera o el proceso de admisi√≥n puedes consultarlo en el canal #consultas_administrativas de Slack.&lt;/p&gt;</summary>
  </entry>
</feed>