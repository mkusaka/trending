<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-15T01:45:01Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>naganandy/graph-based-deep-learning-literature</title>
    <updated>2022-06-15T01:45:01Z</updated>
    <id>tag:github.com,2022-06-15:/naganandy/graph-based-deep-learning-literature</id>
    <link href="https://github.com/naganandy/graph-based-deep-learning-literature" rel="alternate"></link>
    <summary type="html">&lt;p&gt;links to conference publications in graph-based deep learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Graph-based Deep Learning Literature&lt;/h1&gt; &#xA;&lt;p&gt;The repository contains links primarily to &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/README.md&#34;&gt;conference publications&lt;/a&gt; in graph-based deep learning. The repository contains links also to&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/workshops/README.md&#34;&gt;Related Workshops&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/surveys/README.md&#34;&gt;Surveys / Literature Reviews / Books&lt;/a&gt;,&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/software/README.md&#34;&gt;Software/Libraries&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/README.md#conferences&#34;&gt;The links to conference publications&lt;/a&gt; are arranged in the reverse chronological order of conference dates from the conferences below (and also arranged year-wise for each conference).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h2&gt;Machine Learning Conferences&lt;/h2&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://nips.cc/&#34;&gt;NeurIPS&lt;/a&gt; - 2022 (Dec) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_neurips21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_neurips20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_neurips19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_neurips18/README.md&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#neurips-2017&#34;&gt;2017&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#neurips-2016&#34;&gt;2016&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#neurips-2015&#34;&gt;2015&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://icml.cc/&#34;&gt;ICML&lt;/a&gt; - 2022 (Jul) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_icml21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_icml20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_icml19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#icml-2018-jul&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#icml-2017&#34;&gt;2017&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#icml-2016&#34;&gt;2016&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://iclr.cc/&#34;&gt;ICLR&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iclr22/README.md&#34;&gt;2022&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iclr21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iclr20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iclr19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#iclr-2018-may&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#iclr-2017&#34;&gt;2017&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#iclr-2016&#34;&gt;2016&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#iclr-2014&#34;&gt;2014&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h2&gt;Computer Vision Conferences&lt;/h2&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;http://cvpr2022.thecvf.com/&#34;&gt;CVPR&lt;/a&gt; - 2022 (Jun) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_cvpr21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_cvpr20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_cvpr19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#cvpr-2018-jun&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#cvpr-2017&#34;&gt;2017&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;http://iccv2021.thecvf.com/home&#34;&gt;ICCV&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iccv21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iccv19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#iccv-2017&#34;&gt;2017&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://eccv2022.ecva.net/&#34;&gt;ECCV&lt;/a&gt; - 2022 (Oct) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_eccv20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#eccv-2018-sep&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h2&gt;Data Mining Conferences&lt;/h2&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://www.kdd.org/kdd2022/&#34;&gt;KDD&lt;/a&gt; - 2022 (Aug) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/tree/master/conference-publications/folders/publications_kdd21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/tree/master/conference-publications/folders/publications_kdd20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_kdd19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#kdd-2018-aug&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://icdm22.cse.usf.edu/&#34;&gt;ICDM&lt;/a&gt; - 2022 (Dec) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_icdm21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_icdm20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2019.MD#icdm-2019-nov&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#icdm-2018-nov&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://www.wsdm-conference.org/2022/&#34;&gt;WSDM&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_wsdm22/README.md&#34;&gt;2022&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_wsdm21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2020.MD#wsdm-2020-feb&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2019.MD#wsdm-2019-jan&#34;&gt;2019&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h2&gt;Artificial Intelligence Conferences&lt;/h2&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://www2022.thewebconf.org/&#34;&gt;TheWebConf&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_webconf22/README.md&#34;&gt;2022&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_webconf21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_www20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2019.MD#www-2019-may&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#www-2018-april&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://aaai.org/Conferences/AAAI-22/&#34;&gt;AAAI&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_aaai22/README.md&#34;&gt;2022&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_aaai21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_aaai20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_aaai19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#aaai-2018-feb&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#aaai-2017&#34;&gt;2017&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://ijcai-22.org/&#34;&gt;IJCAI&lt;/a&gt; - 2022 (Jul) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_ijcai21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_ijcai20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_ijcai19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#ijcai-2018-jul&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#ijcai-2017&#34;&gt;2017&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;h2&gt;Computational Linguistics Conferences&lt;/h2&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://www.2022.aclweb.org/&#34;&gt;ACL&lt;/a&gt; - &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_acl22/README.md&#34;&gt;2022&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_acl21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_acl20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_acl19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#acl-2018-jul&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://2022.emnlp.org/&#34;&gt;EMNLP&lt;/a&gt; - 2022 (Dec) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_emnlp21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_emnlp20/README.md&#34;&gt;2020&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_emnlp19/README.md&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#emnlp-2018-nov&#34;&gt;2018&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2017.MD#emnlp-2017&#34;&gt;2017&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;h3&gt;&lt;a href=&#34;https://naacl.org/&#34;&gt;NAACL&lt;/a&gt; - 2022 (Jul) | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_naacl21/README.md&#34;&gt;2021&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2019.MD#naacl-2019-jun&#34;&gt;2019&lt;/a&gt; | &lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_years/2018.MD#naacl-2018-jun&#34;&gt;2018&lt;/a&gt;&lt;/h3&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Top 10 Most Cited Conference Publications (on Graph Neural Networks)&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/gcn_iclr17/README.md&#34;&gt;Semi-Supervised Classification with Graph Convolutional Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_conf18/gan_iclr18/README.md&#34;&gt;Graph Attention Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/graphsage_nips17/README.md&#34;&gt;Inductive Representation Learning on Large Graphs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/chebnet_nips16/README.md&#34;&gt;Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/gnn_tnn09/README.md&#34;&gt;The Graph Neural Network Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/mpnn_icml17/README.md&#34;&gt;Neural Message Passing for Quantum Chemistry&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/graphcnn_iclr14/README.md&#34;&gt;Spectral Networks and Locally Connected Networks on Graphs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/graphcnn_nips15/README.md&#34;&gt;Convolutional Networks on Graphs for Learning Molecular Fingerprints&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_iclr19/gin_iclr19/README.md&#34;&gt;How Powerful are Graph Neural Networks?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/naganandy/graph-based-deep-learning-literature/raw/master/conference-publications/folders/publications_pre18/ggnn_iclr16/README.md&#34;&gt;Gated Graph Sequence Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>phlippe/uvadlc_notebooks</title>
    <updated>2022-06-15T01:45:01Z</updated>
    <id>tag:github.com,2022-06-15:/phlippe/uvadlc_notebooks</id>
    <link href="https://github.com/phlippe/uvadlc_notebooks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repository of Jupyter notebook tutorials for teaching the Deep Learning Course at the University of Amsterdam (MSc AI), Fall 2021/Spring 2022&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;UvA Deep Learning Tutorials&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: To look at the notebooks in a nicer format, visit our RTD website: &lt;a href=&#34;https://uvadlc-notebooks.readthedocs.io/en/latest/&#34;&gt;https://uvadlc-notebooks.readthedocs.io/en/latest/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Course website&lt;/em&gt;: &lt;a href=&#34;https://uvadlc.github.io/&#34;&gt;https://uvadlc.github.io/&lt;/a&gt;&lt;br&gt; &lt;em&gt;Course edition&lt;/em&gt;: Fall 2021 (Nov. 01 - Dec. 24) - Being kept up to date&lt;br&gt; &lt;em&gt;Recordings&lt;/em&gt;: &lt;a href=&#34;https://www.youtube.com/playlist?list=PLdlPlO1QhMiAkedeu0aJixfkknLRxk1nA&#34;&gt;YouTube Playlist&lt;/a&gt;&lt;br&gt; &lt;em&gt;Author&lt;/em&gt;: Phillip Lippe&lt;/p&gt; &#xA;&lt;p&gt;or this year&#39;s course edition, we created a series of Jupyter notebooks that are designed to help you understanding the &#34;theory&#34; from the lectures by seeing corresponding implementations. We will visit various topics such as optimization techniques, transformers, graph neural networks, and more (for a full list, see below). The notebooks are there to help you understand the material and teach you details of the &lt;strong&gt;PyTorch&lt;/strong&gt; framework, including &lt;strong&gt;PyTorch Lightning&lt;/strong&gt;. Further, we provide one-to-one translations of the notebooks to &lt;strong&gt;JAX+Flax&lt;/strong&gt; as alternative framework.&lt;/p&gt; &#xA;&lt;p&gt;The notebooks are presented in the first hour of every group tutorial session. During the tutorial sessions, we will present the content and explain the implementation of the notebooks. You can decide yourself whether you just want to look at the filled notebook, want to try it yourself, or code along during the practical session. The notebooks are not directly part of any mandatory assignments on which you would be graded or similarly. However, we encourage you to get familiar with the notebooks and experiment or extend them yourself. Further, the content presented will be relevant for the graded assignment and exam.&lt;/p&gt; &#xA;&lt;p&gt;The tutorials have been integrated as official tutorials of PyTorch Lightning. Thus, you can also view them in &lt;a href=&#34;https://pytorch-lightning.readthedocs.io/en/latest/&#34;&gt;their documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;How to run the notebooks&lt;/h2&gt; &#xA;&lt;p&gt;On this website, you will find the notebooks exported into a HTML format so that you can read them from whatever device you prefer. However, we suggest that you also give them a try and run them yourself. There are three main ways of running the notebooks we recommend:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Locally on CPU&lt;/strong&gt;: All notebooks are stored on the github repository that also builds this website. You can find them here: &lt;a href=&#34;https://github.com/phlippe/uvadlc_notebooks/tree/master/docs/tutorial_notebooks&#34;&gt;https://github.com/phlippe/uvadlc_notebooks/tree/master/docs/tutorial_notebooks&lt;/a&gt;. The notebooks are designed that you can execute them on common laptops without the necessity of a GPU. We provide pretrained models that are automatically downloaded when running the notebooks, or can manually be downloaoded from this &lt;a href=&#34;https://drive.google.com/drive/folders/1SevzqrkhHPAifKEHo-gi7J-dVxifvs4c?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;. The required disk space for the pretrained models and datasets is less than 1GB. To ensure that you have all the right python packages installed, we provide a conda environment in the &lt;a href=&#34;https://github.com/phlippe/uvadlc_notebooks/raw/master/&#34;&gt;same repository&lt;/a&gt; (choose the CPU or GPU version depending on your system).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Google Colab&lt;/strong&gt;: If you prefer to run the notebooks on a different platform than your own computer, or want to experiment with GPU support, we recommend using &lt;a href=&#34;https://colab.research.google.com/notebooks/intro.ipynb#recent=true&#34;&gt;Google Colab&lt;/a&gt;. Each notebook on this documentation website has a badge with a link to open it on Google Colab. Remember to enable GPU support before running the notebook (&lt;code&gt;Runtime -&amp;gt; Change runtime type&lt;/code&gt;). Each notebook can be executed independently, and doesn&#39;t require you to connect your Google Drive or similar. However, when closing the session, changes might be lost if you don&#39;t save it to your local computer or have copied the notebook to your Google Drive beforehand.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Lisa cluster&lt;/strong&gt;: If you want to train your own (larger) neural networks based on the notebooks, you can make use of the Lisa cluster. However, this is only suggested if you really want to train a new model, and use the other two options to go through the discussion and analysis of the models. Lisa might not allow you with your student account to run jupyter notebooks directly on the gpu_shared partition. Instead, you can first convert the notebooks to a script using &lt;code&gt;jupyter nbconvert --to script ...ipynb&lt;/code&gt;, and then start a job on Lisa for running the script. A few advices when running on Lisa:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Disable the tqdm statements in the notebook. Otherwise your slurm output file might overflow and be several MB large. In PyTorch Lightning, you can do this by setting &lt;code&gt;progress_bar_refresh_rate=0&lt;/code&gt; in the trainer.&lt;/li&gt; &#xA;   &lt;li&gt;Comment out the matplotlib plotting statements, or change :code:&lt;code&gt;plt.show()&lt;/code&gt; to &lt;code&gt;plt.savefig(...)&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tutorial-Lecture alignment&lt;/h2&gt; &#xA;&lt;p&gt;We will discuss 7 of the tutorials in the course, spread across lectures to cover something from every area. You can align the tutorials with the lectures based on their topics. The list of tutorials is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Guide 1: Working with the Lisa cluster&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 2: Introduction to PyTorch&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 3: Activation functions&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 4: Optimization and Initialization&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 5: Inception, ResNet and DenseNet&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 6: Transformers and Multi-Head Attention&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 7: Graph Neural Networks&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 8: Deep Energy Models&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 9: Autoencoders&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 10: Adversarial attacks&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 11: Normalizing Flows on image modeling&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 12: Autoregressive Image Modeling&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 15: Vision Transformers&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 16: Meta Learning - Learning to Learn&lt;/li&gt; &#xA; &lt;li&gt;Tutorial 17: Self-Supervised Contrastive Learning with SimCLR&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Feedback, Questions or Contributions&lt;/h2&gt; &#xA;&lt;p&gt;This is the first time we present these tutorials during the Deep Learning course. As with any other project, small bugs and issues are expected. We appreciate any feedback from students, whether it is about a spelling mistake, implementation bug, or suggestions for improvements/additions to the notebooks. Please use the following &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSeIhwrFSHlDSWGAgCN-RcTKm7Sn7P6bxzIyzIGge6xId1K8DQ/viewform?usp=sf_link&#34;&gt;link&lt;/a&gt; to submit feedback, or feel free to reach out to me directly per mail (p dot lippe at uva dot nl), or grab me during any TA session.&lt;/p&gt; &#xA;&lt;p&gt;If you find the tutorials helpful and would like to cite them, you can use the following bibtex:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{lippe2022uvadlc,&#xA;   title        = {{UvA Deep Learning Tutorials}},&#xA;   author       = {Phillip Lippe},&#xA;   year         = 2022,&#xA;   howpublished = {\url{https://uvadlc-notebooks.readthedocs.io/en/latest/}}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>google/dynamicworld</title>
    <updated>2022-06-15T01:45:01Z</updated>
    <id>tag:github.com,2022-06-15:/google/dynamicworld</id>
    <link href="https://github.com/google/dynamicworld" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dynamic World Model Runner&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zenodo.org/badge/latestdoi/413957377&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/413957377.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Model files and example notebook for Dynamic World, see &lt;strong&gt;[PUBLICATION DOI PENDING REVIEW]&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;This is not an officially supported Google product.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/guide/saved_model&#34;&gt;TensorFlow SavedModels&lt;/a&gt; for the forward and backward path can be found in &lt;code&gt;./model/forward&lt;/code&gt; and &lt;code&gt;./model/backward&lt;/code&gt; respectively.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;./single_image_runner.ipynb&lt;/code&gt; gives a step-by-step guide to making predictions with the Dynamic World models.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the image below for the model block diagram. For Dynamic World, &lt;code&gt;m = 1.5&lt;/code&gt; and &lt;code&gt;b = 2&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.github.com/google/dynamicworld/master/dw_model_arch.png&#34; alt=&#34;Dynamic World neural network architecture&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>