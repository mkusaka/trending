<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-29T01:41:06Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>cvg/LightGlue</title>
    <updated>2023-06-29T01:41:06Z</updated>
    <id>tag:github.com,2023-06-29:/cvg/LightGlue</id>
    <link href="https://github.com/cvg/LightGlue" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LightGlue: Local Feature Matching at Light Speed&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h1 align=&#34;center&#34;&gt;&lt;ins&gt;LightGlue&lt;/ins&gt;&lt;br&gt;Local Feature Matching at Light Speed&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://www.linkedin.com/in/philipplindenberger/&#34;&gt;Philipp Lindenberger&lt;/a&gt; ¬∑ &lt;a href=&#34;https://psarlin.com/&#34;&gt;Paul-Edouard&amp;nbsp;Sarlin&lt;/a&gt; ¬∑ &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/mapoll/&#34;&gt;Marc&amp;nbsp;Pollefeys&lt;/a&gt; &lt;/p&gt; &#xA;&lt;!-- &lt;p align=&#34;center&#34;&gt;&#xA;    &lt;img src=&#34;assets/larchitecture.svg&#34; alt=&#34;Logo&#34; height=&#34;40&#34;&gt;&#xA;&lt;/p&gt; --&gt; &#xA;&lt;!-- &lt;h2 align=&#34;center&#34;&gt;PrePrint 2023&lt;/h2&gt; --&gt; &#xA;&lt;h2&gt;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://arxiv.org/pdf/2306.13643.pdf&#34; align=&#34;center&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&lt;/div&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://arxiv.org/abs/2306.13643&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cvg/LightGlue/main/assets/easy_hard.jpg&#34; alt=&#34;Logo&#34; width=&#34;80%&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;em&gt;LightGlue is a Graph Neural Network for local feature matching that introspects its confidences to 1) stop early if all predictions are ready and 2) remove points deemed unmatchable to save compute.&lt;/em&gt; &lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This repository hosts the inference code for LightGlue, a lightweight feature matcher with high accuracy and adaptive pruning techniques, both in the width and depth of the network, for blazing fast inference. It takes as input a set of keypoints and descriptors for each image, and returns the indices of corresponding points between them.&lt;/p&gt; &#xA;&lt;p&gt;We release pretrained weights of LightGlue with &lt;a href=&#34;https://arxiv.org/abs/1712.07629&#34;&gt;SuperPoint&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2006.13566&#34;&gt;DISK&lt;/a&gt; local features.&lt;/p&gt; &#xA;&lt;p&gt;The training end evaluation code will be released in July in a separate repo. If you wish to be notified, subscribe to &lt;a href=&#34;https://github.com/cvg/LightGlue/issues/6&#34;&gt;Issue #6&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation and Demo&lt;/h2&gt; &#xA;&lt;p&gt;You can install this repo pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/cvg/LightGlue.git &amp;amp;&amp;amp; cd LightGlue&#xA;python -m pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We provide a &lt;a href=&#34;https://raw.githubusercontent.com/cvg/LightGlue/main/demo.ipynb&#34;&gt;demo notebook&lt;/a&gt; which shows how to perform feature extraction and matching on an image pair.&lt;/p&gt; &#xA;&lt;p&gt;Here is a minimal script to match two images:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lightglue import LightGlue, SuperPoint, DISK&#xA;from lightglue.utils import load_image, match_pair&#xA;&#xA;# SuperPoint+LightGlue&#xA;extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor&#xA;matcher = LightGlue(pretrained=&#39;superpoint&#39;).eval().cuda()  # load the matcher&#xA;&#xA;# or DISK+LightGlue&#xA;extractor = DISK(max_num_keypoints=2048).eval().cuda()  # load the extractor&#xA;matcher = LightGlue(pretrained=&#39;disk&#39;).eval().cuda()  # load the matcher&#xA;&#xA;# load images to torch and resize to max_edge=1024&#xA;image0, scales0 = load_image(path_to_image_0, resize=1024)&#xA;image1, scales1 = load_image(path_to_image_1, resize=1024)&#xA;&#xA;# extraction + matching + rescale keypoints to original image size&#xA;pred = match_pair(extractor, matcher, image0, image1,&#xA;                  scales0=scales0, scales1=scales1)    &#xA;&#xA;kpts0, kpts1, matches = pred[&#39;keypoints0&#39;], pred[&#39;keypoints1&#39;], pred[&#39;matches&#39;]&#xA;m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tradeoff Speed vs. Accuracy&lt;/h2&gt; &#xA;&lt;p&gt;LightGlue can adjust its depth (number of layers) and width (number of keypoints) per image pair, with a minimal impact on accuracy.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://arxiv.org/abs/2306.13643&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cvg/LightGlue/main/assets/teaser.svg?sanitize=true&#34; alt=&#34;Logo&#34; width=&#34;50%&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cvg/LightGlue/raw/release/lightglue/lightglue.py#L265&#34;&gt;&lt;code&gt;depth_confidence&lt;/code&gt;&lt;/a&gt;: Controls early stopping, improves run time. Recommended: 0.95. Default: -1 (off)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cvg/LightGlue/raw/release/lightglue/lightglue.py#L266&#34;&gt;&lt;code&gt;width_confidence&lt;/code&gt;&lt;/a&gt;: Controls iterative feature removal, improves run time. Recommended: 0.99. Default: -1 (off)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/cvg/LightGlue/raw/release/lightglue/lightglue.py#L262&#34;&gt;&lt;code&gt;flash&lt;/code&gt;&lt;/a&gt;: Enable &lt;a href=&#34;https://github.com/HazyResearch/flash-attention/tree/main&#34;&gt;FlashAttention&lt;/a&gt;. Significantly improves runtime and reduces memory consumption without any impact on accuracy, but requires either &lt;a href=&#34;https://github.com/HazyResearch/flash-attention/tree/main&#34;&gt;FlashAttention&lt;/a&gt; or &lt;code&gt;torch &amp;gt;= 2.0&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;LightGlue in other frameworks&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ONNX: &lt;a href=&#34;https://github.com/fabio-sim&#34;&gt;fabio-sim&lt;/a&gt; was blazing fast in implementing an ONNX-compatible version of LightGlue &lt;a href=&#34;https://github.com/fabio-sim/LightGlue-ONNX&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BibTeX Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use any ideas from the paper or code from this repo, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-txt&#34;&gt;@inproceedings{lindenberger23lightglue,&#xA;  author    = {Philipp Lindenberger and&#xA;               Paul-Edouard Sarlin and&#xA;               Marc Pollefeys},&#xA;  title     = {{LightGlue}: Local Feature Matching at Light Speed},&#xA;  booktitle = {ArXiv PrePrint},&#xA;  year      = {2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>whylabs/langkit</title>
    <updated>2023-06-29T01:41:06Z</updated>
    <id>tag:github.com,2023-06-29:/whylabs/langkit</id>
    <link href="https://github.com/whylabs/langkit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LangKit is an open-source text metrics toolkit for monitoring language models.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangKit&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/static/img/LangKit_graphic.png&#34; alt=&#34;LangKit graphic&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;LangKit is an open-source text metrics toolkit for monitoring language models. It offers an array of methods for extracting relevant signals from the input and/or output text, which are compatible with the open-source data logging library &lt;a href=&#34;https://whylogs.readthedocs.io/en/latest&#34;&gt;whylogs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;üí° Want to experience LangKit? Go to this &lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/examples/Intro_to_Langkit.ipynb&#34;&gt;notebook&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Table of Contents üìñ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/#motivation-&#34;&gt;Motivation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/#features-&#34;&gt;Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/#installation-&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/#usage-&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/whylabs/langkit/main/#modules-&#34;&gt;Modules&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Motivation üéØ&lt;/h2&gt; &#xA;&lt;p&gt;Productionizing language models, including LLMs, comes with a range of risks due to the infinite amount of input combinations, which can elicit an infinite amount of outputs. The unstructured nature of text poses a challenge in the ML observability space - a challenge worth solving, since the lack of visibility on the model&#39;s behavior can have serious consequences.&lt;/p&gt; &#xA;&lt;h2&gt;Features üõ†Ô∏è&lt;/h2&gt; &#xA;&lt;p&gt;The currently supported metrics include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/docs/features/quality.md&#34;&gt;Text Quality&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;readability score&lt;/li&gt; &#xA;   &lt;li&gt;complexity and grade scores&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/docs/features/relevance.md&#34;&gt;Text Relevance&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Similarity scores between prompt/responses&lt;/li&gt; &#xA;   &lt;li&gt;Similarity scores against user-defined themes&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/docs/features/security.md&#34;&gt;Security and Privacy&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;patterns - count of strings matching a user-defined regex pattern group&lt;/li&gt; &#xA;   &lt;li&gt;jailbreaks - similarity scores with respect to known jailbreak attempts&lt;/li&gt; &#xA;   &lt;li&gt;prompt injection - similarity scores with respect to known prompt injection attacks&lt;/li&gt; &#xA;   &lt;li&gt;refusals - similarity scores with respect to known LLM refusal of service responses&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/docs/features/sentiment.md&#34;&gt;Sentiment and Toxicity&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;sentiment analysis&lt;/li&gt; &#xA;   &lt;li&gt;toxicity analysis&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation üíª&lt;/h2&gt; &#xA;&lt;p&gt;To install LangKit, use the Python Package Index (PyPI) as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install langkit[all]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage üöÄ&lt;/h2&gt; &#xA;&lt;p&gt;LangKit modules contain UDFs that automatically wire into the collection of UDFs on String features provided by whylogs by default. All we have to do is import the LangKit modules and then instantiate a custom schema as shown in the example below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import whylogs as why&#xA;from langkit import llm_metrics&#xA;&#xA;results = why.log({&#34;prompt&#34;: &#34;Hello!&#34;, &#34;response&#34;: &#34;World!&#34;}, schema=llm_metrics.init())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The code above will produce a set of metrics comprised of the default whylogs metrics for text features and all the metrics defined in the imported modules. This profile can be visualized and monitored in the &lt;a href=&#34;https://whylabs.ai/safeguard-large-language-models?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=langkit&#34;&gt;WhyLabs platform&lt;/a&gt; or they can be further analyzed by the user on their own accord.&lt;/p&gt; &#xA;&lt;p&gt;More examples are available &lt;a href=&#34;https://github.com/whylabs/langkit/tree/main/langkit/examples&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Modules üì¶&lt;/h2&gt; &#xA;&lt;p&gt;You can have more information about the different modules and their metrics &lt;a href=&#34;https://github.com/whylabs/langkit/raw/main/langkit/docs/modules.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>aiclub-igdtuw/AIMLMonth2023</title>
    <updated>2023-06-29T01:41:06Z</updated>
    <id>tag:github.com,2023-06-29:/aiclub-igdtuw/AIMLMonth2023</id>
    <link href="https://github.com/aiclub-igdtuw/AIMLMonth2023" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI ML Month 2023&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; ü§ñ &lt;br&gt; AI-ML-Month 2023 &lt;br&gt; AI Club IGDTUW &lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt; 5th June 2023 - 19th July 2023&lt;/h3&gt;</summary>
  </entry>
</feed>