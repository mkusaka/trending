<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-06-01T01:32:09Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>2noise/ChatTTS</title>
    <updated>2024-06-01T01:32:09Z</updated>
    <id>tag:github.com,2024-06-01:/2noise/ChatTTS</id>
    <link href="https://github.com/2noise/ChatTTS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatTTS is a generative speech model for daily dialogue.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ChatTTS&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/2noise/ChatTTS/main/README.md&#34;&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/2noise/ChatTTS/main/README_CN.md&#34;&gt;&lt;strong&gt;中文简体&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ChatTTS is a text-to-speech model designed specifically for dialogue scenario such as LLM assistant. It supports both English and Chinese languages. Our model is trained with 100,000+ hours composed of chinese and english. The open-source version on &lt;strong&gt;&lt;a href=&#34;https://huggingface.co/2Noise/ChatTTS&#34;&gt;HuggingFace&lt;/a&gt;&lt;/strong&gt; is a 40,000 hours pre trained model without SFT.&lt;/p&gt; &#xA;&lt;p&gt;For formal inquiries about model and roadmap, please contact us at &lt;strong&gt;&lt;a href=&#34;mailto:open-source@2noise.com&#34;&gt;open-source@2noise.com&lt;/a&gt;&lt;/strong&gt;. You could join our QQ group: 808364215 for discussion. Adding github issues is always welcomed.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Highlights&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Conversational TTS&lt;/strong&gt;: ChatTTS is optimized for dialogue-based tasks, enabling natural and expressive speech synthesis. It supports multiple speakers, facilitating interactive conversations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Fine-grained Control&lt;/strong&gt;: The model could predict and control fine-grained prosodic features, including laughter, pauses, and interjections.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Better Prosody&lt;/strong&gt;: ChatTTS surpasses most of open-source TTS models in terms of prosody. We provide pretrained models to support further research and development.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For the detailed description of the model, you can refer to &lt;strong&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1zn4y1o7iV&#34;&gt;video on Bilibili&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This repo is for academic purposes only. It is intended for educational and research use, and should not be used for any commercial or legal purposes. The authors do not guarantee the accuracy, completeness, or reliability of the information. The information and data used in this repo, are for academic and research purposes only. The data obtained from publicly available sources, and the authors do not claim any ownership or copyright over the data.&lt;/p&gt; &#xA;&lt;p&gt;ChatTTS is a powerful text-to-speech system. However, it is very important to utilize this technology responsibly and ethically. To limit the use of ChatTTS, we added a small amount of high-frequency noise during the training of the 40,000-hour model, and compressed the audio quality as much as possible using MP3 format, to prevent malicious actors from potentially using it for criminal purposes. At the same time, we have internally trained a detection model and plan to open-source it in the future.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h4&gt;Basic usage&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import ChatTTS&#xA;from IPython.display import Audio&#xA;&#xA;chat = ChatTTS.Chat()&#xA;chat.load_models(compile=False) # Set to True for better performance&#xA;&#xA;texts = [&#34;PUT YOUR TEXT HERE&#34;,]&#xA;&#xA;wavs = chat.infer(texts, )&#xA;&#xA;torchaudio.save(&#34;output1.wav&#34;, torch.from_numpy(wavs[0]), 24000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Advanced usage&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;###################################&#xA;# Sample a speaker from Gaussian.&#xA;&#xA;rand_spk = chat.sample_random_speaker()&#xA;&#xA;params_infer_code = {&#xA;  &#39;spk_emb&#39;: rand_spk, # add sampled speaker &#xA;  &#39;temperature&#39;: .3, # using custom temperature&#xA;  &#39;top_P&#39;: 0.7, # top P decode&#xA;  &#39;top_K&#39;: 20, # top K decode&#xA;}&#xA;&#xA;###################################&#xA;# For sentence level manual control.&#xA;&#xA;# use oral_(0-9), laugh_(0-2), break_(0-7) &#xA;# to generate special token in text to synthesize.&#xA;params_refine_text = {&#xA;  &#39;prompt&#39;: &#39;[oral_2][laugh_0][break_6]&#39;&#xA;} &#xA;&#xA;wav = chat.infer(texts, params_refine_text=params_refine_text, params_infer_code=params_infer_code)&#xA;&#xA;###################################&#xA;# For word level manual control.&#xA;text = &#39;What is [uv_break]your favorite english food?[laugh][lbreak]&#39;&#xA;wav = chat.infer(text, skip_refine_text=True, params_refine_text=params_refine_text,  params_infer_code=params_infer_code)&#xA;torchaudio.save(&#34;output2.wav&#34;, torch.from_numpy(wavs[0]), 24000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;h4&gt;Example: self introduction&lt;/h4&gt;&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;inputs_en = &#34;&#34;&#34;&#xA;chat T T S is a text to speech model designed for dialogue applications. &#xA;[uv_break]it supports mixed language input [uv_break]and offers multi speaker &#xA;capabilities with precise control over prosodic elements [laugh]like like &#xA;[uv_break]laughter[laugh], [uv_break]pauses, [uv_break]and intonation. &#xA;[uv_break]it delivers natural and expressive speech,[uv_break]so please&#xA;[uv_break] use the project responsibly at your own risk.[uv_break]&#xA;&#34;&#34;&#34;.replace(&#39;\n&#39;, &#39;&#39;) # English is still experimental.&#xA;&#xA;params_refine_text = {&#xA;  &#39;prompt&#39;: &#39;[oral_2][laugh_0][break_4]&#39;&#xA;} &#xA;# audio_array_cn = chat.infer(inputs_cn, params_refine_text=params_refine_text)&#xA;audio_array_en = chat.infer(inputs_en, params_refine_text=params_refine_text)&#xA;torchaudio.save(&#34;output3.wav&#34;, torch.from_numpy(audio_array_en[0]), 24000)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/2noise/ChatTTS/assets/130631963/e0f51251-db7f-4d39-a0e9-3e095bb65de1&#34;&gt;male speaker&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/2noise/ChatTTS/assets/130631963/f5dcdd01-1091-47c5-8241-c4f6aaaa8bbd&#34;&gt;female speaker&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Open-source the 40k hour base model and spk_stats file&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Open-source VQ encoder and Lora training code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Streaming audio generation without refining the text*&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Open-source the 40k hour version with multi-emotion control&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; ChatTTS.cpp maybe? (PR or new repo are welcomed.)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h5&gt;How much VRAM do I need? How about infer speed?&lt;/h5&gt; &#xA;&lt;p&gt;For a 30-second audio clip, at least 4GB of GPU memory is required. For the 4090 GPU, it can generate audio corresponding to approximately 7 semantic tokens per second. The Real-Time Factor (RTF) is around 0.3.&lt;/p&gt; &#xA;&lt;h5&gt;model stability is not good enough, with issues such as multi speakers or poor audio quality.&lt;/h5&gt; &#xA;&lt;p&gt;This is a problem that typically occurs with autoregressive models(for bark and valle). It&#39;s generally difficult to avoid. One can try multiple samples to find a suitable result.&lt;/p&gt; &#xA;&lt;h5&gt;Besides laughter, can we control anything else? Can we control other emotions?&lt;/h5&gt; &#xA;&lt;p&gt;In the current released model, the only token-level control units are [laugh], [uv_break], and [lbreak]. In future versions, we may open-source models with additional emotional control capabilities.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/suno-ai/bark&#34;&gt;bark&lt;/a&gt;, &lt;a href=&#34;https://github.com/coqui-ai/TTS&#34;&gt;XTTSv2&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2301.02111&#34;&gt;valle&lt;/a&gt; demostrate a remarkable TTS result by a autoregressive-style system.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fishaudio/fish-speech&#34;&gt;fish-speech&lt;/a&gt; reveals capability of GVQ as audio tokenizer for LLM modeling.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gemelo-ai/vocos&#34;&gt;vocos&lt;/a&gt; which is used as a pretrained vocoder.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Special Appreciation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://audio.westlake.edu.cn/&#34;&gt;wlu-audio lab&lt;/a&gt; for early algorithm experiments.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Azure-Samples/AI-Gateway</title>
    <updated>2024-06-01T01:32:09Z</updated>
    <id>tag:github.com,2024-06-01:/Azure-Samples/AI-Gateway</id>
    <link href="https://github.com/Azure-Samples/AI-Gateway" rel="alternate"></link>
    <summary type="html">&lt;p&gt;APIM ❤️ OpenAI - this repo contains a set of experiments on using Azure APIM with Azure OpenAI and other services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;APIM ❤️ OpenAI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/firstcontributions/open-source-badges&#34;&gt;&lt;img src=&#34;https://firstcontributions.github.io/open-source-badges/badges/open-source-v1/open-source.svg?sanitize=true&#34; alt=&#34;Open Source Love&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-ai-gateway&#34;&gt;🧠 AI Gateway&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-labs&#34;&gt;🧪 Labs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-getting-started&#34;&gt;🚀 Getting started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-well-architected-framework&#34;&gt;🏛️ Well Architected Framework&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-mock-server&#34;&gt;🪞 Mock Server&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-show-and-tell&#34;&gt;🎒 Show and tell&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#-other-resources&#34;&gt;🥇 Other Resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The rapid pace of AI advances demands experimentation-driven approaches for organizations to remain at the forefront of the industry. With AI steadily becoming a game-changer for an array of sectors, maintaining a fast-paced innovation trajectory is crucial for businesses aiming to leverage its full potential.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;AI services&lt;/strong&gt; are predominantly accessed via &lt;strong&gt;APIs&lt;/strong&gt;, underscoring the essential need for a robust and efficient API management strategy. This strategy is instrumental for maintaining control and governance over the consumption of &lt;strong&gt;AI services&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;With the expanding horizons of &lt;strong&gt;AI services&lt;/strong&gt; and their seamless integration with &lt;strong&gt;APIs&lt;/strong&gt;, there is a considerable demand for a comprehensive &lt;strong&gt;AI Gateway&lt;/strong&gt; pattern, which broadens the core principles of API management. Aiming to accelerate the experimentation of advanced use cases and pave the road for further innovation in this rapidly evolving field. The well-architected principles of the &lt;strong&gt;AI Gateway&lt;/strong&gt; provides a framework for the confident deployment of &lt;strong&gt;Intelligent Apps&lt;/strong&gt; into production..&lt;/p&gt; &#xA;&lt;h2&gt;🧠 AI Gateway&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/ai-gateway.gif&#34; alt=&#34;AI-Gateway flow&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repo explores the &lt;strong&gt;AI Gateway&lt;/strong&gt; pattern through a series of experimental labs. &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/api-management-key-concepts&#34;&gt;Azure API Management&lt;/a&gt; plays a crucial role within these labs, handling AI services APIs, with security, reliability, performance, overall operational efficiency and cost controls. The primary focus is on &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/ai-services/openai/overview&#34;&gt;Azure OpenAI&lt;/a&gt;, which sets the standard reference for Large Language Models (LLM). However, the same principles and design patterns could potentially be applied to any LLM.&lt;/p&gt; &#xA;&lt;h2&gt;🧪 Labs&lt;/h2&gt; &#xA;&lt;p&gt;Acknowledging the rising dominance of Python, particularly in the realm of AI, along with the powerful experimental capabilities of Jupyter notebooks, the following labs are structured around Jupyter notebooks, with step-by-step instructions with Python scripts, Bicep files and APIM policies:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/request-forwarding/request-forwarding.ipynb&#34;&gt;Request forwarding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/request-forwarding/request-forwarding.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/request-forwarding-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try forwarding requests to either an Azure OpenAI endpoint or a mock server. APIM uses the system &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/api-management-howto-use-managed-service-identity&#34;&gt;managed identity&lt;/a&gt; to authenticate into the Azure OpenAI service.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/11&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-circuit-breaking/backend-circuit-breaking.ipynb&#34;&gt;Backend circuit breaking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-circuit-breaking/backend-circuit-breaking.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/backend-circuit-breaking-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the built-in &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/backends?tabs=bicep&#34;&gt;backend circuit breaker functionality of APIM&lt;/a&gt; to either an Azure OpenAI endpoints or a mock server.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/15&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-pool-load-balancing/backend-pool-load-balancing.ipynb&#34;&gt;Backend pool load balancing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-pool-load-balancing/backend-pool-load-balancing.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/backend-pool-load-balancing-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the built-in load balancing &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/backends?tabs=bicep&#34;&gt;backend pool functionality of APIM&lt;/a&gt; to either a list of Azure OpenAI endpoints or mock servers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/16&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/advanced-load-balancing/advanced-load-balancing.ipynb&#34;&gt;Advanced load balancing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/advanced-load-balancing/advanced-load-balancing.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/advanced-load-balancing-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the advanced load balancing (based on a custom &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/api-management-howto-policies&#34;&gt;APIM policy&lt;/a&gt;) to either a list of Azure OpenAI endpoints or mock servers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/17&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/response-streaming/response-streaming.ipynb&#34;&gt;Response streaming&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/response-streaming/response-streaming.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/response-streaming-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try response streaming with APIM and Azure OpenAI endpoints to explore the advantages and shortcomings associated with &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/how-to-server-sent-events#guidelines-for-sse&#34;&gt;streaming&lt;/a&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/18&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/vector-searching/vector-searching.ipynb&#34;&gt;Vector searching&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/vector-searching/vector-searching.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/vector-searching-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview&#34;&gt;Retrieval Augmented Generation (RAG) pattern&lt;/a&gt; with Azure AI Search, Azure OpenAI embeddings and Azure OpenAI completions. All the endpoints are managed via APIM.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/19&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/built-in-logging/built-in-logging.ipynb&#34;&gt;Built-in logging&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/built-in-logging/built-in-logging.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/built-in-logging-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/observability&#34;&gt;buil-in logging capabilities of API Management&lt;/a&gt;. The requests are logged into Application Insights and it&#39;s easy to track request/response details and token usage with provided notebook.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/20&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/slm-self-hosting/slm-self-hosting.ipynb&#34;&gt;SLM self-hosting&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/slm-self-hosting/slm-self-hosting.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/slm-self-hosting-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the self-hosted &lt;a href=&#34;https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/&#34;&gt;phy-3 Small Language Model (SLM)&lt;/a&gt; trough the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/self-hosted-gateway-overview&#34;&gt;APIM self-hosted gateway&lt;/a&gt; with OpenAI API compatibility.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/21&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/access-controlling/access-controlling.ipynb&#34;&gt;Access controlling&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/access-controlling/access-controlling.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/access-controlling-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai#oauth-20-authorization-using-identity-provider&#34;&gt;OAuth 2.0 authorization feature&lt;/a&gt; using identity provider to enable more fine-grained access to OpenAPI APIs by particular users or client.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/25&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/token-rate-limiting/token-rate-limiting.ipynb&#34;&gt;Token rate limiting&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/token-rate-limiting/token-rate-limiting.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/token-rate-limiting-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/azure-openai-token-limit-policy&#34;&gt;token rate limiting policy&lt;/a&gt; to either a list of Azure OpenAI endpoints or mock servers.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/26&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/semantic-caching/semantic-caching.ipynb&#34;&gt;Semantic caching&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/semantic-caching/semantic-caching.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/semantic-caching-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/azure-openai-semantic-cache-lookup-policy&#34;&gt;sementic caching policy&lt;/a&gt;.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/27&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/token-metrics-emitting/token-metrics-emitting.ipynb&#34;&gt;Token metrics emitting&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/token-metrics-emitting/token-metrics-emitting.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/token-metrics-emitting-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/api-management/azure-openai-emit-token-metric-policy&#34;&gt;emit token metric policy&lt;/a&gt;. The policy sends metrics to Application Insights about consumption of large language model tokens through Azure OpenAI Service APIs.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/28&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/GPT-4o-inferencing/GPT-4o-inferencing.ipynb&#34;&gt;GPT-4o inferencing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/GPT-4o-inferencing/GPT-4o-inferencing.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/GPT-4o-inferencing-small.gif&#34; alt=&#34;flow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Playground to try the new GPT-4o model. GPT-4o (&#34;o&#34; for &#34;omni&#34;) is designed to handle a combination of text, audio, and video inputs, and can generate outputs in text, audio, and image formats.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/29&#34; title=&#34;Discussion&#34;&gt;💬&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Backlog of experiments&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Developer tooling&lt;/li&gt; &#xA; &lt;li&gt;App building&lt;/li&gt; &#xA; &lt;li&gt;Token counting&lt;/li&gt; &#xA; &lt;li&gt;Function calling&lt;/li&gt; &#xA; &lt;li&gt;Assistants load balancing&lt;/li&gt; &#xA; &lt;li&gt;Semantic Kernel plugin&lt;/li&gt; &#xA; &lt;li&gt;Cost tracking&lt;/li&gt; &#xA; &lt;li&gt;Content filtering&lt;/li&gt; &#xA; &lt;li&gt;PII handling&lt;/li&gt; &#xA; &lt;li&gt;Prompt storing&lt;/li&gt; &#xA; &lt;li&gt;Prompt guarding&lt;/li&gt; &#xA; &lt;li&gt;Prompt model routing&lt;/li&gt; &#xA; &lt;li&gt;Llama inferencing&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Kindly use &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/discussions/9&#34;&gt;the feedback discussion&lt;/a&gt; so that we can continuously improve with your experiences, suggestions, ideas or lab requests.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🚀 Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;Python 3.8 or later version&lt;/a&gt; installed&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://code.visualstudio.com/&#34;&gt;VS Code&lt;/a&gt; installed with the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter&#34;&gt;Jupyter notebook extension&lt;/a&gt; enabled&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/cli/azure/install-azure-cli&#34;&gt;Azure CLI&lt;/a&gt; installed&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/free/&#34;&gt;An Azure Subscription&lt;/a&gt; with Contributor permissions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/oai/access&#34;&gt;Access granted to Azure OpenAI&lt;/a&gt; or just enable the mock service&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively&#34;&gt;Sign in to Azure with Azure CLI&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quickstart&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repo and configure your local machine with the prerequisites. Or just create a &lt;a href=&#34;https://codespaces.new/Azure-Samples/AI-Gateway/tree/main&#34;&gt;GitHub Codespace&lt;/a&gt; and run it on the browser or in VS Code.&lt;/li&gt; &#xA; &lt;li&gt;Navigate through the available labs and select one that best suits your needs. For starters we recommend the &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/request-forwarding/request-forwarding.ipynb&#34;&gt;request forwarding&lt;/a&gt; with just the Azure CLI or the &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-pool-load-balancing/backend-pool-load-balancing.ipynb&#34;&gt;backend pool load balancing&lt;/a&gt; with Bicep.&lt;/li&gt; &#xA; &lt;li&gt;Open the notebook and run the provided steps.&lt;/li&gt; &#xA; &lt;li&gt;Tailor the experiment according to your requirements. If you wish to contribute to our collective work, we would appreciate your &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/CONTRIBUTING.MD&#34;&gt;submission of a pull request&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] 🪲 Please feel free to open a new &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/issues/new&#34;&gt;issue&lt;/a&gt; if you find something that should be fixed or enhanced.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🏛️ Well-Architected Framework&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/well-architected/what-is-well-architected-framework&#34;&gt;Azure Well-Architected Framework&lt;/a&gt; is a design framework that can improve the quality of a workload. The following table maps labs with the Well-Architected Framework pillars to set you up for success through architectural experimentation.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Lab&lt;/th&gt; &#xA;   &lt;th&gt;Security&lt;/th&gt; &#xA;   &lt;th&gt;Reliability&lt;/th&gt; &#xA;   &lt;th&gt;Performance&lt;/th&gt; &#xA;   &lt;th&gt;Operations&lt;/th&gt; &#xA;   &lt;th&gt;Costs&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/request-forwarding/request-forwarding.ipynb&#34;&gt;Request forwarding&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-circuit-breaking/backend-circuit-breaking.ipynb&#34;&gt;Backend circuit breaking&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Controls the availability of the OpenAI endpoint with the circuit breaker feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/backend-pool-load-balancing/backend-pool-load-balancing.ipynb&#34;&gt;Backend pool load balancing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;To ensure resilience, the request is distributed to two or more endpoints with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Load balances the requests to increase performance with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/advanced-load-balancing/advanced-load-balancing.ipynb&#34;&gt;Advanced load balancing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;To ensure resilience, the request is distributed to two or more endpoints with a custom policy&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Load balances the requests to increase performance with a custom policy&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/response-streaming/response-streaming.ipynb&#34;&gt;Response streaming&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;To get responses sooner, you can &#39;stream&#39; the completion as it&#39;s being generated&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/vector-searching/vector-searching.ipynb&#34;&gt;Vector searching&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;To ensure resilience, the request is distributed to two or more endpoints with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Load balances the requests to increase performance with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/built-in-logging/built-in-logging.ipynb&#34;&gt;Built-in logging&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Zero trust, keyless approach with manage identities and APIM security features&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;To ensure resilience, the request is distributed to two or more endpoints with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Load balances the requests to increase performance with the built-in feature&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Requests are logged to enable monitoring, alerting and automatic remediation&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Relation between APIM subscription and token consumption allows cost control&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/labs/slm-self-hosting/slm-self-hosting.ipynb&#34;&gt;SLM self-hosting&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Self hosting the model might improve the security posture with network restrictions&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/#%EF%B8%8F-well-architected-framework&#34; title=&#34;Performance might be improved with full control to the self-hosted model&#34;&gt;⭐&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Check the &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure-openai&#34;&gt;Azure Well-Architected Framework perspective on Azure OpenAI Service&lt;/a&gt; for aditional guidance.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🪞 Mock Server&lt;/h2&gt; &#xA;&lt;p&gt;The AI-Gateway Mock server is designed to mimic the behavior and responses of the OpenAI API, thereby creating an efficient simulation environment suitable for testing and development purposes on the integration with APIM and other use cases. The &lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/app.py&#34;&gt;app.py&lt;/a&gt; can be customized to tailor the Mock server to specific use cases.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/mock-server/mock-server.ipynb&#34;&gt;Run locally or deploy to Azure&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;🎒 Show and tell&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Install the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=evilz.vscode-reveal&#34;&gt;VS Code Reveal extension&lt;/a&gt;, open AI-GATEWAY.md and click on &#39;slides&#39; at the botton to present the AI Gateway without leaving VS Code. Or just open the &lt;a href=&#34;https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fraw.githubusercontent.com%2FAzure-Samples%2FAI-Gateway%2Fmain%2FAI-GATEWAY.pptx&amp;amp;wdOrigin=BROWSELINK&#34;&gt;AI-GATEWAY.pptx&lt;/a&gt; for a plain old PowerPoint experience.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;🥇 Other resources&lt;/h2&gt; &#xA;&lt;p&gt;Numerous reference architectures, best practices and starter kits are available on this topic. Please refer to the resources provided if you need comprehensive solutions or a landing zone to initiate your project. We suggest leveraging the AI-Gateway labs to discover additional capabilities that can be integrated into the reference architectures.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure-Samples/ai-hub-gateway-solution-accelerator&#34;&gt;AI Hub Gateway Landing Zone&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/genai-gateway&#34;&gt;Designing and implementing a gateway solution with Azure OpenAI resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/aoai-apim&#34;&gt;Azure OpenAI Using PTUs/TPMs With API Management - Using the Scaling Special Sauce&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/AzureOpenAI-with-APIM&#34;&gt;Manage Azure OpenAI using APIM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/enterprise-azureai&#34;&gt;Setting up Azure OpenAI as a central capability with Azure API Management&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/intro-to-intelligent-apps&#34;&gt;Introduction to Building AI Apps&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;We believe that there may be valuable content that we are currently unaware of. We would greatly appreciate any suggestions or recommendations to enhance this list.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;🌐 WW GBB initiative&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Azure-Samples/AI-Gateway/main/images/gbb.png&#34; alt=&#34;GBB&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Disclaimer&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT] This software is provided for demonstration purposes only. It is not intended to be relied upon for any purpose. The creators of this software make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability or availability with respect to the software or the information, products, services, or related graphics contained in the software for any purpose. Any reliance you place on such information is therefore strictly at your own risk.&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
</feed>