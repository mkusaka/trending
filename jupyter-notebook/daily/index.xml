<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-13T01:37:03Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>airtai/fastkafka</title>
    <updated>2023-03-13T01:37:03Z</updated>
    <id>tag:github.com,2023-03-13:/airtai/fastkafka</id>
    <link href="https://github.com/airtai/fastkafka" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FastKafka is a powerful and easy-to-use Python library for building asynchronous web services that interact with Kafka topics. Built on top of Pydantic, AIOKafka and AsyncAPI, FastKafka simplifies the process of writing producers and consumers for Kafka topics.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FastKafka&lt;/h1&gt; &#xA;&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! --&gt; &#xA;&lt;p&gt;&lt;b&gt;Effortless Kafka integration for your web services&lt;/b&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/fastkafka.png&#34; alt=&#34;PyPI&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/dm/fastkafka.png&#34; alt=&#34;PyPI - Downloads&#34;&gt; &lt;img src=&#34;https://img.shields.io/pypi/pyversions/fastkafka.png&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/actions/workflow/status/airtai/fastkafka/test.yaml&#34; alt=&#34;GitHub Workflow Status&#34;&gt; &lt;img src=&#34;https://github.com/airtai/fastkafka//actions/workflows/codeql.yml/badge.svg?sanitize=true&#34; alt=&#34;CodeQL&#34;&gt; &lt;img src=&#34;https://github.com/airtai/fastkafka//actions/workflows/dependency-review.yml/badge.svg?sanitize=true&#34; alt=&#34;Dependency Review&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/license/airtai/fastkafka.png&#34; alt=&#34;GitHub&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/fastkafka.airt.ai&#34;&gt;FastKafka&lt;/a&gt; is a powerful and easy-to-use Python library for building asynchronous services that interact with Kafka topics. Built on top of &lt;a href=&#34;https://docs.pydantic.dev/&#34;&gt;Pydantic&lt;/a&gt;, &lt;a href=&#34;https://github.com/aio-libs/aiokafka&#34;&gt;AIOKafka&lt;/a&gt; and &lt;a href=&#34;https://www.asyncapi.com/&#34;&gt;AsyncAPI&lt;/a&gt;, FastKafka simplifies the process of writing producers and consumers for Kafka topics, handling all the parsing, networking, task scheduling and data generation automatically. With FastKafka, you can quickly prototype and develop high-performance Kafka-based services with minimal code, making it an ideal choice for developers looking to streamline their workflow and accelerate their projects.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;⭐ Stay in touch&lt;/h4&gt; &#xA;&lt;p&gt;Please show your support and stay in touch by giving our &lt;a href=&#34;https://github.com/airtai/fastkafka/&#34;&gt;GitHub repository&lt;/a&gt; a star! Your support helps us to stay in touch with you and encourages us to continue developing and improving the library. Thank you for your support!&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://repobeats.axiom.co/api/embed/21f36049093d5eb8e5fdad18c3c5d8df5428ca30.svg?sanitize=true&#34; alt=&#34;Activity&#34; title=&#34;Repobeats analytics image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;FastKafka works on macOS, Linux, and most Unix-style operating systems. You can install it with &lt;code&gt;pip&lt;/code&gt; as usual:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install fastkafka&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;You can start an interactive tutorial in Google Colab by clicking the button below:&lt;/p&gt; &#xA;&lt;a href=&#34;https://colab.research.google.com/github/airtai/fastkafka/blob/main/nbs/guides/Guide_00_FastKafka_Demo.ipynb&#34; target=&#34;”_blank”&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Writing server code&lt;/h2&gt; &#xA;&lt;p&gt;Here is an example python script using FastKafka that takes data from a Kafka topic, makes a prediction using a predictive model, and outputs the prediction to another Kafka topic.&lt;/p&gt; &#xA;&lt;h3&gt;Preparing the demo model&lt;/h3&gt; &#xA;&lt;p&gt;First we will prepare our model using the Iris dataset so that we can demonstrate the preditions using FastKafka. The following call downloads the dataset and trains the model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.datasets import load_iris&#xA;from sklearn.linear_model import LogisticRegression&#xA;&#xA;X, y = load_iris(return_X_y=True)&#xA;model = LogisticRegression(random_state=0, max_iter=500).fit(X, y)&#xA;x = X[[0, 55, -1]]&#xA;print(x)&#xA;print(model.predict(x))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;[[5.1 3.5 1.4 0.2]&#xA; [5.7 2.8 4.5 1.3]&#xA; [5.9 3.  5.1 1.8]]&#xA;[0 1 2]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Messages&lt;/h3&gt; &#xA;&lt;p&gt;FastKafka uses &lt;a href=&#34;https://docs.pydantic.dev/&#34;&gt;Pydantic&lt;/a&gt; to parse input JSON-encoded data into Python objects, making it easy to work with structured data in your Kafka-based applications. Pydantic’s &lt;a href=&#34;https://docs.pydantic.dev/usage/models/&#34;&gt;&lt;code&gt;BaseModel&lt;/code&gt;&lt;/a&gt; class allows you to define messages using a declarative syntax, making it easy to specify the fields and types of your messages.&lt;/p&gt; &#xA;&lt;p&gt;This example defines two message classes for use in a FastKafka application:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;IrisInputData&lt;/code&gt; class is used to represent input data for a predictive model. It has four fields of type &lt;a href=&#34;https://docs.pydantic.dev/usage/types/#constrained-types&#34;&gt;&lt;code&gt;NonNegativeFloat&lt;/code&gt;&lt;/a&gt;, which is a subclass of float that only allows non-negative floating point values.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;IrisPrediction&lt;/code&gt; class is used to represent the output of the predictive model. It has a single field &lt;code&gt;species&lt;/code&gt; of type string representing the predicted species.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;These message classes will be used to parse and validate incoming data in Kafka consumers and producers.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel, NonNegativeFloat, Field&#xA;&#xA;&#xA;class IrisInputData(BaseModel):&#xA;    sepal_length: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Sepal length in cm&#34;&#xA;    )&#xA;    sepal_width: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Sepal width in cm&#34;&#xA;    )&#xA;    petal_length: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Petal length in cm&#34;&#xA;    )&#xA;    petal_width: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Petal width in cm&#34;&#xA;    )&#xA;&#xA;&#xA;class IrisPrediction(BaseModel):&#xA;    species: str = Field(..., example=&#34;setosa&#34;, description=&#34;Predicted species&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Application&lt;/h3&gt; &#xA;&lt;p&gt;This example shows how to initialize a FastKafka application.&lt;/p&gt; &#xA;&lt;p&gt;It starts by defining a dictionary called &lt;code&gt;kafka_brokers&lt;/code&gt;, which contains two entries: &lt;code&gt;&#34;localhost&#34;&lt;/code&gt; and &lt;code&gt;&#34;production&#34;&lt;/code&gt;, specifying local development and production Kafka brokers. Each entry specifies the URL, port, and other details of a Kafka broker. This dictionary is used for generating the documentation only and it is not being checked by the actual server.&lt;/p&gt; &#xA;&lt;p&gt;Next, an object of the &lt;a href=&#34;https://airtai.github.io/fastkafka/fastkafka.html#fastkafka&#34;&gt;&lt;code&gt;FastKafka&lt;/code&gt;&lt;/a&gt; class is initialized with the minimum set of arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;kafka_brokers&lt;/code&gt;: a dictionary used for generation of documentation&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;bootstrap_servers&lt;/code&gt;: a &lt;code&gt;host[:port]&lt;/code&gt; string or list of &lt;code&gt;host[:port]&lt;/code&gt; strings that a consumer or a producer should contact to bootstrap initial cluster metadata&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastkafka import FastKafka&#xA;&#xA;kafka_brokers = {&#xA;    &#34;localhost&#34;: {&#xA;        &#34;url&#34;: &#34;localhost&#34;,&#xA;        &#34;description&#34;: &#34;local development kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;    },&#xA;    &#34;production&#34;: {&#xA;        &#34;url&#34;: &#34;kafka.airt.ai&#34;,&#xA;        &#34;description&#34;: &#34;production kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;        &#34;protocol&#34;: &#34;kafka-secure&#34;,&#xA;        &#34;security&#34;: {&#34;type&#34;: &#34;plain&#34;},&#xA;    },&#xA;}&#xA;&#xA;kafka_app = FastKafka(&#xA;    title=&#34;Iris predictions&#34;,&#xA;    kafka_brokers=kafka_brokers,&#xA;    bootstrap_servers=&#34;localhost:9092&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Function decorators&lt;/h3&gt; &#xA;&lt;p&gt;FastKafka provides convenient function decorators &lt;code&gt;@kafka_app.consumes&lt;/code&gt; and &lt;code&gt;@kafka_app.produces&lt;/code&gt; to allow you to delegate the actual process of&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;consuming and producing data to Kafka, and&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;decoding and encoding JSON encode messages&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;from user defined functions to the framework. The FastKafka framework delegates these jobs to AIOKafka and Pydantic libraries.&lt;/p&gt; &#xA;&lt;p&gt;These decorators make it easy to specify the processing logic for your Kafka consumers and producers, allowing you to focus on the core business logic of your application without worrying about the underlying Kafka integration.&lt;/p&gt; &#xA;&lt;p&gt;This following example shows how to use the &lt;code&gt;@kafka_app.consumes&lt;/code&gt; and &lt;code&gt;@kafka_app.produces&lt;/code&gt; decorators in a FastKafka application:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;@kafka_app.consumes&lt;/code&gt; decorator is applied to the &lt;code&gt;on_input_data&lt;/code&gt; function, which specifies that this function should be called whenever a message is received on the “input_data” Kafka topic. The &lt;code&gt;on_input_data&lt;/code&gt; function takes a single argument which is expected to be an instance of the &lt;code&gt;IrisInputData&lt;/code&gt; message class. Specifying the type of the single argument is instructing the Pydantic to use &lt;code&gt;IrisInputData.parse_raw()&lt;/code&gt; on the consumed message before passing it to the user defined function &lt;code&gt;on_input_data&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The &lt;code&gt;@produces&lt;/code&gt; decorator is applied to the &lt;code&gt;to_predictions&lt;/code&gt; function, which specifies that this function should produce a message to the “predictions” Kafka topic whenever it is called. The &lt;code&gt;to_predictions&lt;/code&gt; function takes a single integer argument &lt;code&gt;species_class&lt;/code&gt; representing one of three possible strign values predicted by the mdoel. It creates a new &lt;code&gt;IrisPrediction&lt;/code&gt; message using this value and then returns it. The framework will call the &lt;code&gt;IrisPrediction.json().encode(&#34;utf-8&#34;)&lt;/code&gt; function on the returned value and produce it to the specified topic.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@kafka_app.consumes(topic=&#34;input_data&#34;, auto_offset_reset=&#34;latest&#34;)&#xA;async def on_input_data(msg: IrisInputData):&#xA;    global model&#xA;    species_class = model.predict(&#xA;        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]&#xA;    )[0]&#xA;&#xA;    to_predictions(species_class)&#xA;&#xA;&#xA;@kafka_app.produces(topic=&#34;predictions&#34;)&#xA;def to_predictions(species_class: int) -&amp;gt; IrisPrediction:&#xA;    iris_species = [&#34;setosa&#34;, &#34;versicolor&#34;, &#34;virginica&#34;]&#xA;&#xA;    prediction = IrisPrediction(species=iris_species[species_class])&#xA;    return prediction&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Testing the service&lt;/h2&gt; &#xA;&lt;p&gt;The service can be tested using the &lt;a href=&#34;https://airtai.github.io/fastkafka/tester.html#tester&#34;&gt;&lt;code&gt;Tester&lt;/code&gt;&lt;/a&gt; instances which internally starts Kafka broker and zookeeper.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastkafka.testing import Tester&#xA;&#xA;msg = IrisInputData(&#xA;    sepal_length=0.1,&#xA;    sepal_width=0.2,&#xA;    petal_length=0.3,&#xA;    petal_width=0.4,&#xA;)&#xA;&#xA;# Start Tester app and create local Kafka broker for testing&#xA;async with Tester(kafka_app) as tester:&#xA;    # Send IrisInputData message to input_data topic&#xA;    await tester.to_input_data(msg)&#xA;&#xA;    # Assert that the kafka_app responded with IrisPrediction in predictions topic&#xA;    await tester.awaited_mocks.on_predictions.assert_awaited_with(&#xA;        IrisPrediction(species=&#34;setosa&#34;), timeout=2&#xA;    )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] fastkafka._testing.local_broker: Java is already installed.&#xA;[INFO] fastkafka._testing.local_broker: But not exported to PATH, exporting...&#xA;[INFO] fastkafka._testing.local_broker: Kafka is already installed.&#xA;[INFO] fastkafka._testing.local_broker: But not exported to PATH, exporting...&#xA;[INFO] fastkafka._testing.local_broker: Starting zookeeper...&#xA;[INFO] fastkafka._testing.local_broker: zookeeper started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: zookeeper startup falied, generating a new port and retrying...&#xA;[INFO] fastkafka._testing.local_broker: port=60711&#xA;[INFO] fastkafka._testing.local_broker: zookeeper started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: Starting kafka...&#xA;[INFO] fastkafka._testing.local_broker: kafka started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: Local Kafka broker up and running on 127.0.0.1:9092&#xA;[INFO] fastkafka._application.app: _create_producer() : created producer using the config: &#39;{&#39;bootstrap_servers&#39;: &#39;127.0.0.1:9092&#39;}&#39;&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.&#xA;[INFO] fastkafka._application.app: _create_producer() : created producer using the config: &#39;{&#39;bootstrap_servers&#39;: &#39;127.0.0.1:9092&#39;}&#39;&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {&#39;bootstrap_servers&#39;: &#39;127.0.0.1:9092&#39;, &#39;auto_offset_reset&#39;: &#39;latest&#39;, &#39;max_poll_records&#39;: 100}&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.&#xA;[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({&#39;input_data&#39;})&#xA;[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {&#39;input_data&#39;}&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {&#39;bootstrap_servers&#39;: &#39;127.0.0.1:9092&#39;, &#39;auto_offset_reset&#39;: &#39;earliest&#39;, &#39;max_poll_records&#39;: 100}&#xA;[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {&#39;input_data&#39;: 1}. &#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.&#xA;[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({&#39;predictions&#39;})&#xA;[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {&#39;predictions&#39;}&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.&#xA;[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {&#39;predictions&#39;: 1}. &#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.&#xA;[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...&#xA;[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 123426...&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 123426 terminated.&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 123043...&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 123043 terminated.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Recap&lt;/h3&gt; &#xA;&lt;p&gt;We have created a Iris classification model and encapulated it into our fastkafka application. The app will consume the IrisInputData from the &lt;code&gt;input_data&lt;/code&gt; topic and produce the predictions to &lt;code&gt;predictions&lt;/code&gt; topic.&lt;/p&gt; &#xA;&lt;p&gt;To test the app we have:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Created the app&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Started our Tester class which mirrors the developed app topics for testing purpuoses&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sent IrisInputData message to &lt;code&gt;input_data&lt;/code&gt; topic&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Asserted and checked that the developed iris classification service has reacted to IrisInputData message&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Running the service&lt;/h2&gt; &#xA;&lt;p&gt;The service can be started using builtin faskafka run CLI command. Before we can do that, we will concatenate the code snippets from above and save them in a file &lt;code&gt;&#34;application.py&#34;&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# content of the &#34;application.py&#34; file&#xA;&#xA;from pydantic import BaseModel, NonNegativeFloat, Field&#xA;&#xA;class IrisInputData(BaseModel):&#xA;    sepal_length: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Sepal length in cm&#34;&#xA;    )&#xA;    sepal_width: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Sepal width in cm&#34;&#xA;    )&#xA;    petal_length: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Petal length in cm&#34;&#xA;    )&#xA;    petal_width: NonNegativeFloat = Field(&#xA;        ..., example=0.5, description=&#34;Petal width in cm&#34;&#xA;    )&#xA;&#xA;&#xA;class IrisPredictionData(BaseModel):&#xA;    species: str = Field(..., example=&#34;setosa&#34;, description=&#34;Predicted species&#34;)&#xA;    &#xA;from fastkafka.application import FastKafka&#xA;&#xA;kafka_brokers = {&#xA;    &#34;localhost&#34;: {&#xA;        &#34;url&#34;: &#34;localhost&#34;,&#xA;        &#34;description&#34;: &#34;local development kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;    },&#xA;    &#34;production&#34;: {&#xA;        &#34;url&#34;: &#34;kafka.airt.ai&#34;,&#xA;        &#34;description&#34;: &#34;production kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;        &#34;protocol&#34;: &#34;kafka-secure&#34;,&#xA;        &#34;security&#34;: {&#34;type&#34;: &#34;plain&#34;},&#xA;    },&#xA;}&#xA;&#xA;kafka_app = FastKafka(&#xA;    title=&#34;Iris predictions&#34;,&#xA;    kafka_brokers=kafka_brokers,&#xA;    bootstrap_servers=&#34;localhost:9092&#34;,&#xA;)&#xA;&#xA;iris_species = [&#34;setosa&#34;, &#34;versicolor&#34;, &#34;virginica&#34;]&#xA;&#xA;@kafka_app.consumes(topic=&#34;input_data&#34;, auto_offset_reset=&#34;latest&#34;)&#xA;async def on_input_data(msg: IrisInputData):&#xA;    global model&#xA;    species_class = model.predict([&#xA;          [msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]&#xA;        ])[0]&#xA;&#xA;    to_predictions(species_class)&#xA;&#xA;&#xA;@kafka_app.produces(topic=&#34;predictions&#34;)&#xA;def to_predictions(species_class: int) -&amp;gt; IrisPredictionData:&#xA;    prediction = IrisPredictionData(species=iris_species[species_class])&#xA;    return prediction&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the service, you will need a running Kafka broker on localhost as specified by the &lt;code&gt;bootstrap_servers=&#34;localhost:9092&#34;&lt;/code&gt; parameter above. We can start the Kafka broker locally using the &lt;a href=&#34;https://airtai.github.io/fastkafka/localkafkabroker.html#localkafkabroker&#34;&gt;&lt;code&gt;LocalKafkaBroker&lt;/code&gt;&lt;/a&gt;. Notice that the same happens automatically in the &lt;a href=&#34;https://airtai.github.io/fastkafka/tester.html#tester&#34;&gt;&lt;code&gt;Tester&lt;/code&gt;&lt;/a&gt; as shown above.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] fastkafka._testing.local_broker: LocalKafkaBroker.start(): entering...&#xA;[WARNING] fastkafka._testing.local_broker: LocalKafkaBroker.start(): (&amp;lt;_UnixSelectorEventLoop running=True closed=False debug=False&amp;gt;) is already running!&#xA;[WARNING] fastkafka._testing.local_broker: LocalKafkaBroker.start(): calling nest_asyncio.apply()&#xA;[INFO] fastkafka._testing.local_broker: Java is already installed.&#xA;[INFO] fastkafka._testing.local_broker: Kafka is already installed.&#xA;[INFO] fastkafka._testing.local_broker: Starting zookeeper...&#xA;[INFO] fastkafka._testing.local_broker: zookeeper started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: zookeeper startup falied, generating a new port and retrying...&#xA;[INFO] fastkafka._testing.local_broker: port=42613&#xA;[INFO] fastkafka._testing.local_broker: zookeeper started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: Starting kafka...&#xA;[INFO] fastkafka._testing.local_broker: kafka started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: kafka startup falied, generating a new port and retrying...&#xA;[INFO] fastkafka._testing.local_broker: port=33283&#xA;[INFO] fastkafka._testing.local_broker: kafka started, sleeping for 5 seconds...&#xA;[INFO] fastkafka._testing.local_broker: Local Kafka broker up and running on 127.0.0.1:33283&#xA;[INFO] fastkafka._testing.local_broker: &amp;lt;class &#39;fastkafka._testing.local_broker.LocalKafkaBroker&#39;&amp;gt;.start(): returning 127.0.0.1:33283&#xA;[INFO] fastkafka._testing.local_broker: LocalKafkaBroker.start(): exited.&#xA;&#xA;&#39;127.0.0.1:33283&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, we start the FastKafka service by running the following command in the folder where the &lt;code&gt;application.py&lt;/code&gt; file is located:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fastkafka run --num-workers=2 application:kafka_app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;[127890]: [INFO] fastkafka._application.app: _create_producer() : created producer using the config: &#39;{&#39;bootstrap_servers&#39;: &#39;localhost:9092&#39;}&#39;&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...&#xA;[127888]: [INFO] fastkafka._application.app: _create_producer() : created producer using the config: &#39;{&#39;bootstrap_servers&#39;: &#39;localhost:9092&#39;}&#39;&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {&#39;bootstrap_servers&#39;: &#39;localhost:9092&#39;, &#39;auto_offset_reset&#39;: &#39;latest&#39;, &#39;max_poll_records&#39;: 100}&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {&#39;bootstrap_servers&#39;: &#39;localhost:9092&#39;, &#39;auto_offset_reset&#39;: &#39;latest&#39;, &#39;max_poll_records&#39;: 100}&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.&#xA;[127888]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({&#39;input_data&#39;})&#xA;[127888]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {&#39;input_data&#39;}&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.&#xA;[127890]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({&#39;input_data&#39;})&#xA;[127890]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {&#39;input_data&#39;}&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.&#xA;[127888]: [ERROR] aiokafka.cluster: Topic input_data not found in cluster metadata&#xA;[127888]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {&#39;input_data&#39;: 0}. &#xA;[127890]: [WARNING] aiokafka.cluster: Topic input_data is not available during auto-create initialization&#xA;[127890]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {&#39;input_data&#39;: 0}. &#xA;[127890]: [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed (&#39;172.19.0.6&#39;, 9092)&#xA;[127890]: [ERROR] aiokafka: Unable to update metadata from [0]&#xA;[127888]: [ERROR] aiokafka: Unable connect to node with id 0: [Errno 111] Connect call failed (&#39;172.19.0.6&#39;, 9092)&#xA;[127888]: [ERROR] aiokafka: Unable to update metadata from [0]&#xA;^C&#xA;Starting process cleanup, this may take a few seconds...&#xA;[INFO] fastkafka.server: terminate_asyncio_process(): Terminating the process 127888...&#xA;[INFO] fastkafka.server: terminate_asyncio_process(): Terminating the process 127890...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.&#xA;[127888]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...&#xA;[127888]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.&#xA;[127890]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...&#xA;[127890]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You need to interupt running of the cell above by selecting &lt;code&gt;Runtime-&amp;gt;Interupt execution&lt;/code&gt; on the toolbar above.&lt;/p&gt; &#xA;&lt;p&gt;Finally, we can stop the local Kafka Broker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] fastkafka._testing.local_broker: LocalKafkaBroker.stop(): entering...&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 127341...&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 127341 was already terminated.&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 126482...&#xA;[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 126482 was already terminated.&#xA;[INFO] fastkafka._testing.local_broker: LocalKafkaBroker.stop(): exited.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The kafka app comes with builtin documentation generation using &lt;a href=&#34;https://www.asyncapi.com/tools/generator&#34;&gt;AsyncApi HTML generator&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We need to install all dependancies for the generator using the following command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fastkafka docs install_deps&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] fastkafka._components.asyncapi: AsyncAPI generator installed&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate the documentation programatically you just need to call the folloving command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fastkafka docs generate application:kafka_app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;. This will generate the &lt;em&gt;asyncapi&lt;/em&gt; folder in relative path where all your documentation will be saved. You can check out the content of it with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ls -l asyncapi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;total 8&#xA;drwxrwxr-x 2 davor davor 4096 Jan 25 09:30 docs&#xA;drwxrwxr-x 2 davor davor 4096 Jan 25 09:30 spec&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In docs folder you will find the servable static html file of your documentation. This can also be served using our &lt;code&gt;fastkafka docs serve&lt;/code&gt; CLI command (more on that in our guides).&lt;/p&gt; &#xA;&lt;p&gt;In spec folder you will find a asyncapi.yml file containing the async API specification of your application.&lt;/p&gt; &#xA;&lt;p&gt;We can locally preview the generated documentation by running the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;fastkafka docs serve application:kafka_app&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;[INFO] fastkafka._components.asyncapi: New async specifications generated at: &#39;/work/fastkafka/nbs/asyncapi/spec/asyncapi.yml&#39;&#xA;[INFO] fastkafka._components.asyncapi: Async docs generated at &#39;asyncapi/docs&#39;&#xA;[INFO] fastkafka._components.asyncapi: Output of &#39;$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write&#39;&#xA;&#xA;Done! ✨&#xA;Check out your shiny new generated files at /work/fastkafka/nbs/asyncapi/docs.&#xA;&#xA;&#xA;Serving documentation on http://127.0.0.1:8000&#xA;^C&#xA;Interupting serving of documentation and cleaning up...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From the parameters passed to the application constructor, we get the documentation bellow:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fastkafka import FastKafka&#xA;&#xA;kafka_brokers = {&#xA;    &#34;localhost&#34;: {&#xA;        &#34;url&#34;: &#34;localhost&#34;,&#xA;        &#34;description&#34;: &#34;local development kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;    },&#xA;    &#34;production&#34;: {&#xA;        &#34;url&#34;: &#34;kafka.airt.ai&#34;,&#xA;        &#34;description&#34;: &#34;production kafka broker&#34;,&#xA;        &#34;port&#34;: 9092,&#xA;        &#34;protocol&#34;: &#34;kafka-secure&#34;,&#xA;        &#34;security&#34;: {&#34;type&#34;: &#34;plain&#34;},&#xA;    },&#xA;}&#xA;&#xA;kafka_app = FastKafka(&#xA;    title=&#34;Iris predictions&#34;,&#xA;    kafka_brokers=kafka_brokers,&#xA;    bootstrap_servers=&#34;localhost:9092&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-servers.png&#34; alt=&#34;Kafka_servers&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following documentation snippet are for the consumer as specified in the code above:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-consumer.png&#34; alt=&#34;Kafka_consumer&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The following documentation snippet are for the producer as specified in the code above:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-producer.png&#34; alt=&#34;Kafka_producer&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Finally, all messages as defined as subclasses of &lt;em&gt;BaseModel&lt;/em&gt; are documented as well:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/nbs/images/screenshot-kafka-messages.png&#34; alt=&#34;Kafka_Kafka_servers&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;FastKafka is licensed under the Apache License 2. 0 A permissive license whose main conditions require preservation of copyright and license notices. Contributors provide an express grant of patent rights. Licensed works, modifications, and larger works may be distributed under different terms and without source code.&lt;/p&gt; &#xA;&lt;p&gt;The full text of the license can be found &lt;a href=&#34;https://raw.githubusercontent.com/airtai/fastkafka/main/LICENSE&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Francis-Komizu/Sovits</title>
    <updated>2023-03-13T01:37:03Z</updated>
    <id>tag:github.com,2023-03-13:/Francis-Komizu/Sovits</id>
    <link href="https://github.com/Francis-Komizu/Sovits" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An implementation of the combination of Soft-VC and VITS&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stella VC Based on Soft-VC and VITS&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;strong&gt;This project is closed...&lt;/strong&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Update&#34;&gt;Update&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Models&#34;&gt;Models&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Index&#34;&gt;A Certain Magical Index&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Natsume&#34;&gt;Shiki Natsume&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Natsume2&#34;&gt;Shiki Natsume 2.0&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Usage&#34;&gt;How to use&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#TODO&#34;&gt;TODO&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#Ack&#34;&gt;Acknowledgement&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/#References&#34;&gt;References&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;Update&#34;&gt;Update&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Sovits 2.0 inference demo is available!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;Introduction&#34;&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Inspired by &lt;a href=&#34;https://space.bilibili.com/343303724/?spm_id_from=333.999.0.0&#34;&gt;Rcell&lt;/a&gt;, I replaced the word embedding of &lt;code&gt;TextEncoder&lt;/code&gt; in VITS with the output of the &lt;code&gt;ContentEncoder&lt;/code&gt; used in &lt;a href=&#34;https://github.com/bshall/soft-vc&#34;&gt;Soft-VC&lt;/a&gt; to achieve any-to-one voice conversion with non-parallel data. Of course, any-to-many voice converison is also doable!&lt;/p&gt; &#xA;&lt;p&gt;For better voice quality, in Sovits2, I utilize the f0 model used in &lt;a href=&#34;https://github.com/yl4579/StarGANv2-VC&#34;&gt;StarGANv2-VC&lt;/a&gt; to get fundamental frequency feature of an input audio and feed it to the vocoder of VITS.&lt;/p&gt; &#xA;&lt;h2 id=&#34;Models&#34;&gt;Models&lt;/h2&gt; &#xA;&lt;h3 id=&#34;Index&#34;&gt;A Certain Magical Index&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/assets/cover5.png&#34; alt=&#34;index&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Description&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Speaker&lt;/th&gt; &#xA;   &lt;th&gt;ID&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;一方通行&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;上条当麻&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;御坂美琴&lt;/td&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;白井黑子&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Model: &lt;a href=&#34;https://drive.google.com/file/d/1QfLYyqCEKlqC6fLYccISoIRxeqKEUtLs/view?usp=sharing&#34;&gt;Google drive&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Config: in this repository&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Demo&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Colab: &lt;a href=&#34;https://colab.research.google.com/drive/1OjfH2zpRkLFRp92aU6jAGhqZNopfZMjC?usp=sharing&#34;&gt;Sovits (魔法禁书目录)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;BILIBILI: &lt;a href=&#34;https://www.bilibili.com/video/BV1zY4y1T71W?share_source=copy_web&amp;amp;vd_source=630b87174c967a898cae3765fba3bfa8&#34;&gt;基于Sovits的4人声音转换模型&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3 id=&#34;Natsume&#34;&gt;Shiki Natsume&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/assets/cover2.png&#34; alt=&#34;natsume&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Description&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Single speaker model of Shiki Natsume.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Model: &lt;a href=&#34;https://drive.google.com/file/d/1eco4a1KTQt6YHv6Nza9XesF3Ao6JktBL/view?usp=sharing&#34;&gt;Google drive&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Config: in this repository&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Demo&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Colab: &lt;a href=&#34;https://colab.research.google.com/drive/190IbYEorG1wnw-QbUPH9SD6JytLF0KRv?usp=sharing&#34;&gt;Sovits (四季夏目)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;BILIBILI: &lt;a href=&#34;https://www.bilibili.com/video/BV13e411u7f1?share_source=copy_web&amp;amp;vd_source=630b87174c967a898cae3765fba3bfa8&#34;&gt;枣子姐变声器&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3 id=&#34;Natsume2&#34;&gt;Shiki Natsume 2.0&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/assets/cover6.png&#34; alt=&#34;natsume&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Description&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Single speaker model of Shiki Natsume, trained with F0 feature.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Model: &lt;a href=&#34;https://drive.google.com/file/d/1-0s7NBk49MMJzF-aBaqfuclVgF4yJzXa/view?usp=sharing&#34;&gt;Google drive&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Config: in this repository&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Demo&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Colab: &lt;a href=&#34;https://colab.research.google.com/drive/11GC7uAgPya2UIb5jfIuwnIqUN2qPF37w?usp=sharing&#34;&gt;Sovits2 (四季夏目)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;Usage&#34;&gt;How to use&lt;/h2&gt; &#xA;&lt;h3&gt;Train&lt;/h3&gt; &#xA;&lt;h4&gt;Prepare dataset&lt;/h4&gt; &#xA;&lt;p&gt;Audio should be &lt;code&gt;wav&lt;/code&gt; file, with mono channel and a sampling rate of 22050 Hz.&lt;/p&gt; &#xA;&lt;p&gt;Your dataset should be like:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;└───wavs&#xA;    ├───dev&#xA;    │   ├───LJ001-0001.wav&#xA;    │   ├───...&#xA;    │   └───LJ050-0278.wav&#xA;    └───train&#xA;        ├───LJ002-0332.wav&#xA;        ├───...&#xA;        └───LJ047-0007.wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Extract speech units&lt;/h4&gt; &#xA;&lt;p&gt;Utilize the content encoder to extract speech units in the audio.&lt;/p&gt; &#xA;&lt;p&gt;For more information, refer to &lt;a href=&#34;https://github.com/bshall/acoustic-model&#34;&gt;this repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cd hubert&#xA;python3 encode.py soft path/to/wavs/directory path/to/soft/directory --extension .wav&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then you need to generate filelists for both your training and validation files. It&#39;s recommended that you prepare your filelists beforehand!&lt;/p&gt; &#xA;&lt;p&gt;Your filelists should look like:&lt;/p&gt; &#xA;&lt;p&gt;Single speaker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;path/to/wav|path/to/unit&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multi-speaker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;path/to/wav|id|path/to/unit&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Train Sovits&lt;/h4&gt; &#xA;&lt;p&gt;Single speaker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python train.py -c configs/config.json -m model_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Multi-speaker:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python train_ms.py -c configs/config.json -m model_name&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may also refer to &lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/train.ipynb&#34;&gt;train.ipynb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;Please refer to &lt;a href=&#34;https://raw.githubusercontent.com/Francis-Komizu/Sovits/main/inference.ipynb&#34;&gt;inference.ipynb&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2 id=&#34;TODO&#34;&gt;TOD0&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add F0 model&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add F0 loss&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2 id=&#34;Contact&#34;&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;QQ: 2235306122&lt;/p&gt; &#xA;&lt;p&gt;BILIBILI: &lt;a href=&#34;https://space.bilibili.com/636704927&#34;&gt;Francis-Komizu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2 id=&#34;Ack&#34;&gt;Ackowledgement&lt;/h2&gt; &#xA;&lt;p&gt;Special thanks to &lt;a href=&#34;https://space.bilibili.com/343303724/?spm_id_from=333.999.0.0&#34;&gt;Rcell&lt;/a&gt; for giving me both inspiration and advice!&lt;/p&gt; &#xA;&lt;h2 id=&#34;References&#34;&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1S14y1x78X?share_source=copy_web&amp;amp;vd_source=630b87174c967a898cae3765fba3bfa8&#34;&gt;基于VITS和SoftVC实现任意对一VoiceConversion&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/bshall/soft-vc&#34;&gt;Soft-VC&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;vits&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yl4579/StarGANv2-VC&#34;&gt;StarGANv2-VC&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>IvanReznikov/DataVerse</title>
    <updated>2023-03-13T01:37:03Z</updated>
    <id>tag:github.com,2023-03-13:/IvanReznikov/DataVerse</id>
    <link href="https://github.com/IvanReznikov/DataVerse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Public code of Ivan Reznikov used in posts, articles, conferences&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DataVerse&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to DataVerse, a repository dedicated to sharing code snippets and notebooks used in my blog posts, articles, and conference talks on machine learning, data science, and related topics.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains a collection of code snippets, notebooks and other materials.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to use the code in this repository for your own projects, or to learn from it. Kindly give credit to DataVerse and link back to the original post or article where the code was used.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;All code in this repository is licensed under the MIT License. This means that you are free to use, modify, and distribute the code as long as you give credit to DataVerse and include the original license in your work.&lt;/p&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions or comments about this repository, please feel free to reach out to us at &lt;a href=&#34;mailto:ivanreznikov@gmail.com&#34;&gt;ivanreznikov@gmail.com&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>