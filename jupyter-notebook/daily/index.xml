<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-03-30T01:32:20Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>causify-ai/kaizenflow</title>
    <updated>2025-03-30T01:32:20Z</updated>
    <id>tag:github.com,2025-03-30:/causify-ai/kaizenflow</id>
    <link href="https://github.com/causify-ai/kaizenflow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;KaizenFlow is a framework for Bayesian reasoning and AI/ML stream computing&lt;/p&gt;&lt;hr&gt;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/causify-ai/kaizenflow/master/#kaizen-technologies-internal-documentation&#34;&gt;Kaizen Technologies internal documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- tocstop --&gt; &#xA;&lt;h1&gt;Kaizen Technologies internal documentation&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the internal documentation pages of Kaizen Technologies.&lt;/p&gt; &#xA;&lt;p&gt;To start exploring the repository refer to &lt;a href=&#34;https://raw.githubusercontent.com/causify-ai/kaizenflow/master/all.workflow.explanation.md&#34;&gt;workflows reference&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/KBLaM</title>
    <updated>2025-03-30T01:32:20Z</updated>
    <id>tag:github.com,2025-03-30:/microsoft/KBLaM</id>
    <link href="https://github.com/microsoft/KBLaM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Implementation of &#34;KBLaM: Knowledge Base augmented Language Model&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;KBLaM - Knowledge Base Augmented Language Models [ICLR 2025]&lt;/h1&gt; &#xA;&lt;p&gt;This repo contains the official implementation of &lt;a href=&#34;https://arxiv.org/abs/2410.10450&#34;&gt;KBLaM: Knowledge Base Augmented Language Models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Authors: Xi Wang, Liana Mikaelyan, Taketomo Isazawa, Mathew Salvaris, James Hensman.&lt;/p&gt; &#xA;&lt;p&gt;KBLaM is a new method for augmentating LLMs with external knowledge. Unlike Retrieval-Augmented Generation, KBLAM eliminates external retrieval modules, and unlike in-context learning, its computational overhead scales linearly with KB size rather than quadratically.&lt;/p&gt; &#xA;&lt;h2&gt;Supported Models&lt;/h2&gt; &#xA;&lt;p&gt;The following models from Hugging Face hub are currently supported:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct&#34;&gt;meta-llama/Meta-Llama-3-8B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct&#34;&gt;meta-llama/Llama-3.2-1B-Instruct&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/microsoft/Phi-3-mini-4k-instruct&#34;&gt;Phi-3-mini-4k-instruct&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To add support for new model types, you will need to update the model processing scripts to incorporate an adapter similar to &lt;code&gt;llama_model.py&lt;/code&gt; in &lt;code&gt;src/kblam/models&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Setting up&lt;/h2&gt; &#xA;&lt;p&gt;Install the kblam package with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use Llama models, you will need to generate a token from Hugging Face and use it to log in:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install huggingface_hub&#xA;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The experiments in the paper can be replicated by running the scripts in &lt;code&gt;./experiments&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Dataset Construction&lt;/h2&gt; &#xA;&lt;p&gt;To run the synthetic dataset construction, you will need a valid Azure OpenAI endpoint.&lt;/p&gt; &#xA;&lt;p&gt;To construct a synthetic KB and question-answer pairs use &lt;code&gt;dataset_generation/gen_synthetic_data.py&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;The question-answer pairs are constructed in the form:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;What is the description of {entity_name}?&#xA;The description of {entity_name} is {description}.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To generate KB embeddings, use &lt;code&gt;dataset_generation/generate_kb_embeddings.py&lt;/code&gt;. The embeddings we current support are &lt;a href=&#34;https://openai.com/index/new-and-improved-embedding-model/&#34;&gt;text-embedding-ada-002&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2&#34;&gt;all-MiniLM-L6-v2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;To train the model, run the following (with the appropriate arguments):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python train.py --dataset synthetic_data --N 120000 --B 20 --total_steps 601  --encoder_spec OAI --use_oai_embd --key_embd_src key --use_data_aug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;What is KBLaM?&lt;/h3&gt; &#xA;&lt;p&gt;KBLaM is a method to enhance a transformer-based LLM to augment it with knowledge. It consists of a base LLM, and some adapters that we train to transform the knowledge base to special knowledge tokens that the LLM ingests. In particular, because we only train adapters over the knowledge part, the base LLM is completely unmodified with regards to text input. If given no knowledge base, the model outputs the exact same thing as the base model for any given input.&lt;/p&gt; &#xA;&lt;h3&gt;What can KBLaM do?&lt;/h3&gt; &#xA;&lt;p&gt;KBLaM can, in addition to the base LLM’s capabilities, also attend over the knowledge base to answer questions in a grounded manner.&lt;/p&gt; &#xA;&lt;h3&gt;What is/are KBLaM’s intended use(s)?&lt;/h3&gt; &#xA;&lt;p&gt;The model is intended to be used for research.&lt;/p&gt; &#xA;&lt;h3&gt;How was KBLaM evaluated? What metrics are used to measure performance?&lt;/h3&gt; &#xA;&lt;p&gt;KBLaM was evaluated on accuracy of retrieval from the knowledge base, its refusal rate (how often it correctly said that it didn’t have the requisite information to answer the question), and precision and recall on how well the answers aligned with the correct answers given the knowledge base.&lt;/p&gt; &#xA;&lt;h3&gt;What are the limitations of KBLaM? How can users minimize the impact of KBLaM’s limitations when using the system?&lt;/h3&gt; &#xA;&lt;p&gt;When used with knowledge bases that are very different from the knowledge base it was trained on, KBLaM will give incomplete answers, and the answers can be reworded from the original value in the knowledge base or at times entirely incorrect. As a result, KBLaM is not currently intended for use as a complete system in a production setting, but is a research project that we are sharing.&lt;/p&gt; &#xA;&lt;h3&gt;What operational factors and settings allow for effective and responsible use of KBLaM?&lt;/h3&gt; &#xA;&lt;p&gt;KBLaM with no knowledge base will perform the exact same as the base model. With a knowledge base, for effective use, one should make sure that the training dataset and the usecase have sufficiently similar knowledge bases&lt;/p&gt; &#xA;&lt;h3&gt;How do I provide feedback on KBLaM?&lt;/h3&gt; &#xA;&lt;p&gt;Please add issues to this repository to provide feedback on KBLaM.&lt;/p&gt;</summary>
  </entry>
</feed>