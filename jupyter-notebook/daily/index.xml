<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-07T01:33:23Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Zero-coder/FECAM</title>
    <updated>2022-12-07T01:33:23Z</updated>
    <id>tag:github.com,2022-12-07:/Zero-coder/FECAM</id>
    <link href="https://github.com/Zero-coder/FECAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;About Code release for &#34;FECAM: Frequency Enhanced Channel Attention Mechanism for Time Series Forecasting&#34; (In VLDB 2023 Submission)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FECAM(In VLDB2023 Submission)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.01209&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-FECAM%3A%20Frequency%20Enhanced%20Channel%20Attention%20Mechanism%20for%20Time%20Series%20Forecasting-%09%23FF0000&#34; alt=&#34;Arxiv link&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/-STATE--OF--THE--ART-blue?logo=Accenture&amp;amp;labelColor=lightgrey&#34; alt=&#34;state-of-the-art&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-PyTorch-%23EE4C2C?logo=PyTorch&amp;amp;labelColor=lightgrey&#34; alt=&#34;pytorch&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the original pytorch implementation for the following paper: [&lt;a href=&#34;https://img.shields.io/static/v1?label=%3CLABEL%3E&amp;amp;message=%3CMESSAGE%3E&amp;amp;color=%3CCOLOR%3E&#34;&gt;FECAM: Frequency Enhanced Channel Attention Mechanism for Time Series Forecasting&lt;/a&gt;](&lt;a href=&#34;https://arxiv.org/abs/2212.01209&#34;&gt;https://arxiv.org/abs/2212.01209&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;If you find this repository useful for your research work, please consider citing it as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;@misc{jiang2022fecam,&#xA;      title={FECAM: Frequency Enhanced Channel Attention Mechanism for Time Series Forecasting}, &#xA;      author={Maowei Jiang and Pengyu Zeng and Kai Wang and Huan Liu and Wenbo Chen and Haoran Liu},&#xA;      year={2022},&#xA;      eprint={2212.01209},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI}&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2022-12-01] FECAM v1.0 is released&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support &lt;strong&gt;Six&lt;/strong&gt; popular time-series forecasting datasets, namely Electricity Transformer Temperature (ETTh1, ETTh2 and ETTm1,ETTm2) , Traffic, National Illness, Electricity and Exchange Rate , ranging from power, energy, finance,illness and traffic domains.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;strong&gt;We generalize FECAM into a module which can be flexibly and easily applied into any deep learning models within just few code lines.&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Provide all training logs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;To-do items&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Integrate FECAM into other mainstream models(eg:Pyraformer,Bi-lstm,etc.) for better performance and higher efficiency on real-world time series.&lt;/li&gt; &#xA; &lt;li&gt;Validate FECAM on more spatial-temporal time series datasets.&lt;/li&gt; &#xA; &lt;li&gt;As a sequence modelling module,we believe it can work fine on NLP tasks too,like Machine Translation and Name Entity Recognization.Further more,as a frequency enhanced module it can theoretically work in any deep-learning models like Resnet.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Stay tuned!&lt;/p&gt; &#xA;&lt;h2&gt;Get started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install the required package first(Mainly including Python 3.8, PyTorch 1.9.0):&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;    cd FECAM&#xA;    conda create -n fecam python=3.8&#xA;    conda activate fecam&#xA;    pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Download data. You can obtain all the six benchmarks from &lt;a href=&#34;https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/&#34;&gt;Tsinghua Cloud&lt;/a&gt; or &lt;a href=&#34;https://drive.google.com/drive/folders/1ZOYpTUa82_jCcxIdTmyr0LXQfvaM9vIy?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;. &lt;strong&gt;All the datasets are well pre-processed&lt;/strong&gt; and can be used easily.&lt;/li&gt; &#xA; &lt;li&gt;Train the model. We provide the experiment scripts of all benchmarks under the folder &lt;code&gt;./scripts&lt;/code&gt;. You can reproduce the experiment results by:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;    bash ./scripts/ETT_script/FECAM_ETTm2.sh&#xA;    bash ./scripts/ECL_script/FECAM.sh&#xA;    bash ./scripts/Exchange_script/FECAM.sh&#xA;    bash ./scripts/Traffic_script/FECAM.sh&#xA;    bash ./scripts/Weather_script/FECAM.sh&#xA;    bash ./scripts/ILI_script/FECAM.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;SENET(channel attention)&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\SENET.png&#34; height=&#34;250&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;FECAM(Frequency Enhanced Channel Attention Mechanism)&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\FECAM.png&#34; height=&#34;350&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;As a module to enhance the frequency domain modeling capability of transformers and LSTM&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\as_module.png&#34; height=&#34;450&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Comparison with Transformers and other mainstream forecasting models&lt;/h2&gt; &#xA;&lt;h3&gt;Multivariate Forecasting:&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\mul.png&#34; height=&#34;550&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;FECAM outperforms all transformer-based methods by a large margin.&lt;/p&gt; &#xA;&lt;h3&gt;Univariate Forecasting:&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\uni.png&#34; height=&#34;280&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Efficiency&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\parameter_increment.png&#34; height=&#34;185&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; Compared to vanilla models, only a few parameters are increased by applying our method (See Table 4), and thereby their computationalcomplexities can be preserved. &#xA;&lt;h3&gt;Performance promotion with FECAM module&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\performance_promotion.png&#34; height=&#34;390&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Visualization&lt;/h2&gt; &#xA;&lt;h3&gt;Forecasting visualization:Visualization of ETTm2 and Exchange predictions&amp;nbsp;given by different models.&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\Qualitative_withours.png&#34; height=&#34;397&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h3&gt;FECAM visualization:Visualization of frequency enhanced channel attention and output tensor of encoder layer of transformer.x-axis represents channels,y-axis represents frequency from low to high,performing on datasets weather and exchange.&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;.\pics\tensor_visualization.png&#34; height=&#34;345&#34; alt=&#34;&#34; align=&#34;center&#34;&gt; &lt;/p&gt;&#xA;&lt;h2&gt;Used Datasets&lt;/h2&gt; &#xA;&lt;p&gt;We conduct the experiments on &lt;strong&gt;6&lt;/strong&gt; popular time-series datasets, namely &lt;strong&gt;Electricity Transformer Temperature (ETTh1, ETTh2 and ETTm1) and Traffic, Weather,Illness, Electricity and Exchange Rate&lt;/strong&gt;, ranging from &lt;strong&gt;power, energy, finance , health care and traffic domains&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Overall information of the 9 real world datasets&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Datasets&lt;/th&gt; &#xA;   &lt;th&gt;Variants&lt;/th&gt; &#xA;   &lt;th&gt;Timesteps&lt;/th&gt; &#xA;   &lt;th&gt;Granularity&lt;/th&gt; &#xA;   &lt;th&gt;Start time&lt;/th&gt; &#xA;   &lt;th&gt;Task Type&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ETTh1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;17,420&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;7/1/2016&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ETTh2&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;17,420&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;7/1/2016&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ETTm1&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;69,680&lt;/td&gt; &#xA;   &lt;td&gt;15min&lt;/td&gt; &#xA;   &lt;td&gt;7/1/2016&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ETTm2&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;69,680&lt;/td&gt; &#xA;   &lt;td&gt;15min&lt;/td&gt; &#xA;   &lt;td&gt;7/1/2016&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&amp;amp;Single-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ILI&lt;/td&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;966&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;1/1/2002&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Exchange-Rate&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;7,588&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;1/1/1990&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step&amp;amp;Single-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Electricity&lt;/td&gt; &#xA;   &lt;td&gt;321&lt;/td&gt; &#xA;   &lt;td&gt;26,304&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;1/1/2012&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Traffic&lt;/td&gt; &#xA;   &lt;td&gt;862&lt;/td&gt; &#xA;   &lt;td&gt;17,544&lt;/td&gt; &#xA;   &lt;td&gt;1hour&lt;/td&gt; &#xA;   &lt;td&gt;1/1/2015&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Weather&lt;/td&gt; &#xA;   &lt;td&gt;21&lt;/td&gt; &#xA;   &lt;td&gt;52,695&lt;/td&gt; &#xA;   &lt;td&gt;10min&lt;/td&gt; &#xA;   &lt;td&gt;1/1/2020&lt;/td&gt; &#xA;   &lt;td&gt;Multi-step-step&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Dataset preparation&lt;/h3&gt; &#xA;&lt;p&gt;Download data. You can obtain all the six benchmarks from &lt;a href=&#34;https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/&#34;&gt;Tsinghua Cloud&lt;/a&gt; or &lt;a href=&#34;https://drive.google.com/drive/folders/1ZOYpTUa82_jCcxIdTmyr0LXQfvaM9vIy?usp=sharing&#34;&gt;Google Drive&lt;/a&gt;. &lt;strong&gt;All the datasets are well pre-processed&lt;/strong&gt; and can be used easily.(We thanks Author of Autoformer ,Haixu Wu for sorting datasets and public sharing them.)&lt;/p&gt; &#xA;&lt;p&gt;The data directory structure is shown as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./&#xA;└── datasets/&#xA;    ├── electricity&#xA;    │   └── electricity.csv&#xA;    ├── ETT-small&#xA;    │   ├── ETTh1.csv&#xA;    │   ├── ETTh2.csv&#xA;    │   ├── ETTm1.csv&#xA;    │   └── ETTm2.csv&#xA;    ├── exchange_rate&#xA;    │   └── exchange_rate.csv&#xA;    ├── illness&#xA;    │   └── national_illness.csv&#xA;    ├── traffic&#xA;    │   └── traffic.csv&#xA;    └── weather&#xA;        └── weather.csv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, feel free to contact us or post github issues. Pull requests are highly welcomed!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Maowei Jiang: jiangmaowei@sia.cn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;Thank you all for your attention to our work!&lt;/p&gt; &#xA;&lt;p&gt;This code uses (&lt;a href=&#34;https://github.com/thuml/Autoformer&#34;&gt;Autoformer&lt;/a&gt;,&lt;a href=&#34;https://github.com/zhouhaoyi/Informer2020&#34;&gt;Informer&lt;/a&gt;, &lt;a href=&#34;https://github.com/lucidrains/reformer-pytorch&#34;&gt;Reformer&lt;/a&gt;, &lt;a href=&#34;https://github.com/jadore801120/attention-is-all-you-need-pytorch&#34;&gt;Transformer&lt;/a&gt;, &lt;a href=&#34;https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction&#34;&gt;LSTM&lt;/a&gt;,&lt;a href=&#34;https://github.com/Nixtla/neuralforecast&#34;&gt;N-HiTS&lt;/a&gt;, &lt;a href=&#34;https://github.com/ServiceNow/N-BEATS&#34;&gt;N-BEATS&lt;/a&gt;, &lt;a href=&#34;https://github.com/alipay/Pyraformer&#34;&gt;Pyraformer&lt;/a&gt;, &lt;a href=&#34;https://github.com/gmonaci/ARIMA&#34;&gt;ARIMA&lt;/a&gt;) as baseline methods for comparison and further improvement.&lt;/p&gt; &#xA;&lt;p&gt;We appreciate the following github repos a lot for their valuable code base or datasets:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/zhouhaoyi/Informer2020&#34;&gt;https://github.com/zhouhaoyi/Informer2020&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/thuml/Autoformer&#34;&gt;https://github.com/thuml/Autoformer&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/cure-lab/LTSF-Linear&#34;&gt;https://github.com/cure-lab/LTSF-Linear&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/zhouhaoyi/ETDataset&#34;&gt;https://github.com/zhouhaoyi/ETDataset&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/laiguokun/multivariate-time-series-data&#34;&gt;https://github.com/laiguokun/multivariate-time-series-data&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>