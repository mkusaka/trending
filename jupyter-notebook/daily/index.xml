<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-20T01:43:18Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>AlexTheAnalyst/PortfolioProjects</title>
    <updated>2022-06-20T01:43:18Z</updated>
    <id>tag:github.com,2022-06-20:/AlexTheAnalyst/PortfolioProjects</id>
    <link href="https://github.com/AlexTheAnalyst/PortfolioProjects" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data Analyst Portfolio Project Repository&lt;/h1&gt; &#xA;&lt;p&gt;This Repository will hold all of the code and queries from the Portfolio Projects we create.&lt;/p&gt; &#xA;&lt;p&gt;Please feel free to take these and run with them. Make them your own and find you own insights&lt;/p&gt; &#xA;&lt;p&gt;I really do hope this is helpful and helps you land that dream job! :D&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SelfExplainML/PiML-Toolbox</title>
    <updated>2022-06-20T01:43:18Z</updated>
    <id>tag:github.com,2022-06-20:/SelfExplainML/PiML-Toolbox</id>
    <link href="https://github.com/SelfExplainML/PiML-Toolbox" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PiML (Python Interpretable Machine Learning) toolbox for model development and validation&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoPiML.png&#34; alt=&#34;drawing&#34; width=&#34;314.15926&#34;&gt; &#xA; &lt;p&gt;&lt;strong&gt;A low-code interpretable machine learning toolbox in Python&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/SelfExplainML/PiML-Toolbox/main/#Install&#34;&gt;Installation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/SelfExplainML/PiML-Toolbox/main/#Example&#34;&gt;Examples&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/SelfExplainML/PiML-Toolbox/main/#Usage&#34;&gt;Usage&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/SelfExplainML/PiML-Toolbox/main/#Cite&#34;&gt;Citations&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;PiML (or π·ML, /ˈpaɪ·ˈem·ˈel/) is a new Python toolbox for interpretable machine learning model development and validation. Through low-code automation and high-code programming, PiML supports various machine learning models including&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Inherently interpretable models&lt;/strong&gt;:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;EBM: Explainable Boosting Machine (Nori, et al. 2019; Lou, et al. 2013)&lt;/li&gt; &#xA; &lt;li&gt;GAMI-Net: Generalized Additive Model with Structured Interactions (Yang, Zhang and Sudjianto, 2021)&lt;/li&gt; &#xA; &lt;li&gt;ReLU-DNN: Deep ReLU Networks using Aletheia Unwrapper and Sparsification (Sudjianto, et al. 2020)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Arbitrary machine learning models&lt;/strong&gt;，e.g.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Tree-ensembles: RF, GBM, XGBoost, LightGBM, ...&lt;/li&gt; &#xA; &lt;li&gt;DNNs: MLP, ResNet, CNN, Attention, ...&lt;/li&gt; &#xA; &lt;li&gt;Kernel methods: SVM, Gaussian Process, ...&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;a name=&#34;Install&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip install PiML  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Low-code Examples&lt;a name=&#34;Example&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Click the ipynb links to run examples in Google Colab:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;BikeSharing data: &lt;a style=&#34;text-laign: &#39;center&#39;&#34; target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_BikeSharing.ipynb&#34;&gt;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png&#34; width=&#34;20&#34;&gt; ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;CaliforniaHousing data: &lt;a style=&#34;text-laign: &#39;center&#39;&#34; target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_CaliforniaHousing.ipynb&#34;&gt;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png&#34; width=&#34;20&#34;&gt; ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TaiwanCredit data: &lt;a style=&#34;text-laign: &#39;center&#39;&#34; target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_TaiwanCredit.ipynb&#34;&gt;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png&#34; width=&#34;20&#34;&gt; ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Upload custom data in two ways: &lt;a style=&#34;text-laign: &#39;center&#39;&#34; target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_CustomDataLoad_Two_Ways.ipynb&#34;&gt;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png&#34; width=&#34;20&#34;&gt; ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Begin your own PiML journey with &lt;a style=&#34;text-laign: &#39;center&#39;&#34; target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/PiML%20Low-code%20Example%20Run.ipynb&#34;&gt;this demo notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Low-code Usage on Google Colab&lt;a name=&#34;Usage&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Stage 1: Initialize an experiment, Load and Prepare data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from piml import Experiment&#xA;exp = Experiment(platform=&#34;colab&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.data_loader()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_loader.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.data_summary()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_summary.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.data_prepare()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_prepare.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.eda()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_eda.png&#34;&gt; &#xA;&lt;h3&gt;Stage 2: Train intepretable models&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_train()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_train.png&#34;&gt; &#xA;&lt;h3&gt;Stage 3. Explain and Interpret&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_explain()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_explain.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_interpret() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_interpret.png&#34;&gt; &#xA;&lt;h3&gt;Stage 4. Diagnose and Compare&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_diagnose()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_diagnose.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_compare()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_compare.png&#34;&gt; &#xA;&lt;h2&gt;Arbitrary Black-Box Modeling&lt;/h2&gt; &#xA;&lt;p&gt;For example, train a complex LightGBM with depth 7 and register it to the experiment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from lightgbm import LGBMRegressor&#xA;pipeline = exp.make_pipeline(LGBMRegressor(max_depth=7))&#xA;pipeline.fit() &#xA;exp.register(pipeline=pipeline, name=&#39;LGBM&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, compare it to inherently interpretable models (e.g. EBM and GAMI-Net):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;exp.model_compare()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_compare2.png&#34;&gt; &#xA;&lt;h2&gt;Citations&lt;a name=&#34;Cite&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;strong&gt;PiML, ReLU-DNN Aletheia and GAMI-Net&lt;/strong&gt;&lt;/summary&gt;&#xA; &lt;hr&gt; &#xA; &lt;p&gt;&#34;PiML: A Python Toolbox for Interpretable Machine Learning Model Development and Validation&#34; (A. Sudjianto, A. Zhang, Z. Yang, Y. Su, N. Zeng and V. Nair, 2022)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{sudjianto2022piml,&#xA;title={PiML: A Python Toolbox for Interpretable Machine Learning Model Development and Validation},&#xA;author={Sudjianto, Agus and Zhang, Aijun and Yang, Zebin and Su, Yu and Zeng, Ningzhou and Nair Vijay},&#xA;journal={To appear},&#xA;year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&#34;Designing Inherently Interpretable Machine Learning Models&#34; (A. Sudjianto and A. Zhang, 2021) &lt;a href=&#34;https://arxiv.org/abs/2111.01743&#34;&gt;arXiv link&lt;/a&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{sudjianto2021designing,&#xA;title={Designing Inherently Interpretable Machine Learning Models},&#xA;author={Sudjianto, Agus and Zhang, Aijun},&#xA;journal={arXiv preprint:2111.01743},&#xA;year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&#34;Unwrapping The Black Box of Deep ReLU Networks: Interpretability, Diagnostics, and Simplification&#34; (A. Sudjianto, W. Knauth, R. Singh, Z. Yang and A. Zhang, 2020) &lt;a href=&#34;https://arxiv.org/abs/2011.04041&#34;&gt;arXiv link&lt;/a&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{sudjianto2020unwrapping,&#xA;title={Unwrapping the black box of deep ReLU networks: interpretability, diagnostics, and simplification},&#xA;author={Sudjianto, Agus and Knauth, William and Singh, Rahul and Yang, Zebin and Zhang, Aijun},&#xA;journal={arXiv preprint:2011.04041},&#xA;year={2020}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&#34;GAMI-Net: An Explainable Neural Network based on Generalized Additive Models with Structured Interactions&#34; (Z. Yang, A. Zhang, and A. Sudjianto, 2021) &lt;a href=&#34;https://arxiv.org/abs/2003.07132&#34;&gt;arXiv link&lt;/a&gt;&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{yang2021gami,&#xA;title={GAMI-Net: An explainable neural network based on generalized additive models with structured interactions},&#xA;author={Yang, Zebin and Zhang, Aijun and Sudjianto, Agus},&#xA;journal={Pattern Recognition},&#xA;volume={120},&#xA;pages={108192},&#xA;year={2021}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;details open&gt; &#xA; &lt;summary&gt;&lt;strong&gt;EBM and GA2M&lt;/strong&gt;&lt;/summary&gt;&#xA; &lt;hr&gt; &#xA; &lt;p&gt;&#34;InterpretML: A Unified Framework for Machine Learning Interpretability&#34; (H. Nori, S. Jenkins, P. Koch, and R. Caruana, 2019)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{nori2019interpretml,&#xA;title={InterpretML: A Unified Framework for Machine Learning Interpretability},&#xA;author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},&#xA;journal={arXiv preprint:1909.09223},&#xA;year={2019}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;p&gt;&#34;Accurate intelligible models with pairwise interactions&#34; (Y. Lou, R. Caruana, J. Gehrke, and G. Hooker, 2013)&lt;/p&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@inproceedings{lou2013accurate,&#xA;title={Accurate intelligible models with pairwise interactions},&#xA;author={Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},&#xA;booktitle={Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},&#xA;pages={623--631},&#xA;year={2013},&#xA;organization={ACM}&#xA;}  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
  <entry>
    <title>realpython/materials</title>
    <updated>2022-06-20T01:43:18Z</updated>
    <id>tag:github.com,2022-06-20:/realpython/materials</id>
    <link href="https://github.com/realpython/materials" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Bonus materials, exercises, and example projects for our Python tutorials&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Real Python Materials&lt;/h1&gt; &#xA;&lt;p&gt;Bonus materials, exercises, and example projects for Real Python&#39;s &lt;a href=&#34;https://realpython.com&#34;&gt;Python tutorials&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Build Status: &lt;a href=&#34;https://circleci.com/gh/realpython/materials&#34;&gt;&lt;img src=&#34;https://circleci.com/gh/realpython/materials.svg?style=svg&#34; alt=&#34;CircleCI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Got a Question?&lt;/h2&gt; &#xA;&lt;p&gt;The best way to get support for Real Python courses &amp;amp; articles and code in this repository is to join one of our &lt;a href=&#34;https://realpython.com/office-hours/&#34;&gt;weekly Office Hours calls&lt;/a&gt; or to ask your question in the &lt;a href=&#34;https://realpython.com/community/&#34;&gt;RP Community Slack&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Due to time constraints we cannot provide 1:1 support via GitHub. See you on Slack or on the next Office Hours call 🙂&lt;/p&gt; &#xA;&lt;h2&gt;Adding Source Code &amp;amp; Sample Projects to This Repo (RP Contributors)&lt;/h2&gt; &#xA;&lt;h3&gt;Running Code Style Checks&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;http://flake8.pycqa.org/en/latest/&#34;&gt;flake8&lt;/a&gt; and &lt;a href=&#34;https://github.com/ambv/black&#34;&gt;black&lt;/a&gt; to ensure a consistent code style for all of our sample code in this repository.&lt;/p&gt; &#xA;&lt;p&gt;Run the following commands to validate your code against the linters:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ flake8&#xA;$ black --check .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Running Python Code Formatter&lt;/h3&gt; &#xA;&lt;p&gt;We&#39;re using a tool called &lt;a href=&#34;https://github.com/ambv/black&#34;&gt;black&lt;/a&gt; on this repo to ensure consistent formatting. On CI it runs in &#34;check&#34; mode to ensure any new files added to the repo are following PEP 8. If you see linter warnings that say something like &#34;would reformat some_file.py&#34; it means black disagrees with your formatting.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;The easiest way to resolve these errors is to just run Black locally on the code and then committing those changes, as explained below.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To automatically re-format your code to be consistent with our code style guidelines, run &lt;a href=&#34;https://github.com/ambv/black&#34;&gt;black&lt;/a&gt; in the repository root folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ black .&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>