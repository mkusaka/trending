<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-08T01:35:47Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>avnyadav/sensor-fault-detection</title>
    <updated>2022-11-08T01:35:47Z</updated>
    <id>tag:github.com,2022-11-08:/avnyadav/sensor-fault-detection</id>
    <link href="https://github.com/avnyadav/sensor-fault-detection" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Air Pressure System (APS) is a critical component of a heavy-duty vehicle that uses compressed air to force a piston to provide pressure to the brake pads, slowing the vehicle down. The benefits of using an APS instead of a hydraulic system are the easy availability and long-term sustainability of natural air.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Sensor-Fault-Detection&lt;/h1&gt; &#xA;&lt;h3&gt;Problem Statement&lt;/h3&gt; &#xA;&lt;p&gt;The Air Pressure System (APS) is a critical component of a heavy-duty vehicle that uses compressed air to force a piston to provide pressure to the brake pads, slowing the vehicle down. The benefits of using an APS instead of a hydraulic system are the easy availability and long-term sustainability of natural air.&lt;/p&gt; &#xA;&lt;p&gt;This is a Binary Classification problem, in which the affirmative class indicates that the failure was caused by a certain component of the APS, while the negative class indicates that the failure was caused by something else.&lt;/p&gt; &#xA;&lt;h3&gt;Solution Proposed&lt;/h3&gt; &#xA;&lt;p&gt;In this project, the system in focus is the Air Pressure system (APS) which generates pressurized air that are utilized in various functions in a truck, such as braking and gear changes. The datasets positive class corresponds to component failures for a specific component of the APS system. The negative class corresponds to trucks with failures for components not related to the APS system.&lt;/p&gt; &#xA;&lt;p&gt;The problem is to reduce the cost due to unnecessary repairs. So it is required to minimize the false predictions.&lt;/p&gt; &#xA;&lt;h2&gt;Tech Stack Used&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Python&lt;/li&gt; &#xA; &lt;li&gt;FastAPI&lt;/li&gt; &#xA; &lt;li&gt;Machine learning algorithms&lt;/li&gt; &#xA; &lt;li&gt;Docker&lt;/li&gt; &#xA; &lt;li&gt;MongoDB&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Infrastructure Required.&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;AWS S3&lt;/li&gt; &#xA; &lt;li&gt;AWS EC2&lt;/li&gt; &#xA; &lt;li&gt;AWS ECR&lt;/li&gt; &#xA; &lt;li&gt;Git Actions&lt;/li&gt; &#xA; &lt;li&gt;Terraform&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;How to run?&lt;/h2&gt; &#xA;&lt;p&gt;Before we run the project, make sure that you are having MongoDB in your local system, with Compass since we are using MongoDB for data storage. You also need AWS account to access the service like S3, ECR and EC2 instances.&lt;/p&gt; &#xA;&lt;h2&gt;Data Collections&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/57321948/193536736-5ccff349-d1fb-486e-b920-02ad7974d089.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Project Archietecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/57321948/193536768-ae704adc-32d9-4c6c-b234-79c152f756c5.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Deployment Archietecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/57321948/193536973-4530fe7d-5509-4609-bfd2-cd702fc82423.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Clone the repository&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/sethusaim/Sensor-Fault-Detection.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2- Create a conda environment after opening the repository&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n sensor python=3.7.6 -y&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate sensor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3 - Install the requirements&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 4 - Export the environment variable&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export AWS_ACCESS_KEY_ID=&amp;lt;AWS_ACCESS_KEY_ID&amp;gt;&#xA;&#xA;export AWS_SECRET_ACCESS_KEY=&amp;lt;AWS_SECRET_ACCESS_KEY&amp;gt;&#xA;&#xA;export AWS_DEFAULT_REGION=&amp;lt;AWS_DEFAULT_REGION&amp;gt;&#xA;&#xA;export MONGODB_URL=&#34;mongodb+srv://&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;@ineuron-ai-projects.7eh1w4s.mongodb.net/?retryWrites=true&amp;amp;w=majority&#34;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 5 - Run the application server&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 6. Train application&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;http://localhost:8080/train&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 7. Prediction application&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;http://localhost:8080/predict&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Run locally&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Check if the Dockerfile is available in the project directory&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Build the Docker image&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker build --build-arg AWS_ACCESS_KEY_ID=&amp;lt;AWS_ACCESS_KEY_ID&amp;gt; --build-arg AWS_SECRET_ACCESS_KEY=&amp;lt;AWS_SECRET_ACCESS_KEY&amp;gt; --build-arg AWS_DEFAULT_REGION=&amp;lt;AWS_DEFAULT_REGION&amp;gt; --build-arg MONGODB_URL=&amp;lt;MONGODB_URL&amp;gt; . &#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Run the Docker image&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker run -d -p 8080:8080 &amp;lt;IMAGE_NAME&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run the project first execute the below commmand. MONGO DB URL:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mongodb+srv://avnish:XglZZ9OkjjUw74pZ@ineuron-ai-projects.7eh1w4s.mongodb.net/admin?authSource=admin&amp;amp;replicaSet=atlas-okvkrd-shard-0&amp;amp;w=majority&amp;amp;readPreference=primary&amp;amp;appname=MongoDB%20Compass&amp;amp;retryWrites=true&amp;amp;ssl=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;windows user&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;MONGO_DB_URL=mongodb+srv://avnish:XglZZ9OkjjUw74pZ@ineuron-ai-projects.7eh1w4s.mongodb.net/admin?authSource=admin&amp;amp;replicaSet=atlas-okvkrd-shard-0&amp;amp;w=majority&amp;amp;readPreference=primary&amp;amp;appname=MongoDB%20Compass&amp;amp;retryWrites=true&amp;amp;ssl=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Linux user&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export MONGO_DB_URL=mongodb+srv://avnish:XglZZ9OkjjUw74pZ@ineuron-ai-projects.7eh1w4s.mongodb.net/admin?authSource=admin&amp;amp;replicaSet=atlas-okvkrd-shard-0&amp;amp;w=majority&amp;amp;readPreference=primary&amp;amp;appname=MongoDB%20Compass&amp;amp;retryWrites=true&amp;amp;ssl=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>LuChengTHU/dpm-solver</title>
    <updated>2022-11-08T01:35:47Z</updated>
    <id>tag:github.com,2022-11-08:/LuChengTHU/dpm-solver</id>
    <link href="https://github.com/LuChengTHU/dpm-solver" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code for &#34;DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps&#34; (Neurips 2022 Oral)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps&lt;/h1&gt; &#xA;&lt;p&gt;The official code for the paper &lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps&lt;/a&gt; (&lt;strong&gt;Neurips 2022 Oral&lt;/strong&gt;) and &lt;a href=&#34;https://arxiv.org/abs/2211.01095&#34;&gt;DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models&lt;/a&gt; by Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li and Jun Zhu.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;DPM-Solver (and the improved version DPM-Solver++) is a fast dedicated high-order solver for diffusion ODEs with the convergence order guarantee. DPM-Solver is suitable for both discrete-time and continuous-time diffusion models &lt;strong&gt;without any further training&lt;/strong&gt;. Experimental results show that DPM-Solver can generate high-quality samples in &lt;strong&gt;only 10 to 20&lt;/strong&gt; function evaluations on various datasets.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.05233&#34;&gt;ADM&lt;/a&gt; with DPM-Solver:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/assets/intro.png&#34; alt=&#34;DPM-Solver&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable-Diffusion&lt;/a&gt; with DPM-Solver++:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/assets/sdm-1.png&#34; alt=&#34;sdm&#34;&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#news&#34;&gt;News&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#supported-models-and-algorithms&#34;&gt;Supported Models and Algorithms&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#code-examples&#34;&gt;Code Examples&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#stable-diffusion-with-dpm-solver&#34;&gt;Stable-Diffusion with DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#scoresde-with-dpm-solver&#34;&gt;ScoreSDE with DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#other-examples&#34;&gt;Other Examples&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#use-dpm-solver-in-your-own-code&#34;&gt;Use DPM-Solver in your own code&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#suggestions-for-choosing-the-hyperparameters&#34;&gt;Suggestions for Choosing the Hyperparameters&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#suggestions-for-the-detailed-settings&#34;&gt;Suggestions for the Detailed Settings&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#example--unconditional-sampling-by-dpm-solver&#34;&gt;Example: Unconditional Sampling by DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#example--classifier-guidance-sampling-by-dpm-solver&#34;&gt;Example: Classifier Guidance Sampling by DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#example--classifier-free-guidance-sampling-by-dpm-solver&#34;&gt;Example: Classifier-Free Guidance Sampling by DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#documentation&#34;&gt;Documentation&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#1-define-the-noise-schedule&#34;&gt;1. Define the noise schedule.&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#2-wrap-your-model-to-a-continuous-time-noise-predicition-model&#34;&gt;2. Wrap your model to a continuous-time noise predicition model.&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#3-define-dpm-solver&#34;&gt;3. Define DPM-Solver&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#todo-list&#34;&gt;TODO List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LuChengTHU/dpm-solver/main/#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;DPM-Solver has been used in:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://beta.dreamstudio.ai/home&#34;&gt;DreamStudio&lt;/a&gt; and &lt;a href=&#34;https://stableboost.ai/&#34;&gt;StableBoost&lt;/a&gt; (thanks for the implementations by &lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;Katherine Crowson&#39;s k-diffusion repo&lt;/a&gt;).&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui&#34;&gt;Stable-diffusion-webui&lt;/a&gt;, which supports both DPM-Solver and DPM-Solver++. DPM-Solver++2M is the fastest solver currently. Also many Thanks to &lt;a href=&#34;https://github.com/crowsonkb/k-diffusion&#34;&gt;Katherine Crowson&#39;s k-diffusion repo&lt;/a&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Diffusers&lt;/a&gt;, a widely-used library for diffusion models.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2022-11-07&lt;/strong&gt;. Happy to announce that the multistep DPM-Solver has been supported by &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;diffusers&lt;/a&gt;! Thanks for all the efforts of huggingface team (and me ^_^). Check &lt;a href=&#34;https://github.com/huggingface/diffusers/pull/1132&#34;&gt;this PR&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;2022-10-26&lt;/strong&gt;. We have updated the &lt;strong&gt;DPM-Solver v2.0&lt;/strong&gt;, a more stable version for high-resolutional image synthesis tasks. We have the following upgrades:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;We support the discrete-time DPMs by implementing a picewise linear interpolation of $\log\alpha_t$ for the &lt;code&gt;NoiseScheduleVP&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We strongly recommend to use the new implementation for discrete-time DPMs, especially for high-resolutional image synthesis. You can set &lt;code&gt;schedule=&#39;discrete&#39;&lt;/code&gt; to use the corresponding noise schedule. We also change the mapping between discrete-time inputs and continuous-time inputs in the &lt;code&gt;model_wrapper&lt;/code&gt;, which has a consistent converged results with the other solvers.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;We change the API for &lt;code&gt;model_wrapper&lt;/code&gt;:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;We support four types of diffusion models: noise prediction model, data prediction model, velocity prediction model, score function.&lt;/li&gt; &#xA;     &lt;li&gt;We support unconditional sampling, classifier guidance sampling and classifier-free guidance sampling.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;We support &lt;strong&gt;new algorithms&lt;/strong&gt; for DPM-Solver, which greatly improve the high-resolutional image sample quality by guided sampling.&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;We support both the noise prediction model $\epsilon_\theta(x_t,t)$ and the data prediction model $x_\theta(x_t,t)$. For the data prediction model, we further support the &lt;em&gt;dynamic thresholding&lt;/em&gt; introduced by &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;We support both &lt;em&gt;singlestep&lt;/em&gt; solver (i.e. Runge-Kutta-like solver) and &lt;em&gt;multistep&lt;/em&gt; solver (i.e. Adams-Bashforth-like solver) for DPM-Solver, including order 1, 2, 3.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Supported Models and Algorithms&lt;/h1&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;We support the following four types of diffusion models. You can set the model type by the argument &lt;code&gt;model_type&lt;/code&gt; in the function &lt;code&gt;model_wrapper&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model Type&lt;/th&gt; &#xA;   &lt;th&gt;Training Objective&lt;/th&gt; &#xA;   &lt;th&gt;Example Paper&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;noise&#34;: noise prediction model $\epsilon_\theta$&lt;/td&gt; &#xA;   &lt;td&gt;$E_{x_{0},\epsilon,t}\left[\omega_1(t)||\epsilon_\theta(x_t,t)-\epsilon||_2^2\right]$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt;, &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable-Diffusion&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;x_start&#34;: data prediction model $x_\theta$&lt;/td&gt; &#xA;   &lt;td&gt;$E_{x_0,\epsilon,t}\left[\omega_2(t)||x_\theta(x_t,t)-x_0||_2^2\right]$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.06125&#34;&gt;DALL·E 2&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;v&#34;: velocity prediction model $v_\theta$&lt;/td&gt; &#xA;   &lt;td&gt;$E_{x_0,\epsilon,t}\left[\omega_3(t)||v_\theta(x_t,t)-(\alpha_t\epsilon - \sigma_t x_0)||_2^2\right]$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.02303&#34;&gt;Imagen Video&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;score&#34;: marginal score function $s_\theta$&lt;/td&gt; &#xA;   &lt;td&gt;$E_{x_0,\epsilon,t}\left[\omega_4(t)||\sigma_t s_\theta(x_t,t)+\epsilon||_2^2\right]$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2011.13456&#34;&gt;ScoreSDE&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Sampling Types&lt;/h2&gt; &#xA;&lt;p&gt;We support the following three types of sampling by diffusion models. You can set the argument &lt;code&gt;guidance_type&lt;/code&gt; in the function &lt;code&gt;model_wrapper&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Sampling Type&lt;/th&gt; &#xA;   &lt;th&gt;Equation for Noise Prediction Model&lt;/th&gt; &#xA;   &lt;th&gt;Example Paper&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;uncond&#34;: unconditional sampling&lt;/td&gt; &#xA;   &lt;td&gt;$\tilde\epsilon_\theta(x_t,t)=\epsilon_\theta(x_t,t)$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;classifier&#34;: classifier guidance&lt;/td&gt; &#xA;   &lt;td&gt;$\tilde\epsilon_\theta(x_t,t,c)=\epsilon_\theta(x_t,t)-s\cdot\sigma_t\nabla_{x_t}\log q_\phi(x_t,t,c)$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2105.05233&#34;&gt;ADM&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2112.10741&#34;&gt;GLIDE&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;classifier-free&#34;: classifier-free guidance&lt;/td&gt; &#xA;   &lt;td&gt;$\tilde\epsilon_\theta(x_t,t,c)=s\cdot \epsilon_\theta(x_t,t,c)+(1-s)\cdot\epsilon_\theta(x_t,t)$&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.06125&#34;&gt;DALL·E 2&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt;, &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable-Diffusion&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Algorithms in DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We support the following four algorithms. The algorithms with noise-prediction are referred to &lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;DPM-Solver&lt;/a&gt; which discretizing the integral w.r.t. the &lt;em&gt;noise prediction model&lt;/em&gt;, and the algorithms with data-prediction are referred to &lt;a href=&#34;https://arxiv.org/abs/2211.01095&#34;&gt;DPM-Solver++&lt;/a&gt; which discretizing the &lt;em&gt;data prediction model&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We also support the &lt;em&gt;dynamic thresholding&lt;/em&gt; introduced by &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt; for algorithms with data-prediction. The dynamic thresholding method can further improve the sample quality by pixel-space DPMs with large guidance scales.&lt;/p&gt; &#xA;&lt;p&gt;Note that the &lt;code&gt;model_fn&lt;/code&gt; for initializing DPM-Solver is always the noise prediction model. The setting for &lt;code&gt;predict_x0&lt;/code&gt; is for the algorithm (noise-prediction DPM-Solver or data-prediction DPM-Solver++), not for the model. In other words, even for &lt;code&gt;predict_x0=True&lt;/code&gt;, you can still use the noise prediction model for your &lt;code&gt;model_fn&lt;/code&gt; and the algorithm can work well.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;In fact, we implement the algorithms with data-prediction by firstly converting the noise prediction model to the data prediction model and then use DPM-Solver++ to sample, and users do not need to care about it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The performance of singlestep solvers (i.e. Runge-Kutta-like solvers) and the multistep solvers (i.e. Adams-Bashforth-like solvers) are different. We recommend to use different solvers for different tasks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Supported Orders&lt;/th&gt; &#xA;   &lt;th&gt;Supporting Thresholding&lt;/th&gt; &#xA;   &lt;th&gt;Remark&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;noise-prediction, singlestep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Recommended for &lt;strong&gt;unconditional sampling&lt;/strong&gt; (with order = 3). See &lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;this paper&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;noise-prediction, multistep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;data-prediction, singlestep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;data-prediction, multistep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Recommended for &lt;strong&gt;guided sampling&lt;/strong&gt; (with order = 2). See &lt;a href=&#34;https://arxiv.org/abs/2211.01095&#34;&gt;this paper&lt;/a&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Code Examples&lt;/h1&gt; &#xA;&lt;h2&gt;Stable-Diffusion with DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We provide an &lt;a href=&#34;https://github.com/LuChengTHU/dpm-solver/tree/main/example_v2/stable-diffusion&#34;&gt;example of stable diffusion with DPM-Solver&lt;/a&gt; in &lt;code&gt;example_v2/stable-diffusion&lt;/code&gt;. DPM-Solver can greatly accelerate the sampling speed of the &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;original stable-diffusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ScoreSDE with DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We provide a &lt;a href=&#34;https://github.com/LuChengTHU/dpm-solver/tree/main/example_v2/score_sde_pytorch&#34;&gt;pytorch example&lt;/a&gt; and a &lt;a href=&#34;https://github.com/LuChengTHU/dpm-solver/tree/main/example_v2/score_sde_jax&#34;&gt;JAX example&lt;/a&gt; in &lt;code&gt;example_v2/&lt;/code&gt; which apply DPM-Solver for &lt;a href=&#34;https://github.com/yang-song/score_sde&#34;&gt;Yang Song&#39;s score_sde repo&lt;/a&gt; on CIFAR-10.&lt;/p&gt; &#xA;&lt;h2&gt;Other Examples&lt;/h2&gt; &#xA;&lt;p&gt;Coming soon...&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Use DPM-Solver in your own code&lt;/h1&gt; &#xA;&lt;p&gt;It is very easy to combine DPM-Solver with your own diffusion models. We support both Pytorch and JAX code. You can just copy the file &lt;code&gt;dpm_solver_pytorch.py&lt;/code&gt; or &lt;code&gt;dpm_solver_jax.py&lt;/code&gt; to your own code files and import it.&lt;/p&gt; &#xA;&lt;p&gt;In each step, DPM-Solver needs to compute the corresponding $\alpha_t$, $\sigma_t$ and $\lambda_t$ of the noise schedule. We support the commonly-used variance preserving (VP) noise schedule for both discrete-time and continuous-time DPMs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For discrete-time DPMs, we support a picewise linear interpolation of $\log\alpha_t$ in the &lt;code&gt;NoiseScheduleVP&lt;/code&gt; class. It can support all types of VP noise schedules.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For continuous-time DPMs, we support both linear schedule (as used in &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2011.13456&#34;&gt;ScoreSDE&lt;/a&gt;) and cosine schedule (as used in &lt;a href=&#34;https://arxiv.org/abs/2102.09672&#34;&gt;improved-DDPM&lt;/a&gt;) in the &lt;code&gt;NoiseScheduleVP&lt;/code&gt; class.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Moreover, DPM-Solver is designed for the continuous-time diffusion ODEs. For discrete-time diffusion models, we also implement a wrapper function to convert the discrete-time diffusion models to the continuous-time diffusion models in the &lt;code&gt;model_wrapper&lt;/code&gt; function.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Suggestions for Choosing the Hyperparameters&lt;/h2&gt; &#xA;&lt;p&gt;If you want to find the best setting for accelerating the sampling procedure by your own diffusion models, we provide a reference guide here:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt;: First run 1000-step &lt;a href=&#34;https://arxiv.org/abs/2010.02502&#34;&gt;DDIM&lt;/a&gt; to check the sample quality of your model. &lt;strong&gt;If the sample quality is poor, then DPM-Solver cannot improve it.&lt;/strong&gt; Please further check your model defination or training process.&lt;/p&gt; &lt;p&gt;Reason: DDIM is the first-order special case of DPM-Solver (proved in &lt;a href=&#34;https://arxiv.org/abs/2206.00927&#34;&gt;our paper&lt;/a&gt;). So given the same noise sample at time $T$, the converged samples of DDIM and DPM-Solver are the same. DPM-Solver &lt;strong&gt;can&lt;/strong&gt; accelerate the convergence, but &lt;strong&gt;cannot&lt;/strong&gt; improve the converged sample quality.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;If 1000-step DDIM can generate quite good samples, then DPM-Solver can achieve a quite good sample quality within very few steps because it can greatly accelerate the convergence. You may want to further choose the detailed hyperparameters of DPM-Solver. Here we provide a comprehensive searching routine:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Comparing &lt;code&gt;predict_x0=True&lt;/code&gt; and &lt;code&gt;predict_x0=False&lt;/code&gt;. Note that these settings are for the algorithm, not for the model. In other words, even for &lt;code&gt;predict_x0=True&lt;/code&gt;, you can still use the noise prediction model (such as stable-diffusion) and the algorithm can work well.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(Optional) Comparing &lt;code&gt;thresholding=True&lt;/code&gt; and &lt;code&gt;thresholding=False&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt;: our supported dynamic thresholding method is only valid for &lt;strong&gt;pixel-space&lt;/strong&gt; diffusion models with &lt;code&gt;predict_x0=True&lt;/code&gt;. For example, &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt; uses the dynamic thresholding method and greatly improves the sample quality. The thresholding method pushes the pixel-space samples into the bounded area, so it can generate reasonable images. However, for latent-space diffusion models (such as stable-diffusion), the thresholding method is &lt;strong&gt;unsuitable&lt;/strong&gt; because the $x_0$ at time $0$ of the diffusion model is in fact the &#34;latent variable&#34; in the latent space and it is unbounded.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Comparing &lt;code&gt;singlestep&lt;/code&gt; or &lt;code&gt;multistep&lt;/code&gt; methods.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Comparing &lt;code&gt;order = 2, 3&lt;/code&gt;. Note that the all the first-order versions are equivalent to DDIM, so you do not need to try it.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Comparing &lt;code&gt;steps = 10, 15, 20, 25, 50, 100&lt;/code&gt;. It depends on your computation resources and the need of sample quality.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(Optional) Comparing the &lt;code&gt;time_uniform&lt;/code&gt;, &lt;code&gt;logSNR&lt;/code&gt; and &lt;code&gt;time_quadratic&lt;/code&gt; for the skip type.&lt;/p&gt; &lt;p&gt;We empirically find that for high-resolutional images, the best setting is the &lt;code&gt;time_uniform&lt;/code&gt;. So we recommend this setting and there is no need for extra searching. However, for low-resolutional images such as CIFAR-10, we empirically find that &lt;code&gt;logSNR&lt;/code&gt; is the best setting.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;(Optional) Comparing &lt;code&gt;denoise_to_zero=True&lt;/code&gt; or &lt;code&gt;denoise_to_zero=False&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Empirically, the &lt;code&gt;denoise_to_zero=True&lt;/code&gt; can improve the FID for low-resolutional images such as CIFAR-10. However, the influence of this method for high-resolutional images seem to be small. As the denoise_to_zero method needs one additional function evaluation (i.e. one additional step), we do not recommend to use the denoise_to_zero method for high-resolutional images.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;The detailed pseudo code is like:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for predict_x0 in [True, False]:&#xA;# Optional, for thresholding in [True, False]:&#xA;    dpm_solver = DPM_Solver(..., predict_x0=predict_x0) # ... means other arguments&#xA;    for method in [&#39;singlestep&#39;, &#39;multistep&#39;]:&#xA;        for order in [2, 3]:&#xA;            for steps in [10, 15, 20, 25, 50, 100]:&#xA;                sample = dpm_solver.sample(&#xA;                    ..., # ... means other arguments&#xA;                    method=method,&#xA;                    order=order,&#xA;                    steps=steps,&#xA;                    # optional: skip_type=&#39;time_uniform&#39; or &#39;logSNR&#39; or &#39;time_quadratic&#39;,&#xA;                    # optional: denoise_to_zero=True or False&#xA;                )&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And then compare the samples to choose the best setting.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Moreover, for unconditional sampling and guided sampling, we have some recommendation settings and code examples, which are listed in the following section.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Suggestions for the Detailed Settings&lt;/h2&gt; &#xA;&lt;p&gt;We recommend to use the following two types of solvers for different tasks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;3rd-order (noise-prediction + singlestep) DPM-Solver:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## Define the model and noise schedule (see examples below) &#xA;## ....&#xA;&#xA;## Define DPM-Solver and compute the sample.&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule)&#xA;&#xA;## Steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;2nd-order (data-prediction + multistep) DPM-Solver:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For general DPMs (e.g. latent-space DPMs): &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## Define the model and noise schedule (see examples below) &#xA;## ....&#xA;&#xA;## Define DPM-Solver and compute the sample.&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True)&#xA;&#xA;## Steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;For DPMs trained on bounded data (e.g. pixel-space images), we further support the &lt;em&gt;dynamic thresholding&lt;/em&gt; method introduced by &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt; by setting &lt;code&gt;thresholding = True&lt;/code&gt;. The dynamic thresholding method can greatly improve the sample quality of pixel-space DPMs by guided sampling with large guidance scales. &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## Define the model and noise schedule (see examples below) &#xA;## ....&#xA;&#xA;## Define DPM-Solver and compute the sample.&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True,&#xA;                        thresholding=True, max_val=1.0)&#xA;&#xA;## Steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Specifically, we have the following suggestions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For unconditional sampling:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For obtaining a not too bad sample as fast as possible, use the 2nd-order (data-prediction + multistep) DPM-Solver with &lt;code&gt;steps&lt;/code&gt; &amp;lt;= 10.&lt;/li&gt; &#xA;   &lt;li&gt;For obtaining a good but not converged sample, use the 3rd-order (noise-prediction + singlestep) DPM-Solver with &lt;code&gt;steps&lt;/code&gt; = 15.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;strong&gt;(Recommended)&lt;/strong&gt; For obtaining an almost converged sample, use the 3rd-order (noise-prediction + singlestep) DPM-Solver with &lt;code&gt;steps&lt;/code&gt; = 20.&lt;/li&gt; &#xA;   &lt;li&gt;For obtaining an absolutely converged sample, use the 3rd-order (noise-prediction + singlestep) DPM-Solver with &lt;code&gt;steps&lt;/code&gt; = 50.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For guided sampling (especially with large guidance scales):&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Use the 2nd-order (data-prediction + multistep) DPM-Solver for all steps.&lt;/li&gt; &#xA;   &lt;li&gt;For pixel-space DPMs (i.e. DPMs trained on images), set &lt;code&gt;thresholding = True&lt;/code&gt;; else (e.g. latent-space DPMs) set &lt;code&gt;thresholding = False&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Choices for &lt;code&gt;steps&lt;/code&gt;: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;For obtaining a not too bad sample as fast as possible, use &lt;code&gt;steps&lt;/code&gt; &amp;lt;= 10.&lt;/li&gt; &#xA;     &lt;li&gt;For obtaining a good but not converged sample, use &lt;code&gt;steps&lt;/code&gt; = 15.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;strong&gt;(Recommended)&lt;/strong&gt; For obtaining an almost converged sample, use &lt;code&gt;steps&lt;/code&gt; = 20.&lt;/li&gt; &#xA;     &lt;li&gt;For obtaining an absolutely converged sample, use &lt;code&gt;steps&lt;/code&gt; = 50.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Example: Unconditional Sampling by DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We recommend to use the 3rd-order (noise-prediction + singlestep) DPM-Solver. Here is an example for discrete-time DPMs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dpm_solver_pytorch import NoiseScheduleVP, model_wrapper, DPM_Solver&#xA;&#xA;## You need to firstly define your model and the extra inputs of your model,&#xA;## And initialize an `x_T` from the standard normal distribution.&#xA;## `model` has the format: model(x_t, t_input, **model_kwargs).&#xA;## If your model has no extra inputs, just let model_kwargs = {}.&#xA;&#xA;## If you use discrete-time DPMs, you need to further define the&#xA;## beta arrays for the noise schedule.&#xA;&#xA;# model = ....&#xA;# model_kwargs = {...}&#xA;# x_T = ...&#xA;# betas = ....&#xA;&#xA;## 1. Define the noise schedule.&#xA;noise_schedule = NoiseScheduleVP(schedule=&#39;discrete&#39;, betas=betas)&#xA;&#xA;## 2. Convert your discrete-time `model` to the continuous-time&#xA;## noise prediction model. Here is an example for a diffusion model&#xA;## `model` with the noise prediction type (&#34;noise&#34;) .&#xA;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=&#34;noise&#34;,  # or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;)&#xA;&#xA;## 3. Define dpm-solver and sample by singlestep DPM-Solver.&#xA;## (We recommend singlestep DPM-Solver for unconditional sampling)&#xA;## You can adjust the `steps` to balance the computation&#xA;## costs and the sample quality.&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule)&#xA;&#xA;## You can use steps = 10, 12, 15, 20, 25, 50, 100.&#xA;## Empirically, we find that steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;Example: Classifier Guidance Sampling by DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We recommend to use the 2nd-order (data-prediction + multistep) DPM-Solver, especially for large guidance scales. Here is an example for discrete-time DPMs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dpm_solver_pytorch import NoiseScheduleVP, model_wrapper, DPM_Solver&#xA;&#xA;## You need to firstly define your model and the extra inputs of your model,&#xA;## And initialize an `x_T` from the standard normal distribution.&#xA;## `model` has the format: model(x_t, t_input, **model_kwargs).&#xA;## If your model has no extra inputs, just let model_kwargs = {}.&#xA;&#xA;## If you use discrete-time DPMs, you need to further define the&#xA;## beta arrays for the noise schedule.&#xA;&#xA;## For classifier guidance, you need to further define a classifier function,&#xA;## a guidance scale and a condition variable.&#xA;&#xA;# model = ....&#xA;# model_kwargs = {...}&#xA;# x_T = ...&#xA;# condition = ...&#xA;# betas = ....&#xA;# classifier = ...&#xA;# classifier_kwargs = {...}&#xA;# guidance_scale = ...&#xA;&#xA;## 1. Define the noise schedule.&#xA;noise_schedule = NoiseScheduleVP(schedule=&#39;discrete&#39;, betas=betas)&#xA;&#xA;## 2. Convert your discrete-time `model` to the continuous-time&#xA;## noise prediction model. Here is an example for a diffusion model&#xA;## `model` with the noise prediction type (&#34;noise&#34;) .&#xA;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=&#34;noise&#34;,  # or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;    guidance_type=&#34;classifier&#34;,&#xA;    condition=condition,&#xA;    guidance_scale=guidance_scale,&#xA;    classifier_fn=classifier,&#xA;    classifier_kwargs=classifier_kwargs,&#xA;)&#xA;&#xA;## 3. Define dpm-solver and sample by multistep DPM-Solver.&#xA;## (We recommend multistep DPM-Solver for conditional sampling)&#xA;## You can adjust the `steps` to balance the computation&#xA;## costs and the sample quality.&#xA;&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True)&#xA;&#xA;## If the DPM is defined on pixel-space images, you can further&#xA;## set `thresholding=True`. e.g.:&#xA;&#xA;# dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True,&#xA;#   thresholding=True)&#xA;&#xA;&#xA;## You can use steps = 10, 12, 15, 20, 25, 50, 100.&#xA;## Empirically, we find that steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example: Classifier-Free Guidance Sampling by DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;We recommend to use the 2nd-order (data-prediction + multistep) DPM-Solver, especially for large guidance scales. Here is an example for discrete-time DPMs:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dpm_solver_pytorch import NoiseScheduleVP, model_wrapper, DPM_Solver&#xA;&#xA;## You need to firstly define your model and the extra inputs of your model,&#xA;## And initialize an `x_T` from the standard normal distribution.&#xA;## `model` has the format: model(x_t, t_input, cond, **model_kwargs).&#xA;## If your model has no extra inputs, just let model_kwargs = {}.&#xA;&#xA;## If you use discrete-time DPMs, you need to further define the&#xA;## beta arrays for the noise schedule.&#xA;&#xA;## For classifier-free guidance, you need to further define a guidance scale,&#xA;## a condition variable and an unconditioanal condition variable.&#xA;&#xA;# model = ....&#xA;# model_kwargs = {...}&#xA;# x_T = ...&#xA;# condition = ...&#xA;# unconditional_condition = ...&#xA;# betas = ....&#xA;# guidance_scale = ...&#xA;&#xA;## 1. Define the noise schedule.&#xA;noise_schedule = NoiseScheduleVP(schedule=&#39;discrete&#39;, betas=betas)&#xA;&#xA;## 2. Convert your discrete-time `model` to the continuous-time&#xA;## noise prediction model. Here is an example for a diffusion model&#xA;## `model` with the noise prediction type (&#34;noise&#34;) .&#xA;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=&#34;noise&#34;,  # or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;    guidance_type=&#34;classifier-free&#34;,&#xA;    condition=condition,&#xA;    unconditional_condition=unconditional_condition,&#xA;    guidance_scale=guidance_scale,&#xA;)&#xA;&#xA;## 3. Define dpm-solver and sample by multistep DPM-Solver.&#xA;## (We recommend multistep DPM-Solver for conditional sampling)&#xA;## You can adjust the `steps` to balance the computation&#xA;## costs and the sample quality.&#xA;&#xA;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True)&#xA;&#xA;## If the DPM is defined on pixel-space images, you can further&#xA;## set `thresholding=True`. e.g.:&#xA;&#xA;# dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True,&#xA;#   thresholding=True)&#xA;&#xA;&#xA;## You can use steps = 10, 12, 15, 20, 25, 50, 100.&#xA;## Empirically, we find that steps in [10, 20] can generate quite good samples.&#xA;## And steps = 20 can almost converge.&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;Documentation&lt;/h1&gt; &#xA;&lt;h2&gt;1. Define the noise schedule.&lt;/h2&gt; &#xA;&lt;p&gt;We support the commonly-used variance preserving (VP) noise schedule for both discrete-time and continuous-time DPMs:&lt;/p&gt; &#xA;&lt;h3&gt;1.1. Discrete-time DPMs&lt;/h3&gt; &#xA;&lt;p&gt;We support a picewise linear interpolation of $\log\alpha_{t}$ in the &lt;code&gt;NoiseScheduleVP&lt;/code&gt; class. It can support all types of VP noise schedules.&lt;/p&gt; &#xA;&lt;p&gt;We need either the $\beta_i$ array or the $\bar{\alpha}_i$ array (see &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt; for details) to define the noise schedule. Note that the $\bar{\alpha}_i$ in &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt; is different from the $\alpha_t$ in DPM-Solver, and the detailed relationship is:&lt;/p&gt; &#xA;&lt;p&gt;$$ \bar{\alpha}_i = \prod (1 - \beta_k) $$&lt;/p&gt; &#xA;&lt;p&gt;$$ \alpha_{t_i} = \sqrt{\bar{\alpha}_i} $$&lt;/p&gt; &#xA;&lt;p&gt;Define the discrete-time noise schedule by the $\beta_i$ array:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;noise_schedule = NoiseScheduleVP(schedule=&#39;discrete&#39;, betas=betas)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or define the discrete-time noise schedule by the $\bar{\alpha}_i$ array:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;noise_schedule = NoiseScheduleVP(schedule=&#39;discrete&#39;, alphas_cumprod=alphas_cumprod)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;1.2. Continuous-time DPMs&lt;/h3&gt; &#xA;&lt;p&gt;We support both linear schedule (as used in &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;DDPM&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2011.13456&#34;&gt;ScoreSDE&lt;/a&gt;) and cosine schedule (as used in &lt;a href=&#34;https://arxiv.org/abs/2102.09672&#34;&gt;improved-DDPM&lt;/a&gt;) for the continuous-time DPMs.&lt;/p&gt; &#xA;&lt;p&gt;Define the continuous-time linear noise schedule:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;noise_schedule = NoiseScheduleVP(schedule=&#39;linear&#39;, continuous_beta_0=0.1, continuous_beta_1=20.)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Define the continuous-time cosine noise schedule:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;noise_schedule = NoiseScheduleVP(schedule=&#39;cosine&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- &#xA;If you want to custom your own designed noise schedule, you need to implement the `marginal_log_mean_coeff`, `marginal_std`, `marginal_lambda` and `inverse_lambda` functions of your noise schedule. Please refer to the detailed comments in the code of `NoiseScheduleVP`.&#xA; --&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;2. Wrap your model to a continuous-time noise predicition model.&lt;/h2&gt; &#xA;&lt;p&gt;For a given diffusion &lt;code&gt;model&lt;/code&gt; with an input of the time label (may be discrete-time labels (i.e. 0 to 999) or continuous-time times (i.e. 0 to 1)), and the output type of the model may be &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;, we wrap the model function to the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model_fn(x, t_continuous) -&amp;gt; noise&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;t_continuous&lt;/code&gt; is the continuous time labels (i.e. 0 to 1), and the output type of the model is &#34;noise&#34;, i.e. a noise prediction model. And we use the continuous-time noise prediction model &lt;code&gt;model_fn&lt;/code&gt; for DPM-Solver.&lt;/p&gt; &#xA;&lt;p&gt;Note that DPM-Solver only needs the noise prediction model (the $\epsilon_\theta(x_t, t)$ model, also as known as the &#34;mean&#34; model), so for diffusion models which predict both &#34;mean&#34; and &#34;variance&#34; (such as &lt;a href=&#34;https://arxiv.org/abs/2102.09672&#34;&gt;improved-DDPM&lt;/a&gt;), you need to firstly define another function by yourself to only output the &#34;mean&#34;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;2.1. Sampling without Guidance&lt;/h3&gt; &#xA;&lt;p&gt;After defining the noise schedule, we need to further wrap the &lt;code&gt;model&lt;/code&gt; to a continuous-time noise prediction model. The given &lt;code&gt;model&lt;/code&gt; has the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model(x_t, t_input, **model_kwargs) -&amp;gt; noise | x_start | v | score&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And we wrap the model by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=model_type, # &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;model_kwargs&lt;/code&gt; is the additional inputs of the model, and the &lt;code&gt;model_type&lt;/code&gt; can be &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;2.2. Sampling with Classifier Guidance&lt;/h3&gt; &#xA;&lt;p&gt;After defining the noise schedule, we need to further wrap the &lt;code&gt;model&lt;/code&gt; to a continuous-time noise prediction model. The given &lt;code&gt;model&lt;/code&gt; has the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model(x_t, t_input, **model_kwargs) -&amp;gt; noise | x_start | v | score&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For DPMs with classifier guidance, we also combine the model output with the classifier gradient. We need to specify the classifier function and the guidance scale. The classifier function has the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;classifier_fn(x, t_input, cond, **classifier_kwargs) -&amp;gt; logits(x, t_input, cond)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;t_input&lt;/code&gt; is the same time label as in the original diffusion model &lt;code&gt;model&lt;/code&gt;, and &lt;code&gt;cond&lt;/code&gt; is the condition variable, and &lt;code&gt;classifier_kwargs&lt;/code&gt; is the other inputs of the classifier function.&lt;/p&gt; &#xA;&lt;p&gt;And we wrap the model by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=model_type,  # &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;    guidance_type=&#34;classifier&#34;,&#xA;    condition=condition,&#xA;    guidance_scale=guidance_scale,&#xA;    classifier_fn=classifier,&#xA;    classifier_kwargs=classifier_kwargs,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;model_kwargs&lt;/code&gt; is the additional inputs of the model, and the &lt;code&gt;model_type&lt;/code&gt; can be &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;, and &lt;code&gt;guidance_scale&lt;/code&gt; is the classifier guidance scale, and &lt;code&gt;condition&lt;/code&gt; is the conditional input of the classifier.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;2.3. Sampling with Classifier-free Guidance&lt;/h3&gt; &#xA;&lt;p&gt;After defining the noise schedule, we need to further wrap the &lt;code&gt;model&lt;/code&gt; to a continuous-time noise prediction model. The given &lt;code&gt;model&lt;/code&gt; has the following format:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model(x_t, t_input, cond, **model_kwargs) -&amp;gt; noise | x_start | v | score&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that for classifier-free guidance, the model needs another input &lt;code&gt;cond&lt;/code&gt;. And if &lt;code&gt;cond&lt;/code&gt; is a special variable &lt;code&gt;unconditional_condition&lt;/code&gt;, the model output is the unconditional DPM output.&lt;/p&gt; &#xA;&lt;p&gt;And we wrap the model by:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model_fn = model_wrapper(&#xA;    model,&#xA;    noise_schedule,&#xA;    model_type=model_type,  # &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;&#xA;    model_kwargs=model_kwargs,&#xA;    guidance_type=&#34;classifier-free&#34;,&#xA;    condition=condition,&#xA;    unconditional_condition=unconditional_condition,&#xA;    guidance_scale=guidance_scale,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;model_kwargs&lt;/code&gt; is the additional inputs of the model, and the &lt;code&gt;model_type&lt;/code&gt; can be &#34;noise&#34; or &#34;x_start&#34; or &#34;v&#34; or &#34;score&#34;, and &lt;code&gt;guidance_scale&lt;/code&gt; is the classifier guidance scale, and &lt;code&gt;condition&lt;/code&gt; is the conditional input, and &lt;code&gt;unconditional_condition&lt;/code&gt; is the special unconditional condition variable for the unconditional model.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;2.4. Implementation Details for the Time Inputs&lt;/h3&gt; &#xA;&lt;p&gt;Below we introduce the detailed mapping between the discrete-time labels and the continuous-time times. However, to use DPM-Solver, it is not necessary to understand the following details.&lt;/p&gt; &#xA;&lt;h4&gt;Discrete-time DPM-Solver&lt;/h4&gt; &#xA;&lt;p&gt;For discrete-time DPMs, the noise prediction model noise-prediction is trained for the discrete-time labels from $0$ to $N-1$. Therefore, we sample from the discrete-time label $N - 1$ (e.g. 999) to the discrete-time label $0$. We convert the discrete-time labels in $[0, N-1]$ to the continuous-time times $(0,1]$ by&lt;/p&gt; &#xA;&lt;p&gt;$$ t_{\text{discrete}} = 1000 * \left(t_{\text{continuous}} - \frac{1}{N}\right), $$&lt;/p&gt; &#xA;&lt;p&gt;i.e. we map the discrete-time label $0$ to the continuous-time time $\frac{1}{N}$, and the discrete-time label $N-1$ to the continuous-time time $1$. Therefore, sampling from the discrete time from $N-1$ to $0$ is corresponding to sampling from the continuous time from $1$ to $\frac{1}{N}$.&lt;/p&gt; &#xA;&lt;h4&gt;Continuous-time DPM-Solver&lt;/h4&gt; &#xA;&lt;p&gt;For continuous-time DPMs from defined by $t \in [0,1]$, we simply wrap the model to accept only $x_t$ and $t$. Note that for continuous-time DPMs, we do not modify the time inputs.&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;h2&gt;3. Define DPM-Solver&lt;/h2&gt; &#xA;&lt;p&gt;After defining the &lt;code&gt;model_fn&lt;/code&gt; by the function &lt;code&gt;model_wrapper&lt;/code&gt;, we can further use &lt;code&gt;model_fn&lt;/code&gt; to define DPM-Solver and compute samples.&lt;/p&gt; &#xA;&lt;p&gt;We support the following four algorithms. The algorithms with noise-prediction are referred to DPM-Solver w.r.t. the &lt;em&gt;noise prediction model&lt;/em&gt;, and the algorithms with data-prediction are referred to DPM-Solver w.r.t. the &lt;em&gt;data prediction model&lt;/em&gt;. We also support the &lt;em&gt;dynamic thresholding&lt;/em&gt; introduced by &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt; for algorithms with data-prediction. The dynamic thresholding method can further improve the sample quality by pixel-space DPMs with large guidance scales.&lt;/p&gt; &#xA;&lt;p&gt;Note that the &lt;code&gt;model_fn&lt;/code&gt; for initializing DPM-Solver is always the noise prediction model, and for algorithms with data-prediction we further convert the noise prediction model to the data prediction model inside the implementation of DPM-Solver.&lt;/p&gt; &#xA;&lt;p&gt;The performance of singlestep solvers (i.e. Runge-Kutta-like solvers) and the multistep solvers (i.e. Adams-Bashforth-like solvers) are different. We recommend to use different solvers for different tasks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Method&lt;/th&gt; &#xA;   &lt;th&gt;Supported Orders&lt;/th&gt; &#xA;   &lt;th&gt;Support Thresholding&lt;/th&gt; &#xA;   &lt;th&gt;Remark&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;noise-prediction, singlestep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;Recommended for &lt;strong&gt;unconditional sampling&lt;/strong&gt; (with order = 3)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;noise-prediction, multistep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;No&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;data-prediction, singlestep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;data-prediction, multistep&lt;/td&gt; &#xA;   &lt;td&gt;1, 2, 3&lt;/td&gt; &#xA;   &lt;td&gt;Yes&lt;/td&gt; &#xA;   &lt;td&gt;Recommended for &lt;strong&gt;guided sampling&lt;/strong&gt; (with order = 2)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;For DPM-Solver w.r.t. noise-prediction, define&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dpm_solver = DPM_Solver(model_fn, noise_schedule)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For DPM-Solver w.r.t. data-prediction, define&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For DPM-Solver w.r.t. data-prediction and applying dynamic thresholding, define&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True,&#xA;                        thresholding=True, max_val=1.0)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;dpm_solver.sample&lt;/code&gt; to quickly sample from DPMs. This function computes the ODE solution at time &lt;code&gt;t_end&lt;/code&gt; by DPM-Solver, given the initial &lt;code&gt;x&lt;/code&gt; at time &lt;code&gt;t_start&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We support the following algorithms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Singlestep DPM-Solver. We combine all the singlestep solvers with order &amp;lt;= &lt;code&gt;order&lt;/code&gt; to use up all the function evaluations (steps).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Multistep DPM-Solver.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Fixed order singlestep DPM-Solver (i.e. DPM-Solver-1, DPM-Solver-2 and DPM-Solver-3).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Adaptive step size DPM-Solver. (i.e. DPM-Solver-12 and DPM-Solver-23)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We support three types of &lt;code&gt;skip_type&lt;/code&gt; for the choice of intermediate time steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;logSNR&lt;/code&gt;: uniform logSNR for the time steps. &lt;strong&gt;Recommended for low-resolutional images&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;time_uniform&lt;/code&gt;: uniform time for the time steps. &lt;strong&gt;Recommended for high-resolutional images&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;time_quadratic&lt;/code&gt;: quadratic time for the time steps.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;3.1. Sampling by Singlestep DPM-Solver&lt;/h3&gt; &#xA;&lt;p&gt;We combine all the singlestep solvers with order &amp;lt;= &lt;code&gt;order&lt;/code&gt; to use up all the function evaluations (steps). The total number of function evaluations (NFE) == &lt;code&gt;steps&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For discrete-time DPMs, we do not need to specify the &lt;code&gt;t_start&lt;/code&gt; and &lt;code&gt;t_end&lt;/code&gt;. The default setting is to sample from the discrete-time label $N-1$ to the discrete-time label $0$. For example,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## discrete-time DPMs&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;For continuous-time DPMs, we sample from &lt;code&gt;t_start=1.0&lt;/code&gt; (the default setting) to &lt;code&gt;t_end&lt;/code&gt;. We recommend &lt;code&gt;t_end=1e-3&lt;/code&gt; for &lt;code&gt;steps &amp;lt;= 15&lt;/code&gt;, and &lt;code&gt;t_end=1e-4&lt;/code&gt; for &lt;code&gt;steps &amp;gt; 15&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    t_end=1e-3,&#xA;    steps=12,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## continuous-time DPMs&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    t_end=1e-4,&#xA;    steps=20,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Implementation Details of Singlestep DPM-Solver&lt;/h4&gt; &#xA;&lt;p&gt;Given a fixed NFE == &lt;code&gt;steps&lt;/code&gt;, the sampling procedure is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 1: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Denote K = &lt;code&gt;steps&lt;/code&gt;. We use K steps of DPM-Solver-1 (i.e. DDIM).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 2: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Denote K = (&lt;code&gt;steps&lt;/code&gt; // 2) + (&lt;code&gt;steps&lt;/code&gt; % 2). We take K intermediate time steps for sampling.&lt;/li&gt; &#xA;   &lt;li&gt;If &lt;code&gt;steps&lt;/code&gt; % 2 == 0, we use K steps of singlestep DPM-Solver-2.&lt;/li&gt; &#xA;   &lt;li&gt;If &lt;code&gt;steps&lt;/code&gt; % 2 == 1, we use (K - 1) steps of singlestep DPM-Solver-2 and 1 step of DPM-Solver-1.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 3: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Denote K = (&lt;code&gt;steps&lt;/code&gt; // 3 + 1). We take K intermediate time steps for sampling.&lt;/li&gt; &#xA;   &lt;li&gt;If &lt;code&gt;steps&lt;/code&gt; % 3 == 0, we use (K - 2) steps of singlestep DPM-Solver-3, and 1 step of singlestep DPM-Solver-2 and 1 step of DPM-Solver-1.&lt;/li&gt; &#xA;   &lt;li&gt;If &lt;code&gt;steps&lt;/code&gt; % 3 == 1, we use (K - 1) steps of singlestep DPM-Solver-3 and 1 step of DPM-Solver-1.&lt;/li&gt; &#xA;   &lt;li&gt;If &lt;code&gt;steps&lt;/code&gt; % 3 == 2, we use (K - 1) steps of singlestep DPM-Solver-3 and 1 step of singlestep DPM-Solver-2.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;3.2. Sampling by multistep DPM-Solver&lt;/h3&gt; &#xA;&lt;p&gt;For discrete-time DPMs, we do not need to specify the &lt;code&gt;t_start&lt;/code&gt; and &lt;code&gt;t_end&lt;/code&gt;. The default setting is to sample from the discrete-time label $N-1$ to the discrete-time label $0$. For example,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## discrete-time DPMs&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=20,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;For continuous-time DPMs, we sample from &lt;code&gt;t_start=1.0&lt;/code&gt; (the default setting) to &lt;code&gt;t_end&lt;/code&gt;. We recommend &lt;code&gt;t_end=1e-3&lt;/code&gt; for &lt;code&gt;steps &amp;lt;= 15&lt;/code&gt;, and &lt;code&gt;t_end=1e-4&lt;/code&gt; for &lt;code&gt;steps &amp;gt; 15&lt;/code&gt;. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    t_end=1e-3,&#xA;    steps=10,&#xA;    order=2,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;## continuous-time DPMs&#xA;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    t_end=1e-4,&#xA;    steps=20,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;multistep&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Implementation Details of Multistep DPM-Solver&lt;/h4&gt; &#xA;&lt;p&gt;We initialize the first &lt;code&gt;order&lt;/code&gt; values by lower order multistep solvers.&lt;/p&gt; &#xA;&lt;p&gt;Given a fixed NFE == &lt;code&gt;steps&lt;/code&gt;, the sampling procedure is:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Denote K = &lt;code&gt;steps&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 1: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We use K steps of DPM-Solver-1 (i.e. DDIM).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 2: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We firstly use 1 step of DPM-Solver-1, then use (K - 1) step of multistep DPM-Solver-2.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 3: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;We firstly use 1 step of DPM-Solver-1, then 1 step of multistep DPM-Solver-2, then (K - 2) step of multistep DPM-Solver-3.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;3.3. Sampling by adaptive step size DPM-Solver&lt;/h3&gt; &#xA;&lt;p&gt;For continuous-time DPMs, we recommend &lt;code&gt;t_end=1e-4&lt;/code&gt; for better sample quality.&lt;/p&gt; &#xA;&lt;p&gt;We ignore &lt;code&gt;steps&lt;/code&gt; and use adaptive step size DPM-Solver with a higher order of &lt;code&gt;order&lt;/code&gt;. You can adjust the absolute tolerance &lt;code&gt;atol&lt;/code&gt; and the relative tolerance &lt;code&gt;rtol&lt;/code&gt; to balance the computatation costs (NFE) and the sample quality. For image data, we recommend &lt;code&gt;atol=0.0078&lt;/code&gt; (the default setting).&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 2, we use DPM-Solver-12 which combines DPM-Solver-1 and singlestep DPM-Solver-2.&lt;/li&gt; &#xA; &lt;li&gt;If &lt;code&gt;order&lt;/code&gt; == 3, we use DPM-Solver-23 which combines singlestep DPM-Solver-2 and singlestep DPM-Solver-3.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example, to sample by DPM-Solver-12:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    t_end=1e-4,&#xA;    order=2,&#xA;    method=&#34;adaptive&#34;,&#xA;    rtol=0.05,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h3&gt;3.4. Sampling by Singlestep DPM-Solver-k for k = 1, 2, 3&lt;/h3&gt; &#xA;&lt;p&gt;We use DPM-Solver-&lt;code&gt;order&lt;/code&gt; for &lt;code&gt;order&lt;/code&gt; = 1 or 2 or 3, with total [&lt;code&gt;steps&lt;/code&gt; // &lt;code&gt;order&lt;/code&gt;] * &lt;code&gt;order&lt;/code&gt; NFE.&lt;/p&gt; &#xA;&lt;p&gt;For example, to sample by DPM-Solver-3:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_sample = dpm_solver.sample(&#xA;    x_T,&#xA;    steps=30,&#xA;    order=3,&#xA;    skip_type=&#34;time_uniform&#34;,&#xA;    method=&#34;singlestep_fixed&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;TODO List&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Add stable-diffusion examples.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support Diffusers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Documentation for example code.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Clean and add the JAX code example.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add more explanations about DPM-Solver.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add a small jupyter example.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add VE type noise schedule.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;br&gt; &#xA;&lt;h1&gt;References&lt;/h1&gt; &#xA;&lt;p&gt;If you find the code useful for your research, please consider citing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bib&#34;&gt;@article{lu2022dpm,&#xA;  title={DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps},&#xA;  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},&#xA;  journal={arXiv preprint arXiv:2206.00927},&#xA;  year={2022}&#xA;}&#xA;&#xA;@article{lu2022dpm,&#xA;  title={DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models},&#xA;  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},&#xA;  journal={arXiv preprint arXiv:2211.01095},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>