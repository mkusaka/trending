<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-22T01:27:47Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mhamilton723/FeatUp</title>
    <updated>2024-03-22T01:27:47Z</updated>
    <id>tag:github.com,2024-03-22:/mhamilton723/FeatUp</id>
    <link href="https://github.com/mhamilton723/FeatUp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code for &#34;FeatUp: A Model-Agnostic Frameworkfor Features at Any Resolution&#34; ICLR 2024&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FeatUp: A Model-Agnostic Framework for Features at Any Resolution&lt;/h1&gt; &#xA;&lt;h3&gt;ICLR 2024&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://aka.ms/featup&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/FeatUp-%F0%9F%8C%90Website-purple?style=flat&#34; alt=&#34;Website&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2403.10516&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2403.10516-b31b1b.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/mhamilton723/FeatUp/blob/main/example_usage.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/mhamilton723/FeatUp&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-FeatUp-orange&#34; alt=&#34;Huggingface&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://paperswithcode.com/sota/feature-upsampling-on-imagenet?p=featup-a-model-agnostic-framework-for&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/featup-a-model-agnostic-framework-for/feature-upsampling-on-imagenet&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://stephanie-fu.github.io/&#34;&gt;Stephanie Fu*&lt;/a&gt;, &lt;a href=&#34;https://mhamilton.net/&#34;&gt;Mark Hamilton*&lt;/a&gt;, &lt;a href=&#34;https://people.csail.mit.edu/lebrandt/&#34;&gt;Laura Brandt&lt;/a&gt;, &lt;a href=&#34;https://feldmann.nyc/&#34;&gt;Axel Feldman&lt;/a&gt;, &lt;a href=&#34;https://ztzhang.info/&#34;&gt;Zhoutong Zhang&lt;/a&gt;, &lt;a href=&#34;https://billf.mit.edu/about/bio&#34;&gt;William T. Freeman&lt;/a&gt; *Equal Contribution.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://mhamilton.net/images/website_hero_small-p-1080.jpg&#34; alt=&#34;FeatUp Overview Graphic&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;TL;DR&lt;/em&gt;:FeatUp improves the spatial resolution of any model&#39;s features by 16-32x without changing their semantics.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/mhamilton723/FeatUp/assets/6456637/8fb5aa7f-4514-4a97-aebf-76065163cdfd&#34;&gt;https://github.com/mhamilton723/FeatUp/assets/6456637/8fb5aa7f-4514-4a97-aebf-76065163cdfd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;!--ts--&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#install&#34;&gt;Install&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#using-pretrained-upsamplers&#34;&gt;Using Pretrained Upsamplers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#fitting-an-implicit-upsampler-to-an-image&#34;&gt;Fitting an Implicit Upsampler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/coming-soon&#34;&gt;Coming Soon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#contact&#34;&gt;Contact&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--te--&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;h3&gt;Pip&lt;/h3&gt; &#xA;&lt;p&gt;For those just looking to quickly use the FeatUp APIs install via:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install git+https://github.com/mhamilton723/FeatUp&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Local Development&lt;/h3&gt; &#xA;&lt;p&gt;To install FeatUp for local development and to get access to the sample images install using the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/mhamilton723/FeatUp.git&#xA;cd FeatUp&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using Pretrained Upsamplers&lt;/h2&gt; &#xA;&lt;p&gt;To see examples of pretrained model usage please see our &lt;a href=&#34;https://colab.research.google.com/github/mhamilton723/FeatUp/blob/main/example_usage.ipynb&#34;&gt;Collab notebook&lt;/a&gt;. We currently supply the following pretrained versions of FeatUp&#39;s JBU upsampler:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model Name&lt;/th&gt; &#xA;   &lt;th&gt;Checkpoint&lt;/th&gt; &#xA;   &lt;th&gt;Torch Hub Repository&lt;/th&gt; &#xA;   &lt;th&gt;Torch Hub Name&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DINO&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/pretrained/dino16_jbu_stack_cocostuff.ckpt&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mhamilton723/FeatUp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;dino16&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DINO v2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/pretrained/dinov2_jbu_stack_cocostuff.ckpt&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mhamilton723/FeatUp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;dinov2&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CLIP&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/pretrained/clip_jbu_stack_cocostuff.ckpt&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mhamilton723/FeatUp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;clip&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ViT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/pretrained/vit_jbu_stack_cocostuff.ckpt&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mhamilton723/FeatUp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;vit&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet50&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/pretrained/resnet50_jbu_stack_cocostuff.ckpt&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;mhamilton723/FeatUp&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;code&gt;resnet50&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For example, to load the FeatUp JBU upsampler for the DINO backbone:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;upsampler = torch.hub.load(&#34;mhamilton723/FeatUp&#34;, &#39;dino16&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Fitting an Implicit Upsampler to an Image&lt;/h2&gt; &#xA;&lt;p&gt;To train an implicit upsampler for a given image and backbone first clone the repository and install it for &lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/#local-development&#34;&gt;local development&lt;/a&gt;. Then run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;cd featup&#xA;python train_implicit_upsampler.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Parameters for this training operation can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/mhamilton723/FeatUp/main/featup/configs/implicit_upsampler.yaml&#34;&gt;implicit_upsampler config file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Coming Soon:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Training your own FeatUp joint bilateral upsampler&lt;/li&gt; &#xA; &lt;li&gt;Simple API for Implicit FeatUp training&lt;/li&gt; &#xA; &lt;li&gt;Pretrained JBU models without layer-norms&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{&#xA;    fu2024featup,&#xA;    title={FeatUp: A Model-Agnostic Framework for Features at Any Resolution},&#xA;    author={Stephanie Fu and Mark Hamilton and Laura E. Brandt and Axel Feldmann and Zhoutong Zhang and William T. Freeman},&#xA;    booktitle={The Twelfth International Conference on Learning Representations},&#xA;    year={2024},&#xA;    url={https://openreview.net/forum?id=GkJiNn2QDF}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For feedback, questions, or press inquiries please contact &lt;a href=&#34;mailto:fus@mit.edu&#34;&gt;Stephanie Fu&lt;/a&gt; and &lt;a href=&#34;mailto:markth@mit.edu&#34;&gt;Mark Hamilton&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>srush/Triton-Puzzles</title>
    <updated>2024-03-22T01:27:47Z</updated>
    <id>tag:github.com,2024-03-22:/srush/Triton-Puzzles</id>
    <link href="https://github.com/srush/Triton-Puzzles" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Puzzles for learning Triton&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Triton Puzzles&lt;/h1&gt; &#xA;&lt;p&gt;w/ Tejas Ramesh and &lt;a href=&#34;https://www.jokeren.tech/&#34;&gt;Keren Zhou&lt;/a&gt; based on &lt;a href=&#34;https://github.com/Deep-Learning-Profiling-Tools/triton-viz&#34;&gt;Triton-Viz&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/srush/Triton-Puzzles/blob/main/Triton-Puzzles.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Programming for accelerators such as GPUs is critical for modern AI systems. This often means programming directly in proprietary low-level languages such as CUDA. &lt;a href=&#34;https://github.com/openai/triton/&#34;&gt;Triton&lt;/a&gt; is an alternative open-source language that allows you to code at a higher-level and compile to accelerators like GPU.&lt;/p&gt; &#xA;&lt;p&gt;Coding for Triton is very similar to Numpy and PyTorch in both syntax and semantics. However, as a lower-level language there are a lot of details that you need to keep track of. In particular, one area that learners have trouble with is memory loading and storage which is critical for speed on low-level devices.&lt;/p&gt; &#xA;&lt;p&gt;This set is puzzles is meant to teach you how to use Triton from first principles in an interactive fashion. You will start with trivial examples and build your way up to real algorithms like Flash Attention and Quantized neural networks. These puzzles &lt;strong&gt;do not&lt;/strong&gt; need to run on GPU since they use a Triton interpreter.&lt;/p&gt; &#xA;&lt;p&gt;Discord: &lt;a href=&#34;https://discord.gg/cudamode&#34;&gt;https://discord.gg/cudamode&lt;/a&gt; #triton-puzzles&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/srush/Triton-Puzzles/assets/35882/3e18a47d-1311-43d0-a025-ed1f593f919e&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you are into this kind of thing, this is 7th in a series of these puzzles.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/gpu-puzzles&#34;&gt;https://github.com/srush/gpu-puzzles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/tensor-puzzles&#34;&gt;https://github.com/srush/tensor-puzzles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/autodiff-puzzles&#34;&gt;https://github.com/srush/autodiff-puzzles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/transformer-puzzles&#34;&gt;https://github.com/srush/transformer-puzzles&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/GPTworld&#34;&gt;https://github.com/srush/GPTworld&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/srush/LLM-Training-Puzzles&#34;&gt;https://github.com/srush/LLM-Training-Puzzles&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>