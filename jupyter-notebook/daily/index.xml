<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-25T01:33:09Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>huawei-noah/Efficient-Computing</title>
    <updated>2023-09-25T01:33:09Z</updated>
    <id>tag:github.com,2023-09-25:/huawei-noah/Efficient-Computing</id>
    <link href="https://github.com/huawei-noah/Efficient-Computing" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Efficient computing methods developed by Huawei Noah&#39;s Ark Lab&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Efficient Computing&lt;/h1&gt; &#xA;&lt;p&gt;This repo is a collection of Efficient-Computing methods developed by Huawei Noah&#39;s Ark Lab.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Data-Efficient-Model-Compression&#34;&gt;Data-Efficient-Model-Compression&lt;/a&gt; is a series of compression methods with no or little training data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/BinaryNetworks&#34;&gt;BinaryNetworks&lt;/a&gt;: Binary neural networks including &lt;a href=&#34;https://arxiv.org/abs/2208.08084&#34;&gt;AdaBin (ECCV22)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Distillation&#34;&gt;Distillation&lt;/a&gt;: Knowledge distillation methods including &lt;a href=&#34;https://arxiv.org/pdf/2107.01378.pdf&#34;&gt;ManifoldKD (NeurIPS22)&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2305.15781&#34;&gt;VanillaKD (NeurIPS23)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Pruning&#34;&gt;Pruning&lt;/a&gt;: Network pruning methods including &lt;a href=&#34;https://arxiv.org/abs/1907.10804&#34;&gt;GAN-pruning (ICCV19)&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2010.10732&#34;&gt;SCOP (NeurIPS20)&lt;/a&gt; and &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Manifold_Regularized_Dynamic_Network_Pruning_CVPR_2021_paper.pdf&#34;&gt;ManiDP (CVPR21)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Quantization&#34;&gt;Quantization&lt;/a&gt;: Model quantization methods including &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.html&#34;&gt;DynamicQuant (CVPR22)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Self-supervised&#34;&gt;Self-supervised&lt;/a&gt;: self-supervised learning including &lt;a href=&#34;https://arxiv.org/pdf/2212.06593.pdf&#34;&gt;FastMIM&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2303.05251&#34;&gt;LocalMIM (CVPR23)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/TrainingAcceleration&#34;&gt;TrainingAcceleration&lt;/a&gt;: Accelerating neural network training via &lt;a href=&#34;https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Network_Expansion_for_Practical_Training_Acceleration_CVPR_2023_paper.pdf&#34;&gt;NetworkExpansion (CVPR23)&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huawei-noah/Efficient-Computing/tree/master/Detection&#34;&gt;Detection&lt;/a&gt;: Efficient object detectors including &lt;a href=&#34;https://arxiv.org/abs/2309.11331&#34;&gt;Gold-YOLO (NeurIPS23)&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>