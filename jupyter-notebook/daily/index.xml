<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-09T01:33:57Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yformer/EfficientSAM</title>
    <updated>2023-12-09T01:33:57Z</updated>
    <id>tag:github.com,2023-12-09:/yformer/EfficientSAM</id>
    <link href="https://github.com/yformer/EfficientSAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;EfficientSAM&lt;/h1&gt; &#xA;&lt;p&gt;EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;[Dec.6 2023] EfficientSAM demo is available on the &lt;a href=&#34;https://huggingface.co/spaces/yunyangx/EfficientSAM&#34;&gt;Hugging Face Space&lt;/a&gt; (huge thanks to all the HF team for their support).&lt;/p&gt; &#xA;&lt;p&gt;[Dec.5 2023] We release the torchscript version of EfficientSAM and share a colab.&lt;/p&gt; &#xA;&lt;h2&gt;Online Demo &amp;amp; Examples&lt;/h2&gt; &#xA;&lt;p&gt;Online demo and examples can be found in the &lt;a href=&#34;https://yformer.github.io/efficient-sam/&#34;&gt;project page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;EfficientSAM Instance Segmentation Examples&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Point-prompt&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yformer/EfficientSAM/main/figs/examples/demo_point.png&#34; alt=&#34;point-prompt&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Box-prompt&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yformer/EfficientSAM/main/figs/examples/demo_box.png&#34; alt=&#34;box-prompt&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Segment everything&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yformer/EfficientSAM/main/figs/examples/demo_everything.png&#34; alt=&#34;segment everything&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Saliency&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yformer/EfficientSAM/main/figs/examples/demo_saliency.png&#34; alt=&#34;Saliency&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Model&lt;/h2&gt; &#xA;&lt;p&gt;Models for GPU/CPU are available at the file folder of &lt;a href=&#34;https://huggingface.co/spaces/yunyangx/EfficientSAM/&#34;&gt;Hugging Face Space&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;EfficientSAM-S&lt;/th&gt; &#xA;   &lt;th&gt;EfficientSAM-Ti&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/scl/fi/ziif8xudwbyyphb4tohza/efficientsam_s_gpu.jit?rlkey=8aflq9kf0bfujz5ex4lxuoq56&amp;amp;dl=0&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/scl/fi/lup5s4gthmlv6qf3f5zz3/efficientsam_ti_gpu.jit?rlkey=pap1xktxw50qiaey17no16bqz&amp;amp;dl=0&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can directly use EfficientSAM,&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import torch&#xA;&#xA;efficientsam = torch.jit.load(efficientsam_s_gpu.jit)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Colab&lt;/h2&gt; &#xA;&lt;p&gt;The colab is shared &lt;a href=&#34;https://colab.research.google.com/drive/150dvh_lwbliC3020fWO9qASgy-so6sUZ?usp=sharing&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgement&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/segment-anything&#34;&gt;SAM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ChaoningZhang/MobileSAM&#34;&gt;MobileSAM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CASIA-IVA-Lab/FastSAM&#34;&gt;FastSAM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/xuebinqin/U-2-Net&#34;&gt;U-2-Net&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you&#39;re using EfficientSAM in your research or applications, please cite using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;&#xA;&#xA;@article{xiong2023efficientsam,&#xA;  title={EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything},&#xA;  author={Yunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, Raghuraman Krishnamoorthi, Vikas Chandra},&#xA;  journal={arXiv:2312.00863},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>