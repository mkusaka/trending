<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-02-03T01:31:02Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing</title>
    <updated>2024-02-03T01:31:02Z</updated>
    <id>tag:github.com,2024-02-03:/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing</id>
    <link href="https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLM-PowerHouse: Unleash LLMs&#39; potential through curated tutorials, best practices, and ready-to-use code for custom training and inferencing.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM-PowerHouse: A Curated Guide for Large Language Models with Custom Training and Inferencing&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to LLM-PowerHouse, your ultimate resource for unleashing the full potential of Large Language Models (LLMs) with custom training and inferencing. This GitHub repository is a comprehensive and curated guide designed to empower developers, researchers, and enthusiasts to harness the true capabilities of LLMs and build intelligent applications that push the boundaries of natural language understanding.&lt;/p&gt; &#xA;&lt;h1&gt;Table of contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#in-depth-articles&#34;&gt;In-Depth Articles&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#nlp&#34;&gt;NLP&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#models&#34;&gt;Models&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#training&#34;&gt;Training&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#enhancing-model-compression-inference-and-training-optimization-strategies&#34;&gt;Enhancing Model Compression: Inference and Training Optimization Strategies&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#evaluation-metrics&#34;&gt;Evaluation Metrics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#open-llms&#34;&gt;Open LLMs&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#cost-analysis&#34;&gt;Cost Analysis&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#codebase-mastery-building-with-perfection&#34;&gt;Codebase Mastery: Building with Perfection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#what-i-am-learning&#34;&gt;What I am learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;In-Depth Articles&lt;/h1&gt; &#xA;&lt;h2&gt;NLP&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLMs Overview&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/NLP/LLMs%20Overview&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;NLP Embeddings&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/NLP/NLP%20Embeddings&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sampling&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/Articles/NLP/Sampling&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tokenization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/NLP/Tokenization&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transformer&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/NLP/Transformer/Attention%20Is%20All%20You%20Need&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generative Pre-trained Transformer (GPT)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Models/Generative%20Pre-trained%20Transformer%20(GPT)&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Activation Function&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Activation%20Function&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine Tuning Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Training/Fine%20Tuning%20Models&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Enhancing Model Compression: Inference and Training Optimization Strategies&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Training/Model%20Compression&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model Summary&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Model%20Summary&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Splitting Datasets&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Splitting%20Datasets&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Train Loss &amp;gt; Val Loss&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Train%20Loss%20%3E%20Val%20Loss&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Parameter Efficient Fine-Tuning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Parameter%20Efficient%20Fine-Tuning&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient Descent and Backprop&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Training/Gradient%20Descent%20and%20Backprop&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Overfitting And Underfitting&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Training/Overfitting%20And%20Underfitting&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient Accumulation and Checkpointing&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Training/Gradient%20Accumulation%20and%20Checkpointing&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Flash Attention&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Training/Flash%20Attention&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Enhancing Model Compression: Inference and Training Optimization Strategies&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Quantization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Quantization&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Knowledge Distillation&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Knowledge%20Distillation&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Pruning&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Pruning&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DeepSpeed&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/DeepSpeed&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sharding&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Sharding&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mixed Precision Training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Mixed%20Precision%20Training&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Inference Optimization&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Model%20Compression/Inference%20Optimization&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Evaluation Metrics&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Classification&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Evaluation%20Metrics/Classification&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Regression&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Evaluation%20Metrics/Regression&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generative Text Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/articles/Articles/Evaluation%20Metrics/Generative%20Text%20Models&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Open LLMs&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open Source LLM Space for Commercial Use&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/Commercial%20Use&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Open Source LLM Space for Research Use&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/Research%20Use&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLM Training Frameworks&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/LLM%20Training%20Frameworks&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Effective Deployment Strategies for Language Models&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/Deployment&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Tutorials about LLM&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/Tutorials&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Courses about LLM&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Open%20LLMs/Courses&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Cost Analysis&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Article&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Resources&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lambda Labs vs AWS Cost Analysis&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/Articles/Resources&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Codebase Mastery: Building with Perfection&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Repository&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Instruction based data prepare using OpenAI&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/data_generate_prepare&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Optimal Fine-Tuning using the Trainer API: From Training to Model Inference&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/train_inference&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Efficient Fine-tuning and inference LLMs with PEFT and LoRA&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/train_inference_peft_lora&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Efficient Fine-tuning and inference LLMs Accelerate&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/train_inference_accelerate&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Efficient Fine-tuning with T5&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/t5&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Train Large Language Models with LoRA and Hugging Face&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Efficiently_train_Large_Language_Models_with_LoRA_and_Hugging_Face.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine-Tune Your Own Llama 2 Model in a Colab Notebook&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Guanaco Chatbot Demo with LLaMA-7B Model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Guanaco%20Chatbot%20Demo%20with%20LLaMA-7B%20Model.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PEFT Finetune-Bloom-560m-tagger&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/PEFT%20Finetune-Bloom-560m-tagger.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetune_Meta_OPT-6-1b_Model_bnb_peft&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Finetune_Meta_OPT-6-1b_Model_bnb_peft.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetune Falcon-7b with BNB Self Supervised Training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Finetune%20Falcon-7b%20with%20BNB%20Self%20Supervised%20Training.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;FineTune LLaMa2 with QLoRa&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/FineTune_LLAMA2_with_QLORA.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Stable_Vicuna13B_8bit_in_Colab&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Stable_Vicuna13B_8bit_in_Colab.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-Neo-X-20B-bnb2bit_training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/GPT-neo-x-20B-bnb_4bit_training.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MPT-Instruct-30B Model Training&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/MPT_Instruct_30B.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RLHF_Training_for_CustomDataset_for_AnyModel&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/RLHF_Training_for_CustomDataset_for_AnyModel.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine_tuning_Microsoft_Phi_1_5b_on_custom_dataset(dialogstudio)&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Fine_tuning_Microsoft_Phi_1_5b_on_custom_dataset(dialogstudio).ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetuning OpenAI GPT3.5 Turbo&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Fine_tuning_OpenAI_GPT_3_5_turbo.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Finetuning Mistral-7b FineTuning Model using Autotrain-advanced&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Finetuning_Mistral_7b_Using_AutoTrain.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RAG LangChain Tutorial&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/RAG_LangChain.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral DPO Trainer&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/tree/main/example_codebase/mistral_trainer_dpo&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLM Sharding&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/LLM_Sharding.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Integrating Unstructured and Graph Knowledge with Neo4j and LangChain for Enhanced Question&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/Neo4j_and_LangChain_for_Enhanced_Question_Answering.ipynb&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;vLLM Benchmarking&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/ghimiresunil/LLM-PowerHouse-A-Curated-Guide-for-Large-Language-Models-with-Custom-Training-and-Inferencing/raw/main/example_codebase/Efficiently%20Fine%20Tune%20LLM/vllm_benchmark.py&#34;&gt;üîó&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;What I am learning&lt;/h1&gt; &#xA;&lt;p&gt;After immersing myself in the recent GenAI text-based language model hype for nearly a month, I have made several observations about its performance on my specific tasks.&lt;/p&gt; &#xA;&lt;p&gt;Please note that these observations are subjective and specific to my own experiences, and your conclusions may differ.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We need a minimum of 7B parameter models (&amp;lt;7B) for optimal natural language understanding performance. Models with fewer parameters result in a significant decrease in performance. However, using models with more than 7 billion parameters requires a GPU with greater than 24GB VRAM (&amp;gt;24GB).&lt;/li&gt; &#xA; &lt;li&gt;Benchmarks can be tricky as different LLMs perform better or worse depending on the task. It is crucial to find the model that works best for your specific use case. In my experience, MPT-7B is still the superior choice compared to Falcon-7B.&lt;/li&gt; &#xA; &lt;li&gt;Prompts change with each model iteration. Therefore, multiple reworks are necessary to adapt to these changes. While there are potential solutions, their effectiveness is still being evaluated.&lt;/li&gt; &#xA; &lt;li&gt;For fine-tuning, you need at least one GPU with greater than 24GB VRAM (&amp;gt;24GB). A GPU with 32GB or 40GB VRAM is recommended.&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuning only the last few layers to speed up LLM training/finetuning may not yield satisfactory results. I have tried this approach, but it didn&#39;t work well.&lt;/li&gt; &#xA; &lt;li&gt;Loading 8-bit or 4-bit models can save VRAM. For a 7B model, instead of requiring 16GB, it takes approximately 10GB or less than 6GB, respectively. However, this reduction in VRAM usage comes at the cost of significantly decreased inference speed. It may also result in lower performance in text understanding tasks.&lt;/li&gt; &#xA; &lt;li&gt;Those who are exploring LLM applications for their companies should be aware of licensing considerations. Training a model with another model as a reference and requiring original weights is not advisable for commercial settings.&lt;/li&gt; &#xA; &lt;li&gt;There are three major types of LLMs: basic (like GPT-2/3), chat-enabled, and instruction-enabled. Most of the time, basic models are not usable as they are and require fine-tuning. Chat versions tend to be the best, but they are often not open-source.&lt;/li&gt; &#xA; &lt;li&gt;Not every problem needs to be solved with LLMs. Avoid forcing a solution around LLMs. Similar to the situation with deep reinforcement learning in the past, it is important to find the most appropriate approach.&lt;/li&gt; &#xA; &lt;li&gt;I have tried but didn&#39;t use langchains and vector-dbs. I never needed them. Simple Python, embeddings, and efficient dot product operations worked well for me.&lt;/li&gt; &#xA; &lt;li&gt;LLMs do not need to have complete world knowledge. Humans also don&#39;t possess comprehensive knowledge but can adapt. LLMs only need to know how to utilize the available knowledge. It might be possible to create smaller models by separating the knowledge component.&lt;/li&gt; &#xA; &lt;li&gt;The next wave of innovation might involve simulating &#34;thoughts&#34; before answering, rather than simply predicting one word after another. This approach could lead to significant advancements.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;Contributions are welcome! If you&#39;d like to contribute to this project, feel free to open an issue or submit a pull request.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mv-lab/InstructIR</title>
    <updated>2024-02-03T01:31:02Z</updated>
    <id>tag:github.com,2024-02-03:/mv-lab/InstructIR</id>
    <link href="https://github.com/mv-lab/InstructIR" rel="alternate"></link>
    <summary type="html">&lt;p&gt;InstructIR: High-Quality Image Restoration Following Human Instructions https://huggingface.co/spaces/marcosv/InstructIR&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;InstructIR ‚úèÔ∏èüñºÔ∏è&lt;/h1&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://mv-lab.github.io/InstructIR/&#34;&gt;High-Quality Image Restoration Following Human Instructions&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.16468&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-Paper-%3CCOLOR%3E.svg?sanitize=true&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1OrTvS-i6uLM2Y8kIkq8ZZRwEQxQFchfq?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/marcosv/InstructIR&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue&#34; alt=&#34;Hugging Face&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://replicate.com/mv-lab/instructir&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Demo-%F0%9F%9A%80%20Replicate-blue&#34; alt=&#34;Replicate&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/papers/2401.16468&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/paper-page-sm.svg?sanitize=true&#34; alt=&#34;Paper page&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=NtB1kjYAAAAJ&amp;amp;hl=en&#34;&gt;Marcos V. Conde&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=uIlyqRwAAAAJ&amp;amp;hl=en&#34;&gt;Gregor Geigle&lt;/a&gt;, &lt;a href=&#34;https://scholar.google.com/citations?user=u3MwH5kAAAAJ&amp;amp;hl=en&#34;&gt;Radu Timofte&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Computer Vision Lab, University of Wuerzburg | Sony PlayStation, FTG&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://mv-lab.github.io/InstructIR/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/instructir_teaser.png&#34; alt=&#34;InstructIR&#34; width=&#34;100%&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;TL;DR: quickstart&lt;/h3&gt; &#xA;&lt;p&gt;InstructIR takes as input an image and a human-written instruction for how to improve that image. The neural model performs all-in-one image restoration. InstructIR achieves state-of-the-art results on several restoration tasks including image denoising, deraining, deblurring, dehazing, and (low-light) image enhancement.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;üöÄ You can start with the &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/demo.ipynb&#34;&gt;demo tutorial&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;b&gt; Abstract&lt;/b&gt; (click me to read)&lt;/summary&gt; &#xA; &lt;p&gt; Image restoration is a fundamental problem that involves recovering a high-quality clean image from its degraded observation. All-In-One image restoration models can effectively restore images from various types and levels of degradation using degradation-specific information as prompts to guide the restoration model. In this work, we present the first approach that uses human-written instructions to guide the image restoration model. Given natural language prompts, our model can recover high-quality images from their degraded counterparts, considering multiple degradation types. Our method, InstructIR, achieves state-of-the-art results on several restoration tasks including image denoising, deraining, deblurring, dehazing, and (low-light) image enhancement. InstructIR improves +1dB over previous all-in-one restoration methods. Moreover, our dataset and results represent a novel benchmark for new research on text-guided image restoration and enhancement. &lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;TODO / News üî•&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; &lt;p&gt;Upload all test results for comparisons (ETA 1st Feb)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;&lt;a href=&#34;https://replicate.com/mv-lab/instructir&#34;&gt;Replicate Demo&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;Upload models to HF ü§ó &lt;a href=&#34;https://huggingface.co/marcosv/InstructIR&#34;&gt;(download the models here)&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/marcosv/InstructIR&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm.svg?sanitize=true&#34; alt=&#34;Model on HF&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;ü§ó &lt;a href=&#34;https://huggingface.co/spaces/marcosv/InstructIR&#34;&gt;Hugging Face Demo&lt;/a&gt; try it now &lt;a href=&#34;https://huggingface.co/spaces/marcosv/InstructIR&#34;&gt;&lt;img src=&#34;https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true&#34; alt=&#34;Open in Spaces&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; &lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1OrTvS-i6uLM2Y8kIkq8ZZRwEQxQFchfq?usp=sharing&#34;&gt;Google Colab Tutorial&lt;/a&gt; (check &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/demo.ipynb&#34;&gt;demo.ipynb&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Try it / Tutorial&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/(https://huggingface.co/spaces/marcosv/InstructIR)&#34;&gt;Try it&lt;/a&gt; directly on ü§ó Hugging Face at no cost, no code.&lt;/p&gt; &#xA;&lt;p&gt;üöÄ You can start with the &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/demo.ipynb&#34;&gt;demo tutorial&lt;/a&gt;. We also host the same tutorial on &lt;a href=&#34;https://colab.research.google.com/drive/1OrTvS-i6uLM2Y8kIkq8ZZRwEQxQFchfq?usp=sharing&#34;&gt;google colab&lt;/a&gt; so you can run it using free GPUs!.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://mv-lab.github.io/InstructIR/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/instructir_teaser.gif&#34; alt=&#34;InstructIR App&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://mv-lab.github.io/InstructIR/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/replicate.png&#34; alt=&#34;InstructIR App&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Gradio Demo&lt;/h3&gt; &#xA;&lt;p&gt;We made a simple &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/app.py&#34;&gt;Gradio demo&lt;/a&gt; you can run (locally) on your machine &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/app.py&#34;&gt;here&lt;/a&gt;. You need Python&amp;gt;=3.9 and &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/requirements_gradio.txt&#34;&gt;these requirements&lt;/a&gt; for it: &lt;code&gt;pip install -r requirements_gradio.txt&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;br&gt; &#xA;&lt;a href=&#34;https://huggingface.co/spaces/marcosv/InstructIR&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/gradio.png&#34; alt=&#34;InstructIR Gradio&#34;&gt; &lt;/a&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;You can download the paper results from here. We test InstructIR in the following benchmarks:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Dataset&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Task&lt;/th&gt; &#xA;   &lt;th align=&#34;right&#34;&gt;Test Results&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;BSD68&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Denoising&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Urban100&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Denoising&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Rain100&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deraining&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://seungjunnah.github.io/Datasets/gopro&#34;&gt;GoPro&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Deblurring&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://daooshee.github.io/BMVC2018website/&#34;&gt;LOL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Lol Image Enhancement&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://data.csail.mit.edu/graphics/fivek/&#34;&gt;MIT5K&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Image Enhancement&lt;/td&gt; &#xA;   &lt;td align=&#34;right&#34;&gt;&lt;a href=&#34;&#34;&gt;Download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;TODO: Add download links for all the benchmarks.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/tables/table1.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;br&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;b&gt; Multi-task Results on Dehazing, Deraining, Denoising &lt;/b&gt; &lt;/summary&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/tables/table-3d.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;b&gt; Denoising Results (click to read) &lt;/b&gt; &lt;/summary&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/tables/table-dn.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;b&gt; Low-light Image Enhancement (LOL) Results (click to read) &lt;/b&gt; &lt;/summary&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/tables/table-lol.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;b&gt; Color Image Enhancement (MIT5K) Results (click to read) &lt;/b&gt; &lt;/summary&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/static/tables/table-mit5k.png&#34; width=&#34;100%&#34;&gt; &#xA;&lt;/details&gt; &#xA;&lt;br&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Control and Interact&lt;/h3&gt; &#xA;&lt;p&gt;Sometimes the blur, rain, or film grain noise are pleasant effects and part of the &lt;strong&gt;&#34;aesthetics&#34;&lt;/strong&gt;. Here we show a simple example on how to interact with InstructIR.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Input&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;(1) I love this photo, could you remove the raindrops? please keep the content intact&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;(2) Can you make it look stunning? like a professional photo&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/rain-020.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/result1.png&#34; width=&#34;95%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/result2.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Input&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(1) my image is too dark, I cannot see anything, can you fix it?&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(2) Great it looks nice! can you apply tone mapping?&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/lol_748.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/resultlol1.png&#34; width=&#34;95%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/resultlol2.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Input&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(1) can you remove the tiny dots in the image? it is very unpleasant&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(2) now please inprove the quality and resolution of the picture&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/frog.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/resultns1.png&#34; width=&#34;95%&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/resultns2.png&#34; width=&#34;100%&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;As you can see our model accepts diverse humman-written prompts, from ambiguous to precise instructions. &lt;em&gt;How does it work?&lt;/em&gt; Imagine we have the following image as input:&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/rain-020.png&#34; width=&#34;50%&#34;&gt; &#xA;&lt;p&gt;Now we can use InstructIR. with the following prompt (1):&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;I love this photo, could you remove the raindrops? please keep the content intact&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/result1.png&#34; width=&#34;50%&#34;&gt; &#xA;&lt;p&gt;Now, let&#39;s enhance the image a bit further (2).&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Can you make it look stunning? like a professional photo&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/images/results/result2.png&#34; width=&#34;50%&#34;&gt; &#xA;&lt;p&gt;The final result looks indeed stunning ü§ó You can do it yourself in the &lt;a href=&#34;&#34;&gt;demo tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;FAQS&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Disclaimer: please remember this is not a product, thus, you will notice some limitations. As most all-in-one restoration methods, it struggles to generalize on real-world images -- we are working on improving it.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;How should I start?&lt;/strong&gt;&lt;/em&gt; Check our &lt;a href=&#34;https://raw.githubusercontent.com/mv-lab/InstructIR/main/demo.ipynb&#34;&gt;demo Tutorial&lt;/a&gt; and also our &lt;a href=&#34;https://colab.research.google.com/drive/1OrTvS-i6uLM2Y8kIkq8ZZRwEQxQFchfq?usp=sharing&#34;&gt;google collab&lt;/a&gt; notebook.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;How can I compare with your method?&lt;/strong&gt;&lt;/em&gt; You can download the results for several benchmarks above on &lt;a href=&#34;###Results&#34;&gt;Results&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;How can I test the model? I just want to play with it&lt;/strong&gt;&lt;/em&gt;: Visit our ü§ó &lt;a href=&#34;https://huggingface.co/spaces/marcosv/InstructIR&#34;&gt;Hugging Face demo&lt;/a&gt; and test ir for free,&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Why aren&#39;t you using diffusion-based models?&lt;/strong&gt;&lt;/em&gt; (1) We want to keep the solution simple and efficient. (2) Our priority is high-fidelity --as in many industry scenarios realted to computational photography--.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Acknowledgments&lt;/h3&gt; &#xA;&lt;p&gt;This work was partly supported by the The Humboldt Foundation (AvH). Marcos Conde is also supported by Sony Interactive Entertainment, FTG.&lt;/p&gt; &#xA;&lt;p&gt;This work is inspired in &lt;a href=&#34;https://arxiv.org/abs/2211.09800&#34;&gt;InstructPix2Pix&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Contacts&lt;/h3&gt; &#xA;&lt;p&gt;For any inquiries contact Marcos V. Conde: &lt;a href=&#34;mailto:marcos.conde@uni-wuerzburg.de&#34;&gt;marcos.conde [at] uni-wuerzburg.de&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Citation BibTeX&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{conde2024instructir,&#xA;    title={High-Quality Image Restoration Following Human Instructions}, &#xA;    author={Marcos V. Conde, Gregor Geigle, Radu Timofte},&#xA;    year={2024},&#xA;    journal={arXiv preprint},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>