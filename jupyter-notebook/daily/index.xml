<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-01T01:40:00Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ctlllll/LLM-ToolMaker</title>
    <updated>2023-06-01T01:40:00Z</updated>
    <id>tag:github.com,2023-06-01:/ctlllll/LLM-ToolMaker</id>
    <link href="https://github.com/ctlllll/LLM-ToolMaker" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Large Language Models as Tool Makers&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.17126&#34;&gt;Paper link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Motivation&lt;/h2&gt; &#xA;&lt;p&gt;Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs A s Tool M akers (LATM), where LLMs create their own reusable tools for problem-solving.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the tasks.&lt;/p&gt; &#xA;&lt;!-- ![overview](./imgs/overview.png) width 80% and centered --&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ctlllll/LLM-ToolMaker/main/imgs/overview.png&#34; width=&#34;80%&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;Furthermore, the division of labor among LLMs for tool-making and tool-using phases introduces the opportunity to achieve cost effectiveness without degrading the quality of generated tools and problem solutions. For example, recognizing that tool-making demands more sophisticated capabilities than tool-using, we can apply a powerful yet resource-intensive model as the tool maker, and a lightweight while cost-effective model as the tool user. We validate the effectiveness of our approach across a variety of complex reasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and GPT-3.5 as the tool user, LATM can achieve performance that is on par with using GPT-4 for both tool making and tool using, while the inference cost is significantly reduced.&lt;/p&gt; &#xA;&lt;h2&gt;Pipeline&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ctlllll/LLM-ToolMaker/main/imgs/pipeline.png&#34; width=&#34;80%&#34;&gt; &lt;/p&gt; LATM can be divided into two stages: 1) tool making: a powerful yet more expensive model serves as the tool maker to generate generic and reusable tools from a few demonstrations; 2) tool using: a lightweight and cheaper model serves as the tool user to use the tool to solve various instances of the task. The tool-making stage can be further divided into three sub-stages: (i) tool proposing: the tool maker makes an attempt to generate the tool (Python function) from a few training demonstrations, if the tool is not executable, report the error and generate a new one (fix the issues in the function); (ii) tool verification: the tool maker runs unit tests on validation samples, if the tool does not pass the tests, report the error and generate new tests (fix the issues in function calls in unit tests); and (iii) tool wrapping: wrapping up the function code and the demonstrations of how to convert a question into a function call from unit tests, preparing usable tools for tool user. &#xA;&lt;h2&gt;Example&lt;/h2&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/ctlllll/LLM-ToolMaker/main/imgs/input_example.png&#34; width=&#34;80%&#34;&gt; &lt;/p&gt; An illustration of the Tool Proposing and Tool Using stages of the LATM pipeline for the Logical Deduction task [Srivastava et al., 2022]. This task requires determining the order of five objects based on several given conditions. In the Tool Proposing stage, the tool maker (such as GPT-4) formulates a generic Python function capable of solving the provided k demonstrations from the task (where k equals 3 in our experiments). The tool maker generates a search algorithm that enumerates all possible orderings and verifies each against the provided conditions. During the tool-using stage, the tool user translates each natural language question into a series of conditions, generating function calls to utilize the tool for each task instance. &#xA;&lt;h2&gt;Code structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;schedule_meeting.ipynb -- notebook for constructing the schedule meeting dataset&lt;/li&gt; &#xA; &lt;li&gt;toolmaker.ipynb -- notebook for making tools, the wrapped tools are stored in tools folder and are ready to use&lt;/li&gt; &#xA; &lt;li&gt;tooluser.ipynb -- notebook for testing Tool User and Dispatcher&lt;/li&gt; &#xA; &lt;li&gt;bbh folder -- the tasks from BigBench in json format&lt;/li&gt; &#xA; &lt;li&gt;cot-prompts folder -- the Chain-of-Thought prompts&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{cai2023large,&#xA;  title   = {Large Language Models as Tool Makers},&#xA;  author  = {Tianle Cai and Xuezhi Wang and Tengyu Ma and Xinyun Chen and Denny Zhou},&#xA;  year    = {2023},&#xA;  journal = {arXiv preprint arXiv: 2305.17126}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>CharlieSCC/alpha</title>
    <updated>2023-06-01T01:40:00Z</updated>
    <id>tag:github.com,2023-06-01:/CharlieSCC/alpha</id>
    <link href="https://github.com/CharlieSCC/alpha" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data, Factor, Model and Evaluate&lt;/h1&gt; &#xA;&lt;h3&gt;Attention&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;The LICENSE of the project is GPL3, which means No matter how you modify or use code, you need to open source it.&#xA;&#xA;这个项目的证书是GPL3，意味着无论以何种方式修改或者使用代码，都需要开源。    &#xA;&#xA;Do not close the source after modification. Failure to do so will result in legal liability。&#xA;&#xA;请不要修改后闭源。否则将带来法律上的责任。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Data&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;All data must be BOD. &#xA;For the universe, if it changes at 2014-12, then it is named as xxx-2015.&#xA;FOr the graph, if it uses the 2014-12 finacial report, then it is named as xxx-2015. &#xA;&#xA;--- Ashare_data --- 1day_data   --- pv.h5&#xA;                --- basic_data  --- stock_id.h5&#xA;                                --- trade_dates.h5&#xA;                                --- zz800.h5&#xA;                                --- zz1800.h5&#xA;                --- factor_data --- alphas_101_alpha_001.h5&#xA;                                --- alphas_101_alpha_002.h5&#xA;                --- graph_data  --- adjacent_matrix_2015.h5&#xA;                                --- adjacent_matrix_2016.h5      &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Factor&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;Now we only include pv factor, which is published in alpha 101.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;Recurrent Model:&#xA;- LSTM&#xA;- GRU&#xA;- Transformer&#xA;&#xA;Graph Model&#xA;- LSTM_GCN&#xA;- TGC&#xA;- HATS&#xA;- THGNN&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Evaluate&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;- eval.py:            Basic Metrics for Finacial Prediction &#xA;- backtest.py:        Backtest for Model Signal&#xA;- plot.py:            Plotting&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Xiang Sheng (https://github.com/xiangsheng1325)&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Zhikang Xu (https://github.com/DVINSION)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>cs231n/cs231n.github.io</title>
    <updated>2023-06-01T01:40:00Z</updated>
    <id>tag:github.com,2023-06-01:/cs231n/cs231n.github.io</id>
    <link href="https://github.com/cs231n/cs231n.github.io" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Public facing notes page&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Notes and assignments for Stanford CS class &lt;a href=&#34;http://vision.stanford.edu/teaching/cs231n/&#34;&gt;CS231n: Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>