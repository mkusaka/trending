<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-01T01:38:55Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>chaitjo/geometric-gnn-dojo</title>
    <updated>2023-02-01T01:38:55Z</updated>
    <id>tag:github.com,2023-02-01:/chaitjo/geometric-gnn-dojo</id>
    <link href="https://github.com/chaitjo/geometric-gnn-dojo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Geometric GNN Dojo provides unified implementations and experiments to explore the design space of Geometric Graph Neural Networks.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;‚öîÔ∏è Geometric GNN Dojo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Geometric GNN Dojo&lt;/em&gt; is a pedagogical resource for beginners and experts to explore the design space of &lt;strong&gt;Graph Neural Networks for geometric graphs&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Check out the accompanying paper &lt;a href=&#34;https://www.chaitjo.com/publication/joshi-2022-expressive/&#34;&gt;&#39;On the Expressive Power of Geometric Graph Neural Networks&#39;&lt;/a&gt;, which studies the expressivity and theoretical limits of geometric GNNs.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chaitanya K. Joshi*, Cristian Bodnar*, Simon V. Mathis, Taco Cohen, and Pietro Li√≤. On the Expressive Power of Geometric Graph Neural Networks. &lt;em&gt;NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations.&lt;/em&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://www.chaitjo.com/publication/joshi-2022-expressive/Geometric_WL_preprint.pdf&#34;&gt;PDF&lt;/a&gt; | &lt;a href=&#34;https://www.chaitjo.com/publication/joshi-2022-expressive/Geometric_GNNs_Slides.pdf&#34;&gt;Slides&lt;/a&gt; | &lt;a href=&#34;https://youtu.be/VKj5wzZsoK4&#34;&gt;Video&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;‚ùì&lt;strong&gt;New to geometric GNNs:&lt;/strong&gt; try our practical notebook on &lt;a href=&#34;https://raw.githubusercontent.com/chaitjo/geometric-gnn-dojo/main/geometric_gnn_101.ipynb&#34;&gt;&lt;em&gt;Geometric GNNs 101&lt;/em&gt;&lt;/a&gt;, prepared for MPhil students at the University of Cambridge.&lt;/p&gt; &#xA;&lt;h2&gt;Architectures&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;/src&lt;/code&gt; directory provides unified implementations of several popular geometric GNN architectures:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Invariant GNNs: &lt;a href=&#34;https://arxiv.org/abs/1706.08566&#34;&gt;SchNet&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2003.03123&#34;&gt;DimeNet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Equivariant GNNs using cartesian vectors: &lt;a href=&#34;https://proceedings.mlr.press/v139/satorras21a.html&#34;&gt;E(n) Equivariant GNN&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2009.01411&#34;&gt;GVP-GNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Equivariant GNNs using spherical tensors: &lt;a href=&#34;https://arxiv.org/abs/1802.08219&#34;&gt;Tensor Field Network&lt;/a&gt;, &lt;a href=&#34;http://arxiv.org/abs/2206.07697&#34;&gt;MACE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üî• Your new geometric GNN architecture?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;figure&gt;&#xA; &lt;center&gt;&#xA;  &lt;img src=&#34;https://raw.githubusercontent.com/chaitjo/geometric-gnn-dojo/main/experiments/fig/axes-of-expressivity.png&#34; width=&#34;70%&#34;&gt;&#xA; &lt;/center&gt;&#xA;&lt;/figure&gt; &#xA;&lt;h2&gt;Experiments&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;code&gt;/experiments&lt;/code&gt; directory contains notebooks with synthetic experiments to highlight practical challenges in building powerful geometric GNNs:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;kchains.ipynb&lt;/code&gt;: Distinguishing k-chains, which test a model&#39;s ability to &lt;strong&gt;propagate geometric information&lt;/strong&gt; non-locally and demonstrate oversquashing with increased depth.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;rotsym.ipynb&lt;/code&gt;: Rotationally symmetric structures, which test a layer&#39;s ability to &lt;strong&gt;identify neighbourhood orientation&lt;/strong&gt; and highlight the utility of higher order tensors in equivariant GNNs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;incompleteness.ipynb&lt;/code&gt;: Counterexamples from &lt;a href=&#34;https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.166001&#34;&gt;Pozdnyakov et al.&lt;/a&gt;, which test a layer&#39;s ability to create &lt;strong&gt;distinguishing fingerprints for local neighbourhoods&lt;/strong&gt; and highlight the need for higher order scalarisation.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Create new conda environment&#xA;conda create -n pyg python=3.8&#xA;conda activate pyg&#xA;&#xA;# Install PyTorch (Check CUDA version!)&#xA;conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch&#xA;&#xA;# Install PyG&#xA;conda install pyg -c pyg -c conda-forge&#xA;&#xA;# Install other dependencies&#xA;pip3 install e3nn==0.4.4&#xA;conda install matplotlib pandas networkx&#xA;pip3 install ipdb ase&#xA;conda install jupyterlab -c conda-forge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Directory Structure and Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;.&#xA;‚îú‚îÄ‚îÄ README.md&#xA;|&#xA;‚îú‚îÄ‚îÄ geometric_gnn_101.ipynb             # A gentle introduction to Geometric GNNs&#xA;| &#xA;‚îú‚îÄ‚îÄ experiments                         # Synthetic experiments&#xA;‚îÇ   ‚îú‚îÄ‚îÄ incompleteness.ipynb            # Experiment on counterexamples from Pozdnyakov et al.&#xA;‚îÇ   ‚îú‚îÄ‚îÄ kchains.ipynb                   # Experiment on k-chains&#xA;‚îÇ   ‚îî‚îÄ‚îÄ rotsym.ipynb                    # Experiment on rotationally symmetric structures&#xA;| &#xA;‚îî‚îÄ‚îÄ src                                 # Geometric GNN models library&#xA;    ‚îú‚îÄ‚îÄ models.py                       # Models built using layers&#xA;    ‚îú‚îÄ‚îÄ gvp_layers.py                   # Layers for GVP-GNN&#xA;    ‚îú‚îÄ‚îÄ egnn_layers.py                  # Layers for E(n) Equivariant GNN&#xA;    ‚îú‚îÄ‚îÄ tfn_layers.py                   # Layers for Tensor Field Networks&#xA;    ‚îú‚îÄ‚îÄ modules                         # Layers for MACE&#xA;    ‚îî‚îÄ‚îÄ utils                           # Helper functions for training, plotting, etc.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{joshi2022expressive,&#xA;  title={On the Expressive Power of Geometric Graph Neural Networks},&#xA;  author={Joshi, Chaitanya K. and Bodnar, Cristian and  Mathis, Simon V. and Cohen, Taco and Li√≤, Pietro},&#xA;  journal={NeurIPS Workshop on Symmetry and Geometry in Neural Representations},&#xA;  year={2022},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>branhoff/python_class_101</title>
    <updated>2023-02-01T01:38:55Z</updated>
    <id>tag:github.com,2023-02-01:/branhoff/python_class_101</id>
    <link href="https://github.com/branhoff/python_class_101" rel="alternate"></link>
    <summary type="html">&lt;p&gt;open source intro to programming class&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;python_class_101&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to this programming course! In this course, we will be introducing the basics of programming using the Python language. Python is a powerful and versatile programming language that is widely used in a variety of fields, such as web development, scientific computing, data analysis, and artificial intelligence. One of the reasons why Python is so popular is because it is easy to read and write, and its syntax is simple and consistent.&lt;/p&gt; &#xA;&lt;p&gt;Throughout this course, we will be focusing on the fundamental concepts of programming rather than the specific syntax of the Python language. This means that we will &lt;strong&gt;NOT&lt;/strong&gt; be teaching you the most optimal or efficient way to write Python code, but rather the basic concepts that you need to know in order to understand and write your own programs.&lt;/p&gt; &#xA;&lt;p&gt;You will learn how to use variables, control flow structures, loops, functions, Object Oriented programming, and how to work with data structures like lists and dictionaries. By the end of this course, you will have a solid understanding of the basic concepts of programming and will be able to write your own simple programs using Python and be able to take these general concepts to learn other programming languages as well.&lt;/p&gt; &#xA;&lt;p&gt;So, let&#39;s get started!&lt;/p&gt; &#xA;&lt;p&gt;This project/course consists of two major components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Jupyter Notebooks outlining essential concepts in programming. These are stored in the &lt;code&gt;01-lesson_notebooks&lt;/code&gt; directory.&lt;/li&gt; &#xA; &lt;li&gt;A corresponding larger project exercise, intended to be built in an IDE (program assumes VS Code), is also included in the &lt;code&gt;02-IDE_excecises folder&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How to use the materials&lt;/h2&gt; &#xA;&lt;p&gt;Lesson notebooks are arranged by topic denoted with a lesson number like &lt;code&gt;01a-...&lt;/code&gt;, &lt;code&gt;03b-...&lt;/code&gt;, or &lt;code&gt;09c-...&lt;/code&gt; . Each notebook contains explanations and examples of the programming principle/concept for that section. Lesson notebooks have simple exercises that you can work out directly in the notebook itself.&lt;/p&gt; &#xA;&lt;p&gt;Each lesson set has a corresponding &#34;IDE Exercise&#34; with the same lesson number that relates to the set of notebooks i.e. &lt;code&gt;01-...&lt;/code&gt;, &lt;code&gt;02a-...&lt;/code&gt;, &lt;code&gt;10-...&lt;/code&gt;, etc. These are projects with a larger scope that you should practice building within in your IDE. I&#39;m generally assuming you&#39;re using VS Code as your IDE in the included notes. Each project folder has a &lt;code&gt;README&lt;/code&gt;, included with the project exercise description.&lt;/p&gt; &#xA;&lt;h2&gt;How to get started&lt;/h2&gt; &#xA;&lt;p&gt;Navigate to the &lt;a href=&#34;https://raw.githubusercontent.com/branhoff/python_class_101/main/01-lesson_notebooks/01a-Tools_You_Will_Need.ipynb&#34;&gt;01-lesson_notebooks/01a-Tools_You_Will_Need.ipynb&lt;/a&gt; and beginning downloading the various tools. You can then checkout &lt;a href=&#34;https://raw.githubusercontent.com/branhoff/python_class_101/main/01-lesson_notebooks/01b-Some_Context.ipynb&#34;&gt;01-lesson_notebooks/01b-Some_Context.ipynb&lt;/a&gt; to get an understanding of the basics and WHY we downloaded the tools we did.&lt;/p&gt; &#xA;&lt;h2&gt;How you can help&lt;/h2&gt; &#xA;&lt;p&gt;There are many ways that people can help contribute to your project. One of the most important ways is by expanding on the explanations and descriptions provided in the project. This can include adding more detailed information and examples, creating diagrams and images to help illustrate key concepts, and providing additional resources and materials for users to reference.&lt;/p&gt; &#xA;&lt;p&gt;Another way that people can help contribute to your project is by adding project exercises and challenges. These can include coding challenges, quizzes, and other interactive activities that help users test their understanding of the concepts covered in the project.&lt;/p&gt; &#xA;&lt;p&gt;Another way to help is to proofreading and spell checking the project for any errors or typos. This will ensure that the project is easy to read and understand for users of all levels.&lt;/p&gt; &#xA;&lt;p&gt;Finally, adding unit tests for users to test their program is a great way to ensure that the program is working correctly and that users are able to understand the concepts covered in the project.&lt;/p&gt; &#xA;&lt;p&gt;Overall, there are many ways that people can help contribute to your project and make it a valuable resource for users. By working together and leveraging the skills and expertise of a diverse group of contributors, you can create a high-quality and effective project that helps users learn and grow.&lt;/p&gt; &#xA;&lt;h2&gt;TODO:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Update Variable and Assignment Modules to teach and require type hinting&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add exercise to count occurence of vowels in string&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add exercise to count occurence of set of strings in total strings&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add exercise that prints the longest substring of string s in which letters occur in alphabetical order&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Finish 7b presentation...&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Finish 7b Notes by adding the pictures&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Add tests for IDE project solutions&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Update embedded images in Jupyter notebooks. &lt;a href=&#34;https://stackoverflow.com/questions/32370281/how-to-embed-image-or-picture-in-jupyter-notebook-either-from-a-local-machine-o&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking</title>
    <updated>2023-02-01T01:38:55Z</updated>
    <id>tag:github.com,2023-02-01:/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking</id>
    <link href="https://github.com/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking" rel="alternate"></link>
    <summary type="html">&lt;p&gt;YOLOv8 Segmentation with DeepSORT Object Tracking (ID + Trails)&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; YOLOv8 Segmentation with DeepSORT Object Tracking(ID + Trails) &lt;/h1&gt; &#xA;&lt;h2&gt;Google Colab File Link (A Single Click Solution)&lt;/h2&gt; &#xA;&lt;p&gt;The google colab file link for yolov8 segmentation and tracking is provided below, you can check the implementation in Google Colab, and its a single click implementation ,you just need to select the Run Time as GPU, and click on Run All.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1wRkrquf_HMV7tyKy2zDAuqqK9G4zZub5?usp=sharing&#34;&gt;&lt;code&gt;Google Colab File&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;YouTube Video Tutorial Link&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0JIPNk21ivU&#34;&gt;&lt;code&gt;YouTube Link&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;YOLOv8 with DeepSORT Object Tracking&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/MuhammadMoinFaisal/YOLOv8-DeepSORT-Object-Tracking.git&#34;&gt;&lt;code&gt;Github Repo Link&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Object Segmentation and Tracking (ID + Trails) using YOLOv8 on Custom Data&lt;/h2&gt; &#xA;&lt;h2&gt;Google Colab File Link (A Single Click Solution)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1cnr9Jjj5Pag5myK6Ny8v5gtHgOqf6uoF?usp=sharing&#34;&gt;&lt;code&gt;Google Colab File&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;YouTube Video Tutorial Link&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=e-uzr2Sm0DA&#34;&gt;&lt;code&gt;YouTube Link&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Steps to run Code&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Clone the repository&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Goto the cloned folder.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd YOLOv8_Segmentation_DeepSORT_Object_Tracking&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install the Dependencies&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -e &#39;.[dev]&#39;&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Setting the Directory.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ultralytics/yolo/v8/segment&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Downloading the DeepSORT Files From The Google Drive&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;https://drive.google.com/drive/folders/1kna8eWGrSfzaR6DtNJ8_GchGgPMv3VC8?usp=sharing&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;After downloading the DeepSORT Zip file from the drive, unzip it go into the subfolders and place the deep_sort_pytorch folder into the ultralytics/yolo/v8/segment folder&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Downloading a Sample Videos from the Google Drive&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Demo Video 1&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;gdown &#34;https://drive.google.com/uc?id=19P9Cf9UiJ9gU9KHnAfud6hrFOgobETTX&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Demo Video 2&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;gdown &#34;https://drive.google.com/uc?id=1rjBn8Fl1E_9d0EMVtL24S9aNQOJAveR5&amp;amp;confirm=t&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Demo Video 3&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;gdown &#34;https://drive.google.com/uc?id=1aL0XIoOQlHf9FBvUx3FMfmPbmRu0-rF-&amp;amp;confirm=t&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Run the code with mentioned command below.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;For yolov8 segmentation + Tracking&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python predict.py model=yolov8x-seg.pt source=&#34;test1.mp4&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;RESULTS&lt;/h3&gt; &#xA;&lt;h4&gt;Object Segmentation and DeepSORT Tracking (ID + Trails) and Vehicles Counting&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking/main/ultralytics/figure_speed.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Object Segmentation and DeepSORT Tracking (ID + Trails)&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking/main/ultralytics/figure2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Watch the Complete Step by Step Explanation&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Video Tutorial Link &lt;a href=&#34;https://www.youtube.com/watch?v=0JIPNk21ivU&#34;&gt;&lt;code&gt;YouTube Link&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MuhammadMoinFaisal/YOLOv8_Segmentation_DeepSORT_Object_Tracking/main/%5Bhttps://www.youtube.com/watch?v=0JIPNk21ivU&amp;amp;t=244s%5D(https://www.youtube.com/watch?v=0JIPNk21ivU)&#34;&gt;&lt;img src=&#34;https://img.youtube.com/vi/0JIPNk21ivU/0.jpg&#34; alt=&#34;Watch the Complete Tutorial for the Step by Step Explanation&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ultralytics/ultralytics&#34;&gt;https://github.com/ultralytics/ultralytics&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>