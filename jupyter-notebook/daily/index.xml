<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-08T01:35:41Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>jxnl/instructor</title>
    <updated>2023-12-08T01:35:41Z</updated>
    <id>tag:github.com,2023-12-08:/jxnl/instructor</id>
    <link href="https://github.com/jxnl/instructor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;openai function calls for humans&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Instructor - Your Gateway to Structured Outputs with OpenAI&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Structured extraction in Python, powered by OpenAI&#39;s function calling api, designed for simplicity, transparency, and control.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.github.com/jxnl/instructor&#34;&gt;Star us on Github!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pydantic.dev&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json&#34; alt=&#34;Pydantic v2&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.python.org/pypi/instructor&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/instructor.svg?sanitize=true&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/jxnl/instructor/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/jxnl/instructor.svg?sanitize=true&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jxnl.github.io/instructor&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-available-brightgreen&#34; alt=&#34;Documentation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/jxnlco&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/jxnlco?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://coveralls.io/github/jxnl/instructor?branch=add-coveralls&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/github/jxnl/instructor/badge.svg?branch=add-coveralls&#34; alt=&#34;Coverage Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://jxnl.github.io/instructor/blog/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/instructor-blog-blue&#34; alt=&#34;Instructor&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Dive into the world of Python-based structured extraction, empowered by OpenAI&#39;s cutting-edge function calling API. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you&#39;re a seasoned developer or just starting out, you&#39;ll find Instructor&#39;s approach intuitive and its results insightful.&lt;/p&gt; &#xA;&lt;h2&gt;Get Started in Moments&lt;/h2&gt; &#xA;&lt;p&gt;Installing Instructor is a breeze. Just run &lt;code&gt;pip install instructor&lt;/code&gt; in your terminal and you&#39;re on your way to a smoother data handling experience.&lt;/p&gt; &#xA;&lt;h2&gt;How Instructor Enhances Your Workflow&lt;/h2&gt; &#xA;&lt;p&gt;Our &lt;code&gt;instructor.patch&lt;/code&gt; for the &lt;code&gt;OpenAI&lt;/code&gt; class introduces three key enhancements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Response Mode:&lt;/strong&gt; Specify a Pydantic model to streamline data extraction.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Max Retries:&lt;/strong&gt; Set your desired number of retry attempts for requests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Validation Context:&lt;/strong&gt; Provide a context object for enhanced validator access. A Glimpse into Instructor&#39;s Capabilities&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;!!! note &#34;Using Validators&#34;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Learn more about validators checkout our blog post [Good llm validation is just good validation](https://jxnl.github.io/instructor/blog/2023/10/23/good-llm-validation-is-just-good-validation/)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With Instructor, your code becomes more efficient and readable. Here’s a quick peek:&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import instructor&#xA;from openai import OpenAI&#xA;from pydantic import BaseModel&#xA;&#xA;# Enables `response_model`&#xA;client = instructor.patch(OpenAI())&#xA;&#xA;class UserDetail(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;user = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetail,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract Jason is 25 years old&#34;},&#xA;    ]&#xA;)&#xA;&#xA;assert isinstance(user, UserDetail)&#xA;assert user.name == &#34;Jason&#34;&#xA;assert user.age == 25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Using &lt;code&gt;openai&amp;lt;1.0.0&lt;/code&gt;&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;re using &lt;code&gt;openai&amp;lt;1.0.0&lt;/code&gt; then make sure you &lt;code&gt;pip install instructor&amp;lt;0.3.0&lt;/code&gt; where you can patch a global client like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;import instructor&#xA;&#xA;instructor.patch()&#xA;&#xA;user = openai.ChatCompletion.create(&#xA;    ...,&#xA;    response_model=UserDetail,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Using async clients&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;For async clients you must use apatch vs patch like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;import instructor&#xA;from openai import AsyncOpenAI&#xA;from pydantic import BaseModel&#xA;&#xA;aclient = instructor.apatch(AsyncOpenAI())&#xA;&#xA;class UserExtract(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;model = await aclient.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserExtract,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract jason is 25 years old&#34;},&#xA;    ],&#xA;)&#xA;&#xA;assert isinstance(model, UserExtract)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 1: Patch the client&lt;/h3&gt; &#xA;&lt;p&gt;First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import instructor&#xA;from openai import OpenAI&#xA;from pydantic import BaseModel&#xA;&#xA;# This enables response_model keyword&#xA;# from client.chat.completions.create&#xA;client = instructor.patch(OpenAI())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Define the Pydantic Model&lt;/h3&gt; &#xA;&lt;p&gt;Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel&#xA;&#xA;class UserDetail(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 3: Extract&lt;/h3&gt; &#xA;&lt;p&gt;Use the &lt;code&gt;client.chat.completions.create&lt;/code&gt; method to send a prompt and extract the data into the Pydantic object. The response_model parameter specifies the Pydantic model to use for extraction. Its helpful to annotate the variable with the type of the response model. which will help your IDE provide autocomplete and spell check.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;user: UserDetail = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetail,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract Jason is 25 years old&#34;},&#xA;    ]&#xA;)&#xA;&#xA;assert user.name == &#34;Jason&#34;&#xA;assert user.age == 25&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pydantic Validation&lt;/h2&gt; &#xA;&lt;p&gt;Validation can also be plugged into the same Pydantic model. Here, if the answer attribute contains content that violates the rule &#34;don&#39;t say objectionable things,&#34; Pydantic will raise a validation error.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pydantic import BaseModel, ValidationError, BeforeValidator&#xA;from typing_extensions import Annotated&#xA;from instructor import llm_validator&#xA;&#xA;class QuestionAnswer(BaseModel):&#xA;    question: str&#xA;    answer: Annotated[&#xA;        str,&#xA;        BeforeValidator(llm_validator(&#34;don&#39;t say objectionable things&#34;))&#xA;    ]&#xA;&#xA;try:&#xA;    qa = QuestionAnswer(&#xA;        question=&#34;What is the meaning of life?&#34;,&#xA;        answer=&#34;The meaning of life is to be evil and steal&#34;,&#xA;    )&#xA;except ValidationError as e:&#xA;    print(e)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Its important to not here that the error message is generated by the LLM, not the code, so it&#39;ll be helpful for re asking the model.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-plaintext&#34;&gt;1 validation error for QuestionAnswer&#xA;answer&#xA;   Assertion failed, The statement is objectionable. (type=assertion_error)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Reask on validation error&lt;/h2&gt; &#xA;&lt;p&gt;Here, the &lt;code&gt;UserDetails&lt;/code&gt; model is passed as the &lt;code&gt;response_model&lt;/code&gt;, and &lt;code&gt;max_retries&lt;/code&gt; is set to 2.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import instructor&#xA;&#xA;from openai import OpenAI&#xA;from pydantic import BaseModel, field_validator&#xA;&#xA;# Apply the patch to the OpenAI client&#xA;client = instructor.patch(OpenAI())&#xA;&#xA;class UserDetails(BaseModel):&#xA;    name: str&#xA;    age: int&#xA;&#xA;    @field_validator(&#34;name&#34;)&#xA;    @classmethod&#xA;    def validate_name(cls, v):&#xA;        if v.upper() != v:&#xA;            raise ValueError(&#34;Name must be in uppercase.&#34;)&#xA;        return v&#xA;&#xA;model = client.chat.completions.create(&#xA;    model=&#34;gpt-3.5-turbo&#34;,&#xA;    response_model=UserDetails,&#xA;    max_retries=2,&#xA;    messages=[&#xA;        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Extract jason is 25 years old&#34;},&#xA;    ],&#xA;)&#xA;&#xA;assert model.name == &#34;JASON&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/jxnl/instructor/tree/main/tests/openai/evals&#34;&gt;Evals&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;We invite you to contribute evals in pytest as a way to monitor the quality of the openai models and the instructor library. To get started check out the &lt;a href=&#34;https://github.com/jxnl/instructor/tree/main/tests/openai/evals&#34;&gt;jxnl/instructor/tests/evals&lt;/a&gt; and contribute your own evals in the form of pytest tests. These evals will be run once a week and the results will be posted.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you want to help out checkout some of the issues marked as &lt;code&gt;good-first-issue&lt;/code&gt; or &lt;code&gt;help-wanted&lt;/code&gt;. Found &lt;a href=&#34;https://github.com/jxnl/instructor/labels/good%20first%20issue&#34;&gt;here&lt;/a&gt;. They could be anything from code improvements, a guest blog post, or a new cook book.&lt;/p&gt; &#xA;&lt;h2&gt;CLI&lt;/h2&gt; &#xA;&lt;p&gt;We also provide some added CLI functionality for easy convinience&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;instructor jobs&lt;/code&gt; : This helps with the creation of fine-tuning jobs with OpenAI. Simple use &lt;code&gt;instructor jobs create-from-file --help&lt;/code&gt; to get started creating your first fine-tuned GPT3.5 model&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;instructor files&lt;/code&gt; : Manage your uploaded files with ease. You&#39;ll be able to create, delete and upload files all from the command line&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;instructor usage&lt;/code&gt; : Instead of heading to the OpenAI site each time, you can monitor your usage from the cli and filter by date and time period. Note that usage often takes ~5-10 minutes to update from OpenAI&#39;s side&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT License.&lt;/p&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; &#xA;&lt;!-- prettier-ignore-start --&gt; &#xA;&lt;!-- markdownlint-disable --&gt; &#xA;&lt;!-- markdownlint-restore --&gt; &#xA;&lt;!-- prettier-ignore-end --&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; &#xA;&lt;a href=&#34;https://github.com/jxnl/instructor/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=jxnl/instructor&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>seculayer/AutoAPE-challenge1</title>
    <updated>2023-12-08T01:35:41Z</updated>
    <id>tag:github.com,2023-12-08:/seculayer/AutoAPE-challenge1</id>
    <link href="https://github.com/seculayer/AutoAPE-challenge1" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Kaggle Challenge History&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kaggle&lt;/h1&gt; &#xA;&lt;p&gt;Kaggle Challenge History&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>seculayer/AutoAPE-challenge2</title>
    <updated>2023-12-08T01:35:41Z</updated>
    <id>tag:github.com,2023-12-08:/seculayer/AutoAPE-challenge2</id>
    <link href="https://github.com/seculayer/AutoAPE-challenge2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Kaggle 2차년도(2021)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Competitions 2&lt;/h1&gt; &#xA;&lt;p&gt;Competitions 2차년도(2021)&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/seculayer/AutoAPE-challenge2/main/#kaggle-%EA%B5%AC%EC%A1%B0&#34;&gt;kaggle&lt;/a&gt;/dacon 안에 구조를 맞추어서, 참가한 대회 내용을 작성합니다.&lt;/li&gt; &#xA; &lt;li&gt;Pull Request를 작성합니다.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Kaggle 구조&lt;/h2&gt; &#xA;&lt;p&gt;Kaggle 폴더 구조입니다.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;kaggle/&#xA;├── titanic/ # 예시 대회&#xA;│  ├── metadata.yaml&#xA;│  ├── README.md&#xA;│  └── *&#xA;└── {kaggle-competition-id}/&#xA;   ├── metadata.yaml&#xA;   ├── README.md&#xA;   └── *&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Kaggle 대회 ID로 폴더를 생성합니다.&lt;/p&gt; &lt;p&gt;Kaggle 대회 ID는 URL에서 찾을 수 있습니다.&lt;/p&gt; &lt;p&gt;예시 - kaggle 대회 URL이 &lt;code&gt;https://www.kaggle.com/c/acea-water-prediction&lt;/code&gt;이면, &lt;code&gt;acea-water-prediction&lt;/code&gt; 부분이 대회 ID입니다.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;metadata.yaml&lt;/code&gt;과 &lt;code&gt;README.md&lt;/code&gt;를 작성합니다.&lt;/p&gt; &lt;p&gt;metadata에는 아래와 같은 내용들이 있어야합니다.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: 2&#xA;id: kaggle-competition-id&#xA;score: 캐글 대회 점수&#xA;teams: 참가한 총 팀 수&#xA;rank: 등수&#xA;date: 대회에 제출한 날짜&#xA;organization:&#xA;team:&#xA;  name: 팀 이름&#xA;  members:&#xA;    - id: Kaggle ID&#xA;      name: 이름&#xA;    - id: Kaggle ID&#xA;      name: 이름&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;팀 참여 예시.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: 2&#xA;id: titanic&#xA;score: 0.817&#xA;teams: 1000&#xA;rank: 100&#xA;date: 2021-05-20&#xA;organization: Hanyang University&#xA;team:&#xA;  name: &#34;Team Example&#34;&#xA;  members:&#xA;    - id: User1&#xA;      name: Jone&#xA;    - id: User2&#xA;      name: 홍길동&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;개인 참여 예시&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;version: 2&#xA;id: titanic&#xA;score: 0.817&#xA;teams: 1000&#xA;rank: 100&#xA;date: 2021-05-20&#xA;organization: SecuLayer&#xA;team:&#xA;  name: User1&#xA;  members:&#xA;    - id: User1&#xA;      name: Jone&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;README.md&lt;/code&gt;에는 다음과 같은 내용이 있어야 합니다.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;결과 요약&lt;/li&gt; &#xA;   &lt;li&gt;리더보드 이미지 &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;대회 점수 이미지&lt;/li&gt; &#xA;     &lt;li&gt;등수 이미지&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;알고리즘, 문제 해결 방법&lt;/li&gt; &#xA;   &lt;li&gt;팀 참여 시 역할 및 기여도&lt;/li&gt; &#xA;   &lt;li&gt;참고 자료&lt;/li&gt; &#xA;   &lt;li&gt;기타&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;작성했던 코드들을 생성했던 폴더에 넣습니다.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;colab, jupyter 등을 사용했다면 &lt;code&gt;ipynb&lt;/code&gt;을 그대로 올려도 됩니다.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Commit 하기&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;팀 참여 시 commit 본문에 마지막에 &lt;code&gt;Co-authored-by: name &amp;lt;name@example.com&amp;gt;&lt;/code&gt;를 추가하면, 한 커밋에 여러 작성자를 추가할 수 있습니다.&lt;/li&gt; &#xA;   &lt;li&gt;팀 참여 &lt;code&gt;git commit&lt;/code&gt; 커맨드 예제&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt; git commit -m &#34;Refactor usability tests.&#xA;&amp;gt;&#xA;&amp;gt;&#xA;Co-authored-by: name &amp;lt;name@example.com&amp;gt;&#xA;Co-authored-by: another-name &amp;lt;another-name@example.com&amp;gt;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;참고자료 : &lt;a href=&#34;https://docs.github.com/en/github/committing-changes-to-your-project/creating-and-editing-commits/creating-a-commit-with-multiple-authors&#34;&gt;Creating a commit with multiple authors&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;참고&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yaml.org/&#34;&gt;YAML&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://ko.wikipedia.org/wiki/YAML&#34;&gt;YAML - 위키백과&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://git-scm.com/book/ko/v2/GitHub-GitHub-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EC%97%90-%EA%B8%B0%EC%97%AC%ED%95%98%EA%B8%B0&#34;&gt;Pro Git: 6.2 GitHub - GitHub 프로젝트에 기여하기&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>