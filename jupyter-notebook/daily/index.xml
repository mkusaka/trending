<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-02T01:34:40Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>bharathsudharsan/TinyML-CAM</title>
    <updated>2022-11-02T01:34:40Z</updated>
    <id>tag:github.com,2022-11-02:/bharathsudharsan/TinyML-CAM</id>
    <link href="https://github.com/bharathsudharsan/TinyML-CAM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code for MobiCom&#39;22 paper &#39;TinyML-CAM: 80 FPS Image Recognition in 1 Kb RAM&#39;&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;TinyML-CAM - Image Recognition System that Runs at 80 FPS in 1 Kb RAM&lt;/h2&gt; &#xA;&lt;h3&gt;Demo - HOG and Random Forest based Image Recognition on ESP32&lt;/h3&gt; &#xA;&lt;p&gt;ESP32 classifying Raspberry Pi Pico, Portenta H7, Wio Terminal from image frames&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/16524846/179447640-d7f5efa9-3a44-431c-922d-348ee526c782.mp4&#34;&gt;https://user-images.githubusercontent.com/16524846/179447640-d7f5efa9-3a44-431c-922d-348ee526c782.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Results&lt;/h3&gt; &#xA;&lt;p&gt;Following can be observed from the video:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Time.&lt;/strong&gt; For image frames, the digital signal processing (DSP) based features extraction time is ‚âà 12 ms, while classification time is ‚âà &amp;lt; 20 ùúáùë† (1/1000&lt;sup&gt;th&lt;/sup&gt; of DSP).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;FPS.&lt;/strong&gt; It is 1000/12 ms = 83.3 FPS, which is the time taken by the TinyML-CAM system for HOG features extraction (using DSP) plus classification. Since the ESP32 has a 30 FPS frame rate, just to capture frames, it takes 1000/30 = 33 ms. Since the DSP plus classification time is only ‚âà 12 ms, the image recognition happens in real-time between two consecutive frames, thus not altering the ESP32 camera&#39;s FPS.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Accuracy.&lt;/strong&gt; As expected during Pairplot analysis, Portenta and Pi (features overlapped) are mislabelled quite often, which can be rectified by improving dataset quality.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Memory.&lt;/strong&gt; Consumes only 1 kB of RAM - difference between the RAM calculated by Arduino IDE before and after adding the TinyML-CAM image recognition system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Paper&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/3495243.3558264&#34;&gt;https://dl.acm.org/doi/pdf/10.1145/3495243.3558264&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To capture images from the ESP32 with ease, install Eloquent library via Arduino IDE library manager.&lt;/li&gt; &#xA; &lt;li&gt;To collect images on a PC and train an ML classifier, install EverywhereML Python package.&lt;/li&gt; &#xA; &lt;li&gt;To test the TinyML-CAM pipeline, users only require an ESP32 of any variant: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://randomnerdtutorials.com/program-upload-code-esp32-cam/&#34;&gt;AI Thinker&lt;/a&gt; (the most widely used)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://shop.m5stack.com/products/esp32-camera?variant=16804741316698&#34;&gt;M5Stack&lt;/a&gt; (recommend as it comes with 4 Mb external PSRAM)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.espressif.com/en/products/devkits/esp-eye/overview&#34;&gt;Espressif&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Code&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-CAM/raw/main/%5Bino%5D-CameraWebServer.ino&#34;&gt;[ino]-CameraWebServer.ino&lt;/a&gt; - For image dataset collection. After upload to ESP32, it will connect to WiFi network and start an HTTP video streaming server that can be accessed from any web broswer.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-CAM/raw/main/%5Bh%5D-HogClassifier.h&#34;&gt;[h]-HogClassifier.h&lt;/a&gt; - Contains the RandomForestClassifier trained using the collected image data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-CAM/raw/main/%5Bh%5D-HogPipeline.h&#34;&gt;[h]-HogPipeline.h&lt;/a&gt; - Contains the HOG features extrator for image frames.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-CAM/raw/main/%5Bino%5D-arduino-ESP32-code.ino&#34;&gt;[ino]-arduino-ESP32-code.ino&lt;/a&gt; - Upload to ESP32 along with the above two .h files. After upload, put your objects in front of the camera to see predicted labels.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-CAM/raw/main/%5Bipynb%5D-TinyML-CAM-full-code-with-markdown.ipynb&#34;&gt;[ipynb]-TinyML-CAM-full-code-with-markdown.ipynb&lt;/a&gt; - Contains all the required code required for this project, along with sample outputs in each step.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Future Work&lt;/h3&gt; &#xA;&lt;p&gt;To lower the DSP time (currently 12 ms) by implementing mathematical approximation methods, which will boost the frame rate - i.e., if reduced to 6 ms, then 1000/6 ms = 166.6 FPS.&lt;/p&gt; &#xA;&lt;p&gt;Similar to the &lt;a href=&#34;https://github.com/bharathsudharsan/TinyML-Benchmark-NNs-on-MCUs&#34;&gt;TinyML benchmark&lt;/a&gt;, we plan to test the pipeline on a range of datasets, ML algorithms, and IoT boards.&lt;/p&gt;</summary>
  </entry>
</feed>