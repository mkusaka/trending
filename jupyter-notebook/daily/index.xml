<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-04T01:37:32Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dumyCq/ESFPNet</title>
    <updated>2022-09-04T01:37:32Z</updated>
    <id>tag:github.com,2022-09-04:/dumyCq/ESFPNet</id>
    <link href="https://github.com/dumyCq/ESFPNet" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Implementation of &#34;ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ESFPNet&lt;/h1&gt; &#xA;&lt;p&gt;Official Implementation of &#34;ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video&#34;&lt;/p&gt; &#xA;&lt;h2&gt;Global Rank&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/medical-image-segmentation-on-cvc-clinicdb?p=esfpnet-efficient-deep-learning-architecture&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/esfpnet-efficient-deep-learning-architecture/medical-image-segmentation-on-cvc-clinicdb&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/medical-image-segmentation-on-etis?p=esfpnet-efficient-deep-learning-architecture&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/esfpnet-efficient-deep-learning-architecture/medical-image-segmentation-on-etis&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/medical-image-segmentation-on-kvasir-seg?p=esfpnet-efficient-deep-learning-architecture&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/esfpnet-efficient-deep-learning-architecture/medical-image-segmentation-on-kvasir-seg&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/medical-image-segmentation-on-cvc-colondb?p=esfpnet-efficient-deep-learning-architecture&#34;&gt;&lt;img src=&#34;https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/esfpnet-efficient-deep-learning-architecture/medical-image-segmentation-on-cvc-colondb&#34; alt=&#34;PWC&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Architecture of ESFPNet&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt;&#xA; &lt;img src=&#34;https://github.com/dumyCq/ESFPNet/raw/main/Figures/Network.jpg&#34; width=&#34;1000&#34; height=&#34;550&#34; alt=&#34;Result&#34;&gt;&#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Installation &amp;amp; Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Enviroment (Python 3.8)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Pytorch:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install image reading and writting library:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c conda-forge imageio&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install image processing library:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install scikit-image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install library for parsing and emitting YAML:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install pyyaml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install other packages:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install pillow numpy matplotlib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Install Jupyter-Notebook to run .ipynb file&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install -c anaconda jupyter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the training and testing dataset from this link: &lt;a href=&#34;https://drive.google.com/drive/folders/1FneOIY5OC0gaIHceBqYXqj5GCdutcLfv?usp=sharing&#34;&gt;Experiment Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Extract the folders and copy them under &#34;Endoscope-WL&#34; folder&lt;/li&gt; &#xA; &lt;li&gt;The training and testing dataset are ordered as follows in &#34;Endoscope-WL&#34; folder:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;|-- TrainDataset&#xA;|   |-- CVC-ClinicDB&#xA;|   |   |-- images&#xA;|   |   |-- masks&#xA;|   |-- Kvasir&#xA;|       |-- images&#xA;|       |-- masks&#xA;&#xA;|-- TestDataset&#xA;|   |-- CVC-300&#xA;|   |   |-- images&#xA;|   |   |-- masks&#xA;|   |-- CVC-ClinicDB&#xA;|   |   |-- images&#xA;|   |   |-- masks&#xA;|   |-- CVC-ColonDB&#xA;|   |   |-- images&#xA;|   |   |-- masks&#xA;|   |-- ETIS-LaribPolypDB&#xA;|   |   |-- images&#xA;|   |   |-- masks&#xA;|   |-- Kvasir&#xA;|       |-- images&#xA;|       |-- masks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The default dataset paths can be changed in &#34;Configure.yaml&#34;&lt;/li&gt; &#xA; &lt;li&gt;To randomly split the CVC-ClincDB or Kvasir dataset, set &#34;if_renew = True&#34; in &#34;ESFPNet_Endoscope_Learning_Ability.ipynb&#34;&lt;/li&gt; &#xA; &lt;li&gt;To repeat generate the splitting dataset, previous generated folder shold be detelted first&lt;/li&gt; &#xA; &lt;li&gt;To reuse the splitting dataset without generating a new dataset, set &#34;if_renew = False&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Pretrained model&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the pretrained Mixtransformer from this link: &lt;a href=&#34;https://drive.google.com/drive/folders/1FLtIfDHDaowqyF_HhmORFMlRzCpB94hV?usp=sharing&#34;&gt;Pretrained Model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Put the pretrained models under &#34;Pretrained&#34; folder&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;If you think this paper helps, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{chang2022esfpnet,&#xA;  title={ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video},&#xA;  author={Chang, Qi and Ahmad, Danish and Toth, Jennifer and Bascom, Rebecca and Higgins, William E},&#xA;  journal={arXiv preprint arXiv:2207.07759},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Since the training of MixTransformer based network requires a good GPU. One helpful state-of-the-art work compared in this paper without using MixTransformer backbone is &lt;a href=&#34;https://github.com/AngeLouCN/CaraNet&#34;&gt;CARANet&lt;/a&gt; If you also think this work helps, please cite:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{lou2021caranet,&#xA;author = {Ange Lou and Shuyue Guan and Hanseok Ko and Murray H. Loew},&#xA;title = {{CaraNet: context axial reverse attention network for segmentation of small medical objects}},&#xA;volume = {12032},&#xA;booktitle = {Medical Imaging 2022: Image Processing},&#xA;organization = {International Society for Optics and Photonics},&#xA;publisher = {SPIE},&#xA;pages = {81 -- 92},&#xA;year = {2022},&#xA;doi = {10.1117/12.2611802}}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>