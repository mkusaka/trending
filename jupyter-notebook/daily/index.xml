<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-01T01:34:36Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tensorflow/probability</title>
    <updated>2024-04-01T01:34:36Z</updated>
    <id>tag:github.com,2024-04-01:/tensorflow/probability</id>
    <link href="https://github.com/tensorflow/probability" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Probabilistic reasoning and statistical analysis in TensorFlow&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TensorFlow Probability&lt;/h1&gt; &#xA;&lt;p&gt;TensorFlow Probability is a library for probabilistic reasoning and statistical analysis in TensorFlow. As part of the TensorFlow ecosystem, TensorFlow Probability provides integration of probabilistic methods with deep networks, gradient-based inference via automatic differentiation, and scalability to large datasets and models via hardware acceleration (e.g., GPUs) and distributed computation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TFP also works as &#34;Tensor-friendly Probability&#34; in pure JAX!&lt;/strong&gt;: &lt;code&gt;from tensorflow_probability.substrates import jax as tfp&lt;/code&gt; -- Learn more &lt;a href=&#34;https://www.tensorflow.org/probability/examples/TensorFlow_Probability_on_JAX&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Our probabilistic machine learning tools are structured as follows.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Layer 0: TensorFlow.&lt;/strong&gt; Numerical operations. In particular, the LinearOperator class enables matrix-free implementations that can exploit special structure (diagonal, low-rank, etc.) for efficient computation. It is built and maintained by the TensorFlow Probability team and is now part of &lt;a href=&#34;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/ops/linalg&#34;&gt;&lt;code&gt;tf.linalg&lt;/code&gt;&lt;/a&gt; in core TF.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Layer 1: Statistical Building Blocks&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Distributions (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/distributions&#34;&gt;&lt;code&gt;tfp.distributions&lt;/code&gt;&lt;/a&gt;): A large collection of probability distributions and related statistics with batch and &lt;a href=&#34;https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html&#34;&gt;broadcasting&lt;/a&gt; semantics. See the &lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb&#34;&gt;Distributions Tutorial&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Bijectors (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/bijectors&#34;&gt;&lt;code&gt;tfp.bijectors&lt;/code&gt;&lt;/a&gt;): Reversible and composable transformations of random variables. Bijectors provide a rich class of transformed distributions, from classical examples like the &lt;a href=&#34;https://en.wikipedia.org/wiki/Log-normal_distribution&#34;&gt;log-normal distribution&lt;/a&gt; to sophisticated deep learning models such as &lt;a href=&#34;https://arxiv.org/abs/1705.07057&#34;&gt;masked autoregressive flows&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Layer 2: Model Building&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Joint Distributions (e.g., &lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/distributions/joint_distribution_sequential.py&#34;&gt;&lt;code&gt;tfp.distributions.JointDistributionSequential&lt;/code&gt;&lt;/a&gt;): Joint distributions over one or more possibly-interdependent distributions. For an introduction to modeling with TFP&#39;s &lt;code&gt;JointDistribution&lt;/code&gt;s, check out &lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb&#34;&gt;this colab&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Probabilistic Layers (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/layers&#34;&gt;&lt;code&gt;tfp.layers&lt;/code&gt;&lt;/a&gt;): Neural network layers with uncertainty over the functions they represent, extending TensorFlow Layers.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Layer 3: Probabilistic Inference&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Markov chain Monte Carlo (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/mcmc&#34;&gt;&lt;code&gt;tfp.mcmc&lt;/code&gt;&lt;/a&gt;): Algorithms for approximating integrals via sampling. Includes &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo&#34;&gt;Hamiltonian Monte Carlo&lt;/a&gt;, random-walk Metropolis-Hastings, and the ability to build custom transition kernels.&lt;/li&gt; &#xA; &lt;li&gt;Variational Inference (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/vi&#34;&gt;&lt;code&gt;tfp.vi&lt;/code&gt;&lt;/a&gt;): Algorithms for approximating integrals via optimization.&lt;/li&gt; &#xA; &lt;li&gt;Optimizers (&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/python/optimizer&#34;&gt;&lt;code&gt;tfp.optimizer&lt;/code&gt;&lt;/a&gt;): Stochastic optimization methods, extending TensorFlow Optimizers. Includes &lt;a href=&#34;http://www.icml-2011.org/papers/398_icmlpaper.pdf&#34;&gt;Stochastic Gradient Langevin Dynamics&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Monte Carlo (&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/python/monte_carlo&#34;&gt;&lt;code&gt;tfp.monte_carlo&lt;/code&gt;&lt;/a&gt;): Tools for computing Monte Carlo expectations.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;TensorFlow Probability is under active development. Interfaces may change at any time.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples/&#34;&gt;&lt;code&gt;tensorflow_probability/examples/&lt;/code&gt;&lt;/a&gt; for end-to-end examples. It includes tutorial notebooks such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Linear_Mixed_Effects_Models.ipynb&#34;&gt;Linear Mixed Effects Models&lt;/a&gt;. A hierarchical linear model for sharing statistical strength across examples.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Eight_Schools.ipynb&#34;&gt;Eight Schools&lt;/a&gt;. A hierarchical normal model for exchangeable treatment effects.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/HLM_TFP_R_Stan.ipynb&#34;&gt;Hierarchical Linear Models&lt;/a&gt;. Hierarchical linear models compared among TensorFlow Probability, R, and Stan.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Bayesian_Gaussian_Mixture_Model.ipynb&#34;&gt;Bayesian Gaussian Mixture Models&lt;/a&gt;. Clustering with a probabilistic generative model.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_PCA.ipynb&#34;&gt;Probabilistic Principal Components Analysis&lt;/a&gt;. Dimensionality reduction with latent variables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Gaussian_Copula.ipynb&#34;&gt;Gaussian Copulas&lt;/a&gt;. Probability distributions for capturing dependence across random variables.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Distributions_Tutorial.ipynb&#34;&gt;TensorFlow Distributions: A Gentle Introduction&lt;/a&gt;. Introduction to TensorFlow Distributions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/Understanding_TensorFlow_Distributions_Shapes.ipynb&#34;&gt;Understanding TensorFlow Distributions Shapes&lt;/a&gt;. How to distinguish between samples, batches, and events for arbitrarily shaped probabilistic computations.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/raw/main/tensorflow_probability/examples/jupyter_notebooks/TensorFlow_Probability_Case_Study_Covariance_Estimation.ipynb&#34;&gt;TensorFlow Probability Case Study: Covariance Estimation&lt;/a&gt;. A user&#39;s case study in applying TensorFlow Probability to estimate covariances.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It also includes example scripts such as:&lt;/p&gt; &#xA;&lt;p&gt;Representation learning with a latent code and variational inference.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples/vq_vae.py&#34;&gt;Vector-Quantized Autoencoder&lt;/a&gt;. Discrete representation learning with vector quantization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples/disentangled_vae.py&#34;&gt;Disentangled Sequential Variational Autoencoder&lt;/a&gt; Disentangled representation learning over sequences with variational inference.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples/bayesian_neural_network.py&#34;&gt;Bayesian Neural Networks&lt;/a&gt;. Neural networks with uncertainty over their weights.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples/logistic_regression.py&#34;&gt;Bayesian Logistic Regression&lt;/a&gt;. Bayesian inference for binary classification.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;For additional details on installing TensorFlow, guidance installing prerequisites, and (optionally) setting up virtual environments, see the &lt;a href=&#34;https://www.tensorflow.org/install&#34;&gt;TensorFlow installation guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Stable Builds&lt;/h3&gt; &#xA;&lt;p&gt;To install the latest stable version, run the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Notes:&#xA;&#xA;# - The `--upgrade` flag ensures you&#39;ll get the latest version.&#xA;# - The `--user` flag ensures the packages are installed to your user directory&#xA;#   rather than the system directory.&#xA;# - TensorFlow 2 packages require a pip &amp;gt;= 19.0&#xA;python -m pip install --upgrade --user pip&#xA;python -m pip install --upgrade --user tensorflow tensorflow_probability&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For CPU-only usage (and a smaller install), install with &lt;code&gt;tensorflow-cpu&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use a pre-2.0 version of TensorFlow, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install --upgrade --user &#34;tensorflow&amp;lt;2&#34; &#34;tensorflow_probability&amp;lt;0.9&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: Since &lt;a href=&#34;https://www.tensorflow.org/install&#34;&gt;TensorFlow&lt;/a&gt; is &lt;em&gt;not&lt;/em&gt; included as a dependency of the TensorFlow Probability package (in &lt;code&gt;setup.py&lt;/code&gt;), you must explicitly install the TensorFlow package (&lt;code&gt;tensorflow&lt;/code&gt; or &lt;code&gt;tensorflow-cpu&lt;/code&gt;). This allows us to maintain one package instead of separate packages for CPU and GPU-enabled TensorFlow. See the &lt;a href=&#34;https://github.com/tensorflow/probability/releases&#34;&gt;TFP release notes&lt;/a&gt; for more details about dependencies between TensorFlow and TensorFlow Probability.&lt;/p&gt; &#xA;&lt;h3&gt;Nightly Builds&lt;/h3&gt; &#xA;&lt;p&gt;There are also nightly builds of TensorFlow Probability under the pip package &lt;code&gt;tfp-nightly&lt;/code&gt;, which depends on one of &lt;code&gt;tf-nightly&lt;/code&gt; or &lt;code&gt;tf-nightly-cpu&lt;/code&gt;. Nightly builds include newer features, but may be less stable than the versioned releases. Both stable and nightly docs are available &lt;a href=&#34;https://www.tensorflow.org/probability/api_docs/python/tfp?version=nightly&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m pip install --upgrade --user tf-nightly tfp-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing from Source&lt;/h3&gt; &#xA;&lt;p&gt;You can also install from source. This requires the &lt;a href=&#34;https://bazel.build/&#34;&gt;Bazel&lt;/a&gt; build system. It is highly recommended that you install the nightly build of TensorFlow (&lt;code&gt;tf-nightly&lt;/code&gt;) before trying to build TensorFlow Probability from source. The most recent version of Bazel that TFP currently supports is 6.4.0; support for 7.0.0+ is WIP.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# sudo apt-get install bazel git python-pip  # Ubuntu; others, see above links.&#xA;python -m pip install --upgrade --user tf-nightly&#xA;git clone https://github.com/tensorflow/probability.git&#xA;cd probability&#xA;bazel build --copt=-O3 --copt=-march=native :pip_pkg&#xA;PKGDIR=$(mktemp -d)&#xA;./bazel-bin/pip_pkg $PKGDIR&#xA;python -m pip install --upgrade --user $PKGDIR/*.whl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Community&lt;/h2&gt; &#xA;&lt;p&gt;As part of TensorFlow, we&#39;re committed to fostering an open and welcoming environment.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/tagged/tensorflow&#34;&gt;Stack Overflow&lt;/a&gt;: Ask or answer technical questions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tensorflow/probability/issues&#34;&gt;GitHub&lt;/a&gt;: Report bugs or make feature requests.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.tensorflow.org/&#34;&gt;TensorFlow Blog&lt;/a&gt;: Stay up to date on content from the TensorFlow team and best articles from the community.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://youtube.com/tensorflow/&#34;&gt;Youtube Channel&lt;/a&gt;: Follow TensorFlow shows.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/a/tensorflow.org/forum/#!forum/tfprobability&#34;&gt;tfprobability@tensorflow.org&lt;/a&gt;: Open mailing list for discussion and questions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://www.tensorflow.org/community/&#34;&gt;TensorFlow Community&lt;/a&gt; page for more details. Check out our latest publicity here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=BjUkL8DFH5Q&#34;&gt;Coffee with a Googler: Probabilistic Machine Learning in TensorFlow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/tensorflow/introducing-tensorflow-probability-dca4c304e245&#34;&gt;Introducing TensorFlow Probability&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re eager to collaborate with you! See &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/probability/main/CONTRIBUTING.md&#34;&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; for a guide on how to contribute. This project adheres to TensorFlow&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/tensorflow/probability/main/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;. By participating, you are expected to uphold this code.&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;p&gt;If you use TensorFlow Probability in a paper, please cite:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;TensorFlow Distributions.&lt;/em&gt; Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A. Saurous. &lt;a href=&#34;https://arxiv.org/abs/1711.10604&#34;&gt;arXiv preprint arXiv:1711.10604, 2017&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;(We&#39;re aware there&#39;s a lot more to TensorFlow Probability than Distributions, but the Distributions paper lays out our vision and is a fine thing to cite for now.)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/MLOps</title>
    <updated>2024-04-01T01:34:36Z</updated>
    <id>tag:github.com,2024-04-01:/microsoft/MLOps</id>
    <link href="https://github.com/microsoft/MLOps" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MLOps examples&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;p&gt;page_type: sample languages:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;python products:&lt;/li&gt; &#xA; &lt;li&gt;azure&lt;/li&gt; &#xA; &lt;li&gt;azure-machine-learning-service&lt;/li&gt; &#xA; &lt;li&gt;azure-devops description: &#34;MLOps end to end examples &amp;amp; solutions. A collection of examples showing different end to end scenarios operationalizing ML workflows with Azure Machine Learning, integrated with GitHub and other Azure services such as Data Factory and DevOps.&#34;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Updated MLOps Guidance on Azure (2023)&lt;/h1&gt; &#xA;&lt;p&gt;To learn the more about the latest guidance from Microsoft about MLOps review the following links.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/mlops-v2&#34;&gt;Azure MLOps (v2) Solution Accelerator&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-mlops-azureml?view=azureml-api-2&amp;amp;tabs=azure-shell&#34;&gt;Set up MLOps with Azure DevOps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-mlops-github-azure-ml?view=azureml-api-2&amp;amp;tabs=azure-shell&#34;&gt;Set up MLOps with Github&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/machine-learning/concept-model-management-and-deployment?view=azureml-api-2&#34;&gt;Offical Microsoft Documentatation on MLOps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/training/paths/introduction-machine-learn-operations/&#34;&gt;Microsoft Learn cournse for intro to MLOps&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learn.microsoft.com/en-us/training/paths/build-first-machine-operations-workflow/&#34;&gt;Microsoft Learn course for E2E MLOps&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;MLOps on Azure&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dev.azure.com/aidemos/MLOps/_build/latest?definitionId=96?branchName=master&#34;&gt;&lt;img src=&#34;https://dev.azure.com/aidemos/MLOps/_apis/build/status/microsoft.MLOps?branchName=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dev.azure.com/customai/DevopsForAI-AML/_release?view=all&amp;amp;_a=releases&amp;amp;definitionId=16&#34;&gt;Example MLOps Release Pipeline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/MLOpsPython&#34;&gt;Official Python Azure MLOps repo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nst3UAGpiBA&#34;&gt;MLOps Architecture Deep Dive video&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What is MLOps?&lt;/h2&gt; &#xA;&lt;p&gt;MLOps empowers data scientists and app developers to help bring ML models to production. MLOps enables you to track / version / audit / certify / re-use every asset in your ML lifecycle and provides orchestration services to streamline managing this lifecycle.&lt;/p&gt; &#xA;&lt;h3&gt;MLOps podcast&lt;/h3&gt; &#xA;&lt;p&gt;Check out the recent TwiML podcast on MLOps &lt;a href=&#34;https://twimlai.com/twiml-talk-321-enterprise-readiness-mlops-and-lifecycle-management-with-jordan-edwards/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;How does Azure ML help with MLOps?&lt;/h2&gt; &#xA;&lt;p&gt;Azure ML contains a number of asset management and orchestration services to help you manage the lifecycle of your model training &amp;amp; deployment workflows.&lt;/p&gt; &#xA;&lt;p&gt;With Azure ML + Azure DevOps you can effectively and cohesively manage your datasets, experiments, models, and ML-infused applications. &lt;img src=&#34;https://raw.githubusercontent.com/microsoft/MLOps/master/media/ml-lifecycle.png&#34; alt=&#34;ML lifecycle&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;New MLOps features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml&#34;&gt;Azure DevOps Machine Learning extension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/azmlcli&#34;&gt;Azure ML CLI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/azure/machine-learning/service/how-to-use-event-grid&#34;&gt;Create event driven workflows&lt;/a&gt; using Azure Machine Learning and Azure Event Grid for scenarios such as triggering retraining pipelines&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/devops/pipelines/targets/azure-machine-learning?view=azure-devops&#34;&gt;Set up model training &amp;amp; deployment with Azure DevOps&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If you are using the Machine Learning DevOps extension, you can access model name and version info using these variables:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;Model Name: Release.Artifacts.{alias}.DefinitionName containing model name&lt;/li&gt; &#xA;  &lt;li&gt;Model Version: Release.Artifacts.{alias}.BuildNumber where alias is source alias set while adding the release artifact.&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Getting Started / MLOps Workflow&lt;/h2&gt; &#xA;&lt;p&gt;An example repo which exercises our recommended flow can be found &lt;a href=&#34;https://github.com/Microsoft/MLOpsPython&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;MLOps Best Practices&lt;/h2&gt; &#xA;&lt;h3&gt;Train Model&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data scientists work in topic branches off of master.&lt;/li&gt; &#xA; &lt;li&gt;When code is pushed to the Git repo, trigger a CI (continuous integration) pipeline.&lt;/li&gt; &#xA; &lt;li&gt;First run: Provision infra-as-code (ML workspace, compute targets, datastores).&lt;/li&gt; &#xA; &lt;li&gt;For new code: Every time new code is committed to the repo, run unit tests, data quality checks, train model.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We recommend the following steps in your CI process:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Train Model&lt;/strong&gt; - run training code / algo &amp;amp; output a &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture#model&#34;&gt;model&lt;/a&gt; file which is stored in the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#run&#34;&gt;run history&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Evaluate Model&lt;/strong&gt; - compare the performance of newly trained model with the model in production. If the new model performs better than the production model, the following steps are executed. If not, they will be skipped.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Register Model&lt;/strong&gt; - take the best model and register it with the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#model-registry&#34;&gt;Azure ML Model registry&lt;/a&gt;. This allows us to version control it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Operationalize Model&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;You can package and validate your ML model using the &lt;strong&gt;Azure ML CLI&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Once you have registered your ML model, you can use Azure ML + Azure DevOps to deploy it.&lt;/li&gt; &#xA; &lt;li&gt;You can define a &lt;strong&gt;release definition&lt;/strong&gt; in Azure Pipelines to help coordinate a release. Using the DevOps extension for Machine Learning, you can include artifacts from Azure ML, Azure Repos, and GitHub as part of your Release Pipeline.&lt;/li&gt; &#xA; &lt;li&gt;In your release definition, you can leverage the Azure ML CLI&#39;s &lt;strong&gt;model deploy&lt;/strong&gt; command to deploy your Azure ML model to the cloud (ACI or AKS).&lt;/li&gt; &#xA; &lt;li&gt;Define your deployment as a &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/devops/pipelines/release/approvals/gates?view=azure-devops&#34;&gt;gated release&lt;/a&gt;. This means that once the model web service deployment in the Staging/QA environment is successful, a notification is sent to approvers to manually review and approve the release. Once the release is approved, the model scoring web service is deployed to &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/aks/intro-kubernetes&#34;&gt;Azure Kubernetes Service(AKS)&lt;/a&gt; and the deployment is tested.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;MLOps Solutions&lt;/h1&gt; &#xA;&lt;p&gt;We are committed to providing a collection of best-in-class solutions for MLOps, both in terms of well documented &amp;amp; fully managed cloud solutions, as well as reusable recipes which can help your organization to bootstrap its MLOps muscle. These examples are community supported and are not guaranteed to be up-to-date as new features enter the product.&lt;/p&gt; &#xA;&lt;p&gt;All of our examples will be built in the open and we welcome contributions from the community!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/MLOpsPython&#34;&gt;https://github.com/Microsoft/MLOpsPython&lt;/a&gt; (reference architecture for MLOps + python)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/Recommenders&#34;&gt;https://github.com/Microsoft/Recommenders&lt;/a&gt; (recommender systems with E2E mlops baked in)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MicrosoftDocs/pipelines-azureml&#34;&gt;https://github.com/MicrosoftDocs/pipelines-azureml&lt;/a&gt; (CI/CD with the azure ML CLI)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Microsoft/MLOps_VideoAnomalyDetection&#34;&gt;https://github.com/Microsoft/MLOps_VideoAnomalyDetection&lt;/a&gt; (self-supervised learning with hyperparameter tuning and automated retraining)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure-Samples/MLOpsDatabricks&#34;&gt;https://github.com/Azure-Samples/MLOpsDatabricks&lt;/a&gt; (set up MLOps with Azure ML + databricks)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/roalexan/azureml#schedule-using-adf&#34;&gt;https://github.com/roalexan/azureml#schedule-using-adf&lt;/a&gt; (schedule an azure ML pipeline from an azure data factory pipeline)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.azuredevopslabs.com/labs/vstsextend/aml/&#34;&gt;https://www.azuredevopslabs.com/labs/vstsextend/aml/&lt;/a&gt; (automated template to deploy MLOps on ADO)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/ACE_Azure_ML/tree/master/devops&#34;&gt;https://github.com/Azure/ACE_Azure_ML/tree/master/devops&lt;/a&gt; (set up azure ML + azure DevOps together for predictive maintenance)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/nlp&#34;&gt;https://github.com/microsoft/nlp&lt;/a&gt; ( Natural language processing examples using MLOps + GitHub + Azure)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/AIArchitecturesAndPractices&#34;&gt;https://github.com/microsoft/AIArchitecturesAndPractices&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/danielsc/azureml-debug-training/raw/master/Setting%20up%20VSCode%20Remote%20on%20an%20AzureML%20Notebook%20VM.md&#34;&gt;https://github.com/danielsc/azureml-debug-training/blob/master/Setting%20up%20VSCode%20Remote%20on%20an%20AzureML%20Notebook%20VM.md&lt;/a&gt; - code from a notebook VM in VSCode&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jomit/SecureAzureMLWorkshop&#34;&gt;https://github.com/jomit/SecureAzureMLWorkshop&lt;/a&gt; (code + scripts to run workshop around building secure ml platform on azure)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure/ml-functions-package-demo&#34;&gt;https://github.com/Azure/ml-functions-package-demo&lt;/a&gt; package an ML model for use in Azure Functions&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/seismic-deeplearning&#34;&gt;https://github.com/microsoft/seismic-deeplearning&lt;/a&gt; (deep learning for seismic imaging and interpretation)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CESARDELATORRE/poc-spark-aml/raw/master/spark-job.py&#34;&gt;https://github.com/CESARDELATORRE/poc-spark-aml/blob/master/spark-job.py&lt;/a&gt; (Spark job on aml compute)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Azure-Samples/azure-machine-learning-pipeline-observability-sample&#34;&gt;https://github.com/Azure-Samples/azure-machine-learning-pipeline-observability-sample&lt;/a&gt; (Azure Machine Learning Pipeline Run Observability)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;How is MLOps different from DevOps?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data/model versioning != code versioning - how to version data sets as the schema and origin data change&lt;/li&gt; &#xA; &lt;li&gt;Digital audit trail requirements change when dealing with code + (potentially customer) data&lt;/li&gt; &#xA; &lt;li&gt;Model reuse is different than software reuse, as models must be tuned based on input data / scenario.&lt;/li&gt; &#xA; &lt;li&gt;To reuse a model you may need to fine-tune / transfer learn on it (meaning you need the training pipeline)&lt;/li&gt; &#xA; &lt;li&gt;Models tend to decay over time &amp;amp; you need the ability to retrain them on demand to ensure they remain useful in a production context.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;What are the key challenges we wish to solve with MLOps?&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Model reproducibility &amp;amp; versioning&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Track, snapshot &amp;amp; manage assets used to create the model&lt;/li&gt; &#xA; &lt;li&gt;Enable collaboration and sharing of ML pipelines&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Model auditability &amp;amp; explainability&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Maintain asset integrity &amp;amp; persist access control logs&lt;/li&gt; &#xA; &lt;li&gt;Certify model behavior meets regulatory &amp;amp; adversarial standards&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Model packaging &amp;amp; validation&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Support model portability across a variety of platforms&lt;/li&gt; &#xA; &lt;li&gt;Certify model performance meets functional and latency requirements&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Model deployment &amp;amp; monitoring&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Release models with confidence&lt;/li&gt; &#xA; &lt;li&gt;Monitor &amp;amp; know when to retrain by analyzing signals such as data drift&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.microsoft.com&#34;&gt;https://cla.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h3&gt;Related projects&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://aka.ms/ai-labs&#34;&gt;Microsoft AI Labs Github&lt;/a&gt; Find other Best Practice projects, and Azure AI design patterns in our central repository.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>alura-cursos/imersao-python-dados-03-2024</title>
    <updated>2024-04-01T01:34:36Z</updated>
    <id>tag:github.com,2024-04-01:/alura-cursos/imersao-python-dados-03-2024</id>
    <link href="https://github.com/alura-cursos/imersao-python-dados-03-2024" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Imersão Python: do Excel à Análise de Dados&lt;/h1&gt; &#xA;&lt;p&gt;Conteúdo das aulas e respostas dos desafios&lt;/p&gt;</summary>
  </entry>
</feed>