<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-18T01:34:25Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dome272/Paella</title>
    <updated>2022-11-18T01:34:25Z</updated>
    <id>tag:github.com,2022-11-18:/dome272/Paella</id>
    <link href="https://github.com/dome272/Paella" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Implementation of Paella (https://arxiv.org/abs/2211.07292v1)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1HH5Fey_mTiz29l9dGmHGqZqdzwLpLrxj?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/spaces/pcuenq/paella&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/%F0%9F%A4%97-Huggingface%20Space-cyan.svg?sanitize=true&#34; alt=&#34;Huggingface Space&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Paella&lt;/h1&gt; &#xA;&lt;p&gt;Conditional text-to-image generation has seen countless recent improvements in terms of quality, diversity and fidelity. Nevertheless, most state-of-the-art models require numerous inference steps to produce faithful generations, resulting in performance bottlenecks for end-user applications. In this paper we introduce Paella, a novel text-to-image model requiring less than 10 steps to sample high-fidelity images, using a speed-optimized architecture allowing to sample a single image in less than 500 ms, while having 573M parameters. The model operates on a compressed &amp;amp; quantized latent space, it is conditioned on CLIP embeddings and uses an improved sampling function over previous works. Aside from text-conditional image generation, our model is able to do latent space interpolation and image manipulations such as inpainting, outpainting, and structural editing. &lt;br&gt; &lt;br&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/117442814/201474789-a192f6ab-9626-4402-a3ec-81b8f3fd436c.png&#34; alt=&#34;cover-figure&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Code&lt;/h2&gt; &#xA;&lt;p&gt;We especially want to highlight the minimalistic amount of code that is necessary to run &amp;amp; train Paella. The entire code including training, sampling, architecture and utilities can fit in approx. 400 lines of code. We hope to make this method more accessible to more people this way. In order to just understand the basic logic you can take a look at &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/paella_minimal.py&#34;&gt;paella_minimal.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Sampling&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1HH5Fey_mTiz29l9dGmHGqZqdzwLpLrxj?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;For sampling you can just take a look at the &lt;a href=&#34;https://github.com/delicious-tasty/Paella/raw/main/paella_sampling.ipynb&#34;&gt;sampling.ipynb&lt;/a&gt; notebook. &lt;span&gt;ðŸ˜Ž&lt;/span&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Train your own Paella&lt;/h2&gt; &#xA;&lt;p&gt;The main file for training will be &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/paella.py&#34;&gt;paella.py&lt;/a&gt;. You can adjust all &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/paella.py#L322&#34;&gt;hyperparameters&lt;/a&gt; to your own needs. During training we use webdataset, but you are free to replace that with your own custom dataloader. Just change the line on 119 in &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/paella.py#L119&#34;&gt;paella.py&lt;/a&gt; to point to your own dataloader. Make sure it returns a tuple of &lt;code&gt;(images, captions)&lt;/code&gt; where &lt;code&gt;images&lt;/code&gt; is a &lt;code&gt;torch.Tensor&lt;/code&gt; of shape &lt;code&gt;batch_size x channels x height x width&lt;/code&gt; and captions is a &lt;code&gt;List&lt;/code&gt; of length &lt;code&gt;batch_size&lt;/code&gt;. Now decide if you want to finetune Paella or start a new training from scratch:&lt;/p&gt; &#xA;&lt;h3&gt;From Scratch&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 paella.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Finetune&lt;/h3&gt; &#xA;&lt;p&gt;If you want to finetune you first need to download the &lt;a href=&#34;https://drive.google.com/drive/folders/1ADAV-WPhMKGnm2w0bTO4HKhv6yoHB0Co&#34;&gt;latest checkpoint and it&#39;s optimizer state&lt;/a&gt;, set the &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/paella.py#L251&#34;&gt;finetune hyperparameter&lt;/a&gt; to &lt;code&gt;True&lt;/code&gt; and create a folder &lt;code&gt;models/&amp;lt;RUN_NAME&amp;gt;&lt;/code&gt; and move both checkpoints to this folder. After that you can also just run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 paella.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;License&lt;/h3&gt; &#xA;&lt;p&gt;The model code and weights are released under the &lt;a href=&#34;https://github.com/dome272/Paella/raw/main/LICENSE&#34;&gt;MIT license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>MadryLab/photoguard</title>
    <updated>2022-11-18T01:34:25Z</updated>
    <id>tag:github.com,2022-11-18:/MadryLab/photoguard</id>
    <link href="https://github.com/MadryLab/photoguard" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PhotoGuard: Defending Against Diffusion-based Image Manipulation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PhotoGuard: Defending Against Diffusion-based Image Manipulation&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the code for our recent work on safe-guarding images against manipulation by ML-powerd photo-editing models such as &lt;a href=&#34;https://stability.ai/blog/stable-diffusion-public-release&#34;&gt;stable diffusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;PhotoGuard: Defending Against Diffusion-based Image Manipulation&lt;/strong&gt; &lt;br&gt; &lt;em&gt;Hadi Salman*, Alaa Khaddaj*, Guillaume Leclerc*, Andrew Ilyas*, Aleksander Madry&lt;/em&gt; &lt;br&gt; &lt;strong&gt;Paper:&lt;/strong&gt; Coming soon! &lt;br&gt; &lt;strong&gt;Blog post:&lt;/strong&gt; &lt;a href=&#34;https://gradientscience.org/photoguard/&#34;&gt;https://gradientscience.org/photoguard/&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;    @article{salman2022photoguard,&#xA;        title={PhotoGuard: Defending Against Diffusion-based Image Manipulation},&#xA;        author={Hadi Salman and Alaa Khaddaj and Guillaume Leclerc and Andrew Ilyas and Aleksander Madry},&#xA;        year={2022},&#xA;        booktitle={Github Repository}&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/assets/hero_fig.png&#34; width=&#34;1000&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Getting started&lt;/h2&gt; &#xA;&lt;p&gt;Our code relies on the &lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;stable diffusion code on Hugging Face&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Clone our repo: &lt;code&gt;git clone https://github.com/madrylab/photoguard.git&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install dependencies:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  conda create -n photoguard python=3.10&#xA;  conda activate photoguard&#xA;  pip install --upgrade diffusers transformers scipy&#xA;  huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;You should now be all set! Check out our notebooks!&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Generating high-quality fake images&lt;/h2&gt; &#xA;&lt;p&gt;The first step is we will walk you through how you can generate high quality fake images. Check out this notebook! The result will be such images:&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/notebooks/generating_fake_images.ipynb&#34;&gt;this notebook&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/assets/hadi_trevor.png&#34; width=&#34;1000&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Simple photo-guarding:&lt;/h2&gt; &#xA;&lt;p&gt;Now, we describe the simplest form of photo safeguarding that we implement. In particular, we implement a simple PGD attack on the image embedding part of the stable diffusion model. We have two demos demonstrating the efficacy of such photo safeguarding method. The goal of both is to cause the stable diffusion model to generate something that is either unrealistic, or unrelated to the original image.&lt;/p&gt; &#xA;&lt;h3&gt;Photo-guarding against Image-to-Image pipelines&lt;/h3&gt; &#xA;&lt;p&gt;The first is the case where someone uses an image + prompt to modify the input image based on the prompt description.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/notebooks/demo_simple_attack_img2img.ipynb&#34;&gt;this notebook&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/assets/simple_attack_img2img.png&#34; width=&#34;1000&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Photo-guarding against Inpainting pipelines&lt;/h3&gt; &#xA;&lt;p&gt;The second is the more interesting scenario where someone wants to edit parts of an existing image via inpainting. The generated images after immunization are clearly fake!&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/notebooks/demo_simple_attack_inpainting.ipynb&#34;&gt;this notebook&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/assets/simple_attack_inpaint.png&#34; width=&#34;1000&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Complex photo-guarding&lt;/h2&gt; &#xA;&lt;p&gt;For more effective photo-guarding especially against image inpainting, we need to attack the stable diffusion model end-to-end. Now, the generated images after immunization are even more clearly fake than above!&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/notebooks/demo_complex_attack_inpainting.ipynb&#34;&gt;this notebook&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MadryLab/photoguard/main/assets/complex_attack_inpaint.png&#34; width=&#34;1000&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;That&#39;s it! Please let us know if you have any questions.&lt;/p&gt; &#xA;&lt;h1&gt;Maintainers&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/hadisalmanX&#34;&gt;Hadi Salman&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/Alaa_Khaddaj&#34;&gt;Alaa Khaddaj&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.gcom/gpoleclerc&#34;&gt;Guillaume Leclerc&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/andrew_ilyas&#34;&gt;Andrew Ilyas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/aleks_madry&#34;&gt;Aleksander Madry&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>