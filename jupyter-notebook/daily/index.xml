<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-30T01:39:52Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>tuw-python/tuw-python-2022WS</title>
    <updated>2022-09-30T01:39:52Z</updated>
    <id>tag:github.com,2022-09-30:/tuw-python/tuw-python-2022WS</id>
    <link href="https://github.com/tuw-python/tuw-python-2022WS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;194.123 Programming in Python&lt;/h1&gt; &#xA;&lt;h3&gt;TU Wien, 2022 WS&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://tiss.tuwien.ac.at/course/educationDetails.xhtml?dswid=2845&amp;amp;dsrid=656&amp;amp;courseNr=194123&amp;amp;semester=2022W&#34;&gt;TISS page&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;WARNING: the course material is not yet finalized. If you download the notebooks now, make sure you update them before the course starts&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Time and place&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Every day between 2022.09.26 (Mo) - 09.30 (Fr)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Daily from 10.15 - 11.45 (lectures) and 13.15 - 15.30 (practice)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Using &lt;a href=&#34;https://tuwien.zoom.us/j/94257349304?pwd=dVE4WmJMSlVoTEtRbDJvOWExU2wxQT09&#34;&gt;Zoom&lt;/a&gt; and &lt;a href=&#34;https://join.slack.com/t/tuw-python/shared_invite/zt-1g2dom5fa-M~lZwH56tsfuLn67U3jGrw&#34;&gt;Slack&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Instructors&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hlt.bme.hu/en/judit&#34;&gt;Judit Ács&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tiss.tuwien.ac.at/person/324397&#34;&gt;Gabriel Breiner&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tiss.tuwien.ac.at/person/341880.html&#34;&gt;Kinga Gémes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tiss.tuwien.ac.at/person/341881.html&#34;&gt;Ádám Kovács&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tiss.tuwien.ac.at/person/336863.html&#34;&gt;Gábor Recski&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Administrative questions should be directed to Gabor Recski&lt;/p&gt; &#xA;&lt;h3&gt;Schedule&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Date&lt;/th&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09/26/2022&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to Python, basic types. Using git for version control.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09/27/2022&lt;/td&gt; &#xA;   &lt;td&gt;Advanced types, operators, strings. Functions, lambda functions.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09/28/2022&lt;/td&gt; &#xA;   &lt;td&gt;Object-oriented programming. Classes, attributes, inheritence, magic functions, static methods.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09/29/2022&lt;/td&gt; &#xA;   &lt;td&gt;List comprehensions, decorators, functional programming.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;09/30/2022&lt;/td&gt; &#xA;   &lt;td&gt;Common Python modules. collection, re, networkx, itertools&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Who should take this course&lt;/h3&gt; &#xA;&lt;p&gt;Anyone with knowledge of programming basics who would like to learn (more) about Python and get practical experience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/tuw-python/tuw-python-2022WS/main/self_assessment.ipynb&#34;&gt;Self-assessment questions&lt;/a&gt; are provided, please have a look if you are about to attend &lt;a href=&#34;https://tiss.tuwien.ac.at/course/educationDetails.xhtml?dswid=2344&amp;amp;dsrid=881&amp;amp;courseNr=188995&amp;amp;semester=2022W&#34;&gt;188.995 Data-oriented Programming Paradigms&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Evaluation&lt;/h3&gt; &#xA;&lt;p&gt;Homework exercises will be released on each of the first 4 days. Solutions must be submitted via GitHub classroom, links for this will be available to registered students on &lt;a href=&#34;https://tuwel.tuwien.ac.at/course/view.php?idnumber=194123-2022W&#34;&gt;TUWEL&lt;/a&gt;. The deadline for submitting all exercises is Thursday (9/29) 23.59 (CEST), scores will be published the next morning. The exercises on Friday can be used to earn bonus points.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DEADLINE EXTENSION: We decided to extend the deadline for submissions. The new deadline for &lt;strong&gt;ALL EXERCISES&lt;/strong&gt; is Sunday (10/2) 23.59 (CEST). You can expect the scores to be published next week.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Grading&lt;/h3&gt; &#xA;&lt;p&gt;Each of the first 4 daily exercises are worth 25 points, for a maximum of 100 points. The Friday exercise is worth a maximum of 15 bonus points.&lt;/p&gt; &#xA;&lt;p&gt;Final grades will be determined using the following ranges:&lt;/p&gt; &#xA;&lt;p&gt;1: 89 – 115, 2: 76 – 88, 3: 63 – 75, 4: 50 – 62&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yiyixuxu/denoising-diffusion-flax</title>
    <updated>2022-09-30T01:39:52Z</updated>
    <id>tag:github.com,2022-09-30:/yiyixuxu/denoising-diffusion-flax</id>
    <link href="https://github.com/yiyixuxu/denoising-diffusion-flax" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementing the Denoising Diffusion Probabilistic Model in Flax&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Denoising Diffusion Probabilistic Model in Flax&lt;/h1&gt; &#xA;&lt;p&gt;This implementation is based on &lt;a href=&#34;https://github.com/lucidrains&#34;&gt;lucidrains&lt;/a&gt;&#39;s &lt;a href=&#34;https://github.com/lucidrains/denoising-diffusion-pytorch&#34;&gt;denoising-diffusion-pytorch&lt;/a&gt;, where he implemented the original DDPM model proposed from paper &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;Denoising Diffusion Probabilistic Models&lt;/a&gt;, as well as latest research findings&lt;/p&gt; &#xA;&lt;p&gt;I will keep adding new research findings to this repo, let me know if you have any suggestions!&lt;/p&gt; &#xA;&lt;h2&gt;end-to-end training on colab notebook&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yiyixuxu/denoising-diffusion-flax/raw/main/ddpm_flax_oxford102_end_to_end.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can run this code and even modify it directly in Google Colab, no installation required:&lt;/p&gt; &#xA;&lt;p&gt;[https://github.com/yiyixuxu/denoising-diffusion-flax/blob/main/ddpm_flax_oxford102_end_to_end.ipynb]&lt;/p&gt; &#xA;&lt;p&gt;The Colab also demonstrates how to configure your own training and load pre-trained checkpoint to generate samples on your own!&lt;/p&gt; &#xA;&lt;h2&gt;generated sample from oxford102 flower dataset&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;on going at 27k steps (self-conditioning + P2 weighting)&lt;/em&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/images/27k.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;on going at 85k steps (self-conditioning + P2 weighting)&lt;/em&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/images/sample.png&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;300k steps!&lt;/em&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/images/300k.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;To-do list&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; write a wandb report about the p2-weighting, self-conditioning and predict_from_x0&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; implement gradient accumulation&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; implement ddim&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yiyixuxu/denoising-diffusion-flax/edit/main/README.md#running-locally&#34;&gt;Running locally&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/#google-cloud-tpu&#34;&gt;Using Google Cloud TPU&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/load-a-model-checkpoint-from-W&amp;amp;B&#34;&gt;pre-trained model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiyixuxu/denoising-diffusion-flax/main/#train-your-own-model&#34;&gt;Train your own model&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Running locally&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python main.py --workdir=./fashion_mnist_cpu --mode=train --config=configs/fashion_mnist_cpu.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Google Cloud TPU&lt;/h3&gt; &#xA;&lt;p&gt;If you&#39;re new to Jax/Flax ecosystem, you can apply to TPU for free for your research project here &lt;a href=&#34;https://sites.research.google/trc/about/&#34;&gt;https://sites.research.google/trc/about/&lt;/a&gt; (This project is enabled by TRC program. Thank you google!)&lt;/p&gt; &#xA;&lt;p&gt;See below for commands to set up a single VM with 8 TPUs attached (&lt;code&gt;--accelerator-type v3-8&lt;/code&gt;). For more details about how to set up and use TPUs, refer to Cloud docs for &lt;a href=&#34;https://cloud.google.com/tpu/docs/jax-quickstart-tpu-vm&#34;&gt;single VM setup&lt;/a&gt;(&lt;a href=&#34;https://cloud.google.com/tpu/docs/jax-quickstart-tpu-vm&#34;&gt;https://cloud.google.com/tpu/docs/jax-quickstart-tpu-vm&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;First create a single TPUv3-8 VM and connect to it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ZONE=europe-west4-a&#xA;TPU_TYPE=v3-8&#xA;VM_NAME=ddpm&#xA;&#xA;gcloud alpha compute tpus tpu-vm create $VM_NAME \&#xA;    --zone $ZONE \&#xA;    --accelerator-type $TPU_TYPE \&#xA;    --version tpu-vm-base&#xA;&#xA;gcloud alpha compute tpus tpu-vm ssh $VM_NAME --zone $ZONE -- \&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;When connected install JAX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install &#34;jax[tpu]&amp;gt;=0.2.16&#34; -f https://storage.googleapis.com/jax-releases/libtpu_releases.html&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then install denoising-diffusion-flax and required libraries&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/yiyixuxu/denoising-diffusion-flax.git&#xA;cd denoising-diffusion-flax/denoising_diffusion_flax&#xA;pip install einops&#xA;pip install wandb&#xA;pip install --upgrade clu&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;create a tmux session&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;tmux new -s ddpm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And finally start the training, to train a model on fashion-mnist dataset with default setting, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./fashion-mnist --mode=train --config=configs/fashion_mnist.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;All examples use read-to-use tensorflow dataset, and have the training process and model checkpoint available on W&amp;amp;B so it is very easy to reproduce&lt;/p&gt; &#xA;&lt;h3&gt;cifar10&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./cifar10 --mode=train --config=configs/cifar10.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;W&amp;amp;B project page: &lt;a href=&#34;https://wandb.ai/yiyixu/ddpm-flax-cifar10?workspace=user-yiyixu&#34;&gt;ddpm-flax-cifar10&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;fashion-mnist&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./fashion-mnist --mode=train --config=configs/fashion_mnist.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;W&amp;amp;B project page: &lt;a href=&#34;https://wandb.ai/yiyixu/ddpm-flax-fashion-mnist?workspace=user-yiyixu&#34;&gt;ddpm-flax-fashion-mnist&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;oxford_flowers102&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./flower102--mode=train --config=configs/oxford102_p2_selfcondition.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;W&amp;amp;B project page: &lt;a href=&#34;https://wandb.ai/yiyixu/ddpm-flax-flower102?workspace=user-yiyixu&#34;&gt;ddpm-flax-flower102&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Load a model checkpoint from W&amp;amp;B&lt;/h2&gt; &#xA;&lt;p&gt;By default, we log our model as W&amp;amp;B artifact at end of the training, you can restore your checkpoint from wandb artifact directly by pass the &lt;code&gt;--wandb_artifact&lt;/code&gt; argument on commend line; In the example below, we will load our model checkpint from the wandb artifact &lt;code&gt;yiyixu/ddpm-flax-fashion-mnist/model-3j8xvqwf:v0&lt;/code&gt; and continue our training from there&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py --workdir=./fashion_mnist_wandb --mode=train --wandb_artifact=yiyixu/ddpm-flax-fashion-mnist/model-3j8xvqwf:v0 --config=configs/fashion_mnist_cpu.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Train your own model&lt;/h2&gt; &#xA;&lt;p&gt;You can customize your training either by &lt;strong&gt;update the config file&lt;/strong&gt; or &lt;strong&gt;overriding parameters on the command line&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;see more details on how to configure your training from the &lt;a href=&#34;https://github.com/yiyixuxu/denoising-diffusion-flax/raw/main/ddpm_flax_oxford102_end_to_end.ipynb&#34;&gt;notebook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yiyixuxu/denoising-diffusion-flax/raw/main/ddpm_flax_oxford102_end_to_end.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;Update the config file&lt;/h4&gt; &#xA;&lt;p&gt;You can find example configuration files under &lt;code&gt;configs/&lt;/code&gt; folder - you can create your own configuration file and run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./your_test_folder --mode=train --config=configs/your_config_file.py &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Overriding parameters on the command line&lt;/h4&gt; &#xA;&lt;p&gt;Specify a hyperparameter configuration by the means of setting &lt;code&gt;--config&lt;/code&gt; flag. Configuration flag is defined using &lt;a href=&#34;https://github.com/google/ml_collections/tree/master#config-flags&#34;&gt;config_flags&lt;/a&gt;. &lt;code&gt;config_flags&lt;/code&gt; allows overriding configuration fields. This can be done as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python main.py --workdir=./fashion_mnist_cpu --config=configs/fashion_mnist_cpu.py  \&#xA;--config.training.num_train_steps=100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Configuration&lt;/h3&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;p&gt;the script can run directly on any TensorFlow dataset, just set the configuration field &lt;code&gt;data.dataset&lt;/code&gt; to the desired dataset name. You can find a list of ready-to-use dataset [here](tensorflow dataset name &lt;a href=&#34;https://www.tensorflow.org/datasets/catalog/overview&#34;&gt;https://www.tensorflow.org/datasets/catalog/overview&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;See below the list of hyperparameters for data processing; If you are using TPU with &lt;code&gt;8&lt;/code&gt; devices, make sure your &lt;code&gt;batch_size&lt;/code&gt; is dividable by &lt;code&gt;8&lt;/code&gt;; If you set &lt;code&gt;data.image_size&lt;/code&gt; to a different size than your actual image, it will be resized, so make sure to set the size properly&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;data.dataset           &#xA;data.batch_size              &#xA;data.cache                   &#xA;data.image_size&#xA;data.channels&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;W&amp;amp;B Logging&lt;/h3&gt; &#xA;&lt;p&gt;It use Weights and Bias logging by default, if you don&#39;t already have an W&amp;amp;B acccount, you can sign up &lt;a href=&#34;https://wandb.ai/signup&#34;&gt;here&lt;/a&gt; - you will also be given option to create an account when you run the script on comand line&lt;/p&gt; &#xA;&lt;p&gt;To disable W&amp;amp;B logging, you can override with &lt;code&gt;--config&lt;/code&gt; flag on command line&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python3 main.py --workdir=./fashion-mnist --mode=train --config=configs/fashion_mnist.py --config.wandb.log_train=False&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find below list of hyperparameters for W&amp;amp;B logging in config file&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  wandb.entity = None&#xA;  wandb.project = &#34;ddpm-flax-flower102&#34;&#xA;  wandb.job_type = &#34;training&#34;&#xA;  wandb.name = None &#xA;  wandb.log_train = True&#xA;  wandb.log_sample = True&#xA;  wandb.log_model = True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;wandb.entity&lt;/code&gt;, &lt;code&gt;wandb.project&lt;/code&gt;, &lt;code&gt;wandb.job_type&lt;/code&gt; and &lt;code&gt;wandb.name&lt;/code&gt; is used to initialize the wandb run; &lt;code&gt;wandb.project&lt;/code&gt; is required field because we will create a project with that name to send the run to; all the other fields can be left as None&lt;/p&gt; &#xA;&lt;p&gt;read more about how to set up these values in Weights &amp;amp; Biase documentation about &lt;code&gt;wandb.init()&lt;/code&gt; &lt;a href=&#34;https://docs.wandb.ai/ref/python/init&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;by default, we will log training metrics (&lt;code&gt;wandb.log_train = True&lt;/code&gt;), generated samples (&lt;code&gt;wandb.log_sample = True&lt;/code&gt;), as well as the final model checkpoint (&lt;code&gt;wandb.log_model = True&lt;/code&gt;);&lt;/p&gt; &#xA;&lt;h3&gt;Predict x0&lt;/h3&gt; &#xA;&lt;p&gt;By default, we train our model to predict noise by modifying its parameterization, if you want to predict &lt;code&gt;x_0&lt;/code&gt; directly from &lt;code&gt;x_t&lt;/code&gt;, set &lt;code&gt;config.ddpm.pred_x0=True&lt;/code&gt;;&lt;/p&gt; &#xA;&lt;p&gt;The authors of DDPM paper claimed that they it lead to worse sample quality in their experiments&lt;/p&gt; &#xA;&lt;h3&gt;Self-Conditioning&lt;/h3&gt; &#xA;&lt;p&gt;Self-Conditioning is a useful technique for improving diffusion models. In a typical diffusion sampling process, the model iteratively predict &lt;code&gt;x0&lt;/code&gt; in order to gradually denoise the image, and the &lt;code&gt;x0&lt;/code&gt; estimated from previous step is discard in the new step; with self-conditioning, the model will also take previously generated samples as input.&lt;/p&gt; &#xA;&lt;p&gt;You read more about the technique in the paper &lt;a href=&#34;https://arxiv.org/abs/2208.04202&#34;&gt;Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;By default, we do not apply self-conditioning; If you wish to apply self-conditioning, set &lt;code&gt;config.ddpm.self_condition=True&lt;/code&gt;;&lt;/p&gt; &#xA;&lt;h3&gt;P2 Weighting&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;P2 (perception prioritized) weighting&lt;/strong&gt; optimizes the weighting scheme of the training objective function to improve sample quality. It encourages the diffusion model to focus on recovering signals from highly corrupted data, where the model learns global and perceptually rich concepts.&lt;/p&gt; &#xA;&lt;p&gt;You can read more about P2 weighting in the &lt;a href=&#34;https://arxiv.org/abs/2204.00227&#34;&gt;paper&lt;/a&gt; and check out the github &lt;a href=&#34;https://github.com/jychoi118/P2-weighting&#34;&gt;repo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;By default, we do not apply P2 weighting. However you can apply it by change the values of p2 hyperparameters in config file, i.e. &lt;code&gt;config.ddpm.p2_loss_weight_gamma&lt;/code&gt; and &lt;code&gt;config.ddpm.p2_loss_weight_k&lt;/code&gt;;&lt;/p&gt; &#xA;&lt;p&gt;the paper recomend use &lt;code&gt;p2_loss_weight_gamma=1&lt;/code&gt; and &lt;code&gt;p2_loss_weight_k=1&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Model EMA&lt;/h3&gt; &#xA;&lt;p&gt;By default, we will keep track of an exponential moving average version of the model and use it to generate samples. You can find the list of hyperparameters with default values for ema calculation in config file &lt;code&gt;config.ema&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  ema.beta = 0.995&#xA;  ema.update_every = 10&#xA;  ema.update_after_step = 100&#xA;  ema.inv_gamma = 1.0&#xA;  ema.power = 2 / 3&#xA;  ema.min_value = 0.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;ema.inv_gamma&lt;/code&gt; and &lt;code&gt;ema.power&lt;/code&gt; is used to calculate &lt;code&gt;ema_decay&lt;/code&gt; rate for each training step. i.e. &lt;code&gt;ema_decay = (1 + steps / config.inv_gamma) ** - config.power &lt;/code&gt;; &lt;code&gt;ema.min_value&lt;/code&gt; and &lt;code&gt;ema.beta&lt;/code&gt; determine the minimum and maximum decay rate&lt;/p&gt; &#xA;&lt;p&gt;by default, we start to average the parameters after &lt;code&gt;100&lt;/code&gt; steps (&lt;code&gt;ema.update_after_step = 100&lt;/code&gt;) and we update the average every &lt;code&gt;10&lt;/code&gt; steps (&lt;code&gt;ema.update_every = 10&lt;/code&gt;)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>yuanxiaosc/Machine-Learning-Book</title>
    <updated>2022-09-30T01:39:52Z</updated>
    <id>tag:github.com,2022-09-30:/yuanxiaosc/Machine-Learning-Book</id>
    <link href="https://github.com/yuanxiaosc/Machine-Learning-Book" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《机器学习宝典》包含：谷歌机器学习速成课程（招式）+机器学习术语表（口诀）+机器学习规则（心得）+机器学习中的常识性问题 （内功）。该资源适用于机器学习、深度学习研究人员和爱好者参考！&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine-Learning-Book&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/yuanxiaosc/Machine-Learning-Book&#34;&gt;Machine-Learning-Book（机器学习宝典）&lt;/a&gt;涵盖了从机器学习从入门到精通所需的所有必备知识。&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;其中《&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E5%BD%A9%E5%9B%BE%E7%89%88.pdf&#34;&gt;机器学习知识点彩图版.pdf&lt;/a&gt;》以生动形象的图片描述机器学习中的知识点。&lt;/li&gt; &#xA; &lt;li&gt;其中《&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B.pdf&#34;&gt;Google机器学习速成课程.pdf&lt;/a&gt;》以加利福尼亚房价预测为线索，讲解了机器学习概念、特征工程以及机器学习在现实世界的应用。该课程有对应知识点的习题和解答，你可以随时检测自己的学习效果。&lt;/li&gt; &#xA; &lt;li&gt;其中《&lt;a href=&#34;https://yuanxiaosc.github.io/2019/08/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%AF%86%E6%80%A7%E9%97%AE%E9%A2%98/&#34;&gt;机器学习中的常识性问题 (最新网页版)&lt;/a&gt;》 ， 该文系统性总结了机器学习基础知识。比如你了解机器学习中常见的二分类问题评价指标：混淆矩阵、准确率、精确率、召回率、敏感性、特异性、AUC、ROC以及它们之间的关系吗？（答案见文末）&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/%E5%9B%BE%E7%89%87/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BD%A9%E5%9B%BE%E7%89%88-%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E6%9D%83%E8%A1%A1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;center&gt;&#xA; 机器学习彩图版-偏差和方差的权衡&#xA;&lt;/center&gt; &#xA;&lt;h2&gt;机器学习宝典内容汇总&lt;/h2&gt; &#xA;&lt;p&gt;百度网盘打包下载本资源：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;链接：&lt;a href=&#34;https://pan.baidu.com/s/1OLscfquhYKOuN7X-QVqQNA&#34;&gt;https://pan.baidu.com/s/1OLscfquhYKOuN7X-QVqQNA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;提取码：6g4l&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;标签&lt;/th&gt; &#xA;   &lt;th&gt;名称&lt;/th&gt; &#xA;   &lt;th&gt;说明&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;养兴趣&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%E5%BD%A9%E5%9B%BE%E7%89%88.pdf&#34;&gt;机器学习知识点彩图版.pdf&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;以生动形象的图片描述机器学习中的知识点。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;练招式&lt;/td&gt; &#xA;   &lt;td&gt;完整版&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B.md&#34;&gt;Google机器学习速成课程.md&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B.pdf&#34;&gt;Google机器学习速成课程.pdf&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8BCode&#34;&gt;谷歌机器学习速成课程-配套TensorFlow代码&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;本文讲解了机器学习概念、特征工程以及机器学习在现实世界的应用。解决了：加利福利亚房价预测问题（回归问题）+分类问题+手写字体识别问题&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;口诀&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E8%A1%A8GoogleDevelopers.pdf&#34;&gt;机器学习术语表（PDF）&lt;/a&gt; or &lt;a href=&#34;https://developers.google.com/machine-learning/glossary/&#34;&gt;机器学习术语表（网页版）&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;本术语表中列出了一般的机器学习术语和 TensorFlow 专用术语的定义。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;心得&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%99GoogleDevelopers.pdf&#34;&gt;机器学习规则（PDF）&lt;/a&gt; or &lt;a href=&#34;https://developers.google.com/machine-learning/guides/rules-of-ml/&#34;&gt;机器学习规则（网页版）&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;本文档旨在帮助已掌握机器学习基础知识的人员从 Google 机器学习的最佳实践（经验）中受益。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;练内功&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%AF%86%E6%80%A7%E9%97%AE%E9%A2%98_%E6%9C%9B%E6%B1%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E5%BA%93.pdf&#34;&gt;机器学习中的常识性问题（PDF）&lt;/a&gt; or &lt;a href=&#34;https://yuanxiaosc.github.io/2019/08/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%AF%86%E6%80%A7%E9%97%AE%E9%A2%98/&#34;&gt;机器学习中的常识性问题 (最新网页版)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;系统性深入学习机器学习。机器学习中的常识性问题定义：作为一名合格的机器学习从业人员必须理解的机器学习领域的常识性问题。&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;开始学习 练招式&lt;/h2&gt; &#xA;&lt;p&gt;点击开始学习完整版 &lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B.md&#34;&gt;Google机器学习速成课程.md&lt;/a&gt;，也可以下载完整版&lt;a href=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/PDF/Google%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%80%9F%E6%88%90%E8%AF%BE%E7%A8%8B.pdf&#34;&gt;Google机器学习速成课程.pdf&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h2&gt;学习进阶 练内功&lt;/h2&gt; &#xA;&lt;p&gt;机器学习中的常识性问题定义：作为一名合格的机器学习从业人员必须理解的机器学习领域的常识性问题。&lt;/p&gt; &#xA;&lt;p&gt;点击开始学习 &lt;a href=&#34;https://yuanxiaosc.github.io/2019/08/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%AF%86%E6%80%A7%E9%97%AE%E9%A2%98/&#34;&gt;机器学习中的常识性问题&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;机器学习中常见的二分类问题评价指标：混淆矩阵、准确率、精确率、召回率、敏感性、特异性、AUC、ROC以及它们之间的关系吗？&lt;/p&gt; &#xA;&lt;p&gt;答案：&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/%E5%9B%BE%E7%89%87/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E5%92%8C12%E7%8E%87%E5%85%AC%E5%BC%8F.png&#34; alt=&#34;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/yuanxiaosc/Machine-Learning-Book/master/%E5%9B%BE%E7%89%87/%E4%BA%8C%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87%E8%A1%A8%E6%A0%BC.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>