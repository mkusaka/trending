<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-24T01:33:13Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>MetaGLM/glm-cookbook</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/MetaGLM/glm-cookbook</id>
    <link href="https://github.com/MetaGLM/glm-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Zhipu API series cookbook&lt;/p&gt;&lt;hr&gt;&lt;h1&gt; &lt;img src=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/asset/glm.png&#34; alt=&#34;glm&#34; style=&#34;height: 1.5em; vertical-align: bottom;&#34;&gt; glm-cookbook &lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/README_en.md&#34;&gt;Read this in English&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;æ¬¢è¿æ¥åˆ° GLM API æ¨¡å‹å…¥é—¨ä»“åº“ğŸ“˜ã€‚è¿™æ˜¯ä¸€æœ¬å¼€æºçš„ GLM API å…¥é—¨ä»£ç æ•™æã€‚&lt;/p&gt; &#xA;&lt;p&gt;åœ¨è¿™é‡Œï¼Œä½ ä¼šå‘ç°ä¸°å¯Œçš„ &lt;strong&gt;ä»£ç ç¤ºä¾‹ğŸ‘¨â€&lt;/strong&gt;ã€&lt;strong&gt;å®ç”¨æŒ‡å—ğŸ—º&lt;/strong&gt;ï¸ ä»¥åŠ &lt;strong&gt;èµ„æºé“¾æ¥ğŸ”—&lt;/strong&gt;ï¼Œæˆ–è®¸èƒ½å¸®åŠ©ä½ è½»æ¾æŒæ¡ GLM API çš„ä½¿ç”¨ï¼&lt;/p&gt; &#xA;&lt;h2&gt;æ›´æ–°æƒ…å†µ ğŸ”¥&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ğŸ”¥ 2024-03-18: ä»“åº“å¼€å§‹æ›´æ–° &lt;a href=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/Users/zr/Code/glm-cookbook/glms&#34;&gt;æ™ºè°±æ¸…è¨€&lt;/a&gt; åŸºç¡€å¼€å‘è€…æ•™å­¦æ–‡æ¡£ï¼ŒåŸºç¡€æç¤ºè¯æ–‡æ¡£ å’Œ æ™ºèƒ½ä½“æ–‡æ¡£ å·²ç»åœ¨ &lt;a href=&#34;https://zhipu-ai.feishu.cn/wiki/SPyFwjSI7iOCoCksq2sc3Eb7nXd&#34;&gt;æŠ€æœ¯æ–‡æ¡£&lt;/a&gt; æ¨å‡ºï¼Œæ¬¢è¿ä½“éªŒå’Œç•™è¨€ï¼Œæˆ‘ä»¬å°†ç»§ç»­å¿«é€Ÿè¿­ä»£ï¼&lt;/li&gt; &#xA; &lt;li&gt;ğŸ”¥ 2024-03-06: ä»“åº“æ‰€åœ¨ç»„ç»‡ &lt;a href=&#34;https://github.com/MetaGLM&#34;&gt;MetaGLM&lt;/a&gt; æ›´æ–°äº†4é—¨è¯­è¨€ (Python, Java,C#,Node.js) çš„SDKï¼Œæ¬¢è¿æå‡ºæ„è§å’Œå¯¹é¡¹ç›®è¿›è¡ŒPRï¼&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å¿«é€Ÿå¼€å§‹ ğŸš€&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;è¦å¼€å§‹ä½¿ç”¨GLM APIï¼Œä½ é¦–å…ˆéœ€è¦ä¸€ä¸ª GLM API è´¦æˆ·å’Œç›¸åº”çš„ API å¯†é’¥ã€‚ å¦‚æœä½ è¿˜æ²¡æœ‰è´¦æˆ·ï¼Œå¯ä»¥åœ¨ &lt;a href=&#34;https://open.bigmodel.cn/&#34;&gt;è¿™é‡Œ&lt;/a&gt; å…è´¹æ³¨å†Œã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;æˆ‘çš„ä»£ç ä»¥ &lt;strong&gt;Python, Jupyter Note&lt;/strong&gt; ä¸ºä¸»ï¼Œä½†åŒæ ·çš„æ¦‚å¿µä¹Ÿå¯ä»¥åº”ç”¨äºå…¶ä»–ç¼–ç¨‹è¯­è¨€ï¼ˆä¸è¿‡è¿™å¯èƒ½è¦ä½ ä»¬è‡ªå·±å®ç°å’¯ï¼‰ã€‚ è¿™äº›ä»£ç ç¤ºä¾‹æ—¨åœ¨å¸®åŠ©æˆ‘ï¼ˆæˆ–è®¸ä¹Ÿèƒ½å¯¹ä½ ï¼‰å¦‚ä½•é«˜æ•ˆåœ°ä½¿ç”¨ GLM API å®Œæˆå¸¸è§çš„ç®€å•ä»»åŠ¡ã€‚ æ¨èä½¿ç”¨&lt;code&gt;Python 3.9 - 3.12&lt;/code&gt; çš„ç‰ˆæœ¬ï¼ˆæˆ‘è‡ªå·±æ˜¯Python 3.10ï¼‰ã€‚ä½ éœ€è¦å®‰è£…å¿…é¡»çš„ä¾èµ–ï¼Œæ‰èƒ½æ›´å¥½çš„ä½¿ç”¨ Demoã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥å®‰è£…æ€»çš„ä¾èµ–ï¼š&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;å¯¹äº†ï¼Œæˆ‘ä¸€èˆ¬ä½¿ç”¨ âœ…GLM4 æ¥å®Œæˆä»»åŠ¡ï¼Œæˆ‘ä¹Ÿæ¨èä½ ä½¿ç”¨è¿™ä¸ªæ¨¡å‹å“¦ï¼&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;ä»“åº“æ–‡ä»¶ ğŸ“‚&lt;/h2&gt; &#xA;&lt;p&gt;æˆ‘å·²ç»åˆ†ç±»å¥½äº†å¤šä¸ªæ–‡ä»¶å¤¹ï¼Œè¿™äº›æ–‡ä»¶å¤¹éƒ½æœ‰è‡ªå·±çš„å†…å®¹ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚æ¥æŸ¥çœ‹ï¼&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸŒ±&lt;code&gt;basic&lt;/code&gt; æœ€åŸºç¡€çš„å†…å®¹ï¼Œå¸®åŠ©ä½ ç†Ÿæ‚‰åŸºæœ¬çš„ API è°ƒç”¨ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ‘ï¸&lt;code&gt;vision&lt;/code&gt; å…³äºè§†è§‰æ¨¡å‹å’Œç»˜å›¾æ¨¡å‹çš„è°ƒç”¨å’ŒåŸºæœ¬åº”ç”¨ã€‚&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ”§&lt;code&gt;finetune&lt;/code&gt; æˆ–è®¸å¯ä»¥æ¥è¿™é‡Œæ‰¾æ‰¾å¾®è°ƒçš„å†…å®¹ï¼Ÿ&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ‰&lt;code&gt;demo&lt;/code&gt; ä¸€äº›æœ‰è¶£çš„å°é¡¹ç›®ï¼Œæˆ–è®¸å¯ä»¥æ¿€å‘ç‚¹çµæ„Ÿã€‚&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ğŸ¤–&lt;code&gt;agent&lt;/code&gt; çœ‹çœ‹å‘å¸ƒä¼šçš„æ™ºèƒ½ä½“æœ‰å¤šå‰å®³ï¼&lt;/li&gt; &#xA;   &lt;li&gt;ğŸ“š&lt;code&gt;data&lt;/code&gt; è¿è¡Œdemoæ‰€éœ€è¦çš„æ•°æ®ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ“Š&lt;code&gt;glms&lt;/code&gt; æ™ºèƒ½ä½“ (æ™ºè°±æ¸…è¨€) ä¸“åŒºï¼Œå³ä½¿ä½ ä¸ä¼šä»£ç ï¼Œä¹Ÿèƒ½å¿«é€Ÿä¸Šæ‰‹ï¼&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;ğŸ &lt;code&gt;asset&lt;/code&gt; ä¸€äº›ç›¸å…³çš„å›¾ç‰‡èµ„æ–™&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å›¾ç‰‡å¿«é€Ÿäº†è§£æœ¬ä»“åº“æ„æˆ, æˆ‘å°†å°½å¿«åŒæ­¥æ›´æ–° Zhipu AI SDKçš„æœ€æ–°å®éªŒå’Œæ•™å­¦å†…å®¹ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/MetaGLM/glm-cookbook/main/asset/plan.png&#34; alt=&#34;å®ç°åŸç†å›¾&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;å¼€æºSDK&lt;/h2&gt; &#xA;&lt;p&gt;GLM-4ç³»åˆ—SDKå·²ç»å¼€æºï¼Œå¦‚æœä½ æƒ³ç›´æ¥åœ¨æˆ‘ä»¬çš„SDKä¸Šè¿›è¡Œä¿®æ”¹ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹åœ°å€è¿›è¡Œéœ€æ”¹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-python-v4&#34;&gt;Python SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-java-v4&#34;&gt;Java SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-csharp-v4&#34;&gt;C# SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MetaGLM/zhipuai-sdk-nodejs-v4&#34;&gt;Node.js SDK&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;å¦‚æœä½ æœ‰å…¶ä»–è¯­è¨€çš„SDKæƒ³è´¡çŒ®åˆ°å®˜æ–¹ä»“åº“ï¼Œæ¬¢è¿æå‡ºPRã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;è´¡çŒ®æŒ‡å— ğŸ¤&lt;/h2&gt; &#xA;&lt;p&gt;æ¬¢è¿å¤§å®¶è´¡çŒ®è‡ªå·±çš„æƒ³æ³•å’Œä»£ç ï¼å¦‚æœä½ æœ‰ä»»ä½•å»ºè®®æˆ–æƒ³æ·»åŠ è‡ªå·±çš„ä»£ç ï¼Œè¯·éšæ—¶æäº¤ Pull Request æˆ–å¼€ Issue è®¨è®ºã€‚ å¦‚æœä½ å–œæ¬¢è¿™ä¸ªä»“åº“ï¼Œæ¬¢è¿ç»™å®ƒä¸€ä¸ª â­ï¼Œè¿™å°†å¯¹æˆ‘æœ‰å¾ˆå¤§å¸®åŠ©ï¼&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ora-io/keras2circom</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/ora-io/keras2circom</id>
    <link href="https://github.com/ora-io/keras2circom" rel="alternate"></link>
    <summary type="html">&lt;p&gt;python tool to transpile a tf.keras model into a circom circuit&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;keras2circom&lt;/h1&gt; &#xA;&lt;p&gt;keras2circom is a python tool that transpiles a tf.keras model into a circom circuit.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;First, clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/socathie/keras2circom.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, install the dependencies. You can use pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use conda, you can also create a new environment with the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You will also need to install circom and snarkjs. You can run the following commands to install them:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash setup-circom.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Last but not least, run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;To use the package, you can run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py &amp;lt;model_path&amp;gt; [-o &amp;lt;output_dir&amp;gt;] [--raw]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example, to transpile the model in &lt;code&gt;models/model.h5&lt;/code&gt; into a circom circuit, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py models/model.h5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The output will be in the &lt;code&gt;output&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;If you want to transpile the model into a circom circuit with &#34;raw&#34; output, i.e. no ArgMax at the end, you can run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py models/model.h5 --raw&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Testing&lt;/h2&gt; &#xA;&lt;p&gt;To test the package, you can run the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;npm test&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>lichao-sun/Mora</title>
    <updated>2024-03-24T01:33:13Z</updated>
    <id>tag:github.com,2024-03-24:/lichao-sun/Mora</id>
    <link href="https://github.com/lichao-sun/Mora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Mora: More like Sora for Generalist Video Generation&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mora: More like Sora for Generalist Video Generation&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ğŸ” See our newest Video Generation paper: &lt;a href=&#34;http://arxiv.org/abs/2403.13248&#34;&gt;&lt;strong&gt;&#34;Mora: Enabling Generalist Video Generation via A Multi-Agent Framework&#34;&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;http://arxiv.org/abs/2403.13248&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Paper-%F0%9F%8E%93-lightblue?style=flat-square&#34; alt=&#34;Paper&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lichao-sun/Mora&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gtihub-%F0%9F%8E%93-lightblue?style=flat-square&#34; alt=&#34;GitHub&#34;&gt;)&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;ğŸ“§ Please let us know if you find a mistake or have any suggestions by e-mail: &lt;a href=&#34;mailto:lis221@lehigh.edu&#34;&gt;lis221@lehigh.edu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ğŸ“°News&lt;/h2&gt; &#xA;&lt;p&gt;ğŸš€ï¸ Mar 20: Our paper &#34;&lt;a href=&#34;https://arxiv.org/abs/2403.13248&#34;&gt;Mora: Enabling Generalist Video Generation via A Multi-Agent Framework&lt;/a&gt;&#34; is released!&lt;/p&gt; &#xA;&lt;h2&gt;What is Mora&lt;/h2&gt; &#xA;&lt;p&gt;Mora is a multi-agent framework designed to facilitate generalist video generation tasks, leveraging a collaborative approach with multiple visual agents. It aims to replicate and extend the capabilities of OpenAI&#39;s Sora. &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task.jpg&#34; alt=&#34;Task&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¥Demo (1024Ã—576 resolution, 12 seconds and more!)&lt;/h2&gt; &#xA;&lt;p align=&#34;left&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo1.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo2.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo3.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/demo4.gif&#34; width=&#34;49%&#34; height=&#34;auto&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Mora: A Multi-Agent Framework for Video Generation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/method.jpg&#34; alt=&#34;test image&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Multi-Agent Collaboration&lt;/strong&gt;: Utilizes several advanced visual AI agents, each specializing in different aspects of the video generation process, to achieve high-quality outcomes across various tasks.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Broad Spectrum of Tasks&lt;/strong&gt;: Capable of performing text-to-video generation, text-conditional image-to-video generation, extending generated videos, video-to-video editing, connecting videos, and simulating digital worlds, thereby covering an extensive range of video generation applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open-Source and Extendable&lt;/strong&gt;: Moraâ€™s open-source nature fosters innovation and collaboration within the community, allowing for continuous improvement and customization.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Proven Performance&lt;/strong&gt;: Experimental results demonstrate Mora&#39;s ability to achieve performance that is close to that of Sora in various tasks, making it a compelling open-source alternative for the video generation domain.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;h3&gt;Text-to-video generation&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input prompt&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Output video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A vibrant coral reef teeming with life under the crystal-clear blue ocean, with colorful fish swimming among the coral, rays of sunlight filtering through the water, and a gentle current moving the sea plants. &lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_1.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A majestic mountain range covered in snow, with the peaks touching the clouds and a crystal-clear lake at its base, reflecting the mountains and the sky, creating a breathtaking natural mirror.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_2.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;In the middle of a vast desert, a golden desert city appears on the horizon, its architecture a blend of ancient Egyptian and futuristic elements.The city is surrounded by a radiant energy barrier, while in the air, seve&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task_1_demo_3.gif&#34; width=&#34;480&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Text-conditional image-to-video generation&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input prompt&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input image&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora generated Video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora generated Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Monster Illustration in the flat design style of a diverse family of monsters. The group includes a furry brown monster, a sleek black monster with antennas, a spotted green monster, and a tiny polka-dotted monster, all interacting in a playful environment. &lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/input1.jpg&#34; width=&#34;600&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task2_demo1.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/sora_demo1.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;An image of a realistic cloud that spells â€œSORAâ€.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/input2.jpg&#34; width=&#34;600&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task2_demo2.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/sora_demo2.gif&#34; width=&#34;160&#34; height=&#34;90&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Extend generated video&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Original video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora extended video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora extended video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;./image/original video.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/mora_task3.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task3_sora.gif&#34; width=&#34;330&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Video-to-video editing&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Instruction&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Original video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora edited Video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora edited Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Change the setting to the 1920s with an old school car. make sure to keep the red color.&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_original.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_mora_1920.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_sora_1920.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Put the video in space with a rainbow road&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_original.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_mora_rainbow.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task4_sora_rainbow.gif&#34; width=&#34;240&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Connect videos&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input previous video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Input next video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Output connect Video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora1.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora2.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_mora.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora1.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora2.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task5_sora.gif&#34; width=&#34;300&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Simulate digital worlds&lt;/h3&gt; &#xA;&lt;table class=&#34;left&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Mora simulating video&lt;/b&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;b&gt;Sora simulating video&lt;/b&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_mora1.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_sora1.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_mora2.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lichao-sun/Mora/main/image/task6_sora2.gif&#34; width=&#34;100%&#34; height=&#34;auto&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Code will be released as soon as possible!&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{yuan2024mora,&#xA;  title={Mora: Enabling Generalist Video Generation via A Multi-Agent Framework},&#xA;  author={Yuan, Zhengqing and Chen, Ruoxi and Li, Zhaoxu and Jia, Haolong and He, Lifang and Wang, Chi and Sun, Lichao},&#xA;  journal={arXiv preprint arXiv:2403.13248},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{liu2024sora,&#xA;  title={Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models},&#xA;  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},&#xA;  journal={arXiv preprint arXiv:2402.17177},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{openai2024sorareport,&#xA;  title={Video generation models as world simulators},&#xA;  author={OpenAI},&#xA;  year={2024},&#xA;  howpublished={https://openai.com/research/video-generation-models-as-world-simulators},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>