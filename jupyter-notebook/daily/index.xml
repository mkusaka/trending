<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-27T01:38:22Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>makcedward/nlpaug</title>
    <updated>2023-01-27T01:38:22Z</updated>
    <id>tag:github.com,2023-01-27:/makcedward/nlpaug</id>
    <link href="https://github.com/makcedward/nlpaug" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Data augmentation for NLP&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://github.com/makcedward/nlpaug/raw/master/res/logo_small.png&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://travis-ci.org/makcedward/nlpaug&#34;&gt; &lt;img alt=&#34;Build&#34; src=&#34;https://travis-ci.org/makcedward/nlpaug.svg?branch=master&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.codacy.com/app/makcedward/nlpaug?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=makcedward/nlpaug&amp;amp;utm_campaign=Badge_Grade&#34;&gt; &lt;img alt=&#34;Code Quality&#34; src=&#34;https://api.codacy.com/project/badge/Grade/2d6d1d08016a4f78818161a89a2dfbfb&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://pepy.tech/badge/nlpaug&#34;&gt; &lt;img alt=&#34;Downloads&#34; src=&#34;https://pepy.tech/badge/nlpaug&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;nlpaug&lt;/h1&gt; &#xA;&lt;p&gt;This python library helps you with augmenting nlp for your machine learning projects. Visit this introduction to understand about &lt;a href=&#34;https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28&#34;&gt;Data Augmentation in NLP&lt;/a&gt;. &lt;code&gt;Augmenter&lt;/code&gt; is the basic element of augmentation while &lt;code&gt;Flow&lt;/code&gt; is a pipeline to orchestra multi augmenter together.&lt;/p&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Generate synthetic data for improving model performance without manual effort&lt;/li&gt; &#xA; &lt;li&gt;Simple, easy-to-use and lightweight library. Augment data in 3 lines of code&lt;/li&gt; &#xA; &lt;li&gt;Plug and play to any machine leanring/ neural network frameworks (e.g. scikit-learn, PyTorch, TensorFlow)&lt;/li&gt; &#xA; &lt;li&gt;Support textual and audio input&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;Textual Data Augmentation Example&lt;/h3&gt; &#xA;&lt;br&gt;&#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/makcedward/nlpaug/raw/master/res/textual_example.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34;&gt;Acoustic Data Augmentation Example&lt;/h3&gt; &#xA;&lt;br&gt;&#xA;&lt;p align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/makcedward/nlpaug/raw/master/res/audio_example.png&#34;&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Section&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#quick-demo&#34;&gt;Quick Demo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;How to use this library&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#augmenter&#34;&gt;Augmenter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Introduce all available augmentation methods&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#installation&#34;&gt;Installation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;How to install this library&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#recent-changes&#34;&gt;Recent Changes&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Latest enhancement&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#extension-reading&#34;&gt;Extension Reading&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;More real life examples or researchs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug#reference&#34;&gt;Reference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Reference of external resources such as data or model&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Quick Demo&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/quick_example.ipynb&#34;&gt;Quick Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/textual_augmenter.ipynb&#34;&gt;Example of Augmentation for Textual Inputs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/textual_language_augmenter.ipynb&#34;&gt;Example of Augmentation for Multilingual Textual Inputs &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/spectrogram_augmenter.ipynb&#34;&gt;Example of Augmentation for Spectrogram Inputs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/audio_augmenter.ipynb&#34;&gt;Example of Augmentation for Audio Inputs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/flow.ipynb&#34;&gt;Example of Orchestra Multiple Augmenters&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/change_log.ipynb&#34;&gt;Example of Showing Augmentation History&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;How to train &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/tfidf-train_model.ipynb&#34;&gt;TF-IDF model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;How to train &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/lambada-train_model.ipynb&#34;&gt;LAMBADA model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;How to create &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/example/custom_augmenter.ipynb&#34;&gt;custom augmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://nlpaug.readthedocs.io/en/latest/&#34;&gt;API Documentation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Augmenter&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Augmenter&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Target&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Augmenter&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Action&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Character&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;KeyboardAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simulate keyboard distance error&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;OcrAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Simulate OCR engine error&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c&#34;&gt;RandomAug&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;insert, substitute, swap, delete&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Apply augmentation randomly&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Word&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;AntonymAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Substitute opposite meaning word according to WordNet antonym&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ContextualWordEmbsAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;insert, substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Feeding surroundings word to &lt;a href=&#34;https://towardsdatascience.com/how-bert-leverage-attention-mechanism-and-transformer-to-learn-word-contextual-relations-5bbee1b6dbdb&#34;&gt;BERT&lt;/a&gt;, DistilBERT, &lt;a href=&#34;https://medium.com/towards-artificial-intelligence/a-robustly-optimized-bert-pretraining-approach-f6b6e537e6a6&#34;&gt;RoBERTa&lt;/a&gt; or &lt;a href=&#34;https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b&#34;&gt;XLNet&lt;/a&gt; language model to find out the most suitlabe word for augmentation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;RandomWordAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;swap, crop, delete&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Apply augmentation randomly&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SpellingAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Substitute word according to spelling mistake dictionary&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SplitAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;split&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Split one word to two words randomly&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SynonymAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Substitute similar word according to WordNet/ PPDB synonym&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143&#34;&gt;TfIdfAug&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;insert, substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Use TF-IDF to find out how word should be augmented&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;WordEmbsAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;insert, substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Leverage &lt;a href=&#34;https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a&#34;&gt;word2vec&lt;/a&gt;, &lt;a href=&#34;https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a&#34;&gt;GloVe&lt;/a&gt; or &lt;a href=&#34;https://towardsdatascience.com/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a&#34;&gt;fasttext&lt;/a&gt; embeddings to apply augmentation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28&#34;&gt;BackTranslationAug&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Leverage two translation models for augmentation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ReservedAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Replace reserved words&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Sentence&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ContextualWordEmbsForSentenceAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;insert&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Insert sentence according to &lt;a href=&#34;https://medium.com/dataseries/why-does-xlnet-outperform-bert-da98a8503d5b&#34;&gt;XLNet&lt;/a&gt;, &lt;a href=&#34;https://towardsdatascience.com/too-powerful-nlp-model-generative-pre-training-2-4cc6afb6655&#34;&gt;GPT2&lt;/a&gt; or DistilGPT2 prediction&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;AbstSummAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Summarize article by abstractive summarization method&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Textual&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LambadaAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Using language model to generate text and then using classification model to retain high quality results&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Audio&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;CropAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;delete&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Delete audio&#39;s segment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LoudnessAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Adjust audio&#39;s volume&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;MaskAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Mask audio&#39;s segment&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;NoiseAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Inject noise&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PitchAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Adjust audio&#39;s pitch&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;ShiftAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Shift time dimension forward/ backward&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;SpeedAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Adjust audio&#39;s speed&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;VtlpAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Change vocal tract&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;NormalizeAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Normalize audio&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;PolarityInverseAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Swap positive and negative for audio&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Spectrogram&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;FrequencyMaskingAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Set block of values to zero according to frequency dimension&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;TimeMaskingAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Set block of values to zero according to time dimension&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Signal&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;LoudnessAug&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;substitute&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Adjust volume&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Flow&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Augmenter&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Augmenter&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Pipeline&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Sequential&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Apply list of augmentation functions sequentially&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Pipeline&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Sometimes&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Apply some augmentation functions randomly&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;The library supports python 3.5+ in linux and window platform.&lt;/p&gt; &#xA;&lt;p&gt;To install the library:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install numpy requests nlpaug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or install the latest version (include BETA features) from github directly&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install numpy git+https://github.com/makcedward/nlpaug.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or install over conda&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install -c makcedward nlpaug&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use BackTranslationAug, ContextualWordEmbsAug, ContextualWordEmbsForSentenceAug and AbstSummAug, installing the following dependencies as well&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install torch&amp;gt;=1.6.0 transformers&amp;gt;=4.11.3 sentencepiece&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use LambadaAug, installing the following dependencies as well&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install simpletransformers&amp;gt;=0.61.10&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use AntonymAug, SynonymAug, installing the following dependencies as well&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install nltk&amp;gt;=3.4.5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use WordEmbsAug (word2vec, glove or fasttext), downloading pre-trained model first and installing the following dependencies as well&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;from nlpaug.util.file.download import DownloadUtil&#xA;DownloadUtil.download_word2vec(dest_dir=&#39;.&#39;) # Download word2vec model&#xA;DownloadUtil.download_glove(model_name=&#39;glove.6B&#39;, dest_dir=&#39;.&#39;) # Download GloVe model&#xA;DownloadUtil.download_fasttext(model_name=&#39;wiki-news-300d-1M&#39;, dest_dir=&#39;.&#39;) # Download fasttext model&#xA;&#xA;pip install gensim&amp;gt;=4.1.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use SynonymAug (PPDB), downloading file from the following URI. You may not able to run the augmenter if you get PPDB file from other website&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;http://paraphrase.org/#/download&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you use PitchAug, SpeedAug and VtlpAug, installing the following dependencies as well&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install librosa&amp;gt;=0.9.1 matplotlib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Recent Changes&lt;/h2&gt; &#xA;&lt;h3&gt;1.1.11 Jul 6, 2022&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/issues/302&#34;&gt;Return list of output&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/issues/301&#34;&gt;Fix download util&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/issues/295&#34;&gt;Fix lambda label misalignment&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/makcedward/nlpaug/issues/289&#34;&gt;Add language pack reference link for SynonymAug&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/CHANGE.md&#34;&gt;changelog&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Extension Reading&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/data-augmentation-library-for-text-9661736b13ff&#34;&gt;Data Augmentation library for Text&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/hackernoon/does-your-nlp-model-able-to-prevent-adversarial-attack-45b5ab75129c&#34;&gt;Does your NLP model able to prevent adversarial attack?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/how-does-data-noising-help-to-improve-your-nlp-model-480619f9fb10&#34;&gt;How does Data Noising Help to Improve your NLP Model?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/data-augmentation-for-speech-recognition-e7c607482e78&#34;&gt;Data Augmentation library for Speech Recognition&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/data-augmentation-for-audio-76912b01fdf6&#34;&gt;Data Augmentation library for Audio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/towards-artificial-intelligence/unsupervised-data-augmentation-6760456db143&#34;&gt;Unsupervied Data Augmentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/05/data-augmentation-for-nlp/&#34;&gt;A Visual Survey of Data Augmentation in NLP&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;p&gt;This library uses data (e.g. capturing from internet), research (e.g. following augmenter idea), model (e.g. using pre-trained model) See &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/SOURCE.md&#34;&gt;data source&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@misc{ma2019nlpaug,&#xA;  title={NLP Augmentation},&#xA;  author={Edward Ma},&#xA;  howpublished={https://github.com/makcedward/nlpaug},&#xA;  year={2019}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This package is cited by many books, workshop and academic research papers (70+). Here are some of examples and you may visit &lt;a href=&#34;https://github.com/makcedward/nlpaug/raw/master/CITED.md&#34;&gt;here&lt;/a&gt; to get the full list.&lt;/p&gt; &#xA;&lt;h3&gt;Workshops cited nlpaug&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;S. Vajjala. &lt;a href=&#34;https://rpubs.com/vbsowmya/tmls2021&#34;&gt;NLP without a readymade labeled dataset&lt;/a&gt; at &lt;a href=&#34;https://www.torontomachinelearning.com/&#34;&gt;Toronto Machine Learning Summit, 2021&lt;/a&gt;. 2021&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Book cited nlpaug&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;S. Vajjala, B. Majumder, A. Gupta and H. Surana. &lt;a href=&#34;https://www.amazon.com/Practical-Natural-Language-Processing-Pragmatic/dp/1492054054&#34;&gt;Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems&lt;/a&gt;. 2020&lt;/li&gt; &#xA; &lt;li&gt;A. Bartoli and A. Fusiello. &lt;a href=&#34;https://books.google.com/books?hl=en&amp;amp;lr=lang_en&amp;amp;id=0rYREAAAQBAJ&amp;amp;oi=fnd&amp;amp;pg=PR7&amp;amp;dq=nlpaug&amp;amp;ots=88bPp5rhnY&amp;amp;sig=C2ue8Xxbu09l59nAMOcVxWYvvWM#v=onepage&amp;amp;q=nlpaug&amp;amp;f=false&#34;&gt;Computer Vision‚ÄìECCV 2020 Workshops&lt;/a&gt;. 2020&lt;/li&gt; &#xA; &lt;li&gt;L. Werra, L. Tunstall, and T. Wolf &lt;a href=&#34;https://www.amazon.com/Natural-Language-Processing-Transformers-Applications/dp/1098103246/ref=sr_1_3?crid=2CWBPA8QG0TRU&amp;amp;keywords=Natural+Language+Processing+with+Transformers&amp;amp;qid=1645646312&amp;amp;sprefix=natural+language+processing+with+transformers%2Caps%2C111&amp;amp;sr=8-3&#34;&gt;Natural Language Processing with Transformers&lt;/a&gt;. 2022&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Research paper cited nlpaug&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Google: M. Raghu and E. Schmidt. &lt;a href=&#34;https://arxiv.org/pdf/2003.11755.pdf&#34;&gt;A Survey of Deep Learning for Scientific Discovery&lt;/a&gt;. 2020&lt;/li&gt; &#xA; &lt;li&gt;Sirius XM: E. Jing, K. Schneck, D. Egan and S. A. Waterman. &lt;a href=&#34;https://arxiv.org/pdf/2110.07096.pdf&#34;&gt;Identifying Introductions in Podcast Episodes from Automatically Generated Transcripts&lt;/a&gt;. 2021&lt;/li&gt; &#xA; &lt;li&gt;Salesforce Research: B. Newman, P. K. Choubey and N. Rajani. &lt;a href=&#34;https://arxiv.org/pdf/2110.07280.pdf&#34;&gt;P-adapters: Robustly Extracting Factual Information from Language Modesl with Diverse Prompts&lt;/a&gt;. 2021&lt;/li&gt; &#xA; &lt;li&gt;Salesforce Research: L. Xue, M. Gao, Z. Chen, C. Xiong and R. Xu. &lt;a href=&#34;https://arxiv.org/pdf/2110.04413.pdf&#34;&gt;Robustness Evaluation of Transformer-based Form Field Extractors via Form Attacks&lt;/a&gt;. 2021&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributions&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/sakares&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/1306031&#34; width=&#34;100px;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;sakares saengkaew&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bdalal&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/3478378?s=400&amp;amp;v=4&#34; width=&#34;100px;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Binoy Dalal&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/emrecncelik&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/20845117?v=4&#34; width=&#34;100px;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Emrecan √áelik&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>stanfordnlp/dsp</title>
    <updated>2023-01-27T01:38:22Z</updated>
    <id>tag:github.com,2023-01-27:/stanfordnlp/dsp</id>
    <link href="https://github.com/stanfordnlp/dsp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Demonstrate-Search-Predict Framework: Composing retrieval and language models for knowledge-intensive NLP&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üéìùóóùó¶ùó£: Demonstrate‚ÄìSearch‚ÄìPredict&lt;/h1&gt; &#xA;&lt;p&gt;A framework for composing retrieval models and language models into powerful pipelines that tackle knowledge-intensive tasks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2212.14024.pdf&#34;&gt;Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;pip install dsp-ml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üèÉ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Our &lt;a href=&#34;https://raw.githubusercontent.com/stanfordnlp/dsp/main/intro.ipynb&#34;&gt;intro notebook&lt;/a&gt; provides examples of five &#34;multi-hop&#34; question answering programs of increasing complexity written in DSP.&lt;/p&gt; &#xA;&lt;p&gt;You can &lt;a href=&#34;https://colab.research.google.com/github/stanfordnlp/dsp/blob/main/intro.ipynb&#34;&gt;open the notebook in Google Colab&lt;/a&gt;. You don&#39;t even need an API key to get started with it.&lt;/p&gt; &#xA;&lt;p&gt;Once you go through the notebook, you&#39;ll be ready to create your own DSP pipelines!&lt;/p&gt; &#xA;&lt;h2&gt;‚úçÔ∏è Reference&lt;/h2&gt; &#xA;&lt;p&gt;If you use DSP in a research paper, please cite our work as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{khattab2022demonstrate,&#xA;  title={Demonstrate-Search-Predict: Composing Retrieval and Language Models for Knowledge-Intensive {NLP}},&#xA;  author={Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},&#xA;  journal={arXiv preprint arXiv:2212.14024},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>VikParuchuri/zero_to_gpt</title>
    <updated>2023-01-27T01:38:22Z</updated>
    <id>tag:github.com,2023-01-27:/VikParuchuri/zero_to_gpt</id>
    <link href="https://github.com/VikParuchuri/zero_to_gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Go from no deep learning knowledge to implementing GPT.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Zero to GPT&lt;/h1&gt; &#xA;&lt;p&gt;This course will get you from no knowledge of deep learning to training a GPT model. We&#39;ll start with the basics, then build up to complex networks.&lt;/p&gt; &#xA;&lt;p&gt;To use this course, go through each chapter from the beginning. Read the lessons, or watch the optional videos. Then look through the implementations to solidify your understanding. I also recommend implementing each algorithm on your own.&lt;/p&gt; &#xA;&lt;h1&gt;Course Outline&lt;/h1&gt; &#xA;&lt;h2&gt;0. Introduction&lt;/h2&gt; &#xA;&lt;p&gt;Get an overview of the course and what we&#39;ll learn. Includes some math and NumPy fundamentals you&#39;ll need for deep learning.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/explanations/intro.ipynb&#34;&gt;intro&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;1. Gradient Descent&lt;/h2&gt; &#xA;&lt;p&gt;Gradient descent is how neural networks train their parameters to match the data. It&#39;s the &#34;learning&#34; part of deep learning.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/explanations/linreg.ipynb&#34;&gt;gradient descent tutorial&lt;/a&gt; and watch the optional &lt;a href=&#34;https://youtu.be/-cs5D91eBLE&#34;&gt;video&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/linreg/linreg.ipynb&#34;&gt;Notebook&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/nnets/dense.py&#34;&gt;class&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;2. Dense networks&lt;/h2&gt; &#xA;&lt;p&gt;Dense networks are the basic form of a neural network, where every input is connected to an output. These can also be called fully connected networks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/explanations/dense.ipynb&#34;&gt;dense network tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/dense/dense.ipynb&#34;&gt;Notebook&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/nnets/dense.py&#34;&gt;class&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;3. Classification with neural networks&lt;/h2&gt; &#xA;&lt;p&gt;In the last two lessons, we learned how to perform regression with neural networks. Now, we&#39;ll learn how to perform classification.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/explanations/classification.ipynb&#34;&gt;classification tutorial&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;4. Recurrent networks&lt;/h2&gt; &#xA;&lt;p&gt;Recurrent neural networks can process sequences of data. They&#39;re used for time series and natural language processing.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/explanations/rnn.ipynb&#34;&gt;recurrent network tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/rnn/rnn.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;5. Regularization&lt;/h2&gt; &#xA;&lt;p&gt;Regularization prevents overfitting to the training set. This means that the network can generalize well to new data.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the regularization tutorial (coming soon)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;6. PyTorch&lt;/h2&gt; &#xA;&lt;p&gt;PyTorch is a framework for deep learning that automates the backward pass of neural networks. This makes it simpler to implement complex networks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the PyTorch tutorial (coming soon)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;7. Gated recurrent networks&lt;/h2&gt; &#xA;&lt;p&gt;Gated recurrent networks help RNNs process long sequences by helping networks forget irrelevant information. LSTM and GRU are two popular types of gated networks.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the GRU tutorial (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/gru/gru.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;8. Encoders and Decoders&lt;/h2&gt; &#xA;&lt;p&gt;Encoder/decoders are used for NLP tasks when the output isn&#39;t the same length as the input. For example, if you want to use questions/answers as training data, the answers may be a different length than the question.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the encoder/decoder tutorial (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/rnnencoder/encoder.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;9. Transformers&lt;/h2&gt; &#xA;&lt;p&gt;Transformers fix the problem of vanishing/exploding gradients in RNNs by using attention. Attention allows the network to process the whole sequence at once, instead of iteratively.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the transformer tutorial (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/transformer/transformer.ipynb&#34;&gt;Notebook&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;10. Efficient Transformers&lt;/h2&gt; &#xA;&lt;p&gt;GPT models take a long time to train. We can reduce that time by using more GPUs, but we don&#39;t all have access to GPU clusters. To reduce training time, we&#39;ll incorporate some recent advances to make the transformer model more efficient.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the efficient transformer tutorial (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Implementation: Notebook coming soon&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;More Chapters Coming Soon&lt;/h2&gt; &#xA;&lt;h1&gt;Optional Chapters&lt;/h1&gt; &#xA;&lt;h2&gt;Convolutional networks&lt;/h2&gt; &#xA;&lt;p&gt;Convolutional neural networks are used for working with images and time series.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Lesson: Read the convolutional network tutorial (coming soon)&lt;/li&gt; &#xA; &lt;li&gt;Implementation: &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/notebooks/cnn/cnn.ipynb&#34;&gt;Notebook&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/VikParuchuri/zero_to_gpt/master/nnets/conv.py&#34;&gt;class&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;p&gt;If you want to run these notebooks locally, you&#39;ll need to install some Python packages.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make sure you have Python 3.8 or higher installed.&lt;/li&gt; &#xA; &lt;li&gt;Clone this repository.&lt;/li&gt; &#xA; &lt;li&gt;Run &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;You can use and adapt this material for your own courses, but not commercially. You also must provide attribution.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc/4.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by-nc/4.0/80x15.png&#34;&gt;&lt;/a&gt;&lt;br&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc/4.0/&#34;&gt;Creative Commons Attribution-NonCommercial 4.0 International License&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>