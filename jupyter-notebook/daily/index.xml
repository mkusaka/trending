<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-01-15T01:32:35Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>meta-llama/llama-cookbook</title>
    <updated>2025-01-15T01:32:35Z</updated>
    <id>tag:github.com,2025-01-15:/meta-llama/llama-cookbook</id>
    <link href="https://github.com/meta-llama/llama-cookbook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Welcome to the Llama Cookbook! This is your go to guide for Building with Llama: Getting started with Inference, Fine-Tuning, RAG. We also show you how to solve end to end problems using Llama model family and using them on various provider services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama Cookbook: The Official Guide to building with Llama Models&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the official repository for helping you get started with &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/inference/&#34;&gt;inference&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/finetuning&#34;&gt;fine-tuning&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases&#34;&gt;end-to-end use-cases&lt;/a&gt; of building with the Llama Model family.&lt;/p&gt; &#xA;&lt;p&gt;This repository covers the most popular community approaches, use-cases and the latest recipes for Llama Text and Vision models.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Popular getting started links:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/build_with_Llama_3_2.ipynb&#34;&gt;Build with Llama Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/inference/local_inference/README.md#multimodal-inference&#34;&gt;Multimodal Inference with Llama 3.2 Vision&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases/responsible_ai/llama_guard/&#34;&gt;Inferencing using Llama Guard (Safety Model)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] Popular end to end recipes:&lt;/p&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases/email_agent/&#34;&gt;Email Agent&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases/NotebookLlama/&#34;&gt;NotebookLlama&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases/coding/text2sql/&#34;&gt;Text to SQL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: We recently did a refactor of the repo, &lt;a href=&#34;https://github.com/meta-llama/llama-recipes/tree/archive-main&#34;&gt;archive-main&lt;/a&gt; is a snapshot branch from before the refactor&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Repository Structure:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/3p-integrations&#34;&gt;3P Integrations&lt;/a&gt;: Getting Started Recipes and End to End Use-Cases from various Llama providers&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/end-to-end-use-cases&#34;&gt;End to End Use Cases&lt;/a&gt;: As the name suggests, spanning various domains and applications&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/getting-started/&#34;&gt;Getting Started&lt;/a&gt;: Reference for inferencing, fine-tuning and RAG examples&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/src/&#34;&gt;src&lt;/a&gt;: Contains the src for the original llama-recipes library along with some FAQs for fine-tuning.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;FAQ:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Q: What happened to llama-recipes?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A: We recently renamed llama-recipes to llama-cookbook&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Q: Prompt Template changes for Multi-Modality?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A: Llama 3.2 follows the same prompt template as Llama 3.1, with a new special token &lt;code&gt;&amp;lt;|image|&amp;gt;&lt;/code&gt; representing the input image for the multimodal models.&lt;/p&gt; &#xA;&lt;p&gt;More details on the prompt templates for image reasoning, tool-calling and code interpreter can be found &lt;a href=&#34;https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_2&#34;&gt;on the documentation website&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Q: I have some questions for Fine-Tuning, is there a section to address these?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A: Checkout the Fine-Tuning FAQ &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/src/docs/&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Q: Some links are broken/folders are missing:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A: We recently did a refactor of the repo, &lt;a href=&#34;https://github.com/meta-llama/llama-recipes/tree/archive-main&#34;&gt;archive-main&lt;/a&gt; is a snapshot branch from before the refactor&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Where can we find details about the latest models?&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;A: Official &lt;a href=&#34;https://www.llama.com&#34;&gt;Llama models website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-cookbook/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;!-- markdown-link-check-disable --&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3.1 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3_1/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 3 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama3/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See the License file for Meta Llama 2 &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://github.com/meta-llama/llama-models/raw/main/models/llama2/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;!-- markdown-link-check-enable --&gt;</summary>
  </entry>
</feed>