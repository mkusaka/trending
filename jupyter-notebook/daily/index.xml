<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-20T01:35:46Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Azure/gen-cv</title>
    <updated>2023-11-20T01:35:46Z</updated>
    <id>tag:github.com,2023-11-20:/Azure/gen-cv</id>
    <link href="https://github.com/Azure/gen-cv" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Vision AI Solution Accelerator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vision AI Solution Accelerator&lt;/h1&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/media/gen-cv.png&#34; alt=&#34;drawing&#34; style=&#34;width:1200px;&#34;&gt; &#xA;&lt;p&gt;This repository serves as a rich resource offering numerous examples of synthetic image generation, manipulation, and reasoning. Utilizing Azure Machine Learning, Computer Vision, OpenAI, and widely acclaimed open-source frameworks like Stable Diffusion, it equips users with practical insights into the application of these powerful tools in the realm of image processing.&lt;/p&gt; &#xA;&lt;h3&gt;Content&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ðŸ†• &lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/avatar/video/README.md&#34;&gt;Create engagaing Avatar Videos&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ðŸ†• &lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/avatar/interactive/readme.md&#34;&gt;Create interactive Avatar Experiences&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/sdxl-azureml/sdxl-on-azureml.ipynb&#34;&gt;Stable Diffusion XL with Azure Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/azure_computer_vision_workshop/README.md&#34;&gt;Azure Computer Vision in a Day Workshop&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/dalle2-api/DALLE2-api-intro.ipynb&#34;&gt;Explore the OpenAI DALL E-2 API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/dalle2-api/Florence-AOAI-DALLE2.ipynb&#34;&gt;Create images with the Azure OpenAI DALL E-2 API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/dalle2-api/Remove-background.ipynb&#34;&gt;Remove background from images using the Florence foundation model&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/dalle2-api/DALLE2-Segment-Anything-edits.ipynb&#34;&gt;Precise Inpainting with Segment Anything, DALLE-2 and Stable Diffusion&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/generation-finetuning/README.md&#34;&gt;Add custom objects and styles to image generation models with Dreambooth&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/image-embeddings/generate-and-search-images.ipynb&#34;&gt;Create and find images with Stable Diffusion and Florence Vector Search&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Azure/gen-cv/main/image-embeddings/image-search-embeddings.ipynb&#34;&gt;Manage image embeddings with the Cognitive Search Vector Store&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Getting Started&lt;/h3&gt; &#xA;&lt;p&gt;The code within this repository has been tested on both &lt;strong&gt;Github Codespaces&lt;/strong&gt; compute and an &lt;strong&gt;Azure Machine Learning Compute Instance&lt;/strong&gt;. Although the use of a GPU is not a requirement, it is highly recommended if you aim to generate a large number of sample images using Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;Follow these steps to get started:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone this repository on your preferred compute using the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/Azure/gen-cv.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Create your Python environment and install the necessary dependencies. For our development, we utilized Conda. You can do the same with these commands:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n gen-cv python=3.10&#xA;conda activate gen-cv&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;From the list provided above, select a sample notebook. After making your selection, configure the Jupyter notebook to use the kernel associated with the environment you set up in Step 2.&lt;/li&gt; &#xA; &lt;li&gt;Copy the &lt;code&gt;.env.template&lt;/code&gt; file to &lt;code&gt;.env&lt;/code&gt; to store your parameters:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp .env.template .env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Add the required parameters and keys for your services to the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href=&#34;https://cla.opensource.microsoft.com&#34;&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; &#xA;&lt;p&gt;This project has adopted the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/&#34;&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href=&#34;https://opensource.microsoft.com/codeofconduct/faq/&#34;&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href=&#34;mailto:opencode@microsoft.com&#34;&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; &#xA;&lt;h2&gt;Trademarks&lt;/h2&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>