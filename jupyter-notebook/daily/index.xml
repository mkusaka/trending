<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-18T01:39:24Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>mkturkcan/generative-agents</title>
    <updated>2023-04-18T01:39:24Z</updated>
    <id>tag:github.com,2023-04-18:/mkturkcan/generative-agents</id>
    <link href="https://github.com/mkturkcan/generative-agents" rel="alternate"></link>
    <summary type="html">&lt;p&gt;An attempt to build a working, locally-running cheap version of Generative Agents: Interactive Simulacra of Human Behavior&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Generative Large Language Models for Human-Like Behavior&lt;/h1&gt; &#xA;&lt;p&gt;This repository includes a working version of the type of model described in Generative Agents: Interactive Simulacra of Human Behavior.&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;The models are distributed as notebooks that are easy to run locally, or on Google Colab. We recommend the use of Jupyter Lab if running locally. The notebook(s) should work as-is on Google Colab.&lt;/p&gt; &#xA;&lt;h2&gt;Model&lt;/h2&gt; &#xA;&lt;p&gt;The current model is a simulation of the town of Phandalin from an introductory D&amp;amp;D 5e adventure. This setting is chosen as it is much more free form than the simple scenario described in the original paper.&lt;/p&gt; &#xA;&lt;h2&gt;Limitations&lt;/h2&gt; &#xA;&lt;p&gt;The model, as described in the paper, requires access to a very high quality instruction model such as GPT-3. However, the model also requires many high-context queries to work, making it expensive to run. As such, in this work we use low-parameter, locally runnable models instead.&lt;/p&gt; &#xA;&lt;p&gt;We expect that with the advent of the next generation of instruction-tuned models, the model in this repo will perform better.&lt;/p&gt; &#xA;&lt;h2&gt;Future Steps&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Summarize agent decisions as emojis.&lt;/li&gt; &#xA; &lt;li&gt;Create a family of questions to compress agent contexts better.&lt;/li&gt; &#xA; &lt;li&gt;Check if the agent contexts are compressed well with an another layer of prompts.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>santiagobasulto/ipython-gpt</title>
    <updated>2023-04-18T01:39:24Z</updated>
    <id>tag:github.com,2023-04-18:/santiagobasulto/ipython-gpt</id>
    <link href="https://github.com/santiagobasulto/ipython-gpt" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;IPython ChatGPT extension&lt;/h1&gt; &#xA;&lt;p&gt;This extension allows you to use ChatGPT directly from your Jupyter Notebook or IPython Shell (&lt;a href=&#34;https://github.com/santiagobasulto/ipython-gpt/raw/master/Demo.ipynb&#34;&gt;Demo&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;img width=&#34;900&#34; alt=&#34;IPython GPT, a Jupyter/IPython interface for Chat GPT&#34; src=&#34;https://user-images.githubusercontent.com/872296/232230454-44529ea4-920e-4294-9d61-550771a4a95e.png&#34;&gt; &#xA;&lt;img width=&#34;900&#34; alt=&#34;IPython GPT, a Jupyter/IPython interface for Chat GPT&#34; src=&#34;https://user-images.githubusercontent.com/872296/232230492-9bc50342-9d78-4adb-8168-2f94fcbc3b73.png&#34;&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important!&lt;/strong&gt; This is a very early and raw version, I have a lot of things to improve regarding code quality and missing functionality. Check &lt;a href=&#34;https://github.com/santiagobasulto/ipython-gpt/issues/4&#34;&gt;this issue&lt;/a&gt; for a rough &#34;roadmap&#34;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!pip install ipython-gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then in your notebook or ipython shell:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;%load_ext ipython_gpt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;You must first generate an API key at OpenAI (&lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt;) and set is an environment variable &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;. You can do it by modifying your &lt;code&gt;.bashrc/.zshrc&lt;/code&gt; or starting jupyter with it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ OPENAI_API_KEY=[YOUR-KEY] jupyter lab&#xA;# ...&#xA;$ OPENAI_API_KEY=[YOUR-KEY] ipython&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are a few other ways to set the API KEY, but the envvar is the recommended one.&lt;/p&gt; &#xA;&lt;h2&gt;ChatGPT API&lt;/h2&gt; &#xA;&lt;p&gt;The command &lt;code&gt;%%chat&lt;/code&gt; interfaces with ChatGPT. It accepts multiple parameters (see Usage). Here&#39;s an example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%chat --max-tokens=25&#xA;&#xA;What&#39;s the purpose of life?&#xA;...&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; CHAT RESPONSE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt; by default, the &lt;code&gt;%%chat&lt;/code&gt; command preserves the conversation to give the Agent some context, in the same way that ChatGPT works. You can &#34;reset&#34; its status passing the flag &lt;code&gt;--reset-conversation&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%chat --reset-conversation&#xA;&#xA;How can I avoid pandas using scientific notation in outputs, and do it globally?&#xA;...&#xA;...&#xA;&amp;gt;&amp;gt;&amp;gt; CHAT RESPONSE&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Agent&#39;s role (system message) and other chat parameters&lt;/h2&gt; &#xA;&lt;p&gt;By default, the Chat is started with the role: &lt;em&gt;&#34;You&#39;re a python data science coding assistant&#34;&lt;/em&gt;. You can change that by passing something different in your first &lt;code&gt;%%chat&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;%%chat --system-message=&#34;You&#39;re a R Data Science assistant&#34;&#xA;&#xA;Your message...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once the conversation has started, you can&#39;t change the original message, as the context is preserved. To do so, you must reset the conversation:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;%%chat --system-message=&#34;You&#39;re a R Data Science assistant&#34; --reset-conversation&#xA;&#xA;Your message...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setting global config&lt;/h2&gt; &#xA;&lt;p&gt;You can change the defaults using the &lt;code&gt;%chat_config&lt;/code&gt; line magic:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-ipython&#34;&gt;%chat_config --system-message=&#34;You&#39;re an R data scientist coding assistant specialized in visualizations&#34; --model &#34;other model&#34; --reset-conversation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Invoke it without parameters to see the defaults set:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%chat_config&#xA;...&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;##### Conf set:&#xA;&#xA;* **Default model**: gpt-3.5-turbo&#xA;* **Default system message**: You&#39;re a python data science coding assistant&#xA;* **Chat history length**: 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Other methods&lt;/h2&gt; &#xA;&lt;h4&gt;Display available models&lt;/h4&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%chat_models [--all-models]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%chat_models&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;Available models:&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code&gt;- gpt-3.5-turbo-0301&#xA;- gpt-3.5-turbo&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Display usage and accepted parameters&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%reload_ext ipython_gpt&#xA;%chat_help&#xA;...&#xA;&#xA;&#xA;    usage: ipykernel_launcher.py [-h] [--openai-api-key OPENAI_API_KEY]&#xA;                                 [--reset-conversation]&#xA;                                 [--system-message SYSTEM_MESSAGE]&#xA;                                 [--no-system-message] [--model MODEL]&#xA;                                 [--temperature TEMPERATURE]&#xA;                                 [--max-tokens MAX_TOKENS] [--all-models]&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Alternative authentication&lt;/h2&gt; &#xA;&lt;p&gt;Aside from setting the environment variable, you can also set &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as a global variable in your notebook, or pass it directly as a parameter in any method &lt;code&gt;--openai-api-key=YOUR-KEY&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;These alternative methods are NOT recommended, as you might leak your API Key in the notebooks&#39; history, stored in &lt;code&gt;.ipynb_checkpoints&lt;/code&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>aiplaybookin/novice-ChatGPT</title>
    <updated>2023-04-18T01:39:24Z</updated>
    <id>tag:github.com,2023-04-18:/aiplaybookin/novice-ChatGPT</id>
    <link href="https://github.com/aiplaybookin/novice-ChatGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ChatGPT API Usage using LangChain, LlamaIndex, Guardrails, AutoGPT and more&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;novice-ChatGPT&lt;/h1&gt; &#xA;&lt;p&gt;ChatGPT API Usage using -&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt-index.readthedocs.io/en/latest/index.html&#34;&gt;Llamaindex&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://openai.com&#34;&gt;OpenAI&lt;/a&gt; and&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://shreyar.github.io/guardrails/&#34;&gt;Guardrails&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/en/latest/index.html&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;1. &lt;a href=&#34;https://raw.githubusercontent.com/aiplaybookin/novice-ChatGPT/main/unstructuredToStructured/&#34;&gt;Unstructured to Structured&lt;/a&gt; ( pdfs invoices to pandas DataFrame)&lt;/h1&gt; &#xA;&lt;h3&gt;Source e.g.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aiplaybookin/novice-ChatGPT/main/unstructuredToStructured/images/pdf.png&#34; alt=&#34;source pdf&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Target e.g.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aiplaybookin/novice-ChatGPT/main/unstructuredToStructured/images/table.png&#34; alt=&#34;source pdf&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>