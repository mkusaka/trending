<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-05-04T01:27:46Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>neo4j-labs/llm-graph-builder</title>
    <updated>2024-05-04T01:27:46Z</updated>
    <id>tag:github.com,2024-05-04:/neo4j-labs/llm-graph-builder</id>
    <link href="https://github.com/neo4j-labs/llm-graph-builder" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Neo4j graph construction from unstructured data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Knowledge Graph Builder App&lt;/h1&gt; &#xA;&lt;p&gt;This application is designed to convert PDF documents into a knowledge graph stored in Neo4j. It utilizes the power of OpenAI&#39;s GPT/Diffbot LLM(Large language model) to extract nodes, relationships and properties from the text content of the PDF and then organizes them into a structured knowledge graph using Langchain framework. Files can be uploaded from local machine or S3 bucket and then LLM model can be chosen to create the knowledge graph.&lt;/p&gt; &#xA;&lt;h3&gt;Getting started&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Run Docker Compose to build and start all components:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up --build&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Alternatively, you can run specific directories separately:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;For the frontend:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd frontend&#xA;yarn&#xA;yarn run dev&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;For the backend:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd backend&#xA;python -m venv envName&#xA;source envName/bin/activate &#xA;pip install -r requirements.txt&#xA;uvicorn score:app --reload&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;&lt;/h3&gt; &#xA;&lt;p&gt;To deploy the app and packages on Google Cloud Platform, run the following command on google cloud run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Frontend deploy &#xA;gcloud run deploy &#xA;source location current directory &amp;gt; Frontend&#xA;region : 32 [us-central 1]&#xA;Allow unauthenticated request : Yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Backend deploy &#xA;gcloud run deploy --set-env-vars &#34;OPENAI_API_KEY = &#34; --set-env-vars &#34;DIFFBOT_API_KEY = &#34; --set-env-vars &#34;NEO4J_URI = &#34; --set-env-vars &#34;NEO4J_PASSWORD = &#34; --set-env-vars &#34;NEO4J_USERNAME = &#34;&#xA;source location current directory &amp;gt; Backend&#xA;region : 32 [us-central 1]&#xA;Allow unauthenticated request : Yes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;PDF Upload&lt;/strong&gt;: Users can upload PDF documents using the Drop Zone.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;S3 Bucket Integration&lt;/strong&gt;: Users can also specify PDF documents stored in an S3 bucket for processing.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Knowledge Graph Generation&lt;/strong&gt;: The application employs OpenAI/Diffbot&#39;s LLM to extract relevant information from the PDFs and construct a knowledge graph.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Neo4j Integration&lt;/strong&gt;: The extracted nodes and relationships are stored in a Neo4j database for easy visualization and querying.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Grid View of source node files with&lt;/strong&gt; : Name,Type,Size,Nodes,Relations,Duration,Status,Source,Model&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setting up Environment Variables&lt;/h2&gt; &#xA;&lt;p&gt;Create .env file and update the following env variables.&lt;br&gt; OPENAI_API_KEY = &#34;&#34;&lt;br&gt; DIFFBOT_API_KEY = &#34;&#34;&lt;br&gt; NEO4J_URI = &#34;&#34;&lt;br&gt; NEO4J_USERNAME = &#34;&#34;&lt;br&gt; NEO4J_PASSWORD = &#34;&#34;&lt;br&gt; AWS_ACCESS_KEY_ID = &#34;&#34;&lt;br&gt; AWS_SECRET_ACCESS_KEY = &#34;&#34;&lt;br&gt; EMBEDDING_MODEL = &#34;&#34;&lt;br&gt; IS_EMBEDDING = &#34;TRUE&#34; KNN_MIN_SCORE = &#34;&#34;\&lt;/p&gt; &#xA;&lt;h2&gt;Functions/Modules&lt;/h2&gt; &#xA;&lt;h4&gt;extract_graph_from_file(uri, userName, password, file_path, model):&lt;/h4&gt; &#xA;&lt;p&gt;Extracts nodes , relationships and properties from a PDF file leveraging LLM models.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Args:&#xA; uri: URI of the graph to extract&#xA; userName: Username to use for graph creation ( if None will use username from config file )&#xA; password: Password to use for graph creation ( if None will use password from config file )&#xA; file: File object containing the PDF file path to be used&#xA; model: Type of model to use (&#39;Gemini Pro&#39; or &#39;Diffbot&#39;)&#xA;&#xA; Returns: &#xA; Json response to API with fileName, nodeCount, relationshipCount, processingTime, &#xA; status and model as attributes.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;692&#34; alt=&#34;neoooo&#34; src=&#34;https://github.com/neo4j-labs/llm-graph-builder/assets/118245454/01e731df-b565-4f4f-b577-c47e39dd1748&#34;&gt; &#xA;&lt;h4&gt;create_source_node_graph(uri, userName, password, file):&lt;/h4&gt; &#xA;&lt;p&gt;Creates a source node in Neo4jGraph and sets properties.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Args:&#xA; uri: URI of Graph Service to connect to&#xA; userName: Username to connect to Graph Service with ( default : None )&#xA; password: Password to connect to Graph Service with ( default : None )&#xA; file: File object with information about file to be added&#xA;&#xA;Returns: &#xA; Success or Failure message of node creation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;958&#34; alt=&#34;neo_workspace&#34; src=&#34;https://github.com/neo4j-labs/llm-graph-builder/assets/118245454/f2eb11cd-718c-453e-bec9-11410ec6e45d&#34;&gt; &#xA;&lt;h4&gt;get_source_list_from_graph():&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt; Returns a list of file sources in the database by querying the graph and &#xA; sorting the list by the last updated date. &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;822&#34; alt=&#34;get_source&#34; src=&#34;https://github.com/neo4j-labs/llm-graph-builder/assets/118245454/1d8c7a86-6f10-4916-a4c1-8fdd9f312bcc&#34;&gt; &#xA;&lt;h4&gt;Chunk nodes and embeddings creation in Neo4j&lt;/h4&gt; &#xA;&lt;img width=&#34;926&#34; alt=&#34;chunking&#34; src=&#34;https://github.com/neo4j-labs/llm-graph-builder/assets/118245454/4d61479c-e5e9-415e-954e-3edf6a773e72&#34;&gt; &#xA;&lt;h2&gt;Application Walkthrough&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/neo4j-labs/llm-graph-builder/assets/121786590/b725a503-6ade-46d2-9e70-61d57443c311&#34;&gt;https://github.com/neo4j-labs/llm-graph-builder/assets/121786590/b725a503-6ade-46d2-9e70-61d57443c311&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;p&gt;The Public &lt;a href=&#34;https://devfrontend-dcavk67s4a-uc.a.run.app&#34;&gt; Google cloud Run URL&lt;/a&gt;. &lt;a href=&#34;https://workspace-preview.neo4j.io/workspace&#34;&gt;Workspace URL&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>pererossello/nbody_whatever</title>
    <updated>2024-05-04T01:27:46Z</updated>
    <id>tag:github.com,2024-05-04:/pererossello/nbody_whatever</id>
    <link href="https://github.com/pererossello/nbody_whatever" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;nbody_whatever&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pererossello/nbody_whatever/main/example.gif&#34; alt=&#34;Example&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;A toy N-body simulator. Use an image for your initial conditions by converting it into N bodies. The simulator uses a brute force approach (at O(N^2) force calculations per time step) and it is parallelized with numba. Snapshots from the simulation are saved at predefined times as an &lt;code&gt;.hdf5&lt;/code&gt; file. Initial conditions are also stored as &lt;code&gt;.hdf5&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;main/&lt;/code&gt;: Main module. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;main/make_ics.py&lt;/code&gt;: Contains the &lt;code&gt;InitialConditions&lt;/code&gt; class for reading the image and converting it to N bodies.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;main/simulate.py&lt;/code&gt;: Contains the &lt;code&gt;NBodySimulation&lt;/code&gt; class for performing the simulation.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;main/plot_utils.py&lt;/code&gt;: Utility functions for plotting and making animations of the simulated output.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Check the notebook &lt;code&gt;example_usage.ipynb&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;Check requirements.txt, but mainly: &lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, &lt;code&gt;PIL&lt;/code&gt;, &lt;code&gt;h5py&lt;/code&gt; (for storing data) and &lt;code&gt;numba&lt;/code&gt; (for parallelization)&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>KindXiaoming/pykan</title>
    <updated>2024-05-04T01:27:46Z</updated>
    <id>tag:github.com,2024-05-04:/KindXiaoming/pykan</id>
    <link href="https://github.com/KindXiaoming/pykan" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Kolmogorov Arnold Networks&lt;/p&gt;&lt;hr&gt;&lt;img width=&#34;600&#34; alt=&#34;kan_plot&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/a2d2d225-b4d2-4c1e-823e-bc45c7ea96f9&#34;&gt; &#xA;&lt;h1&gt;Kolmogorov-Arnold Networks (KANs)&lt;/h1&gt; &#xA;&lt;p&gt;This is the github repo for the paper &lt;a href=&#34;https://arxiv.org/abs/2404.19756&#34;&gt;&#34;KAN: Kolmogorov-Arnold Networks&#34;&lt;/a&gt;. Find the documentation &lt;a href=&#34;https://kindxiaoming.github.io/pykan/&#34;&gt;here&lt;/a&gt;. Here&#39;s &lt;a href=&#34;https://github.com/KindXiaoming/pykan/raw/master/README.md#authors-note&#34;&gt;author&#39;s note&lt;/a&gt; responding to current hype of KANs.&lt;/p&gt; &#xA;&lt;p&gt;Kolmogorov-Arnold Networks (KANs) are promising alternatives of Multi-Layer Perceptrons (MLPs). KANs have strong mathematical foundations just like MLPs: MLPs are based on the universal approximation theorem, while KANs are based on Kolmogorov-Arnold representation theorem. KANs and MLPs are dual: KANs have activation functions on edges, while MLPs have activation functions on nodes. This simple change makes KANs better (sometimes much better!) than MLPs in terms of both model &lt;strong&gt;accuracy&lt;/strong&gt; and &lt;strong&gt;interpretability&lt;/strong&gt;. A quick intro of KANs &lt;a href=&#34;https://kindxiaoming.github.io/pykan/intro.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;img width=&#34;1163&#34; alt=&#34;mlp_kan_compare&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/695adc2d-0d0b-4e4b-bcff-db2c8070f841&#34;&gt; &#xA;&lt;h2&gt;Accuracy&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;KANs have faster scaling than MLPs. KANs have better accuracy than MLPs with fewer parameters.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 1: fitting symbolic formulas&lt;/strong&gt; &lt;img width=&#34;1824&#34; alt=&#34;Screenshot 2024-04-30 at 10 55 30&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/e1fc3dcc-c1f6-49d5-b58e-79ff7b98a49b&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 2: fitting special functions&lt;/strong&gt; &lt;img width=&#34;1544&#34; alt=&#34;Screenshot 2024-04-30 at 11 07 20&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/b2124337-cabf-4e00-9690-938e84058a91&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 3: PDE solving&lt;/strong&gt; &lt;img width=&#34;1665&#34; alt=&#34;Screenshot 2024-04-30 at 10 57 25&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/5da94412-c409-45d1-9a60-9086e11d6ccc&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 4: avoid catastrophic forgetting&lt;/strong&gt; &lt;img width=&#34;1652&#34; alt=&#34;Screenshot 2024-04-30 at 11 04 36&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/57d81de6-7cff-4e55-b8f9-c4768ace2c77&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Interpretability&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;KANs can be intuitively visualized. KANs offer interpretability and interactivity that MLPs cannot provide. We can use KANs to potentially discover new scientific laws.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 1: Symbolic formulas&lt;/strong&gt; &lt;img width=&#34;1510&#34; alt=&#34;Screenshot 2024-04-30 at 11 04 56&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/3cfd1ca2-cd3e-4396-845e-ef8f3a7c55ef&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 2: Discovering mathematical laws of knots&lt;/strong&gt; &lt;img width=&#34;1443&#34; alt=&#34;Screenshot 2024-04-30 at 11 05 25&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/80451ac2-c5fd-45b9-89a7-1637ba8145af&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 3: Discovering physical laws of Anderson localization&lt;/strong&gt; &lt;img width=&#34;1295&#34; alt=&#34;Screenshot 2024-04-30 at 11 05 53&#34; src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/8ee507a0-d194-44a9-8837-15d7f5984301&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example 4: Training of a three-layer KAN&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/KindXiaoming/pykan/assets/23551623/e9f215c7-a393-46b9-8528-c906878f015e&#34; alt=&#34;kan_training_low_res&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Pykan can be installed via PyPI or directly from GitHub.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pre-requisites:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Python 3.9.7 or higher&#xA;pip&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation via github&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv pykan-env&#xA;source pykan-env/bin/activate  # On Windows use `pykan-env\Scripts\activate`&#xA;pip install git+https://github.com/KindXiaoming/pykan.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Installation via PyPI:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv pykan-env&#xA;source pykan-env/bin/activate  # On Windows use `pykan-env\Scripts\activate`&#xA;pip install pykan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Requirements&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# python==3.9.7&#xA;matplotlib==3.6.2&#xA;numpy==1.24.4&#xA;scikit_learn==1.1.3&#xA;setuptools==65.5.0&#xA;sympy==1.11.1&#xA;torch==2.2.2&#xA;tqdm==4.66.2&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After activating the virtual environment, you can install specific package requirements as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Optional: Conda Environment Setup&lt;/strong&gt; For those who prefer using Conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create --name pykan-env python=3.9.7&#xA;conda activate pykan-env&#xA;pip install git+https://github.com/KindXiaoming/pykan.git  # For GitHub installation&#xA;# or&#xA;pip install pykan  # For PyPI installation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Computation requirements&lt;/h2&gt; &#xA;&lt;p&gt;Examples in &lt;a href=&#34;https://raw.githubusercontent.com/KindXiaoming/pykan/master/tutorials&#34;&gt;tutorials&lt;/a&gt; are runnable on a single CPU typically less than 10 minutes. All examples in the paper are runnable on a single CPU in less than one day. Training KANs for PDE is the most expensive and may take hours to days on a single CPU. We use CPUs to train our models because we carried out parameter sweeps (both for MLPs and KANs) to obtain Pareto Frontiers. There are thousands of small models which is why we use CPUs rather than GPUs. Admittedly, our problem scales are smaller than typical machine learning tasks, but are typical for science-related tasks. In case the scale of your task is large, it is advisable to use GPUs.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;The documentation can be found &lt;a href=&#34;https://kindxiaoming.github.io/pykan/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Tutorials&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Quickstart&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Get started with &lt;a href=&#34;https://raw.githubusercontent.com/KindXiaoming/pykan/master/hellokan.ipynb&#34;&gt;hellokan.ipynb&lt;/a&gt; notebook.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;More demos&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;More Notebook tutorials can be found in &lt;a href=&#34;https://raw.githubusercontent.com/KindXiaoming/pykan/master/tutorials&#34;&gt;tutorials&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@misc{liu2024kan,&#xA;      title={KAN: Kolmogorov-Arnold Networks}, &#xA;      author={Ziming Liu and Yixuan Wang and Sachin Vaidya and Fabian Ruehle and James Halverson and Marin Soljačić and Thomas Y. Hou and Max Tegmark},&#xA;      year={2024},&#xA;      eprint={2404.19756},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.LG}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions, please contact &lt;a href=&#34;mailto:zmliu@mit.edu&#34;&gt;zmliu@mit.edu&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Author&#39;s note&lt;/h2&gt; &#xA;&lt;p&gt;I would like to thank everyone who&#39;s interested in KANs. When I designed KANs and wrote codes, I have math &amp;amp; physics examples (which are quite small scale!) in mind, so did not consider much optimization in efficiency or reusability. It&#39;s so honored to receive this unwarranted attention, which is way beyond my expectation. So I accept any criticism from people complaning about the efficiency and resuability of the codes, my apology. My only hope is that you find &lt;code&gt;model.plot()&lt;/code&gt; fun to play with :).&lt;/p&gt; &#xA;&lt;p&gt;For users who are interested in scientific discoveries and scientific computing (the orginal users intended for), I&#39;m happy to hear your applications and collaborate. This repo will continue remaining mostly for this purpose, probably without signifiant updates for efficiency. In fact, there are already implmentations like &lt;a href=&#34;https://github.com/Blealtan/efficient-kan&#34;&gt;efficientkan&lt;/a&gt; or &lt;a href=&#34;https://github.com/GistNoesis/FourierKAN/&#34;&gt;fouierkan&lt;/a&gt; that look promising for improving efficiency.&lt;/p&gt; &#xA;&lt;p&gt;For users who are machine learning focus, I have to be honest that KANs are likely not a simple plug-in that can be used out-of-the box (yet). Hyperparameters need tuning, and more tricks special to your applications should be introduced. For example, &lt;a href=&#34;https://github.com/WillHua127/GraphKAN-Graph-Kolmogorov-Arnold-Networks&#34;&gt;GraphKAN&lt;/a&gt; suggests that KANs should better be used in latent space (need embedding and unembedding linear layers after inputs and before outputs). &lt;a href=&#34;https://github.com/riiswa/kanrl&#34;&gt;KANRL&lt;/a&gt; suggests that some trainable parameters should better be fixed in reinforcement learning to increase training stability.&lt;/p&gt; &#xA;&lt;p&gt;The most common question I&#39;ve been asked lately is whether KANs will be next-gen LLMs. I don&#39;t have good intuition about this. KANs are designed for applications where one cares about high accuracy and/or interpretability. We do care about LLM interpretability for sure, but interpretability can mean wildly different things for LLM and for science. Do we care about high accuracy for LLMs? I don&#39;t know, scaling laws seem to imply so, but probably not too high precision. Also, accuracy can also mean different things for LLM and for science. This subtlety makes it hard to directly transfer conclusions in our paper to LLMs, or machine learning tasks in general. However, I would be very happy if you have enjoyed the high-level idea (learnable activation functions on edges, or interacting with AI for scientific discoveries), which is not necessariy &lt;em&gt;the future&lt;/em&gt;, but can hopefully inspire and impact &lt;em&gt;many possible futures&lt;/em&gt;. As a physicist, the message I want to convey is less of &#34;KANs are great&#34;, but more of &#34;try thinking of current architectures critically and seeking fundamentally different alternatives that can do fun and/or useful stuff&#34;.&lt;/p&gt; &#xA;&lt;p&gt;I would like to welcome people to be critical of KANs, but also to be critical of critiques as well. Practice is the only criterion for testing understanding (实践是检验真理的唯一标准). We don&#39;t know many things beforehand until they are really tried and shown to be succeeding or failing. As much as I&#39;m willing to see success mode of KANs, I&#39;m equally curious about failure modes of KANs, to better understand the boundaries. KANs and MLPs cannot replace each other (as far as I can tell); they each have advantages in some settings and limitations in others. I would be intrigued by a theoretical framework that encompasses both and could even suggest new alternatives (physicists love unified theories, sorry :).&lt;/p&gt;</summary>
  </entry>
</feed>