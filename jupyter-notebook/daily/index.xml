<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-04T01:33:58Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facebookresearch/personal-timeline</title>
    <updated>2023-09-04T01:33:58Z</updated>
    <id>tag:github.com,2023-09-04:/facebookresearch/personal-timeline</id>
    <link href="https://github.com/facebookresearch/personal-timeline" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A public release of TimelineBuilder for building personal digital data timelines.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TimelineBuilder&lt;/h1&gt; &#xA;&lt;h2&gt;Table of Content&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#general-setup&#34;&gt;Setup&lt;/a&gt;: how to set up for this repo&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#digital-data-importers&#34;&gt;Importers&lt;/a&gt;: how to create LifeLog entries from several data sources. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#downloading-your-personal-data&#34;&gt;Downloading Digital Data&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#running-the-code&#34;&gt;Running the importers&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/DATASET.md&#34;&gt;Sample Dataset&lt;/a&gt;: a sampled set of anonymized data for testing&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#visualization-of-the-personal-timeline&#34;&gt;Data Visualization&lt;/a&gt;: a ReactJS-based visualization frontend of the personal timeline&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#question-answer-over-the-personal-timeline&#34;&gt;Question Answering&lt;/a&gt;: a LLM-based QA engine over the personal timeline&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/#timelineqa-a-benchmark-for-question-answer-over-the-personal-timeline&#34;&gt;TimelineQA&lt;/a&gt;: a synthetic benchmark for evaluating personal timeline QA systems&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;General Setup&lt;/h2&gt; &#xA;&lt;h2&gt;Step 0: Create environment&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Install Docker Desktop from &lt;a href=&#34;https://docs.docker.com/desktop/&#34;&gt;this link&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Follow install steps and use the Desktop app to start the docker engine.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Install &lt;code&gt;git-lfs&lt;/code&gt; and clone the repo. You may need a conda env to do that:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -n personal-timeline python=3.10&#xA;conda activate personal-timeline&#xA;&#xA;conda install -c conda-forge git-lfs&#xA;git lfs install&#xA;&#xA;git clone https://github.com/facebookresearch/personal-timeline&#xA;cd personal-timeline&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Run init script (needs python)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;sh src/init.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create a bunch of files/folders/symlinks needed for running the app. This will also create a new directory under your home folder &lt;code&gt;~/personal-data&lt;/code&gt;, the directory where your personal data will reside.&lt;/p&gt; &#xA;&lt;h2&gt;Step 1: Setting up&lt;/h2&gt; &#xA;&lt;h2&gt;For Data Ingestion&lt;/h2&gt; &#xA;&lt;p&gt;Ingestion configs are controlled via parameters in &lt;code&gt;conf/ingest.conf&lt;/code&gt; file. The configurations are defaulted for optimized processing and don&#39;t need to be changed. You can adjust values for these parameters to run importer with a different configuration.&lt;/p&gt; &#xA;&lt;h2&gt;For Data visualization&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;To set up a Google Map API (free), follow these &lt;a href=&#34;https://developers.google.com/maps/documentation/embed/quickstart#create-project&#34;&gt;instructions&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Copy the following lines to &lt;code&gt;env/frontend.env.list&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;GOOGLE_MAP_API=&amp;lt;the API key goes here&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;To embed Spotify, you need to set up a Spotify API (free) following &lt;a href=&#34;https://developer.spotify.com/dashboard/applications&#34;&gt;here&lt;/a&gt;. You need to log in with a Spotify account, create a project, and show the &lt;code&gt;secret&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Copy the following lines to &lt;code&gt;env/frontend.env.list&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;SPOTIFY_TOKEN=&amp;lt;the token goes here&amp;gt;&#xA;SPOTIFY_SECRET=&amp;lt;the secret goes here&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;For Question-Answering&lt;/h2&gt; &#xA;&lt;p&gt;Set up an OpenAI API following these &lt;a href=&#34;https://openai.com/api/&#34;&gt;instructions&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Copy the following line to &lt;code&gt;env/frontend.env.list&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=&amp;lt;the API key goes here&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Digital Data Importers&lt;/h2&gt; &#xA;&lt;h2&gt;Downloading your personal data&lt;/h2&gt; &#xA;&lt;p&gt;We currently support 9 data sources. Here is a summary table:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Digital Services&lt;/th&gt; &#xA;   &lt;th&gt;Instructions&lt;/th&gt; &#xA;   &lt;th&gt;Destinations&lt;/th&gt; &#xA;   &lt;th&gt;Use cases&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Apple Health&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#apple-health&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/apple-health&lt;/td&gt; &#xA;   &lt;td&gt;Exercise patterns, calorie counts&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Amazon&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#amazon&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/amazon&lt;/td&gt; &#xA;   &lt;td&gt;Product recommendation, purchase history summarization&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Amazon Kindle&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#amazon&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/amazon-kindle&lt;/td&gt; &#xA;   &lt;td&gt;Book recommendation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Spotify&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#spotify&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/spotify&lt;/td&gt; &#xA;   &lt;td&gt;Music / streaming recommendation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Venmo&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#venmo&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/venmo&lt;/td&gt; &#xA;   &lt;td&gt;Monthly spend summarization&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Libby&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#libby&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/libby&lt;/td&gt; &#xA;   &lt;td&gt;Book recommendation&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Google Photos&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#google-photos&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/google_photos&lt;/td&gt; &#xA;   &lt;td&gt;Food recommendation, Object detections, and more&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Google Location&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#google-photos&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/google-timeline/Location History/Semantic Location History&lt;/td&gt; &#xA;   &lt;td&gt;Location tracking / visualization&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Facebook posts&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/alonhalevy/personal-timeline#facebook-data&#34;&gt;Link&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;personal-data/facebook&lt;/td&gt; &#xA;   &lt;td&gt;Question-Answering over FB posts / photos&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you have a different data source not listed above, follow the instructions &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/NEW_DATASOURCE.md&#34;&gt;here&lt;/a&gt; to add this data source to the importer.&lt;/p&gt; &#xA;&lt;h3&gt;GOOGLE PHOTOS and GOOGLE TIMELINE&lt;/h3&gt; &#xA;&lt;!--1. You need to download your Google photos from [Google Takeout](https://takeout.google.com/).  &#xA;The download from Google Takeout would be in multiple zip files. Unzip all the files.&#xA;&#xA;2. It may be the case that some of your photo files are .HEIC. In that case follow the steps below to convert them to .jpeg  &#xA;The easiest way to do this on a Mac is:&#xA;&#xA;     -- Select the .HEIC files you want to convert.   &#xA;     -- Right click and choose &#34;quick actions&#34; and then you&#39;ll have an option to convert the image.  &#xA;     -- If you&#39;re converting many photos, this may take a few minutes. &#xA;&#xA;2. Move all the unzipped folders inside `~/personal-data/google_photos/`. There can be any number of sub-folders under `google_photos`.--&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;You can download your Google photos and location (also Gmail, map and google calendar) data from &lt;a href=&#34;https://takeout.google.com/&#34;&gt;Google Takeout&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The download from Google Takeout would be in multiple zip files. Unzip all the files.&lt;/li&gt; &#xA; &lt;li&gt;For Google photos, move all the unzipped folders inside &lt;code&gt;~/personal-data/google_photos/&lt;/code&gt;. There can be any number of sub-folders under &lt;code&gt;google_photos&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;For Google locations, move the unzipped files to &lt;code&gt;personal-data/google-timeline/Location History/Semantic Location History&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;FACEBOOK DATA&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to &lt;a href=&#34;https://www.facebook.com/settings?tab=your_facebook_information&#34;&gt;Facebook Settings&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Click on &lt;b&gt;Download your information&lt;/b&gt; and download FB data in JSON format&lt;/li&gt; &#xA; &lt;li&gt;Unzip the downloaded file and copy the directory &lt;code&gt;posts&lt;/code&gt; sub-folder to &lt;code&gt;~/personal-data/facebook&lt;/code&gt;. The &lt;code&gt;posts&lt;/code&gt; folder would sit directly under the Facebook folder.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;APPLE HEALTH&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Go to the Apple Health app on your phone and ask to export your data. This will create a file called iwatch.xml and that&#39;s the input file to the importer.&lt;/li&gt; &#xA; &lt;li&gt;Move the downloaded file to this &lt;code&gt;~/personal-data/apple-health&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;AMAZON&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Request your data from Amazon here: &lt;a href=&#34;https://www.amazon.com/gp/help/customer/display.html?nodeId=GXPU3YPMBZQRWZK2&#34;&gt;https://www.amazon.com/gp/help/customer/display.html?nodeId=GXPU3YPMBZQRWZK2&lt;/a&gt; They say it can take up to 30 days, but it took about 2 days. They&#39;ll email you when it&#39;s ready.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;They separate Amazon purchases from Kindle purchases into two different directories.&lt;/p&gt; &#xA;&lt;p&gt;The file you need for Amazon purchases is Retail.OrderHistory.1.csv The file you need for Kindle purchases is Digital Items.csv&lt;/p&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Move data for Amazon purchases to &lt;code&gt;~/personal-data/amazon&lt;/code&gt; folder and of kindle downloads to &lt;code&gt;~/personal-data/amazon-kindle&lt;/code&gt; folder&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;VENMO&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download your data from Venmo here -- &lt;a href=&#34;https://help.venmo.com/hc/en-us/articles/360016096974-Transaction-History&#34;&gt;https://help.venmo.com/hc/en-us/articles/360016096974-Transaction-History&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Move the data into &lt;code&gt;~/personal-data/venmo&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;LIBBY&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download your data from Libby here -- &lt;a href=&#34;https://libbyapp.com/timeline/activities&#34;&gt;https://libbyapp.com/timeline/activities&lt;/a&gt;. Click on &lt;code&gt;Actions&lt;/code&gt; then &lt;code&gt;Export Timeline&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Move the data into &lt;code&gt;~/personal-data/libby&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;SPOTIFY&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Download your data from Spotify here -- &lt;a href=&#34;https://support.spotify.com/us/article/data-rights-and-privacy-settings/&#34;&gt;https://support.spotify.com/us/article/data-rights-and-privacy-settings/&lt;/a&gt; They say it can take up to 30 days, but it took about 2 days. They&#39;ll email you when it&#39;s ready.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Move the data into &lt;code&gt;~/personal-data/spotify&lt;/code&gt; folder.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Running the code&lt;/h1&gt; &#xA;&lt;p&gt;Now that we have all the data and setting in place, we can either run individual steps or the end-to-end system. This will import your photo data to SQLite (this is what will go into the episodic database), build summaries and make data available for visualization and search.&lt;/p&gt; &#xA;&lt;p&gt;Running the Ingestion container will add two types of file to &lt;code&gt;~/personal-data/app_data&lt;/code&gt; folder&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Import your data to an SQLite DB named &lt;code&gt;raw_data.db&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Export your personal data into csv files such as &lt;code&gt;books.csv&lt;/code&gt;, &lt;code&gt;exercise.csv&lt;/code&gt;, etc.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Option 1:&lt;/h3&gt; &#xA;&lt;p&gt;To run the pipeline end-to-end (with frontend and QA backend), simply run&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up -d --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Option 2:&lt;/h3&gt; &#xA;&lt;p&gt;You can also run ingestion, visualization, and the QA engine separately. To start data ingestion, use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up -d backend --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Check progress&lt;/h2&gt; &#xA;&lt;p&gt;Once the docker command is run, you can see running containers for backend and frontend in the docker for Mac UI. Copy the container Id for ingest and see logs by running the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker logs -f &amp;lt;container_id&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!-- # Step 5: Visualization and Question Answering --&gt; &#xA;&lt;h2&gt;Visualization of the personal timeline&lt;/h2&gt; &#xA;&lt;p&gt;To start the visualization frontend:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up -d frontend --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Running the Frontend will start a ReactJS UI at &lt;code&gt;http://localhost:3000&lt;/code&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/src/frontend/&#34;&gt;here&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;We provide an anonymized digital data &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/sample_data/&#34;&gt;dataset&lt;/a&gt; for testing the UI and QA system, see &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/DATASET.md&#34;&gt;here&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/ui.png&#34; alt=&#34;Timeline Visualization&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Question Answer over the personal timeline&lt;/h2&gt; &#xA;&lt;p&gt;The QA engine is based on PostText, a QA system for answering queries that require computing aggregates over personal data.&lt;/p&gt; &#xA;&lt;p&gt;PostText Reference --- &lt;a href=&#34;https://arxiv.org/abs/2306.01061&#34;&gt;https://arxiv.org/abs/2306.01061&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{tan2023posttext,&#xA;      title={Reimagining Retrieval Augmented Language Models for Answering Queries},&#xA;      author={Wang-Chiew Tan and Yuliang Li and Pedro Rodriguez and Richard James and Xi Victoria Lin and Alon Halevy and Scott Yih},&#xA;      journal={arXiv preprint:2306.01061},&#xA;      year={2023},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To start the QA engine, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;docker-compose up -d qa --build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The QA engine will be running on a flask server inside a docker container at &lt;code&gt;http://localhost:8085&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/src/qa&#34;&gt;here&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/qa.png&#34; alt=&#34;QA Engine&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;There are 3 options for the QA engine.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;ChatGPT&lt;/em&gt;: uses OpenAI&#39;s gpt-3.5-turbo &lt;a href=&#34;https://platform.openai.com/docs/models/overview&#34;&gt;API&lt;/a&gt; without the personal timeline as context. It answers world knowledge question such as &lt;code&gt;what is the GDP of US in 2021&lt;/code&gt; but not personal questions.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;Retrieval-based&lt;/em&gt;: answers question by retrieving the top-k most relevant episodes from the personal timeline as the LLM&#39;s context. It can answer questions over the personal timeline such as &lt;code&gt;show me some plants in my neighborhood&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;View-based&lt;/em&gt;: translates the input question to a (customized) SQL query over tabular views (e.g., books, exercise, etc.) of the personal timeline. This QA engine is good at answering aggregate queries (&lt;code&gt;how many books did I purchase?&lt;/code&gt;) and min/max queries (&lt;code&gt;when was the last time I travel to Japan&lt;/code&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Example questions you may try:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;Show me some photos of plants in my neighborhood&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;Which cities did I visit when I traveled to Japan?&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;How many books did I purchase in April?&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TimelineQA: a benchmark for Question Answer over the personal timeline&lt;/h2&gt; &#xA;&lt;p&gt;TimelineQA is a synthetic benchmark for accelerating progress on querying personal timelines. TimelineQA generates lifelogs of imaginary people. The episodes in the lifelog range from major life episodes such as high school graduation to those that occur on a daily basis such as going for a run. We have evaluated SOTA models for atomic and multi-hop QA on the benchmark.&lt;/p&gt; &#xA;&lt;p&gt;Please check out the TimelineQA github &lt;a href=&#34;https://github.com/facebookresearch/TimelineQA&#34;&gt;repo&lt;/a&gt; and the TimelineQA paper --- &lt;a href=&#34;https://arxiv.org/abs/2306.01061&#34;&gt;https://arxiv.org/abs/2306.01061&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{tan2023timelineqa,&#xA;  title={TimelineQA: A Benchmark for Question Answering over Timelines},&#xA;  author={Tan, Wang-Chiew and Dwivedi-Yu, Jane and Li, Yuliang and Mathias, Lambert and Saeidi, Marzieh and Yan, Jing Nathan and Halevy, Alon Y},&#xA;  journal={arXiv preprint arXiv:2306.01069},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The codebase is licensed under the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/LICENSE&#34;&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/CONTRIBUTING.md&#34;&gt;contributing&lt;/a&gt; and the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/personal-timeline/main/CODE_OF_CONDUCT.md&#34;&gt;code of conduct&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>PacktPublishing/Causal-Inference-and-Discovery-in-Python</title>
    <updated>2023-09-04T01:33:58Z</updated>
    <id>tag:github.com,2023-09-04:/PacktPublishing/Causal-Inference-and-Discovery-in-Python</id>
    <link href="https://github.com/PacktPublishing/Causal-Inference-and-Discovery-in-Python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Causal Inference and Discovery in Python by Packt Publishing&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Causal Inference and Discovery in Python&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.packtpub.com/product/causal-inference-and-discovery-in-python/9781804612989&#34;&gt;&lt;img src=&#34;https://content.packt.com/B18993/cover_image_small.jpg&#34; alt=&#34;Causal Inference and Discovery in Python&#34; height=&#34;256px&#34; align=&#34;right&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the code repository for &lt;a href=&#34;https://www.packtpub.com/product/causal-inference-and-discovery-in-python/9781804612989&#34;&gt;Causal Inference and Discovery in Python&lt;/a&gt;, published by Packt.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Unlock the secrets of modern causal machine learning with DoWhy, EconML, PyTorch and more&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is this book about?&lt;/h2&gt; &#xA;&lt;p&gt;Causal methods present unique challenges compared to traditional machine learning and statistics. Learning causality can be challenging, but it offers distinct advantages that elude a purely statistical mindset. Causal Inference and Discovery in Python helps you unlock the potential of causality.&lt;/p&gt; &#xA;&lt;p&gt;You’ll start with basic motivations behind causal thinking and a comprehensive introduction to Pearlian causal concepts, such as structural causal models, interventions, counterfactuals, and more. Each concept is accompanied by a theoretical explanation and a set of practical exercises with Python code.&lt;/p&gt; &#xA;&lt;p&gt;Next, you’ll dive into the world of causal effect estimation, consistently progressing towards modern machine learning methods. Step-by-step, you’ll discover Python causal ecosystem and harness the power of cutting-edge algorithms. You’ll further explore the mechanics of how “causes leave traces” and compare the main families of causal discovery algorithms.&lt;/p&gt; &#xA;&lt;p&gt;The final chapter gives you a broad outlook into the future of causal AI where we examine challenges and opportunities and provide you with a comprehensive list of resources to learn more.&lt;/p&gt; &#xA;&lt;p&gt;This book covers the following exciting features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Master the fundamental concepts of causal inference&lt;/li&gt; &#xA; &lt;li&gt;Decipher the mysteries of structural causal models&lt;/li&gt; &#xA; &lt;li&gt;Unleash the power of the 4-step causal inference process in Python&lt;/li&gt; &#xA; &lt;li&gt;Explore advanced uplift modeling techniques&lt;/li&gt; &#xA; &lt;li&gt;Unlock the secrets of modern causal discovery using Python&lt;/li&gt; &#xA; &lt;li&gt;Use causal inference for social impact and community benefit&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you feel this book is for you, get your &lt;a href=&#34;https://www.amazon.com/Causal-Inference-Discovery-Python-learning/dp/1804612987/ref=sr_1_1?keywords=Causal+Inference+and+Discovery+in+Python&amp;amp;s=books&amp;amp;sr=1-1&#34;&gt;copy&lt;/a&gt; today!&lt;/p&gt; &#xA;&lt;h2&gt;Instructions and Navigations&lt;/h2&gt; &#xA;&lt;p&gt;All of the code is organized into folders.&lt;/p&gt; &#xA;&lt;p&gt;The code will look like the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;preds = causal_bert.inference(&#xA;    texts=df[&#39;text&#39;],&#xA;    confounds=df[&#39;has_photo&#39;],&#xA;)[0]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Following is what you need for this book:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This book is for machine learning engineers, data scientists, and machine learning researchers looking to extend their data science toolkit and explore causal machine learning. It will also help developers familiar with causality who have worked in another technology and want to switch to Python, and data scientists with a history of working with traditional causality who want to learn causal machine learning. It’s also a must-read for tech-savvy entrepreneurs looking to build a competitive edge for their products and go beyond the limitations of traditional machine learning.&lt;/p&gt; &#xA;&lt;p&gt;With the following software and hardware list you can run all code files present in the book (Chapter 1-15).&lt;/p&gt; &#xA;&lt;h3&gt;Software and Hardware List&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Chapter&lt;/th&gt; &#xA;   &lt;th&gt;Software required&lt;/th&gt; &#xA;   &lt;th&gt;OS required&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;Python 3.9&lt;/td&gt; &#xA;   &lt;td&gt;Windows macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;DoWhy 0.8&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;EconML 0.12.0&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;CATENets 0.2.3&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;gCastle 1.0.3&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;Causica 0.2.0&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;Causal-learn 0.1.3.3&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1-15&lt;/td&gt; &#xA;   &lt;td&gt;Transformers 4.24.0&lt;/td&gt; &#xA;   &lt;td&gt;Windows, macOS, or Linux&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Related products &#xA; &lt;other books you may enjoy&gt;&lt;/other&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Hands-On Graph Neural Networks Using Python &lt;a href=&#34;https://www.packtpub.com/product/hands-on-graph-neural-networks-using-python/9781804617526&#34;&gt;[Packt]&lt;/a&gt; &lt;a href=&#34;https://www.amazon.com/Hands-Graph-Neural-Networks-Python/dp/1804617520/ref=sr_1_1?keywords=Hands-On+Graph+Neural+Networks+Using+Python&amp;amp;s=books&amp;amp;sr=1-1&#34;&gt;[Amazon]&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Applying Math with Python - Second Edition &lt;a href=&#34;https://www.packtpub.com/product/applying-math-with-python-second-edition/9781804618370&#34;&gt;[Packt]&lt;/a&gt; &lt;a href=&#34;https://www.amazon.com/Applying-Math-Python-real-world-computational/dp/1804618373/ref=sr_1_1?keywords=Applying+Math+with+Python+-+Second+Edition&amp;amp;s=books&amp;amp;sr=1-1&#34;&gt;[Amazon]&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Get to Know the Author&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Aleksander Molak&lt;/strong&gt; is a Machine Learning Researcher and Consultant who gained experience working with Fortune 100, Fortune 500, and Inc. 5000 companies across Europe, the USA, and Israel, designing and building large-scale machine learning systems. On a mission to democratize causality for businesses and machine learning practitioners, Aleksander is a prolific writer, creator, and international speaker. As a co-founder of Lespire, an innovative provider of AI and machine learning training for corporate teams, Aleksander is committed to empowering businesses to harness the full potential of cutting-edge technologies that allow them to stay ahead of the curve.&lt;/p&gt; &#xA;&lt;h1&gt;Note from the Author:&lt;/h1&gt; &#xA;&lt;h2&gt;Environment installation&lt;/h2&gt; &#xA;&lt;p&gt;To install the basic environment run: &lt;code&gt;conda env create -f causal_book_py39_cuda117.yml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;To install the environment for notebook &lt;code&gt;Chapter_11.2.ipynb&lt;/code&gt; run: &lt;code&gt;conda create -f causal-pymc.yml&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Selecting the kernel&lt;/h2&gt; &#xA;&lt;p&gt;After a successful installation of the environment, open your notebook and select the kernel &lt;code&gt;causal_book_py39_cuda117&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;For notebook &lt;code&gt;Chapter_11.2.ipynb&lt;/code&gt; change kernel to &lt;code&gt;causal-pymc&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Using &lt;code&gt;graphviz&lt;/code&gt; and GPU&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Depending on your system settings, you might need to install &lt;code&gt;graphviz&lt;/code&gt; manually in order to recreate the graph plots in the code. Check &lt;a href=&#34;https://pypi.org/project/graphviz/&#34;&gt;https://pypi.org/project/graphviz/&lt;/a&gt; for specific instructions specific to your operating system.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note 2&lt;/strong&gt;: To use GPU you&#39;ll need to install CUDA 11.7 drivers. This can be done here: &lt;a href=&#34;https://developer.nvidia.com/cuda-11-7-0-download-archive&#34;&gt;https://developer.nvidia.com/cuda-11-7-0-download-archive&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‼️ Known mistakes // errata&lt;/h2&gt; &#xA;&lt;p&gt;For known errors and corrections check:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/PacktPublishing/Causal-Inference-and-Discovery-in-Python/raw/main/errata/Errata%20-%20Early%20Print%20(ordered%20before%20June%2013%202023).ipynb&#34;&gt;Books purchased before ~12:00 PM on June 13, 2023&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/PacktPublishing/Causal-Inference-and-Discovery-in-Python/raw/main/errata/Errata%20-%20Non-Early%20Print%20(ordered%20after%20June%2013%202023).ipynb&#34;&gt;Books purchased after ~12:00 PM on June 13, 2023&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;If you spotted a mistake, let us know at book(at)causalpython.io or just open an &lt;strong&gt;issue&lt;/strong&gt; in this repo. Thank you 🙏🏼&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>boyu-ai/Hands-on-ML</title>
    <updated>2023-09-04T01:33:58Z</updated>
    <id>tag:github.com,2023-09-04:/boyu-ai/Hands-on-ML</id>
    <link href="https://github.com/boyu-ai/Hands-on-ML" rel="alternate"></link>
    <summary type="html">&lt;p&gt;https://hml.boyuai.com&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;动手学机器学习&lt;/h1&gt;</summary>
  </entry>
</feed>