<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-24T01:32:13Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>ArcInstitute/evo2</title>
    <updated>2025-05-24T01:32:13Z</updated>
    <id>tag:github.com,2025-05-24:/ArcInstitute/evo2</id>
    <link href="https://github.com/ArcInstitute/evo2" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Genome modeling and design across all domains of life&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Evo 2: Genome modeling and design across all domains of life&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/evo2.jpg&#34; alt=&#34;Evo 2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Evo 2 is a state of the art DNA language model for long context modeling and design. Evo 2 models DNA sequences at single-nucleotide resolution at up to 1 million base pair context length using the &lt;a href=&#34;https://github.com/Zymrael/savanna/raw/main/paper.pdf&#34;&gt;StripedHyena 2&lt;/a&gt; architecture. Evo 2 was pretrained using &lt;a href=&#34;https://github.com/Zymrael/savanna&#34;&gt;Savanna&lt;/a&gt;. Evo 2 was trained autoregressively on &lt;a href=&#34;https://huggingface.co/datasets/arcinstitute/opengenome2&#34;&gt;OpenGenome2&lt;/a&gt;, a dataset containing 8.8 trillion tokens from all domains of life.&lt;/p&gt; &#xA;&lt;p&gt;We describe Evo 2 in the preprint: &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2025.02.18.638918v1&#34;&gt;&#34;Genome modeling and design across all domains of life with Evo 2&#34;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#checkpoints&#34;&gt;Checkpoints&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#usage&#34;&gt;Usage&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#forward&#34;&gt;Forward&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#embeddings&#34;&gt;Embeddings&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#generation&#34;&gt;Generation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#notebooks&#34;&gt;Notebooks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#nvidia-nim&#34;&gt;Nvidia NIM&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#dataset&#34;&gt;Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#training-and-finetuning&#34;&gt;Training and Finetuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;This repo is for running Evo 2 locally for inference or generation, using our &lt;a href=&#34;https://github.com/Zymrael/vortex&#34;&gt;Vortex&lt;/a&gt; inference code. For training and finetuning, see the section &lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#training-and-finetuning&#34;&gt;here&lt;/a&gt;. You can run Evo 2 without any installation using the &lt;a href=&#34;https://build.nvidia.com/arc/evo2-40b&#34;&gt;Nvidia Hosted API&lt;/a&gt;. You can also self-host an instance using Nvidia NIM. See the &lt;a href=&#34;https://raw.githubusercontent.com/ArcInstitute/evo2/main/#nvidia-nim&#34;&gt;Nvidia NIM&lt;/a&gt; section for more information.&lt;/p&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 is based on &lt;a href=&#34;https://github.com/Zymrael/vortex&#34;&gt;StripedHyena 2&lt;/a&gt; which requires python&amp;gt;=3.11. Evo 2 uses &lt;a href=&#34;https://github.com/NVIDIA/TransformerEngine&#34;&gt;Transformer Engine&lt;/a&gt; FP8 for some layers which requires an H100 (or other GPU with compute capability â‰¥8.9). We are actively investigating ways to avoid this requirement.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;To install Evo 2 for inference or generation, please clone and install from GitHub. We recommend using a new conda environment with python&amp;gt;=3.11.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone --recurse-submodules git@github.com:ArcInstitute/evo2.git&#xA;cd evo2&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If this did not work for whatever reason, you can also install from &lt;a href=&#34;https://github.com/Zymrael/vortex&#34;&gt;Vortex&lt;/a&gt; and follow the instructions there. PyPi support coming soon!&lt;/p&gt; &#xA;&lt;p&gt;You can check that the installation was correct by running a test.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python ./test/test_evo2.py --model_name evo2_7b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Checkpoints&lt;/h2&gt; &#xA;&lt;p&gt;We provide the following model checkpoints, hosted on &lt;a href=&#34;https://huggingface.co/arcinstitute&#34;&gt;HuggingFace&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Checkpoint Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo2_40b&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 1 million context obtained through context extension of &lt;code&gt;evo2_40b_base&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo2_7b&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 1 million context obtained through context extension of &lt;code&gt;evo2_7b_base&lt;/code&gt;.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo2_40b_base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 8192 context length.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo2_7b_base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 8192 context length.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo2_1b_base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A smaller model pretrained with 8192 context length.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;To use Evo 2 40B, you will need multiple GPUs. Vortex automatically handles device placement, splitting the model across available cuda devices.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Below are simple examples of how to download Evo 2 and use it locally in Python.&lt;/p&gt; &#xA;&lt;h3&gt;Forward&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 can be used to score the likelihoods across a DNA sequence.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from evo2 import Evo2&#xA;&#xA;evo2_model = Evo2(&#39;evo2_7b&#39;)&#xA;&#xA;sequence = &#39;ACGT&#39;&#xA;input_ids = torch.tensor(&#xA;    evo2_model.tokenizer.tokenize(sequence),&#xA;    dtype=torch.int,&#xA;).unsqueeze(0).to(&#39;cuda:0&#39;)&#xA;&#xA;outputs, _ = evo2_model(input_ids)&#xA;logits = outputs[0]&#xA;&#xA;print(&#39;Logits: &#39;, logits)&#xA;print(&#39;Shape (batch, length, vocab): &#39;, logits.shape)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Embeddings&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 embeddings can be saved for use downstream. We find that intermediate embeddings work better than final embeddings, see our paper for details.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from evo2 import Evo2&#xA;&#xA;evo2_model = Evo2(&#39;evo2_7b&#39;)&#xA;&#xA;sequence = &#39;ACGT&#39;&#xA;input_ids = torch.tensor(&#xA;    evo2_model.tokenizer.tokenize(sequence),&#xA;    dtype=torch.int,&#xA;).unsqueeze(0).to(&#39;cuda:0&#39;)&#xA;&#xA;layer_name = &#39;blocks.28.mlp.l3&#39;&#xA;&#xA;outputs, embeddings = evo2_model(input_ids, return_embeddings=True, layer_names=[layer_name])&#xA;&#xA;print(&#39;Embeddings shape: &#39;, embeddings[layer_name].shape)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 can generate DNA sequences based on prompts.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from evo2 import Evo2&#xA;&#xA;evo2_model = Evo2(&#39;evo2_7b&#39;)&#xA;&#xA;output = evo2_model.generate(prompt_seqs=[&#34;ACGT&#34;], n_tokens=400, temperature=1.0, top_k=4)&#xA;&#xA;print(output.sequences[0])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Notebooks&lt;/h3&gt; &#xA;&lt;p&gt;We provide example notebooks.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/ArcInstitute/evo2/raw/main/notebooks/brca1/brca1_zero_shot_vep.ipynb&#34;&gt;BRCA1 notebook&lt;/a&gt; shows zero-shot &lt;em&gt;BRCA1&lt;/em&gt; variant effect prediction. This example includes a walkthrough of:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Performing zero-shot &lt;em&gt;BRCA1&lt;/em&gt; variant effect predictions using Evo 2&lt;/li&gt; &#xA; &lt;li&gt;Reference vs alternative allele normalization&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://github.com/ArcInstitute/evo2/raw/main/notebooks/generation/generation_notebook.ipynb&#34;&gt;generation notebook&lt;/a&gt; shows DNA sequence completion with Evo 2. This example shows:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;DNA prompt based generation and &#39;DNA autocompletion&#39;&lt;/li&gt; &#xA; &lt;li&gt;How to get and prompt using phylogenetic species tags for generation&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Nvidia NIM&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 is available on &lt;a href=&#34;https://catalog.ngc.nvidia.com/containers?filters=&amp;amp;orderBy=scoreDESC&amp;amp;query=evo2&amp;amp;page=&amp;amp;pageSize=&#34;&gt;Nvidia NIM&lt;/a&gt; and &lt;a href=&#34;https://build.nvidia.com/arc/evo2-40b&#34;&gt;hosted API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/nim/bionemo/evo2/latest/overview.html&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.nvidia.com/nim/bionemo/evo2/latest/quickstart-guide.html&#34;&gt;Quickstart&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The quickstart guides users through running Evo 2 on the NVIDIA NIM using a python or shell client after starting NIM. An example python client script is shown below. This is the same way you would interact with the &lt;a href=&#34;https://build.nvidia.com/arc/evo2-40b?snippet_tab=Python&#34;&gt;Nvidia hosted API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/env python3&#xA;import requests&#xA;import os&#xA;import json&#xA;from pathlib import Path&#xA;&#xA;key = os.getenv(&#34;NVCF_RUN_KEY&#34;) or input(&#34;Paste the Run Key: &#34;)&#xA;&#xA;r = requests.post(&#xA;    url=os.getenv(&#34;URL&#34;, &#34;https://health.api.nvidia.com/v1/biology/arc/evo2-40b/generate&#34;),&#xA;    headers={&#34;Authorization&#34;: f&#34;Bearer {key}&#34;},&#xA;    json={&#xA;        &#34;sequence&#34;: &#34;ACTGACTGACTGACTG&#34;,&#xA;        &#34;num_tokens&#34;: 8,&#xA;        &#34;top_k&#34;: 1,&#xA;        &#34;enable_sampled_probs&#34;: True,&#xA;    },&#xA;)&#xA;&#xA;if &#34;application/json&#34; in r.headers.get(&#34;Content-Type&#34;, &#34;&#34;):&#xA;    print(r, &#34;Saving to output.json:\n&#34;, r.text[:200], &#34;...&#34;)&#xA;    Path(&#34;output.json&#34;).write_text(r.text)&#xA;elif &#34;application/zip&#34; in r.headers.get(&#34;Content-Type&#34;, &#34;&#34;):&#xA;    print(r, &#34;Saving large response to data.zip&#34;)&#xA;    Path(&#34;data.zip&#34;).write_bytes(r.content)&#xA;else:&#xA;    print(r, r.headers, r.content)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Very long sequences&lt;/h3&gt; &#xA;&lt;p&gt;We are actively working on optimizing performance for long sequence processing in Vortex. Vortex can currently compute over very long sequences via teacher prompting. However please note that forward pass on long sequences may currently be slow. You can instead use &lt;a href=&#34;https://github.com/Zymrael/savanna&#34;&gt;Savanna&lt;/a&gt; or &lt;a href=&#34;https://github.com/NVIDIA/bionemo-framework&#34;&gt;Nvidia BioNemo&lt;/a&gt; for embedding long sequences.&lt;/p&gt; &#xA;&lt;h3&gt;Dataset&lt;/h3&gt; &#xA;&lt;p&gt;The OpenGenome2 dataset used for pretraining Evo2 is available on &lt;a href=&#34;https://huggingface.co/datasets/arcinstitute/opengenome2&#34;&gt;HuggingFace &lt;/a&gt;. Data is available either as raw fastas or as JSONL files which include preprocessing and data augmentation.&lt;/p&gt; &#xA;&lt;h3&gt;Training and Finetuning&lt;/h3&gt; &#xA;&lt;p&gt;Evo 2 was trained using &lt;a href=&#34;https://github.com/Zymrael/savanna&#34;&gt;Savanna&lt;/a&gt;, an open source framework for training alternative architectures.&lt;/p&gt; &#xA;&lt;p&gt;To train or finetune Evo 2, you can use &lt;a href=&#34;https://github.com/Zymrael/savanna&#34;&gt;Savanna&lt;/a&gt; or &lt;a href=&#34;https://github.com/NVIDIA/bionemo-framework&#34;&gt;Nvidia BioNemo&lt;/a&gt; which provides a &lt;a href=&#34;https://github.com/NVIDIA/bionemo-framework/raw/ca16c2acf9bf813d020b6d1e2d4e1240cfef6a69/docs/docs/user-guide/examples/bionemo-evo2/fine-tuning-tutorial.ipynb&#34;&gt;Evo 2 finetuning tutorial here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find these models useful for your research, please cite the relevant papers&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article {Brixi2025.02.18.638918,&#xA;&#x9;author = {Brixi, Garyk and Durrant, Matthew G and Ku, Jerome and Poli, Michael and Brockman, Greg and Chang, Daniel and Gonzalez, Gabriel A and King, Samuel H and Li, David B and Merchant, Aditi T and Naghipourfar, Mohsen and Nguyen, Eric and Ricci-Tam, Chiara and Romero, David W and Sun, Gwanggyu and Taghibakshi, Ali and Vorontsov, Anton and Yang, Brandon and Deng, Myra and Gorton, Liv and Nguyen, Nam and Wang, Nicholas K and Adams, Etowah and Baccus, Stephen A and Dillmann, Steven and Ermon, Stefano and Guo, Daniel and Ilango, Rajesh and Janik, Ken and Lu, Amy X and Mehta, Reshma and Mofrad, Mohammad R.K. and Ng, Madelena Y and Pannu, Jaspreet and Re, Christopher and Schmok, Jonathan C and St. John, John and Sullivan, Jeremy and Zhu, Kevin and Zynda, Greg and Balsam, Daniel and Collison, Patrick and Costa, Anthony B. and Hernandez-Boussard, Tina and Ho, Eric and Liu, Ming-Yu and McGrath, Tom and Powell, Kimberly and Burke, Dave P. and Goodarzi, Hani and Hsu, Patrick D and Hie, Brian},&#xA;&#x9;title = {Genome modeling and design across all domains of life with Evo 2},&#xA;&#x9;elocation-id = {2025.02.18.638918},&#xA;&#x9;year = {2025},&#xA;&#x9;doi = {10.1101/2025.02.18.638918},&#xA;&#x9;publisher = {Cold Spring Harbor Laboratory},&#xA;&#x9;URL = {https://www.biorxiv.org/content/early/2025/02/21/2025.02.18.638918},&#xA;&#x9;eprint = {https://www.biorxiv.org/content/early/2025/02/21/2025.02.18.638918.full.pdf},&#xA;&#x9;journal = {bioRxiv}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>