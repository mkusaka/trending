<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-09T01:39:36Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>TonyLianLong/stable-diffusion-xl-demo</title>
    <updated>2023-07-09T01:39:36Z</updated>
    <id>tag:github.com,2023-07-09:/TonyLianLong/stable-diffusion-xl-demo</id>
    <link href="https://github.com/TonyLianLong/stable-diffusion-xl-demo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A gradio web demo for Stable Diffusion XL 0.9&lt;/p&gt;&lt;hr&gt;&lt;hr&gt; &#xA;&lt;h2&gt;title: Stable Diffusion XL 0.9 emoji: ğŸ”¥ colorFrom: yellow colorTo: gray sdk: gradio sdk_version: 3.11.0 app_file: app.py pinned: true license: mit&lt;/h2&gt; &#xA;&lt;h1&gt;StableDiffusion XL Gradio Demo&lt;/h1&gt; &#xA;&lt;p&gt;This is a gradio demo supporting &lt;a href=&#34;https://github.com/Stability-AI/generative-models&#34;&gt;Stable Diffusion XL 0.9&lt;/a&gt;. This demo loads the base and the refiner model.&lt;/p&gt; &#xA;&lt;p&gt;This is forked from &lt;a href=&#34;https://huggingface.co/spaces/gradio-client-demos/stable-diffusion&#34;&gt;StableDiffusion v2.1 Demo&lt;/a&gt;. Refer to the git commits to see the changes.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Seems like Reddit people released the weights to the public: &lt;a href=&#34;https://www.reddit.com/r/StableDiffusion/comments/14s04t1/happy_sdxl_leak_day/&#34;&gt;reddit post on the leaked weights&lt;/a&gt;. The weights, if downloaded in the full folder, may be loaded with Option 1. &lt;strong&gt;Though I have not tried the weights. Nor do I encourage using leaked weights.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Colab is supported! You can run this demo on Colab for free even on T4. &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/TonyLianLong/stable-diffusion-xl-demo/blob/main/Stable_Diffusion_XL_Demo.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;a href=&#34;https://github.com/TonyLianLong/stable-diffusion-xl-demo/tree/benchmark/benchmark&#34;&gt;See a more comprehensive comparison with 1200+ images here&lt;/a&gt;. Both SD XL and SD v2.1 are benchmarked on prompts from &lt;a href=&#34;https://github.com/Stability-AI/StableStudio&#34;&gt;StableStudio&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Left: SDXL 0.9. Right: &lt;a href=&#34;https://huggingface.co/spaces/gradio-client-demos/stable-diffusion&#34;&gt;SD v2.1&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Without any tuning, SDXL generates much better images compared to SD v2.1!&lt;/p&gt; &#xA;&lt;h3&gt;Example 1&lt;/h3&gt; &#xA;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img1_sdxl0.9.png&#34; width=&#34;48%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img1_sdv2.1.png&#34; width=&#34;48%&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Example 2&lt;/h3&gt; &#xA;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img2_sdxl0.9.png&#34; width=&#34;48%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img2_sdv2.1.png&#34; width=&#34;48%&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Example 3&lt;/h3&gt; &#xA;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img3_sdxl0.9.png&#34; width=&#34;48%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img3_sdv2.1.png&#34; width=&#34;48%&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Example 4&lt;/h3&gt; &#xA;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img4_sdxl0.9.png&#34; width=&#34;48%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img4_sdv2.1.png&#34; width=&#34;48%&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Example 5&lt;/h3&gt; &#xA;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img5_sdxl0.9.png&#34; width=&#34;48%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/TonyLianLong/stable-diffusion-xl-demo/main/imgs/img5_sdv2.1.png&#34; width=&#34;48%&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;With torch 2.0.1 installed, we also need to install:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install accelerate transformers invisible-watermark &#34;numpy&amp;gt;=1.17&#34; &#34;PyWavelets&amp;gt;=1.1.1&#34; &#34;opencv-python&amp;gt;=4.1.0.25&#34; safetensors &#34;gradio==3.11.0&#34;&#xA;pip install git+https://github.com/huggingface/diffusers.git@sd_xl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Launching&lt;/h2&gt; &#xA;&lt;p&gt;It&#39;s free but you need to &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9&#34;&gt;submit a quick form&lt;/a&gt; to get access to the weights. Leaked weights seem to be available on &lt;a href=&#34;https://www.reddit.com/r/StableDiffusion/comments/14s04t1/happy_sdxl_leak_day/&#34;&gt;reddit&lt;/a&gt;, but I have not used/tested them.&lt;/p&gt; &#xA;&lt;p&gt;There are two ways to load the weights. After getting access to weights, you can either clone them locally or this repo can load them for you.&lt;/p&gt; &#xA;&lt;h3&gt;Option 1&lt;/h3&gt; &#xA;&lt;p&gt;If you have cloned both repo (&lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-xl-base-0.9&#34;&gt;base&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-0.9&#34;&gt;refiner&lt;/a&gt;) locally (please change the &lt;code&gt;path_to_sdxl&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 SDXL_MODEL_DIR=/path_to_sdxl python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Option 2&lt;/h3&gt; &#xA;&lt;p&gt;If you want to load from the huggingface hub (please set up a &lt;a href=&#34;https://huggingface.co/docs/hub/security-tokens&#34;&gt;HuggingFace access token&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 ACCESS_TOKEN=YOUR_HF_ACCESS_TOKEN python app.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;&lt;code&gt;torch.compile&lt;/code&gt; support&lt;/h3&gt; &#xA;&lt;p&gt;Turn on &lt;code&gt;torch.compile&lt;/code&gt; will make overall inference faster. However, this will add some overhead to the first run (i.e., have to wait for compilation during the first run).&lt;/p&gt; &#xA;&lt;h3&gt;To save memory&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Turn on &lt;code&gt;pipe.enable_model_cpu_offload()&lt;/code&gt; and turn off &lt;code&gt;pipe.to(&#34;cuda&#34;)&lt;/code&gt; in &lt;code&gt;app.py&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Turn off refiner by setting &lt;code&gt;enable_refiner&lt;/code&gt; to False.&lt;/li&gt; &#xA; &lt;li&gt;More ways to &lt;a href=&#34;https://huggingface.co/docs/diffusers/optimization/fp16&#34;&gt;save memory and make things faster&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Several options through environment variables&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;SDXL_MODEL_DIR&lt;/code&gt; and &lt;code&gt;ACCESS_TOKEN&lt;/code&gt;: load SDXL locally or from HF hub.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;ENABLE_REFINER=true/false&lt;/code&gt; turn on/off the refiner (&lt;a href=&#34;https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-0.9&#34;&gt;refiner&lt;/a&gt; refines the generation).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OUTPUT_IMAGES_BEFORE_REFINER=true/false&lt;/code&gt; useful is refiner is enabled. Output images before and after the refiner stage.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;SHARE=true/false&lt;/code&gt; creates public link (useful for sharing and on colab)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;If you enjoy this demo, please give &lt;a href=&#34;https://github.com/TonyLianLong/stable-diffusion-xl-demo&#34;&gt;this repo&lt;/a&gt; a star â­.&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>kyegomez/swarms</title>
    <updated>2023-07-09T01:39:36Z</updated>
    <id>tag:github.com,2023-07-09:/kyegomez/swarms</id>
    <link href="https://github.com/kyegomez/swarms" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Automating all digital activities with millions of autonomous AI Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Agora ğŸ›ï¸&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/images/Agora-Banner-blend.png&#34; alt=&#34;Agora banner&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://discord.gg/qUtxnK2NMf&#34;&gt;Swarms is brought to you by Agora, the open source AI research organization. Join Agora and Help create swarms and or recieve support to advance Humanity. &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Swarming AI Agents (Swarms)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/images/swarms.png&#34; alt=&#34;Swarming banner&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/intent/tweet?text=Check%20out%20this%20amazing%20AI%20project:%20&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&amp;amp;label=Share%20%40kyegomez/swarms&#34; alt=&#34;Share on Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Share-%20facebook-blue&#34; alt=&#34;Share on Facebook&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&amp;amp;title=&amp;amp;summary=&amp;amp;source=&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Share-%20linkedin-blue&#34; alt=&#34;Share on LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Welcome to Swarms - the future of AI, where we leverage the power of autonomous agents to create &#39;swarms&#39; of Language Models (LLM) that work together, creating a dynamic and interactive AI system.&lt;/p&gt; &#xA;&lt;h2&gt;Vision&lt;/h2&gt; &#xA;&lt;p&gt;Artificial Intelligence has grown at an exponential rate over the past decade. Yet, we are far from fully harnessing its potential. Today&#39;s AI operates in isolation, each working separately in their corner. But life doesn&#39;t work like that. The world doesn&#39;t work like that. Success isn&#39;t built in silos; it&#39;s built in teams.&lt;/p&gt; &#xA;&lt;p&gt;Imagine a world where AI models work in unison. Where they can collaborate, interact, and pool their collective intelligence to achieve more than any single model could. This is the future we envision. But today, we lack a framework for AI to collaborate effectively, to form a true swarm of intelligent agents.&lt;/p&gt; &#xA;&lt;p&gt;This is a difficult problem, one that has eluded solution. It requires sophisticated systems that can allow individual models to not just communicate but also understand each other, pool knowledge and resources, and create collective intelligence. This is the next frontier of AI.&lt;/p&gt; &#xA;&lt;p&gt;But here at Swarms, we have a secret sauce. It&#39;s not just a technology or a breakthrough invention. It&#39;s a way of thinking - the philosophy of rapid iteration. With each cycle, we make massive progress. We experiment, we learn, and we grow. We have developed a pioneering framework that can enable AI models to work together as a swarm, combining their strengths to create richer, more powerful outputs.&lt;/p&gt; &#xA;&lt;p&gt;We are uniquely positioned to take on this challenge with 1,500+ devoted researchers in Agora. We have assembled a team of world-class experts, experienced and driven, united by a shared vision. Our commitment to breaking barriers, pushing boundaries, and our belief in the power of collective intelligence makes us the best team to usher in this future to fundamentally advance our species, Humanity.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/#sharing&#34;&gt;Sharing&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;There are 2 methods, one is through &lt;code&gt;git clone&lt;/code&gt; and the other is by &lt;code&gt;pip install swarms&lt;/code&gt;. Check out the &lt;a href=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/DOCUMENTATION.md&#34;&gt;document&lt;/a&gt; for more information on the classes.&lt;/p&gt; &#xA;&lt;h1&gt;Method1&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Pip install &lt;code&gt;python3 -m pip install swarms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create new python file and unleash superintelligence&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;from swarms import swarm&#xA;&#xA;api_key = &#34;api key for openai&#34;&#xA;&#xA;objective = &#34;What is the capital of the Uk&#34;&#xA;&#xA;result = swarm(api_key, objective)&#xA;print(result)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Method 2&lt;/h1&gt; &#xA;&lt;p&gt;Download via Github, and install requirements. Simple example by:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;git cloning https://github.com/kyegomez/swarms.git&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;cd swarms&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;python3 -m pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;python3 example.py&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;or create a new file:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from swarms.swarms import Swarms&#xA;&#xA;# Retrieve your API key from the environment or replace with your actual key&#xA;api_key = &#34;sksdsds&#34;&#xA;&#xA;# Initialize Swarms with your API key&#xA;swarm = Swarms(openai_api_key=api_key)&#xA;&#xA;# Define an objective&#xA;objective = &#34;&#34;&#34;&#xA;Please develop and serve a simple community web service. &#xA;People can signup, login, post, comment. &#xA;Post and comment should be visible at once. &#xA;I want it to have neumorphism-style. &#xA;The ports you can use are 4500 and 6500.&#xA;&#34;&#34;&#34;&#xA;&#xA;# Run Swarms&#xA;swarm.run_swarms(objective)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create and execute a task to write a summary about the latest news on quantum computing. The result will be the summary of the news.&lt;/p&gt; &#xA;&lt;h2&gt;Share with your Friends&lt;/h2&gt; &#xA;&lt;p&gt;Share on Twitter: &lt;a href=&#34;https://twitter.com/intent/tweet?text=Check%20out%20Swarms%20-%20the%20future%20of%20AI%20%23swarms%20%23AI&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url?style=social&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34; alt=&#34;Share on Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on Facebook: &lt;a href=&#34;https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20Facebook-blue&#34; alt=&#34;Share on Facebook&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on LinkedIn: &lt;a href=&#34;https://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&amp;amp;title=Swarms%20-%20the%20future%20of%20AI&amp;amp;summary=Check%20out%20Swarms%2C%20the%20future%20of%20AI%20where%20swarms%20of%20Language%20Models%20work%20together%20to%20create%20dynamic%20and%20interactive%20AI%20systems.&amp;amp;source=&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20LinkedIn-blue&#34; alt=&#34;Share on LinkedIn&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on Reddit: &lt;a href=&#34;https://www.reddit.com/submit?url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&amp;amp;title=Swarms%20-%20the%20future%20of%20AI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20Reddit-orange&#34; alt=&#34;Share on Reddit&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on Hacker News: &lt;a href=&#34;https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&amp;amp;t=Swarms%20-%20the%20future%20of%20AI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20Hacker%20News-orange&#34; alt=&#34;Share on Hacker News&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on Pinterest: &lt;a href=&#34;https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&amp;amp;media=https%3A%2F%2Fexample.com%2Fimage.jpg&amp;amp;description=Swarms%20-%20the%20future%20of%20AI&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20Pinterest-red&#34; alt=&#34;Share on Pinterest&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Share on WhatsApp: &lt;a href=&#34;https://api.whatsapp.com/send?text=Check%20out%20Swarms%20-%20the%20future%20of%20AI%20%23swarms%20%23AI%0A%0Ahttps%3A%2F%2Fgithub.com%2Fkyegomez%2Fswarms&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Share%20on%20WhatsApp-green&#34; alt=&#34;Share on WhatsApp&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Contribute&lt;/h2&gt; &#xA;&lt;p&gt;We&#39;re always looking for contributors to help us improve and expand this project. If you&#39;re interested, please check out our &lt;a href=&#34;https://raw.githubusercontent.com/kyegomez/swarms/master/CONTRIBUTING.md&#34;&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thank you for being a part of our project!&lt;/p&gt; &#xA;&lt;h1&gt;Open Source Roadmap&lt;/h1&gt; &#xA;&lt;p&gt;Here is the detailed roadmap of our priorities and planned features for the near term:&lt;/p&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Create extensive documentation&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure that the boss agent successfully calls the worker agent if when it&#39;s finished makinng a plan&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure the worker agent can access tools like web browser, terminal, and code editor, and multi-modal agents&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure inputs and outputs from boss to worker are well defined and are collaborating if not then readjust prompt&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a tool that creates other tools with access to write code, debug, and an architectural argent that creates the architecture and then another agent that creates the code[Architecter(with code examples), code generator (with access to writing code and terminalrools)] -- The Compiler?&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a screenshot tool that takes a screen shot and then passes it to a worker multi-modal agent for visual context.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;API endroute in FASTAPI&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Develop Conversational UI with Gradio&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrate omni agent as a worker tool&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrate Ocean Database as primary vectorstore&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrate visual agent&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Integrate quantized hf models as base models with langchain huggingface&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-Agent Debate Integration&lt;/strong&gt;: Integrate multi-agent debate frameworks (&lt;a href=&#34;https://github.com/Skytliang/Multi-Agents-Debate&#34;&gt;Multi Agent debate&lt;/a&gt; and &lt;a href=&#34;https://github.com/composable-models/llm_multiagent_debate&#34;&gt;Multi agent2 debate&lt;/a&gt;) to improve decision-making.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Meta Prompting Integration&lt;/strong&gt;: Include meta prompting across all worker agents to guide their actions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Swarms Class&lt;/strong&gt;: Create a main swarms class &lt;code&gt;swarms(&#39;Increase sales by 40$&#39;, workers=4)&lt;/code&gt; for managing and coordinating multiple worker nodes.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Integration of Additional Tools&lt;/strong&gt;: Integrate &lt;a href=&#34;https://github.com/microsoft/JARVIS&#34;&gt;Jarvis&lt;/a&gt; as worker nodes, add text to speech and text to script tools (&lt;a href=&#34;https://github.com/kyegomez/youtubeURL-to-text&#34;&gt;whisper x&lt;/a&gt;), and integrate Hugging Face agents and other external tools.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Task Completion and Evaluation Logic&lt;/strong&gt;: Include task completion logic with meta prompting, and evaluate task completion on a scale from 0.0 to 1.0.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ocean Integration&lt;/strong&gt;: Use the &lt;a href=&#34;https://github.com/kyegomez/Ocean&#34;&gt;Ocean&lt;/a&gt; vector database as the main embedding database for all the agents, both boss and worker.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improved Communication&lt;/strong&gt;: Develop a universal vector database that is only used when a task is completed in this format &lt;code&gt;[TASK][COMPLETED]&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Testing and Evaluation&lt;/strong&gt;: Create unit tests, benchmarks, and evaluations for performance monitoring and continuous improvement.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Worker Swarm Class&lt;/strong&gt;: Create a class for self-scaling worker swarms. If they need help, they can spawn an entirely new worker and more workers if needed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Examples&lt;/strong&gt;: Create extensive and useful examples for a variety of use cases.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;README&lt;/strong&gt;: Update the README to include the examples and usage instructions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Mid-Long term&lt;/h1&gt; &#xA;&lt;p&gt;Here are some potential middle-to-long-term improvements to consider for this project:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Modular Design&lt;/strong&gt;: Aim to design a more modular and scalable framework, making it easy for developers to plug-and-play various components.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive User Interface&lt;/strong&gt;: Develop a more interactive, user-friendly GUI that allows users to interact with the system without needing to understand the underlying code.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Error Handling&lt;/strong&gt;: Implement advanced error handling and debugging capabilities to make it easier for developers to diagnose and fix issues.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Optimized Resource Utilization&lt;/strong&gt;: Improve the efficiency of resource use, aiming to reduce memory consumption and improve speed without sacrificing accuracy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Collaborative Learning&lt;/strong&gt;: Integrate more sophisticated techniques for collaborative learning among the swarm, allowing them to share knowledge and learn from each other&#39;s successes and failures.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Autonomous Self-Improvement&lt;/strong&gt;: Implement mechanisms that allow the swarm to autonomously learn from its past experiences and improve its performance over time.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Security Enhancements&lt;/strong&gt;: Include robust security measures to protect sensitive data and prevent unauthorized access.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Privacy-Preserving Techniques&lt;/strong&gt;: Consider incorporating privacy-preserving techniques such as differential privacy to ensure the confidentiality of user data.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support for More Languages&lt;/strong&gt;: Expand language support to allow the system to cater to a more global audience.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Robustness and Resilience&lt;/strong&gt;: Improve the system&#39;s robustness and resilience, ensuring that it can operate effectively even in the face of hardware or software failures.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Continual Learning&lt;/strong&gt;: Implement continual learning techniques to allow the system to adapt and evolve as new data comes in.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Contextual Understanding&lt;/strong&gt;: Enhance the system&#39;s capability to understand context better, making it more effective in handling real-world, complex tasks.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Task Prioritization&lt;/strong&gt;: Develop advanced algorithms for dynamic task prioritization, ensuring that the most important tasks are addressed first.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expanding the Swarm&#39;s Skills&lt;/strong&gt;: Train the swarm on a wider range of tasks, gradually expanding their skill set and problem-solving capabilities.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Real-World Deployment&lt;/strong&gt;: Test and refine the system in real-world settings, learning from these experiences to further improve and adapt the system.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Remember, these are potential improvements. It&#39;s important to revisit your priorities regularly and adjust them based on project needs, feedback, and learning from both successes and failures.&lt;/p&gt; &#xA;&lt;h2&gt;Optimization Priorities&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliability&lt;/strong&gt;: Increase the reliability of the swarm - obtaining the desired output with a basic and un-detailed input.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Reduce the time it takes for the swarm to accomplish tasks by improving the communication layer, critiquing, and self-alignment with meta prompting.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Ensure that the system is asynchronous, concurrent, and self-healing to support scalability.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Our goal is to continuously improve Swarms by following this roadmap, while also being adaptable to new needs and opportunities as they arise.&lt;/p&gt; &#xA;&lt;h1&gt;Bounty Program&lt;/h1&gt; &#xA;&lt;p&gt;Our bounty program is an exciting opportunity for contributors to help us build the future of Swarms. By participating, you can earn rewards while contributing to a project that aims to revolutionize digital activity.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s how it works:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Check out our Roadmap&lt;/strong&gt;: We&#39;ve shared our roadmap detailing our short and long-term goals. These are the areas where we&#39;re seeking contributions.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pick a Task&lt;/strong&gt;: Choose a task from the roadmap that aligns with your skills and interests. If you&#39;re unsure, you can reach out to our team for guidance.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Get to Work&lt;/strong&gt;: Once you&#39;ve chosen a task, start working on it. Remember, quality is key. We&#39;re looking for contributions that truly make a difference.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Submit your Contribution&lt;/strong&gt;: Once your work is complete, submit it for review. We&#39;ll evaluate your contribution based on its quality, relevance, and the value it brings to Swarms.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Earn Rewards&lt;/strong&gt;: If your contribution is approved, you&#39;ll earn a bounty. The amount of the bounty depends on the complexity of the task, the quality of your work, and the value it brings to Swarms.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;The Three Phases of Our Bounty Program&lt;/h2&gt; &#xA;&lt;h3&gt;Phase 1: Building the Foundation&lt;/h3&gt; &#xA;&lt;p&gt;In the first phase, our focus is on building the basic infrastructure of Swarms. This includes developing key components like the Swarms class, integrating essential tools, and establishing task completion and evaluation logic. We&#39;ll also start developing our testing and evaluation framework during this phase. If you&#39;re interested in foundational work and have a knack for building robust, scalable systems, this phase is for you.&lt;/p&gt; &#xA;&lt;h3&gt;Phase 2: Optimizing the System&lt;/h3&gt; &#xA;&lt;p&gt;In the second phase, we&#39;ll focus on optimizng Swarms by integrating more advanced features, improving the system&#39;s efficiency, and refining our testing and evaluation framework. This phase involves more complex tasks, so if you enjoy tackling challenging problems and contributing to the development of innovative features, this is the phase for you.&lt;/p&gt; &#xA;&lt;h3&gt;Phase 3: Towards Super-Intelligence&lt;/h3&gt; &#xA;&lt;p&gt;The third phase of our bounty program is the most exciting - this is where we aim to achieve super-intelligence. In this phase, we&#39;ll be working on improving the swarm&#39;s capabilities, expanding its skills, and fine-tuning the system based on real-world testing and feedback. If you&#39;re excited about the future of AI and want to contribute to a project that could potentially transform the digital world, this is the phase for you.&lt;/p&gt; &#xA;&lt;p&gt;Remember, our roadmap is a guide, and we encourage you to bring your own ideas and creativity to the table. We believe that every contribution, no matter how small, can make a difference. So join us on this exciting journey and help us create the future of Swarms.&lt;/p&gt; &#xA;&lt;!-- **To participate in our bounty program, visit the [Swarms Bounty Program Page](https://swarms.ai/bounty).** Let&#39;s build the future together! --&gt; &#xA;&lt;h1&gt;Inspiration&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://twitter.com/hwchase17/status/1645834030519296000&#34;&gt;ğŸªCAMELğŸª&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/rumpfmax/Multi-GPT/raw/master/multigpt/multi_agent_manager.py&#34;&gt;MultiAgent&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;AutoGPT&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;&#34;&gt;SuperAGI&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/DataBassGit/AgentForge&#34;&gt;AgentForge&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/MineDojo/Voyager&#34;&gt;Voyager&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.15334&#34;&gt;Gorilla: Large Language Model Connected with Massive APIs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM powered agents&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Agent System Overview&lt;/h2&gt; &#xA;&lt;p&gt;In a LLM-powered autonomous agent system, LLM functions as the agentâ€™s brain, complemented by several key components:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Planning Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks. Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Memory Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn. Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Tool use The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Communication -&amp;gt; How reliable and fast is the communication between each indivual agent.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;EcoSystem&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kyegomez/the-compiler&#34;&gt;The-Compiler, compile natural language into serene, reliable, and secure programs&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;*&lt;a href=&#34;https://github.com/kyegomez/The-Replicator&#34;&gt;The Replicator, an autonomous swarm that conducts Multi-Modal AI research by creating new underlying mathematical operations and models&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Make a swarm that checks arxviv for papers -&amp;gt; checks if there is a github link -&amp;gt; then implements them and checks them&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>EvilPsyCHo/train_custom_LLM</title>
    <updated>2023-07-09T01:39:36Z</updated>
    <id>tag:github.com,2023-07-09:/EvilPsyCHo/train_custom_LLM</id>
    <link href="https://github.com/EvilPsyCHo/train_custom_LLM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Train your custom LLMs like Llama, baichuan-7b, GPT&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Train Custom LLM&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ¢ç´¢LLMæ›´å¤šæœ‰è¶£çš„ç©æ³•, ç¥å¤§å®¶ç©çš„æ„‰å¿«! æ›´è¯¦ç»†çš„LLMè§†é¢‘æ›´æ–°åœ¨æˆ‘çš„è§†é¢‘åª’ä½“ä¸Š,æ¬¢è¿è®¢é˜….&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;bç«™é¢‘é“: &lt;a href=&#34;https://space.bilibili.com/1751715710/channel/collectiondetail?sid=1485775&#34;&gt;https://space.bilibili.com/1751715710/channel/collectiondetail?sid=1485775&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;youtube: &lt;a href=&#34;https://www.youtube.com/channel/UCxu8MUtWtqfdDB2eTABSePg&#34;&gt;https://www.youtube.com/channel/UCxu8MUtWtqfdDB2eTABSePg&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ç¯å¢ƒ&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;# peft, bitsandbytesæ‹‰github repoæœ€æ–°çš„åˆ†æ”¯è¿›è¡Œå®‰è£…å®‰è£…&#xA;peft==0.4.0.dev0&#xA;torch==2.0.0&#xA;transformers==4.30.2&#xA;bitsandbytes==0.39.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;å¾®è°ƒæ–¹å¼&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ä¸‹è½½æ•°æ®åˆ°æœ¬åœ°&lt;/li&gt; &#xA; &lt;li&gt;ä¸‹è½½æ¨¡å‹æƒé‡åˆ°æœ¬åœ°&lt;/li&gt; &#xA; &lt;li&gt;æ¨¡å‹è®­ç»ƒ&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node 2 train.py \   # å•GPUè¿è¡Œå¯ä»¥ç›´æ¥ python train.py ...&#xA;    --model_name baichuan \                           # æ¨¡å‹åç§°&#xA;    --model_path ./pretrained/baichuan-7b \           # æ¨¡å‹æƒé‡æ–‡ä»¶&#xA;    --data_name belle_open_source_500k \              # æ•°æ®åç§°(å‚è€ƒ)&#xA;    --data_path ./data/Belle_open_source_0.5M.json \  # æ•°æ®æ–‡ä»¶è·¯å¾„&#xA;    --train_size 20000 \                              # ä½¿ç”¨å…¨é‡æ•°æ®è¿™é‡Œè®¾ç½®ä¸º-1&#xA;    --output_dir ./output/baichuan_lorasft \          # æ¨¡å‹å­˜å‚¨åœ°å€&#xA;    --seed 42 \&#xA;    --max_len 1024  \&#xA;    --lora_rank 8 \&#xA;    --num_train_epochs 1 \&#xA;    --learning_rate 3e-4 \&#xA;    --per_device_train_batch_size 4 \                  # æ˜¾å­˜ä¸å¤Ÿå‡å°batch size,åŒæ­¥å¢åŠ gradient_accumulation_steps&#xA;    --per_device_eval_batch_size 8 \&#xA;    --gradient_accumulation_steps 1 \&#xA;    --logging_steps 10 \&#xA;    --evaluation_strategy steps \&#xA;    --save_strategy steps \&#xA;    --eval_steps 100 \&#xA;    --save_steps 100 \&#xA;    --report_to tensorboard \&#xA;    --save_total_limit 3 \&#xA;    --load_best_model_at_end true \&#xA;    --optim adamw_torch \&#xA;    --ddp_find_unused_parameters false                # å•GPUè¿è¡Œå¯ä»¥ä¸è®¾ç½®æ­¤å‚æ•°&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;æŸ¥çœ‹è®­ç»ƒæ—¥å¿—&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shel&#34;&gt;tensorboard --logdir {output_dir}/runs&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EvilPsyCHo/train_custom_LLM/main/image/train_loss.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EvilPsyCHo/train_custom_LLM/main/image/valid_loss.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;ä½¿ç”¨20Kæ•°æ®æ•ˆæœå¯¹æ¯”&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;åŸå§‹æ¨¡å‹&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EvilPsyCHo/train_custom_LLM/main/image/baichuan.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;å¾®è°ƒæ¨¡å‹&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EvilPsyCHo/train_custom_LLM/main/image/baichuan-20k-finetune.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ¨¡å‹è¿è¡Œ&lt;/h2&gt; &#xA;&lt;p&gt;ç›´æ¥åŠ è½½åŸºåº§æ¨¡å‹å¯åŠ¨&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_VISIBLE_DEVICES=0 python.py webui.py --model {æ¨¡å‹ç±»å‹å¦‚ baichuan, chatGLM} --model_ckpt {æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;æ·»åŠ loraæƒé‡ï¼Œä½¿ç”¨é‡åŒ–æ–¹æ³•è¿è¡Œ&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;CUDA_VISIBLE_DEVICES=0 python.py webui.py --model {æ¨¡å‹ç±»å‹å¦‚ baichuan, chatGLM} --model_ckpt {æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„} --lora_ckpt {loraæƒé‡æ–‡ä»¶è·¯å¾„} --quantize {4bit, 8bit}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/EvilPsyCHo/train_custom_LLM/main/image/webui.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;æ”¯æŒæ¨¡å‹&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; chatGLM1/2&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; baichuan-7B&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Dataset&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ•°æ®åç§°&lt;/th&gt; &#xA;   &lt;th&gt;ä¸‹è½½åœ°å€&lt;/th&gt; &#xA;   &lt;th&gt;æ¥æº&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;belle_open_source_500k&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/train_0.5M_CN/blob/main/Belle_open_source_0.5M.json&#34;&gt;url&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;BelleGroup/train_0.5M_CN&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/beyondguo/LLM-Tuning/tree/master&#34;&gt;https://github.com/beyondguo/LLM-Tuning/tree/master&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hiyouga/LLaMA-Efficient-Tuning&#34;&gt;https://github.com/hiyouga/LLaMA-Efficient-Tuning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yangjianxin1/Firefly/tree/master&#34;&gt;https://github.com/yangjianxin1/Firefly/tree/master&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/gradio-app/gradio&#34;&gt;https://github.com/gradio-app/gradio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/imClumsyPanda/langchain-ChatGLM/tree/master&#34;&gt;https://github.com/imClumsyPanda/langchain-ChatGLM/tree/master&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wp931120/baichuan_sft_lora/tree/main&#34;&gt;https://github.com/wp931120/baichuan_sft_lora/tree/main&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>