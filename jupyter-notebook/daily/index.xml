<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-11T01:35:44Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>dennybritz/reinforcement-learning</title>
    <updated>2022-09-11T01:35:44Z</updated>
    <id>tag:github.com,2022-09-11:/dennybritz/reinforcement-learning</id>
    <link href="https://github.com/dennybritz/reinforcement-learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of Reinforcement Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton&#39;s Book and David Silver&#39;s course.&lt;/p&gt;&lt;hr&gt;&lt;h3&gt;Overview&lt;/h3&gt; &#xA;&lt;p&gt;This repository provides code, exercises and solutions for popular Reinforcement Learning algorithms. These are meant to serve as a learning tool to complement the theoretical materials from&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2018.pdf&#34;&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&#34;&gt;David Silver&#39;s Reinforcement Learning Course&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Each folder in corresponds to one or more chapters of the above textbook and/or course. In addition to exercises and solution, each folder also contains a list of learning goals, a brief concept summary, and links to the relevant readings.&lt;/p&gt; &#xA;&lt;p&gt;All code is written in Python 3 and uses RL environments from &lt;a href=&#34;https://gym.openai.com/&#34;&gt;OpenAI Gym&lt;/a&gt;. Advanced techniques use &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;Tensorflow&lt;/a&gt; for neural network implementations.&lt;/p&gt; &#xA;&lt;h3&gt;Table of Contents&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/Introduction/&#34;&gt;Introduction to RL problems &amp;amp; OpenAI Gym&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/MDP/&#34;&gt;MDPs and Bellman Equations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DP/&#34;&gt;Dynamic Programming: Model-Based RL, Policy Iteration and Value Iteration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/MC/&#34;&gt;Monte Carlo Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/TD/&#34;&gt;Temporal Difference Model-Free Prediction &amp;amp; Control&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/FA/&#34;&gt;Function Approximation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DQN/&#34;&gt;Deep Q Learning&lt;/a&gt; (WIP)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/PolicyGradient/&#34;&gt;Policy Gradient Methods&lt;/a&gt; (WIP)&lt;/li&gt; &#xA; &lt;li&gt;Learning and Planning (WIP)&lt;/li&gt; &#xA; &lt;li&gt;Exploration and Exploitation (WIP)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;List of Implemented Algorithms&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DP/Policy%20Evaluation%20Solution.ipynb&#34;&gt;Dynamic Programming Policy Evaluation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DP/Policy%20Iteration%20Solution.ipynb&#34;&gt;Dynamic Programming Policy Iteration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DP/Value%20Iteration%20Solution.ipynb&#34;&gt;Dynamic Programming Value Iteration&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/MC/MC%20Prediction%20Solution.ipynb&#34;&gt;Monte Carlo Prediction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/MC/MC%20Control%20with%20Epsilon-Greedy%20Policies%20Solution.ipynb&#34;&gt;Monte Carlo Control with Epsilon-Greedy Policies&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/MC/Off-Policy%20MC%20Control%20with%20Weighted%20Importance%20Sampling%20Solution.ipynb&#34;&gt;Monte Carlo Off-Policy Control with Importance Sampling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/TD/SARSA%20Solution.ipynb&#34;&gt;SARSA (On Policy TD Learning)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/TD/Q-Learning%20Solution.ipynb&#34;&gt;Q-Learning (Off Policy TD Learning)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/FA/Q-Learning%20with%20Value%20Function%20Approximation%20Solution.ipynb&#34;&gt;Q-Learning with Linear Function Approximation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DQN/Deep%20Q%20Learning%20Solution.ipynb&#34;&gt;Deep Q-Learning for Atari Games&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/DQN/Double%20DQN%20Solution.ipynb&#34;&gt;Double Deep-Q Learning for Atari Games&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Deep Q-Learning with Prioritized Experience Replay (WIP)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/PolicyGradient/CliffWalk%20REINFORCE%20with%20Baseline%20Solution.ipynb&#34;&gt;Policy Gradient: REINFORCE with Baseline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/PolicyGradient/CliffWalk%20Actor%20Critic%20Solution.ipynb&#34;&gt;Policy Gradient: Actor Critic with Baseline&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb&#34;&gt;Policy Gradient: Actor Critic with Baseline for Continuous Action Spaces&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Deterministic Policy Gradients for Continuous Action Spaces (WIP)&lt;/li&gt; &#xA; &lt;li&gt;Deep Deterministic Policy Gradients (DDPG) (WIP)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dennybritz/reinforcement-learning/master/PolicyGradient/a3c&#34;&gt;Asynchronous Advantage Actor Critic (A3C)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Resources&lt;/h3&gt; &#xA;&lt;p&gt;Textbooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://incompleteideas.net/book/RLbook2018.pdf&#34;&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Classes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&#34;&gt;David Silver&#39;s Reinforcement Learning Course (UCL, 2015)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://rll.berkeley.edu/deeprlcourse/&#34;&gt;CS294 - Deep Reinforcement Learning (Berkeley, Fall 2015)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/reinforcement-learning--ud600&#34;&gt;CS 8803 - Reinforcement Learning (Georgia Tech)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://cs.uwaterloo.ca/~ppoupart/teaching/cs885-spring18/&#34;&gt;CS885 - Reinforcement Learning (UWaterloo), Spring 2018&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://rail.eecs.berkeley.edu/deeprlcourse/&#34;&gt;CS294-112 - Deep Reinforcement Learning (UC Berkeley)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Talks/Tutorials:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://videolectures.net/deeplearning2016_pineau_reinforcement_learning/&#34;&gt;Introduction to Reinforcement Learning (Joelle Pineau @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://videolectures.net/deeplearning2016_abbeel_deep_reinforcement/&#34;&gt;Deep Reinforcement Learning (Pieter Abbeel @ Deep Learning Summer School 2016)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://techtalks.tv/talks/deep-reinforcement-learning/62360/&#34;&gt;Deep Reinforcement Learning ICML 2016 Tutorial (David Silver)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ggqnxyjaKe4&#34;&gt;Tutorial: Introduction to Reinforcement Learning with Function Approximation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLjKEIQlKCTZYN3CYBlj8r58SbNorobqcp&#34;&gt;John Schulman - Deep Reinforcement Learning (4 Lectures)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf&#34;&gt;Deep Reinforcement Learning Slides @ NIPS 2016&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://spinningup.openai.com/en/latest/user/introduction.html&#34;&gt;OpenAI Spinning Up&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs&#34;&gt;Advanced Deep Learning &amp;amp; Reinforcement Learning (UCL 2018, DeepMind)&lt;/a&gt; -&lt;a href=&#34;https://sites.google.com/view/deep-rl-bootcamp/lectures&#34;&gt;Deep RL Bootcamp&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Other Projects:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/carpedm20/deep-rl-tensorflow&#34;&gt;carpedm20/deep-rl-tensorflow&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/matthiasplappert/keras-rl&#34;&gt;matthiasplappert/keras-rl&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Selected Papers:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.readcube.com/articles/10.1038/nature14236&#34;&gt;Human-Level Control through Deep Reinforcement Learning (2015-02)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1509.06461&#34;&gt;Deep Reinforcement Learning with Double Q-learning (2015-09)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1509.02971&#34;&gt;Continuous control with deep reinforcement learning (2015-09)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1511.05952&#34;&gt;Prioritized Experience Replay (2015-11)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1511.06581&#34;&gt;Dueling Network Architectures for Deep Reinforcement Learning (2015-11)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1602.01783&#34;&gt;Asynchronous Methods for Deep Reinforcement Learning (2016-02)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://arxiv.org/abs/1603.01121&#34;&gt;Deep Reinforcement Learning from Self-Play in Imperfect-Information Games (2016-03)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf&#34;&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>UBC-CS/cpsc330</title>
    <updated>2022-09-11T01:35:44Z</updated>
    <id>tag:github.com,2022-09-11:/UBC-CS/cpsc330</id>
    <link href="https://github.com/UBC-CS/cpsc330" rel="alternate"></link>
    <summary type="html">&lt;p&gt;CPSC 330: Applied Machine Learning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;UBC CPSC 330: Applied Machine Learning (2022W1)&lt;/h1&gt; &#xA;&lt;p&gt;This is the course homepage for CPSC 330: Applied Machine Learning at the University of British Columbia. You are looking at the current version (Sep-Dec 2022). You can find the earlier versions here:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/v2.0&#34;&gt;Sep-Dec 2020 taught by Mike Gelbart&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/v3.0&#34;&gt;Sep-Dec 2021 taught by Varada Kolhatkar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330-2021W2&#34;&gt;Jan-April 2022 taught by Giulia Toti&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330-2022s&#34;&gt;May-June 2022 taught by Mehrdad Oveisi&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Instructor: Varada Kolhatkar&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Â© 2022 Varada Kolhatkar and Mike Gelbart&lt;/p&gt; &#xA;&lt;p&gt;Software licensed under &lt;a href=&#34;https://spdx.org/licenses/MIT.html&#34;&gt;the MIT License&lt;/a&gt;, non-software content licensed under &lt;a href=&#34;https://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License&lt;/a&gt;. See the &lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/LICENSE.md&#34;&gt;license file&lt;/a&gt; for more information.&lt;/p&gt; &#xA;&lt;h2&gt;Important links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/raw/master/docs/calendar.html&#34;&gt;Calendar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330&#34;&gt;Course GitHub page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ubc-cs.github.io/cpsc330/README.html&#34;&gt;Course Jupyter book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://join.iclicker.com/3DP5H&#34;&gt;iClicker Cloud&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/piazza.com/ubc.ca/winterterm12022/cpsc3301022022w1/home&#34;&gt;Piazza&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;: You will find Gradescope, Piazza, and Panopto links in Canvas&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLHofvQE1VlGtZoAULxcHb7lOsMved0CuM&#34;&gt;Course videos YouTube channel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/docs/course_info.md&#34;&gt;Syllabus / administrative info&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/docs&#34;&gt;Other course documents&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Deliverable due dates (tentative)&lt;/h2&gt; &#xA;&lt;p&gt;Usually the homework assignments will be due on Mondays (except next week) and will be released on Tuesdays. I&#39;ll also add the due dates in the &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/raw/master/docs/calendar.html&#34;&gt;Calendar&lt;/a&gt;. If you find inconsistencies in due dates, follow the due date in the Calendar. For this course, we&#39;ll assume that the &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/raw/master/docs/calendar.html&#34;&gt;Calendar&lt;/a&gt; is always right!&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Assessment&lt;/th&gt; &#xA;   &lt;th&gt;Due date&lt;/th&gt; &#xA;   &lt;th&gt;Where to find?&lt;/th&gt; &#xA;   &lt;th&gt;Where to submit?&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw1&lt;/td&gt; &#xA;   &lt;td&gt;Sept 13, 11:59pm&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Syllabus quiz&lt;/td&gt; &#xA;   &lt;td&gt;Sept 19, 11:59pm&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw2&lt;/td&gt; &#xA;   &lt;td&gt;Sept 19, 11:59pm&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw3&lt;/td&gt; &#xA;   &lt;td&gt;Oct 03, 11:59pm&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw4&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw5&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Midterm&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Oct 27, during class time&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw6&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw7&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;hw8&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/UBC-CS/cpsc330/tree/master/hw/&#34;&gt;Github repo&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.gradescope.ca/courses/7610&#34;&gt;Gradescope&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Final exam&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://canvas.ubc.ca/courses/101888&#34;&gt;Canvas&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Lecture schedule (tentative)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Live lectures&lt;/strong&gt;: The lectures will be in-person in &lt;strong&gt;&lt;a href=&#34;http://www.maps.ubc.ca/PROD/index.php&#34;&gt;DMP 310&lt;/a&gt; from 11am to 12:20pm&lt;/strong&gt;, as marked in &lt;a href=&#34;https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/raw/master/docs/calendar.html&#34;&gt;the Calendar&lt;/a&gt;. The lectures will be live streamed. You can find the link of Panopto videos in Canvas. That said, consider the recordings a backup resource and do not completely rely on it. You will get a lot more out of the course if you show up in person.&lt;/p&gt; &#xA;&lt;p&gt;This course will be run in a semi flipped classroom format. There will be pre-watch videos for many lectures, at least in the first half of the course. All the videos are available on &lt;a href=&#34;https://www.youtube.com/playlist?list=PLHofvQE1VlGtZoAULxcHb7lOsMved0CuM&#34;&gt;YouTube&lt;/a&gt; and are posted in the schedule below. Try to watch the assigned videos before the corresponding lecture. During the lecture, I&#39;ll summarize the important points from the videos and focus on demos, iClickers, and Q&amp;amp;A.&lt;/p&gt; &#xA;&lt;p&gt;I&#39;ll be developing lecture notes directly in this repository. So if you check them before the lecture, they might be in a draft form. Once they are finalized, I&#39;ll post them in the &lt;a href=&#34;https://ubc-cs.github.io/cpsc330/README.html&#34;&gt;Course Jupyter book&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Date&lt;/th&gt; &#xA;   &lt;th&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;Assigned videos&lt;/th&gt; &#xA;   &lt;th&gt;vs. CPSC 340&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;UBC Imagine Day - no class&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/01_intro.ipynb&#34;&gt;Course intro&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/-1hTcS5ZE4w&#34;&gt;1.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;n/a&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 13&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/02_decision-trees.ipynb&#34;&gt;Decision trees&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/YNT8n4cXu4A&#34;&gt;2.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/6eT5cLL-2Vc&#34;&gt;2.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/Hcf19Ij35rA&#34;&gt;2.3&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/KEtsfXn4w2E&#34;&gt;2.4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 15&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/03_ml-fundamentals.ipynb&#34;&gt;ML fundamentals&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/iS2hsRRlc2M&#34;&gt;3.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/h2AEobwcUQw&#34;&gt;3.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/4cv8VYonepA&#34;&gt;3.3&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/Ihay8yE5KTI&#34;&gt;3.4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;similar&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 20&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/04_kNNs-SVM-RBF.ipynb&#34;&gt;$k$-NNs and SVM with RBF kernel&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/hCa3EXEUmQk&#34;&gt;4.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/bENDqXKJLmg&#34;&gt;4.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/IRGbqi5S9gQ&#34;&gt;4.3&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/ic_zqOhi020&#34;&gt;4.4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 22&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/05_preprocessing-pipelines.ipynb&#34;&gt;Preprocessing, &lt;code&gt;sklearn&lt;/code&gt; pipelines&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/xx9HlmzORRk&#34;&gt;5.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/G2IXbVzKlt8&#34;&gt;5.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/nWTce7WJSd4&#34;&gt;5.3&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/2mJ9rAhMMl0&#34;&gt;5.4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;more depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 27&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/06_column-transformer-text-feats.ipynb&#34;&gt;More preprocessing, &lt;code&gt;sklearn&lt;/code&gt; &lt;code&gt;ColumnTransformer&lt;/code&gt;, text features&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/to2mukSyvLk&#34;&gt;6.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/hteVvLwrWZ4&#34;&gt;6.2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;more depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sep 29&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/07_linear-models.ipynb&#34;&gt;Linear models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/HXd1U2q4VFA&#34;&gt;7.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/56L5z_t22qE&#34;&gt;7.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/_OAK5KiGLg0&#34;&gt;7.3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 04&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/08_hyperparameter-optimization.ipynb&#34;&gt;Hyperparameter optimization, overfitting the validation set&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/lMWdHZSZMk8&#34;&gt;8.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/Z9a9XZ0vQv0&#34;&gt;8.2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;different&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 06&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/09_classification-metrics.ipynb&#34;&gt;Evaluation metrics for classification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Reference: &lt;a href=&#34;https://youtu.be/ZCuCErW5lI8&#34;&gt;9.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/XkCTUuoH23c&#34;&gt;9.3&lt;/a&gt;,&lt;a href=&#34;https://youtu.be/jHaKRCFb6Qw&#34;&gt;9.4&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;more depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 11&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/10_regression-metrics&#34;&gt;Regression metrics&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/lgGTKLwNgkQ&#34;&gt;10.1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;more depth on metrics less depth on regression&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 13&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lecture/11_ensembles.ipynb&#34;&gt;Ensembles&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/8litm1H7DLo&#34;&gt;11.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/EkFkY9QB2Hw&#34;&gt;11.2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;similar&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 18&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/12_feat-importances.ipynb&#34;&gt;Feature importances, model interpretation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/xfICsGL7DXE&#34;&gt;12.1&lt;/a&gt;,&lt;a href=&#34;https://youtu.be/tiSN18OmZOo&#34;&gt;12.2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;feature importances is new, feature engineering is new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 20&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/13_feature-engineering-selection.ipynb&#34;&gt;Feature engineering and feature selection&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;None&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 25&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Midterm review&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oct 27&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Midterm&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/14_k-means-clustering.ipynb&#34;&gt;Clustering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/caAuUAXwpb8&#34;&gt;14.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/s6AvSZ1_l7I&#34;&gt;14.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/M5ilrhcL0oY&#34;&gt;14.3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;&#34;&gt;More clustering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/1ZwITQyWpkY&#34;&gt;15.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/T4NLsrUaRtg&#34;&gt;15.2&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/NM8lFKFZ2IU&#34;&gt;15.3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/15_recommender-systems.ipynb&#34;&gt;Simple recommender systems&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 10&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Midterm break - no class&lt;/em&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 15&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/16_natural-language-processing.ipynb&#34;&gt;Text data, embeddings, topic modeling&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ Pre-watch: &lt;a href=&#34;https://youtu.be/GTC_iLPCjdY&#34;&gt;16.1&lt;/a&gt;, &lt;a href=&#34;https://youtu.be/7W5Q8gzNPBc&#34;&gt;16.2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 17&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/17_intro_to_computer-vision.ipynb&#34;&gt;Neural networks and computer vision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;less depth&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 22&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/18_time-series.ipynb&#34;&gt;Time series data&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;(Optional) &lt;a href=&#34;https://www.youtube.com/watch?v=-5wpm-gesOY&#34;&gt;Humour: The Problem with Time &amp;amp; Timezones&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 24&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/19_survival-analysis.ipynb&#34;&gt;Survival analysis&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ (Optional but highly recommended)&lt;a href=&#34;https://www.youtube.com/watch?v=ITWQ5psx9Sw&#34;&gt;Calling Bullshit 4.1: Right Censoring&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nov 29&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/20_ethics.ipynb&#34;&gt;Ethics&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ (Optional but highly recommended) &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&#34;&gt;Calling BS videos&lt;/a&gt; Chapter 5 (6 short videos, 50 min total)&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;http://jtleek.com/ads2020/week-15.html&#34;&gt;The ethics of data science&lt;/a&gt;&lt;/li&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dec 1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/21_communication.ipynb&#34;&gt;Communication&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ðŸ“¹ (Optional but highly recommended) &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLPnZfvKID1Sje5jWxt-4CSZD7bUI4gSPS&#34;&gt;Calling BS videos&lt;/a&gt; Chapter 6 (6 short videos, 47 min total)&lt;/li&gt; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vbDObzI-CTc&#34;&gt;Can you read graphs? Because I can&#39;t.&lt;/a&gt; by Sabrina (7 min)&lt;/li&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dec 6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/UBC-CS/cpsc330/master/lectures/22_deployment-conclusion.ipynb&#34;&gt;Model deployment and conclusion&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;new&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://srs.ubc.ca/covid-19/ubc-campus-rules-guidance-documents/#COVID-19%20Campus%20Rules&#34;&gt;Covid Safety at UBC&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://srs.ubc.ca/covid-19/ubc-campus-rules-guidance-documents/#COVID-19%20Campus%20Rules&#34;&gt;Covid Campus Rules&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Masks:&lt;/strong&gt; This class is going to be in person. UBC no longer requires students, faculty and staff to wear non-medical masks, but continues to recommend that masks be worn in indoor public spaces.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Your personal health:&lt;/strong&gt; If you are ill or believe you have COVID-19 symptoms or been exposed to SARS-CoV-2 use the &lt;a href=&#34;https://bc.thrive.health/covid19/en&#34;&gt;Thrive Health&lt;/a&gt; self-assessment tool for guidance, or download the &lt;a href=&#34;https://welcome.thrive.health/bc-covid19-app&#34;&gt;BC COVID-19 Support App&lt;/a&gt; for iOS or Android device and follow the instructions provided. Follow the advice from &lt;a href=&#34;https://www2.gov.bc.ca/gov/content/covid-19/info/restrictions&#34;&gt;Public Health&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Stay home if you have recently tested positive for COVID-19 or are required to quarantine. You can check &lt;a href=&#34;http://www.bccdc.ca/health-info/diseases-conditions/covid-19/self-isolation#Who&#34;&gt;this website&lt;/a&gt; to find out if you should self-isolate or self-monitor.&lt;/p&gt; &#xA;&lt;p&gt;Your precautions will help reduce risk and keep everyone safer. In this class, the marking scheme is intended to provide flexibility so that you can prioritize your health and still be able to succeed:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All course notes will be provided online.&lt;/li&gt; &#xA; &lt;li&gt;All homework assignments can be done and handed in online.&lt;/li&gt; &#xA; &lt;li&gt;All exams will be held online. (But you need to be present in the classroom to write the exam unless there is a legitimate reason for not doing so.)&lt;/li&gt; &#xA; &lt;li&gt;Most of the class activity will be video recorded and will be made available to you.&lt;/li&gt; &#xA; &lt;li&gt;There will be at least a few office hours which will be held online.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We are working on this course during the global pandemic. In general, everyone is struggling to some extent. If you tell me you are having trouble, I am not going to judge you or think less of you. I hope you will extend me the same grace!&lt;/p&gt; &#xA;&lt;p&gt;Here are some ground rules:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;If you are unable to submit a deliverable on time, please reach out &lt;strong&gt;before&lt;/strong&gt; the deliverable is due.&lt;/li&gt; &#xA; &lt;li&gt;If you need extra support, the teaching team is here to work with you. Our goal is to help each of you succeed in the course.&lt;/li&gt; &#xA; &lt;li&gt;If you are struggling with the material, the new hybrid teaching format, or anything else, please reach out. I will try to find time and listen to you empathetically.&lt;/li&gt; &#xA; &lt;li&gt;If I am unable to help you, I might know someone who can. UBC has some &lt;a href=&#34;https://students.ubc.ca/support&#34;&gt;great student support resources&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Land Acknowledgement&lt;/h2&gt; &#xA;&lt;p&gt;UBCâ€™s Point Grey Campus is located on the traditional, ancestral, and unceded territory of the xwmÉ™Î¸kwÉ™yÌ“É™m (Musqueam) peple. The land it is situated on has always been a place of learning for the Musqueam people, who for millennia have passed on their culture, history, and traditions from one generation to the next on this site.&lt;/p&gt; &#xA;&lt;p&gt;It is important that this recognition of Musqueam territory and our relationship with the Musqueam people does not appear as just a formality. Take a moment to appreciate the meaning behind the words we use:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;TRADITIONAL&lt;/strong&gt; recognizes lands traditionally used and/or occupied by the Musqueam people or other First Nations in other parts of the country.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ANCESTRAL&lt;/strong&gt; recognizes land that is handed down from generation to generation.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;UNCEDED&lt;/strong&gt; refers to land that was not turned over to the Crown (government) by a treaty or other agreement.&lt;/p&gt; &#xA;&lt;p&gt;As you begin your journey at UBC, take some time to learn about the history of this land and to honour its original inhabitants.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>XavierXiao/Dreambooth-Stable-Diffusion</title>
    <updated>2022-09-11T01:35:44Z</updated>
    <id>tag:github.com,2022-09-11:/XavierXiao/Dreambooth-Stable-Diffusion</id>
    <link href="https://github.com/XavierXiao/Dreambooth-Stable-Diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dreambooth on Stable Diffusion&lt;/h1&gt; &#xA;&lt;p&gt;This is an implementtaion of Google&#39;s &lt;a href=&#34;https://arxiv.org/abs/2208.12242&#34;&gt;Dreambooth&lt;/a&gt; with &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;. The original Dreambooth is based on &lt;a href=&#34;https://imagen.research.google/&#34;&gt;Imagen&lt;/a&gt; text-to-image model. However, neither the model nor the pre-trained weights of Imagen is available. To enable people to fine-tune a text-to-image model with a few examples, I implemented the idea of Dreambooth on Stable diffusion.&lt;/p&gt; &#xA;&lt;p&gt;This code repository is based on that of &lt;a href=&#34;https://github.com/rinongal/textual_inversion&#34;&gt;Textual Inversion&lt;/a&gt;. Note that Textual Inversion only optimizes word ebedding, while dreambooth fine-tunes the whole diffusion model.&lt;/p&gt; &#xA;&lt;p&gt;The implementation makes minimum changes over the official codebase of Textual Inversion. In fact, due to lazyness, some components in Textual Inversion, such as the embedding manager, are not deleted, although they will never be used here.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Preparation&lt;/h3&gt; &#xA;&lt;p&gt;To fine-tune a stable diffusion model, you need to obtain the pre-trained stable diffusion models following their &lt;a href=&#34;https://github.com/CompVis/stable-diffusion#stable-diffusion-v1&#34;&gt;instructions&lt;/a&gt;. Weights can be downloaded on &lt;a href=&#34;https://huggingface.co/CompVis&#34;&gt;HuggingFace&lt;/a&gt;. You can decide which version of checkpoint to use, but I use &lt;code&gt;sd-v1-4-full-ema.ckpt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We also need to create a set of images for regularization, as the fine-tuning algorithm of Dreambooth requires that. Details of the algorithm can be found in the paper. Note that in the original paper, the regularization images seem to be generated on-the-fly. However, here I generated a set of regularization images before the training. The text prompt for generating regularization images can be &lt;code&gt;photo of a &amp;lt;class&amp;gt;&lt;/code&gt;, where &lt;code&gt;&amp;lt;class&amp;gt;&lt;/code&gt; is a word that describes the class of your object, such as &lt;code&gt;dog&lt;/code&gt;. The command is&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/stable_txt2img.py --ddim_eta 0.0 --n_samples 8 --n_iter 1 --scale 10.0 --ddim_steps 50  --ckpt /path/to/original/stable-diffusion/sd-v1-4-full-ema.ckpt --prompt &#34;a photo of a &amp;lt;class&amp;gt;&#34; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;I generate 8 images for regularization, but more regularization images may lead to stronger regularization and better editability. After that, save the generated images (separately, one image per &lt;code&gt;.png&lt;/code&gt; file) at &lt;code&gt;/root/to/regularization/images&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Updates on 9/9&lt;/strong&gt; We should definitely use more images for regularization. Please try 100 or 200, to better align with the original paper. To acomodate this, I shorten the &#34;repeat&#34; of reg dataset in the &lt;a href=&#34;https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/raw/main/configs/stable-diffusion/v1-finetune_unfrozen.yaml#L96&#34;&gt;config file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For some cases, if the generated regularization images are highly unrealistic (happens when you want to generate &#34;man&#34; or &#34;woman&#34;), you can find a diverse set of images (of man/woman) online, and use them as regularization images.&lt;/p&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;p&gt;Training can be done by running the following command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py --base configs/stable-diffusion/v1-finetune_unfrozen.yaml &#xA;                -t &#xA;                --actual_resume /path/to/original/stable-diffusion/sd-v1-4-full-ema.ckpt  &#xA;                -n &amp;lt;job name&amp;gt; &#xA;                --gpus 0, &#xA;                --data_root /root/to/training/images &#xA;                --reg_data_root /root/to/regularization/images &#xA;                --class_word &amp;lt;xxx&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Detailed configuration can be found in &lt;code&gt;configs/stable-diffusion/v1-finetune_unfrozen.yaml&lt;/code&gt;. In particular, the default learning rate is &lt;code&gt;1.0e-6&lt;/code&gt; as I found the &lt;code&gt;1.0e-5&lt;/code&gt; in the Dreambooth paper leads to poor editability. The parameter &lt;code&gt;reg_weight&lt;/code&gt; corresponds to the weight of regularization in the Dreambooth paper, and the default is set to &lt;code&gt;1.0&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Dreambooth requires a placeholder word &lt;code&gt;[V]&lt;/code&gt;, called identifier, as in the paper. This identifier needs to be a relatively rare tokens in the vocabulary. The original paper approaches this by using a rare word in T5-XXL tokenizer. For simplicity, here I just use a random word &lt;code&gt;sks&lt;/code&gt; and hard coded it.. If you want to change that, simply make a change in &lt;a href=&#34;https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/raw/main/ldm/data/personalized.py#L10&#34;&gt;this file&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Training will be run for 800 steps, and two checkpoints will be saved at &lt;code&gt;./logs/&amp;lt;job_name&amp;gt;/checkpoints&lt;/code&gt;, one at 500 steps and one at final step. Typically the one at 500 steps works well enough. I train the model use two A6000 GPUs and it takes ~15 mins.&lt;/p&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;After training, personalized samples can be obtained by running the command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/stable_txt2img.py --ddim_eta 0.0 &#xA;                                 --n_samples 8 &#xA;                                 --n_iter 1 &#xA;                                 --scale 10.0 &#xA;                                 --ddim_steps 100  &#xA;                                 --ckpt /path/to/saved/checkpoint/from/training&#xA;                                 --prompt &#34;photo of a sks &amp;lt;class&amp;gt;&#34; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In particular, &lt;code&gt;sks&lt;/code&gt; is the identifier, which should be replaced by your choice if you happen to change the identifier, and &lt;code&gt;&amp;lt;class&amp;gt;&lt;/code&gt; is the class word &lt;code&gt;--class_word&lt;/code&gt; for training.&lt;/p&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;Here I show some qualitative results. The training images are obtained from the &lt;a href=&#34;https://github.com/rinongal/textual_inversion/issues/8&#34;&gt;issue&lt;/a&gt; in the Textual Inversion repository, and they are 3 images of a large trash container. Regularization images are generated by prompt &lt;code&gt;photo of a container&lt;/code&gt;. Regularization images are shown here:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/a-container-0038.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;After training, generated images with prompt &lt;code&gt;photo of a sks container&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/photo-of-a-sks-container-0018.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Generated images with prompt &lt;code&gt;photo of a sks container on the beach&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/photo-of-a-sks-container-on-the-beach-0017.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Generated images with prompt &lt;code&gt;photo of a sks container on the moon&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/photo-of-a-sks-container-on-the-moon-0016.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Some not-so-perfect but still interesting results:&lt;/p&gt; &#xA;&lt;p&gt;Generated images with prompt &lt;code&gt;photo of a red sks container&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/a-red-sks-container-0021.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Generated images with prompt &lt;code&gt;a dog on top of sks container&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/XavierXiao/Dreambooth-Stable-Diffusion/main/assets/a-dog-on-top-of-sks-container-0023.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>