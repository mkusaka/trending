<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-09-09T01:31:23Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>merveenoyan/smol-vision</title>
    <updated>2024-09-09T01:31:23Z</updated>
    <id>tag:github.com,2024-09-09:/merveenoyan/smol-vision</id>
    <link href="https://github.com/merveenoyan/smol-vision" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Recipes for shrinking, optimizing, customizing cutting edge vision models. üíú&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://github.com/merveenoyan/smol-vision/assets/53175384/930d5b36-bb9d-4ab6-8b5a-4fec28c48f80&#34; alt=&#34;Smol&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Smol Vision üê£&lt;/h1&gt; &#xA;&lt;p&gt;Recipes for shrinking, optimizing, customizing cutting edge vision models.&lt;/p&gt; &#xA;&lt;p&gt;Latest examples üëáüèª&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/ColPali_%2B_Qwen2_VL.ipynb&#34;&gt;Multimodal RAG using ColPali and Qwen2-VL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Idefics_FT.ipynb&#34;&gt;QLoRA Fine-tune IDEFICS3 on VQAv2&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;Notebook&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Quantization/ONNX&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Faster_Zero_shot_Object_Detection_with_Optimum.ipynb&#34;&gt;Faster and Smaller Zero-shot Object Detection with Optimum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Quantize the state-of-the-art zero-shot object detection model OWLv2 using Optimum ONNXRuntime tools.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VLM Fine-tuning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Fine_tune_PaliGemma.ipynb&#34;&gt;Fine-tune PaliGemma&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tune state-of-the-art vision language backbone PaliGemma using transformers.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Intro to Optimum/ORT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Reduce_any_model_to_fp16_using_%F0%9F%A4%97_Optimum_DETR.ipynb&#34;&gt;Optimizing DETR with ü§ó Optimum&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A soft introduction to exporting vision models to ONNX and quantizing them.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model Shrinking&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/docs/transformers/en/tasks/knowledge_distillation_for_image_classification&#34;&gt;Knowledge Distillation for Computer Vision&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Knowledge distillation for image classification.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Quantization&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Fit_in_vision_models_using_quanto.ipynb&#34;&gt;Fit in vision models using Quanto&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fit in vision models to smaller hardware using quanto&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Speed-up&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Faster_foundation_models_with_torch_compile.ipynb&#34;&gt;Faster foundation models with torch.compile&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Improving latency for foundation models using &lt;code&gt;torch.compile&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VLM Fine-tuning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Fine_tune_Florence_2.ipynb&#34;&gt;Fine-tune Florence-2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Fine-tune Florence-2 on DocVQA dataset&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fine-tune IDEFICS3 on visual question answering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/Idefics_FT.ipynb&#34;&gt;QLoRA Fine-tune IDEFICS3 on VQAv2&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;QLoRA Fine-tune IDEFICS3 on VQAv2 dataset&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multimodal RAG using ColPali and Qwen2-VL&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/merveenoyan/smol-vision/raw/main/ColPali_%2B_Qwen2_VL.ipynb&#34;&gt;Multimodal RAG using ColPali and Qwen2-VL&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn to retrieve documents and pipeline to RAG without hefty document processing using ColPali through Byaldi and do the generation with Qwen2-VL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Speed-up/Memory Optimization&lt;/td&gt; &#xA;   &lt;td&gt;Vision language model serving using TGI (SOON)&lt;/td&gt; &#xA;   &lt;td&gt;Explore speed-ups and memory improvements for vision-language model serving with text-generation inference&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Quantization/Optimum/ORT&lt;/td&gt; &#xA;   &lt;td&gt;All levels of quantization and graph optimizations for Image Segmentation using Optimum (SOON)&lt;/td&gt; &#xA;   &lt;td&gt;End-to-end model optimization using Optimum&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>