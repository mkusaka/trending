<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-09T01:35:37Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>wowchemy/starter-hugo-academic</title>
    <updated>2022-10-09T01:35:37Z</updated>
    <id>tag:github.com,2022-10-09:/wowchemy/starter-hugo-academic</id>
    <link href="https://github.com/wowchemy/starter-hugo-academic" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üéì Hugo Academic Theme ÂàõÂª∫‰∏Ä‰∏™Â≠¶ÊúØÁΩëÁ´ô. Easily create a beautiful academic r√©sum√© or educational website using Hugo, GitHub, and Netlify.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href=&#34;https://github.com/wowchemy/starter-hugo-academic&#34;&gt;Hugo Academic Theme&lt;/a&gt;&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/hugo-themes/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/wowchemy/starter-hugo-academic/main/preview.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Hugo &lt;strong&gt;Academic Resum√© Template&lt;/strong&gt; empowers you to easily create your job-winning online resum√©, showcase your academic publications, and create online courses or knowledge bases to grow your audience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/hugo-themes/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/-Get%20started-ff4655?style=for-the-badge&#34; alt=&#34;Get Started&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.com/channels/722225264733716590/742892432458252370/742895548159492138&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/722225264733716590?style=for-the-badge&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://twitter.com/wowchemy&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/wowchemy?label=Follow%20on%20Twitter&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Ô∏è&lt;strong&gt;Trusted by 250,000+ researchers, educators, and students.&lt;/strong&gt; Highly customizable via the integrated &lt;strong&gt;no-code, widget-based Wowchemy page builder&lt;/strong&gt;, making every site truly personalized ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê&lt;/p&gt; &#xA;&lt;p&gt;Easily write technical content with plain text Markdown, LaTeX math, diagrams, RMarkdown, or Jupyter, and import publications from BibTeX.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://academic-demo.netlify.app/&#34;&gt;Check out the latest demo&lt;/a&gt; of what you&#39;ll get in less than 10 minutes, or &lt;a href=&#34;https://wowchemy.com/creators/&#34;&gt;get inspired by our academics and research groups&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The integrated &lt;a href=&#34;https://wowchemy.com&#34;&gt;&lt;strong&gt;Wowchemy&lt;/strong&gt;&lt;/a&gt; website builder and CMS makes it easy to create a beautiful website for free. Edit your site in the CMS (or your favorite editor), generate it with &lt;a href=&#34;https://github.com/gohugoio/hugo&#34;&gt;Hugo&lt;/a&gt;, and deploy with GitHub or Netlify. Customize anything on your site with widgets, light/dark themes, and language packs.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üëâ &lt;a href=&#34;https://wowchemy.com/hugo-themes/&#34;&gt;&lt;strong&gt;Get Started&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üìö &lt;a href=&#34;https://wowchemy.com/docs/&#34;&gt;View the &lt;strong&gt;documentation&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üí¨ &lt;a href=&#34;https://discord.gg/z8wNYzb&#34;&gt;Chat with the &lt;strong&gt;Wowchemy research community&lt;/strong&gt;&lt;/a&gt; or &lt;a href=&#34;https://discourse.gohugo.io&#34;&gt;&lt;strong&gt;Hugo community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üê¶ Twitter: &lt;a href=&#34;https://twitter.com/wowchemy&#34;&gt;@wowchemy&lt;/a&gt; &lt;a href=&#34;https://twitter.com/GeorgeCushen&#34;&gt;@GeorgeCushen&lt;/a&gt; &lt;a href=&#34;https://twitter.com/search?q=%23MadeWithWowchemy&amp;amp;src=typed_query&#34;&gt;#MadeWithWowchemy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚¨áÔ∏è &lt;strong&gt;Automatically import your publications from BibTeX&lt;/strong&gt; with the &lt;a href=&#34;https://github.com/wowchemy/hugo-academic-cli&#34;&gt;Hugo Academic CLI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;üí° &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-themes/issues&#34;&gt;Suggest an improvement&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;‚¨ÜÔ∏è &lt;strong&gt;Updating?&lt;/strong&gt; View the &lt;a href=&#34;https://wowchemy.com/docs/hugo-tutorials/update/&#34;&gt;Update Guide&lt;/a&gt; and &lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-themes/releases&#34;&gt;Release Notes&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;We ask you, humbly, to support this open source movement&lt;/h2&gt; &#xA;&lt;p&gt;Today we ask you to defend the open source independence of the Wowchemy website builder and themes üêß&lt;/p&gt; &#xA;&lt;p&gt;We&#39;re an open source movement that depends on your support to stay online and thriving, but 99.9% of our creators don&#39;t give; they simply look the other way.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/sponsors/gcushen&#34;&gt;‚ù§Ô∏è Click here to become a GitHub Sponsor, unlocking awesome perks such as &lt;em&gt;exclusive academic templates and widgets&lt;/em&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://wowchemy.com/templates/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://wowchemy.com/uploads/readmes/academic_logo_200px.png&#34; alt=&#34;Hugo Academic Theme for Wowchemy Website Builder&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo image credits&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://unsplash.com/photos/J4kK8b9Fgj8&#34;&gt;Open book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://unsplash.com/photos/JKUTrJ4vK00&#34;&gt;Course&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Latest news&lt;/h2&gt; &#xA;&lt;!--START_SECTION:news--&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wowchemy.com/blog/easily-make-academic-website/&#34;&gt;Easily make an academic CV website to get more cites and grow your audience üöÄ&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wowchemy.com/blog/whats-new-in-v5.2/&#34;&gt;What&#39;s new in v5.2?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wowchemy.com/blog/whats-new-in-v5.1/&#34;&gt;What&#39;s new in v5.1?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wowchemy.com/blog/version-5.0-february-2021/&#34;&gt;Version 5.0 (February 2021)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://wowchemy.com/blog/version-5.0-beta-3-february-2021/&#34;&gt;Version 5.0 Beta 3 (February 2021)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!--END_SECTION:news--&gt;</summary>
  </entry>
  <entry>
    <title>kishanrajput23/Awesome-Project-Collection</title>
    <updated>2022-10-09T01:35:37Z</updated>
    <id>tag:github.com,2022-10-09:/kishanrajput23/Awesome-Project-Collection</id>
    <link href="https://github.com/kishanrajput23/Awesome-Project-Collection" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository contains a lot of projects in various languages and domains.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Please do not contribute in this repository as it has been excluded from Hacktoberfest 2022&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/70385488/194719413-5c1f8c1a-7462-4411-9dc6-30ec72a473aa.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Awesome-Project-Collectionüî•&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/70385488/192114009-0830321a-d227-4a4d-8411-6c03b54d7ce6.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/kishanrajput23/Hacktoberfest-2022&#34;&gt;&lt;img src=&#34;https://firstcontributions.github.io/open-source-badges/badges/open-source-v1/open-source.svg?sanitize=true&#34; alt=&#34;Open Source Love&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/HacktoberFest-2022-blueviolet&#34; alt=&#34;Hacktober Badge&#34;&gt; &lt;img src=&#34;https://img.shields.io/static/v1?label=%E2%AD%90&amp;amp;message=If%20Useful&amp;amp;style=style=flat&amp;amp;color=BC4E99&#34; alt=&#34;Star Badge&#34;&gt; &lt;a href=&#34;https://github.com/kishanrajput23&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Contributions-welcome-green.svg?style=flat&amp;amp;logo=github&#34; alt=&#34;Contributions&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h3&gt;This repository aims to help code beginners with their first successful pull request and open source contribution. &lt;span&gt;ü•≥&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; Feel free to use this project to make your first contribution to an open-source project on GitHub. Practice making your first pull request to a public repository before doing the real thing!&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; Make sure to grab some cool swags during Hacktoberfest by getting involved in the open-source community.&lt;/p&gt; &#xA;&lt;h3&gt;This repository is open to all members of the GitHub community. Any member can contribute to this project! &lt;span&gt;üòÅ&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;What is Hacktoberfest? &lt;span&gt;ü§î&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;p&gt;A month-long celebration from October 1st to October 31st presented by &lt;a href=&#34;https://hacktoberfest.digitalocean.com/&#34;&gt;Digital Ocean&lt;/a&gt; and &lt;a href=&#34;https://dev.to/&#34;&gt;DEV Community&lt;/a&gt; collaborated with &lt;a href=&#34;https://github.com/blog/2433-celebrate-open-source-this-october-with-hacktoberfest&#34;&gt;GitHub&lt;/a&gt; to get people involved in &lt;a href=&#34;https://github.com/open-source&#34;&gt;Open Source&lt;/a&gt;. Create your very first pull request to any public repository on GitHub and contribute to the open-source developer community.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hacktoberfest.digitalocean.com/&#34;&gt;https://hacktoberfest.digitalocean.com/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Rules &lt;span&gt;üî•&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;p&gt;To qualify for the &lt;strong&gt;official limited edition Hacktoberfest shirt&lt;/strong&gt;, you must register &lt;a href=&#34;https://hacktoberfest.digitalocean.com/&#34;&gt;here&lt;/a&gt; and make four Pull Requests (PRs) between October 1-31, 2022 (in any time zone). PRs can be made to any public repository on GitHub, not only the ones with issues labeled Hacktoberfest. This year, the &lt;strong&gt;first 40,000&lt;/strong&gt; participants who complete Hacktoberfest can elect to receive one of two prizes: a tree planted in their name, or the Hacktoberfest 2022 t-shirt.&lt;/p&gt; &#xA;&lt;h2&gt;Steps to follow &lt;span&gt;üìú&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Tip : Complete this process in GitHub (in your browser)&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;flowchart LR&#xA;    Fork[Fork the project]--&amp;gt;branch[Create a New Branch]&#xA;    branch--&amp;gt;Edit[Edit file]&#xA;    Edit--&amp;gt;commit[Commit the changes]&#xA;    commit --&amp;gt;|Finally|creatpr((Create a Pull Request))&#xA;    &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Star The Repository &lt;span&gt;üåü&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;h2&gt;Awesome contributors &lt;span&gt;ü§©&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/kishanrajput23/Awesome-Project-Collection/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contributors-img.web.app/image?repo=kishanrajput23/Awesome-Project-Collection&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Made with &lt;a href=&#34;https://contributors-img.web.app&#34;&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Help Contributing Guides &lt;span&gt;üëë&lt;/span&gt;&lt;/h2&gt; &#xA;&lt;p&gt;We love to have &lt;code&gt;articles&lt;/code&gt; and &lt;code&gt;codes&lt;/code&gt; in different languages and the &lt;code&gt;betterment&lt;/code&gt; of existing ones.&lt;/p&gt; &#xA;&lt;p&gt;Please discuss it with us first by creating a new issue.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;üéâ&lt;/span&gt; &lt;span&gt;üéä&lt;/span&gt; &lt;span&gt;üòÉ&lt;/span&gt; &lt;em&gt;&lt;strong&gt;Happy Contributing&lt;/strong&gt;&lt;/em&gt; &lt;span&gt;üòÉ&lt;/span&gt; &lt;span&gt;üéä&lt;/span&gt; &lt;span&gt;üéâ&lt;/span&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Author üôã‚Äç‚ôÇÔ∏è : &lt;a href=&#34;https://linktr.ee/kishan_rajput23&#34;&gt;Find Me Here&lt;/a&gt;&lt;/h2&gt;</summary>
  </entry>
  <entry>
    <title>nateraw/stable-diffusion-videos</title>
    <updated>2022-10-09T01:35:37Z</updated>
    <id>tag:github.com,2022-10-09:/nateraw/stable-diffusion-videos</id>
    <link href="https://github.com/nateraw/stable-diffusion-videos" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Create üî• videos with Stable Diffusion by exploring the latent space and morphing between text prompts&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;stable-diffusion-videos&lt;/h1&gt; &#xA;&lt;p&gt;Try it yourself in Colab: &lt;a href=&#34;https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt; - morphing between &#34;blueberry spaghetti&#34; and &#34;strawberry spaghetti&#34;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/32437151/188721341-6f28abf9-699b-46b0-a72e-fa2a624ba0bb.mp4&#34;&gt;https://user-images.githubusercontent.com/32437151/188721341-6f28abf9-699b-46b0-a72e-fa2a624ba0bb.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;How it Works&lt;/h1&gt; &#xA;&lt;h2&gt;The Notebook/App&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb&#34;&gt;in-browser Colab demo&lt;/a&gt; allows you to generate videos by interpolating the latent space of &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34;&gt;Stable Diffusion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can either dream up different versions of the same prompt, or morph between different text prompts (with seeds set for each for reproducibility).&lt;/p&gt; &#xA;&lt;p&gt;The app is built with &lt;a href=&#34;https://gradio.app/&#34;&gt;Gradio&lt;/a&gt;, which allows you to interact with the model in a web app. Here&#39;s how I suggest you use it:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Use the &#34;Images&#34; tab to generate images you like.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Find two images you want to morph between&lt;/li&gt; &#xA;   &lt;li&gt;These images should use the same settings (guidance scale, scheduler, height, width)&lt;/li&gt; &#xA;   &lt;li&gt;Keep track of the seeds/settings you used so you can reproduce them&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Generate videos using the &#34;Videos&#34; tab&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Using the images you found from the step above, provide the prompts/seeds you recorded&lt;/li&gt; &#xA;   &lt;li&gt;Set the &lt;code&gt;num_walk_steps&lt;/code&gt; - for testing you can use a small number like 3 or 5, but to get great results you&#39;ll want to use something larger (60-200 steps).&lt;/li&gt; &#xA;   &lt;li&gt;You can set the &lt;code&gt;output_dir&lt;/code&gt; to the directory you wish to save to&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Python Package&lt;/h2&gt; &#xA;&lt;h3&gt;Setup&lt;/h3&gt; &#xA;&lt;p&gt;Install the package&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install stable_diffusion_videos&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Authenticate with Hugging Face&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;huggingface-cli login&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Making Videos&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_diffusion_videos import StableDiffusionWalkPipeline&#xA;from diffusers.schedulers import LMSDiscreteScheduler&#xA;import torch&#xA;&#xA;pipeline = StableDiffusionWalkPipeline.from_pretrained(&#xA;    &#34;CompVis/stable-diffusion-v1-4&#34;,&#xA;    use_auth_token=True,&#xA;    torch_dtype=torch.float16,&#xA;    revision=&#34;fp16&#34;,&#xA;    scheduler=LMSDiscreteScheduler(&#xA;        beta_start=0.00085, beta_end=0.012, beta_schedule=&#34;scaled_linear&#34;&#xA;    )&#xA;).to(&#34;cuda&#34;)&#xA;&#xA;video_path = pipeline.walk(&#xA;    prompts=[&#39;a cat&#39;, &#39;a dog&#39;],&#xA;    seeds=[42, 1337],&#xA;    num_interpolation_steps=3,&#xA;    height=512,  # use multiples of 64 if &amp;gt; 512. Multiples of 8 if &amp;lt; 512.&#xA;    width=512,   # use multiples of 64 if &amp;gt; 512. Multiples of 8 if &amp;lt; 512.&#xA;    output_dir=&#39;dreams&#39;,        # Where images/videos will be saved&#xA;    name=&#39;animals_test&#39;,        # Subdirectory of output_dir where images/videos will be saved&#xA;    guidance_scale=8.5,         # Higher adheres to prompt more, lower lets model take the wheel&#xA;    num_inference_steps=50,     # Number of diffusion steps per image generated. 50 is good default&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Making Music Videos&lt;/h3&gt; &#xA;&lt;p&gt;&lt;em&gt;New!&lt;/em&gt; Music can be added to the video by providing a path to an audio file. The audio will inform the rate of interpolation so the videos move to the beat üé∂&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_diffusion_videos import StableDiffusionWalkPipeline&#xA;from diffusers.schedulers import LMSDiscreteScheduler&#xA;import torch&#xA;&#xA;pipeline = StableDiffusionWalkPipeline.from_pretrained(&#xA;    &#34;CompVis/stable-diffusion-v1-4&#34;,&#xA;    use_auth_token=True,&#xA;    torch_dtype=torch.float16,&#xA;    revision=&#34;fp16&#34;,&#xA;    scheduler=LMSDiscreteScheduler(&#xA;        beta_start=0.00085, beta_end=0.012, beta_schedule=&#34;scaled_linear&#34;&#xA;    )&#xA;).to(&#34;cuda&#34;)&#xA;&#xA;&#xA;# Seconds in the song.&#xA;audio_offsets = [146, 148]&#xA;fps = 30  # Use lower values for testing (5 or 10), higher values for better quality (30 or 60)&#xA;&#xA;# Convert seconds to frames&#xA;num_interpolation_steps = [(b-a) * fps for a, b in zip(audio_offsets, audio_offsets[1:])]&#xA;&#xA;video_path = pipeline.walk(&#xA;    prompts=[&#39;a cat&#39;, &#39;a dog&#39;],&#xA;    seeds=[42, 1337],&#xA;    num_interpolation_steps=num_interpolation_steps,&#xA;    audio_filepath=&#39;audio.mp3&#39;,&#xA;    audio_start_sec=audio_offsets[0],&#xA;    height=512,  # use multiples of 64 if &amp;gt; 512. Multiples of 8 if &amp;lt; 512.&#xA;    width=512,   # use multiples of 64 if &amp;gt; 512. Multiples of 8 if &amp;lt; 512.&#xA;    output_dir=&#39;dreams&#39;,        # Where images/videos will be saved&#xA;    guidance_scale=7.5,         # Higher adheres to prompt more, lower lets model take the wheel&#xA;    num_inference_steps=50,     # Number of diffusion steps per image generated. 50 is good default&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Run the App Locally&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_diffusion_videos import interface&#xA;&#xA;interface.launch()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;This work built off of &lt;a href=&#34;https://gist.github.com/karpathy/00103b0037c5aaea32fe1da1af553355&#34;&gt;a script&lt;/a&gt; shared by &lt;a href=&#34;https://github.com/karpathy&#34;&gt;@karpathy&lt;/a&gt;. The script was modified to &lt;a href=&#34;https://gist.github.com/nateraw/c989468b74c616ebbc6474aa8cdd9e53&#34;&gt;this gist&lt;/a&gt;, which was then updated/modified to this repo.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;You can file any issues/feature requests &lt;a href=&#34;https://github.com/nateraw/stable-diffusion-videos/issues&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Enjoy ü§ó&lt;/p&gt; &#xA;&lt;h2&gt;Extras&lt;/h2&gt; &#xA;&lt;h3&gt;Upsample with Real-ESRGAN&lt;/h3&gt; &#xA;&lt;p&gt;You can also 4x upsample your images with &lt;a href=&#34;https://github.com/xinntao/Real-ESRGAN&#34;&gt;Real-ESRGAN&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;p&gt;First, you&#39;ll need to install it...&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install realesrgan&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, you&#39;ll be able to use &lt;code&gt;upsample=True&lt;/code&gt; in the &lt;code&gt;walk&lt;/code&gt; function, like this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pipeline.walk([&#39;a cat&#39;, &#39;a dog&#39;], [234, 345], upsample=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above may cause you to run out of VRAM. No problem, you can do upsampling separately.&lt;/p&gt; &#xA;&lt;p&gt;To upsample an individual image:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_diffusion_videos import PipelineRealESRGAN&#xA;&#xA;pipe = PipelineRealESRGAN.from_pretrained(&#39;nateraw/real-esrgan&#39;)&#xA;enhanced_image = pipe(&#39;your_file.jpg&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Or, to do a whole folder:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from stable_diffusion_videos import PipelineRealESRGAN&#xA;&#xA;pipe = PipelineRealESRGAN.from_pretrained(&#39;nateraw/real-esrgan&#39;)&#xA;pipe.upsample_imagefolder(&#39;path/to/images/&#39;, &#39;path/to/output_dir&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>