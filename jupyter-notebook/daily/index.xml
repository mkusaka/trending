<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-20T01:37:12Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facebookresearch/DensePose</title>
    <updated>2023-01-20T01:37:12Z</updated>
    <id>tag:github.com,2023-01-20:/facebookresearch/DensePose</id>
    <link href="https://github.com/facebookresearch/DensePose" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A real-time approach for mapping all human pixels of 2D RGB images to a 3D surface-based model of the body&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DensePose:&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dense Human Pose Estimation In The Wild&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Rıza Alp Güler, Natalia Neverova, Iasonas Kokkinos&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://densepose.org&#34;&gt;&lt;code&gt;densepose.org&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/1802.00434&#34;&gt;&lt;code&gt;arXiv&lt;/code&gt;&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/#CitingDensePose&#34;&gt;&lt;code&gt;BibTeX&lt;/code&gt;&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p&gt;Dense human pose estimation aims at mapping all human pixels of an RGB image to the 3D surface of the human body. DensePose-RCNN is implemented in the &lt;a href=&#34;https://github.com/facebookresearch/Detectron&#34;&gt;Detectron&lt;/a&gt; framework and is powered by &lt;a href=&#34;https://github.com/caffe2/caffe2&#34;&gt;Caffe2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://drive.google.com/uc?export=view&amp;amp;id=1qfSOkpueo1kVZbXOuQJJhyagKjMgepsz&#34; width=&#34;700px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;In this repository, we provide the code to train and evaluate DensePose-RCNN. We also provide notebooks to visualize the collected DensePose-COCO dataset and show the correspondences to the SMPL model.&lt;/p&gt; &#xA;&lt;h2&gt;Important Note&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;!!! This project is no longer supported !!!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;DensePose is now part of Detectron2 (&lt;a href=&#34;https://github.com/facebookresearch/detectron2/tree/master/projects/DensePose&#34;&gt;https://github.com/facebookresearch/detectron2/tree/master/projects/DensePose&lt;/a&gt;). There you can find the most up to date architectures / models. If you think some feature is missing from there, please post an issue in &lt;a href=&#34;https://github.com/facebookresearch/detectron2/tree/master/projects/DensePose&#34;&gt;Detectron2 DensePose&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Please find installation instructions for Caffe2 and DensePose in &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/INSTALL.md&#34;&gt;&lt;code&gt;INSTALL.md&lt;/code&gt;&lt;/a&gt;, a document based on the &lt;a href=&#34;https://github.com/facebookresearch/Detectron&#34;&gt;Detectron&lt;/a&gt; installation instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Inference-Training-Testing&lt;/h2&gt; &#xA;&lt;p&gt;After installation, please see &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/GETTING_STARTED.md&#34;&gt;&lt;code&gt;GETTING_STARTED.md&lt;/code&gt;&lt;/a&gt; for examples of inference and training and testing.&lt;/p&gt; &#xA;&lt;h2&gt;Notebooks&lt;/h2&gt; &#xA;&lt;h3&gt;Visualization of DensePose-COCO annotations:&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/notebooks/DensePose-COCO-Visualize.ipynb&#34;&gt;&lt;code&gt;notebooks/DensePose-COCO-Visualize.ipynb&lt;/code&gt;&lt;/a&gt; to visualize the DensePose-COCO annotations on the images:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://drive.google.com/uc?export=view&amp;amp;id=1uYRJkIA24KkJU2i4sMwrKa61P0xtZzHk&#34; width=&#34;800px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;DensePose-COCO in 3D:&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/notebooks/DensePose-COCO-on-SMPL.ipynb&#34;&gt;&lt;code&gt;notebooks/DensePose-COCO-on-SMPL.ipynb&lt;/code&gt;&lt;/a&gt; to localize the DensePose-COCO annotations on the 3D template (&lt;a href=&#34;http://smpl.is.tue.mpg.de&#34;&gt;&lt;code&gt;SMPL&lt;/code&gt;&lt;/a&gt;) model:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://drive.google.com/uc?export=view&amp;amp;id=1m32oyMuE7AZd3EOf9k8zHpr75C8bHlYj&#34; width=&#34;500px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Visualize DensePose-RCNN Results:&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/notebooks/DensePose-RCNN-Visualize-Results.ipynb&#34;&gt;&lt;code&gt;notebooks/DensePose-RCNN-Visualize-Results.ipynb&lt;/code&gt;&lt;/a&gt; to visualize the inferred DensePose-RCNN Results.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://drive.google.com/uc?export=view&amp;amp;id=1k4HtoXpbDV9MhuyhaVcxDrXnyP_NX896&#34; width=&#34;900px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;DensePose-RCNN Texture Transfer:&lt;/h3&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/notebooks/DensePose-RCNN-Texture-Transfer.ipynb&#34;&gt;&lt;code&gt;notebooks/DensePose-RCNN-Texture-Transfer.ipynb&lt;/code&gt;&lt;/a&gt; to localize the DensePose-COCO annotations on the 3D template (&lt;a href=&#34;http://smpl.is.tue.mpg.de&#34;&gt;&lt;code&gt;SMPL&lt;/code&gt;&lt;/a&gt;) model:&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://drive.google.com/uc?export=view&amp;amp;id=1r-w1oDkDHYnc1vYMbpXcYBVD1-V3B4Le&#34; width=&#34;900px&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This source code is licensed under the license found in the &lt;a href=&#34;https://raw.githubusercontent.com/facebookresearch/DensePose/main/LICENSE&#34;&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; file in the root directory of this source tree.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;a name=&#34;CitingDensePose&#34;&gt;&lt;/a&gt;Citing DensePose&lt;/h2&gt; &#xA;&lt;p&gt;If you use Densepose, please use the following BibTeX entry.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;  @InProceedings{Guler2018DensePose,&#xA;  title={DensePose: Dense Human Pose Estimation In The Wild},&#xA;  author={R\{i}za Alp G\&#34;uler, Natalia Neverova, Iasonas Kokkinos},&#xA;  journal={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},&#xA;  year={2018}&#xA;  }&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>