<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-12-22T01:34:49Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>SocialComplexityLab/life2vec</title>
    <updated>2023-12-22T01:34:49Z</updated>
    <id>tag:github.com,2023-12-22:/SocialComplexityLab/life2vec</id>
    <link href="https://github.com/SocialComplexityLab/life2vec" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Using Sequences of Life-events to Predict Human Lives&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zenodo.org/doi/10.5281/zenodo.10118620&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/doi/10.5281/zenodo.10118620.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains code for the &lt;a href=&#34;https://doi.org/10.21203/rs.3.rs-2975478/v1&#34;&gt;Using Sequences of Life-events to Predict Human Lives&lt;/a&gt; (life2vec) paper.&lt;/p&gt; &#xA;&lt;h3&gt;Source Code&lt;/h3&gt; &#xA;&lt;p&gt;This repository contains scripts and several notebooks for data processing, life2vec training, statistical analysis, and visualization. The model weights, experiment logs, and associated model outputs can be obtained in accordance with the rules of &lt;a href=&#34;https://www.dst.dk/en/TilSalg/Forskningsservice/Dataadgang&#34;&gt;Statistics Denmark&#39;s Research Scheme&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Paths (e.g., to data, or model weights) were &lt;strong&gt;redacted&lt;/strong&gt; before submitting scripts to GitHub.&lt;/p&gt; &#xA;&lt;h3&gt;Overall Structure&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://hydra.cc/docs/intro/&#34;&gt;Hydra&lt;/a&gt; to run the experiments. The &lt;code&gt;/conf&lt;/code&gt; folder contains configs for the experiments:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;/experiment&lt;/code&gt; contains configuration &lt;code&gt;yaml&lt;/code&gt; for pretraining and finetuning,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/tasks&lt;/code&gt; contain the specification for data augmentation in MLM, SOP, etc.,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/trainer&lt;/code&gt; contains configuration for logging (not used) and multithread training (not used),&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/data_new&lt;/code&gt; contains configs for data loading and processing,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/datamodule&lt;/code&gt; contains configs that specify how data should be loaded to PyTorch and PyTorch Lightning&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;callbacks.yaml&lt;/code&gt; specifies the configuration for the PyTorch Lightning Callbacks ,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;prepare_data.yaml&lt;/code&gt; can be used to run data preprocessing.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The &lt;code&gt;/analysis&lt;/code&gt; folder contains &lt;code&gt;ipynb&lt;/code&gt; notebooks for post-hoc evaluation:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;code&gt;/embedding&lt;/code&gt; contains the analysis of the embedding spaces,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/metric&lt;/code&gt; contains notebooks for the model evaluation,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/visualisation&lt;/code&gt; contains notebooks for the visualisation of spaces,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/tcav&lt;/code&gt; includes TCAV implementation,&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/optimization&lt;/code&gt; hyperparameter tuning.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;The source folder, &lt;code&gt;/src&lt;/code&gt;, contains the data loading and model training codes. Due to the specifics of the &lt;code&gt;hydra&lt;/code&gt; package. Here is the overview of the &lt;code&gt;/src&lt;/code&gt; folder:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;The &lt;code&gt;/src/data_new&lt;/code&gt; contains scripts to preprocess data as well as prepare data to load into the PyTorch or PyTorch Lightning,&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;/src/models&lt;/code&gt; contains the implementation of baseline models,&lt;/li&gt; &#xA; &lt;li&gt;The &lt;code&gt;/src/tasks&lt;/code&gt; include code specific to the particular task, aka MLM, SOP, Mortality Prediction, Emigration Prediction, etc.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/src/tranformer&lt;/code&gt; contains the implementation of the life2vec model: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;In &lt;code&gt;performer.py&lt;/code&gt;, we overwrite the functionality of the &lt;code&gt;performer-pytorch&lt;/code&gt; package,&lt;/li&gt; &#xA;   &lt;li&gt;In &lt;code&gt;cls_model.py&lt;/code&gt;, we have an implementation of the finetuning stage for the binary classification tasks (i.e. early mortality and emigration),&lt;/li&gt; &#xA;   &lt;li&gt;In &lt;code&gt;hexaco_model.py&lt;/code&gt;, we have an implementation of the finetuning stage for the &lt;strong&gt;personality nuance prediction&lt;/strong&gt; task,&lt;/li&gt; &#xA;   &lt;li&gt;&lt;code&gt;models.py&lt;/code&gt; contains the code for the life2vec &lt;strong&gt;pretraining&lt;/strong&gt; (aka the base life2vec model),&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;code&gt;transformer_utils.py&lt;/code&gt; contains the implementation of custom modules, like losses, activation functions, etc.&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;code&gt;metrics.py&lt;/code&gt; contains code for the custom metric,&lt;/li&gt; &#xA;   &lt;li&gt;The &lt;code&gt;modules.py&lt;/code&gt;, &lt;code&gt;attention.py&lt;/code&gt;, &lt;code&gt;att_utils.py&lt;/code&gt;, and &lt;code&gt;embeddings.py&lt;/code&gt; contain the implementation of modules used in the transformer network (aka life2vec encoders).&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Scripts such as &lt;code&gt;train.py&lt;/code&gt;, &lt;code&gt;test.py&lt;/code&gt;, &lt;code&gt;tune.py&lt;/code&gt;, and &lt;code&gt;val.py&lt;/code&gt; used to run a particular stage of the training, while &lt;code&gt;prepare_data.py&lt;/code&gt; was used to run the data processing (see below the example).&lt;/p&gt; &#xA;&lt;h3&gt;Run the script&lt;/h3&gt; &#xA;&lt;p&gt;To run the code, you would use the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# run the pretraining:&#xA;HYDRA_FULL_ERROR=1 python -m src.train experiment=pretrain trainer.devices=[7]&#xA;&#xA;# finetuning of the hyperparamaters (for the pretraining)&#xA;HYDRA_FULL_ERROR=1 python -m src.train experiment=pretrain_optim&#xA;&#xA;# assemble general dataset (GLOBAL_SET)&#xA;HYDRA_FULL_ERROR=1 python -m src.prepare_data +data_new/corpus=global_set target=\${data_new.corpus}&#xA;&#xA;# assemble dataset for the mortality prediction task (SURVIVAL_SET)&#xA;HYDRA_FULL_ERROR=1 python -m src.prepare_data +data_new/population=survival_set target=\${data_new.population}&#xA;&#xA;&#xA;# assemble labour source&#xA;python -m src.prepare_data +data_new/sources=labour target=\${data_new.sources}&#xA;&#xA;# run emigration finetuning&#xA;HYDRA_FULL_ERROR=1 python -m src.train experiment=emm trainer.devices=[0] version=0.01&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Another Code Contributors&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Søren Mørk Hartmann.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;How to cite&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;Research Square Preprint&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@article{savcisens2023using,&#xA;  title={Using Sequences of Life-events to Predict Human Lives},&#xA;  author={Savcisens, Germans and Eliassi-Rad, Tina and Hansen, Lars Kai and Mortensen, Laust and Lilleholt, Lau and Rogers, Anna and Zettler, Ingo and Lehmann, Sune},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Code&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{life2vec_code,&#xA;  author = {Germans Savcisens},&#xA;  note = {Zenodo},&#xA;  title = {SocialComplexityLab/life2vec},&#xA;  year = {2023},&#xA;  howpublished = {\url{https://doi.org/10.5281/zenodo.10118621}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>neulab/gemini-benchmark</title>
    <updated>2023-12-22T01:34:49Z</updated>
    <id>tag:github.com,2023-12-22:/neulab/gemini-benchmark</id>
    <link href="https://github.com/neulab/gemini-benchmark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;An In-depth Look at Gemini&#39;s Language Abilities&lt;/h1&gt; &#xA;&lt;p&gt;Repo for the paper &lt;a href=&#34;https://arxiv.org/abs/2312.11444&#34;&gt;An In-depth Look at Gemini&#39;s Language Abilities&lt;/a&gt; by &lt;a href=&#34;https://cmu.edu&#34;&gt;CMU&lt;/a&gt;, &lt;a href=&#34;https://zenoml.com&#34;&gt;Zeno&lt;/a&gt;, and &lt;a href=&#34;https://github.com/BerriAI/litellm&#34;&gt;BerriAI LiteLLM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this paper, we do an in-depth exploration of &lt;a href=&#34;https://blog.google/technology/ai/google-gemini-ai/&#34;&gt;Google Gemini&lt;/a&gt;&#39;s language abilities, making two contributions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We provide a third-party, objective comparison of the abilities of the OpenAI GPT and Google Gemini models with reproducible code and fully transparent results.&lt;/li&gt; &#xA; &lt;li&gt;we take a closer look at the results, identifying areas where one of the two model classes excels.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Results&lt;/h2&gt; &#xA;&lt;p&gt;We perform this analysis over 10 datasets testing a variety of language abilities, including reasoning, answering knowledge-based questions, solving math problems, translating between languages, generating code, and acting as instruction-following agents. From this analysis, we find that (as of this writing on December 18th, 2023):&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Gemini Pro achieves accuracy that is close but slightly inferior to the corresponding GPT 3.5 Turbo on all tasks that we benchmarked.&lt;/li&gt; &#xA; &lt;li&gt;Gemini fails in mathematical reasoning with many digits, and is sensitive to multiple-choice answer ordering, aggressive content filtering, and others.&lt;/li&gt; &#xA; &lt;li&gt;Gemini demonstrates comparably high performance in areas such as generation into non-English languages, handling longer and more complex reasoning chains, and word sorting/rearrangement problems.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The overall results table can be found below:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Task&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Gemini Pro&lt;/th&gt; &#xA;   &lt;th&gt;GPT 3.5 Turbo&lt;/th&gt; &#xA;   &lt;th&gt;GPT 4 Turbo&lt;/th&gt; &#xA;   &lt;th&gt;Mixtral&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Knowledge-based QA&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MMLU (5-shot)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;64.12&lt;/td&gt; &#xA;   &lt;td&gt;67.75&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;80.48&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MMLU (CoT)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;60.63&lt;/td&gt; &#xA;   &lt;td&gt;70.07&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;78.95&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Reasoning&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;BIG-Bench-Hard&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;65.58&lt;/td&gt; &#xA;   &lt;td&gt;71.02&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;83.90&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;41.76&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Mathematics&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;GSM8K&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;69.67&lt;/td&gt; &#xA;   &lt;td&gt;74.60&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;92.95&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;58.45&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;SVAMP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;79.90&lt;/td&gt; &#xA;   &lt;td&gt;82.30&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;92.50&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;73.20&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ASDIV&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;81.53&lt;/td&gt; &#xA;   &lt;td&gt;86.69&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;91.66&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;74.95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MAWPS&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;95.33&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;99.17&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;98.50&lt;/td&gt; &#xA;   &lt;td&gt;89.83&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Code Generation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;HumanEval&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;52.44&lt;/td&gt; &#xA;   &lt;td&gt;65.85&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;73.17&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;ODEX&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;38.27&lt;/td&gt; &#xA;   &lt;td&gt;42.60&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;46.01&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Machine Translation&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;FLORES (0-shot)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;29.59&lt;/td&gt; &#xA;   &lt;td&gt;37.50&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;46.57&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;FLORES (5-shot)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;29.00&lt;/td&gt; &#xA;   &lt;td&gt;38.08&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;48.60&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;Web Agents&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;WebArena&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;7.09&lt;/td&gt; &#xA;   &lt;td&gt;8.75&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;15.16&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;1.37&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;You can find more details on results from each task, and comprehensive analysis at each of the below links:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2674/Gemini%20MMLU&#34;&gt;Knowledge-based QA&lt;/a&gt; (MMLU)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2575/Gemini%20BBH&#34;&gt;Reasoning&lt;/a&gt; (BIG-Bench Hard)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2773/Gemini%20Mathematics&#34;&gt;Mathematics&lt;/a&gt; (GSM8K, SVAMP, ASDIV, MAWPS)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2641/Gemini%20Code&#34;&gt;Code Generation&lt;/a&gt; (HumanEval, ODEX)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2740/Gemini%3A%20Flores%20Translation%20Evaluation&#34;&gt;Machine Translation&lt;/a&gt; (FLORES)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://hub.zenoml.com/report/2608/Gemini%20Webarena&#34;&gt;Web Navigation Agents&lt;/a&gt; (WebArena)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;File Structure&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;/outputs/{dataset}/{model}&lt;/code&gt;: contains the outputs of the systems, separated by dataset and model&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/benchmarking/{dataset}&lt;/code&gt;: contains the code for benchmarking, separated by dataset&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;/visualization&lt;/code&gt;: contains the code for visualization, possibly separated by task type&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root of the repository with your Zeno API key:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ZENO_API_KEY=your_api_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This is loaded by &lt;code&gt;dotenv&lt;/code&gt; in the visualization files.&lt;/p&gt;</summary>
  </entry>
</feed>