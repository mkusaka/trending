<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-07-08T01:46:29Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>eemlcommunity/PracticalSessions2022</title>
    <updated>2022-07-08T01:46:29Z</updated>
    <id>tag:github.com,2022-07-08:/eemlcommunity/PracticalSessions2022</id>
    <link href="https://github.com/eemlcommunity/PracticalSessions2022" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Hands-on tutorials at EEML2022 summer school&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PracticalSessions2022&lt;/h1&gt; &#xA;&lt;p&gt;Repository for tutorial sessions at EEML2022&lt;/p&gt; &#xA;&lt;p&gt;Designed for education purposes. Please do not distribute without permission. Write at &lt;a href=&#34;mailto:contact@eeml.eu&#34;&gt;contact@eeml.eu&lt;/a&gt; if you have any question.&lt;/p&gt; &#xA;&lt;p&gt;You are welcome to reuse this material in other courses or schools, but please reach out to &lt;a href=&#34;mailto:contact@eeml.eu&#34;&gt;contact@eeml.eu&lt;/a&gt; if you plan to do so. We would appreciate it if you could acknowledge that the materials come from EEML2022 and give credits to the authors. Also please keep a link in your materials to the original repo, in case updates occur.&lt;/p&gt; &#xA;&lt;p&gt;MIT License&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) 2022 EEML&lt;/p&gt; &#xA;&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &#34;Software&#34;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt; &#xA;&lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt; &#xA;&lt;p&gt;THE SOFTWARE IS PROVIDED &#34;AS IS&#34;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>clovaai/deep-text-recognition-benchmark</title>
    <updated>2022-07-08T01:46:29Z</updated>
    <id>tag:github.com,2022-07-08:/clovaai/deep-text-recognition-benchmark</id>
    <link href="https://github.com/clovaai/deep-text-recognition-benchmark" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Text recognition (optical character recognition) with deep learning methods.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis&lt;/h1&gt; &#xA;&lt;p&gt;| &lt;a href=&#34;https://arxiv.org/abs/1904.01906&#34;&gt;paper&lt;/a&gt; | &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark#download-lmdb-dataset-for-traininig-and-evaluation-from-here&#34;&gt;training and evaluation data&lt;/a&gt; | &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark#download-failure-cases-and-cleansed-label-from-here&#34;&gt;failure cases and cleansed label&lt;/a&gt; | &lt;a href=&#34;https://www.dropbox.com/sh/j3xmli4di1zuv3s/AAArdcPgz7UFxIHUuKNOeKv_a?dl=0&#34;&gt;pretrained model&lt;/a&gt; | &lt;a href=&#34;https://pan.baidu.com/s/1KSNLv4EY3zFWHpBYlpFCBQ&#34;&gt;Baidu ver(passwd:rryk)&lt;/a&gt; |&lt;/p&gt; &#xA;&lt;p&gt;Official PyTorch implementation of our four-stage STR framework, that most existing STR models fit into. &lt;br&gt; Using this framework allows for the module-wise contributions to performance in terms of accuracy, speed, and memory demand, under one consistent set of training and evaluation datasets. &lt;br&gt; Such analyses clean up the hindrance on the current comparisons to understand the performance gain of the existing modules. &lt;br&gt;&lt;br&gt; &lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/figures/trade-off.png&#34; width=&#34;1000&#34; title=&#34;trade-off&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Honors&lt;/h2&gt; &#xA;&lt;p&gt;Based on this framework, we recorded the 1st place of &lt;a href=&#34;https://rrc.cvc.uab.es/?ch=2&amp;amp;com=evaluation&amp;amp;task=3&#34;&gt;ICDAR2013 focused scene text&lt;/a&gt;, &lt;a href=&#34;https://rrc.cvc.uab.es/files/ICDAR2019-ArT.pdf&#34;&gt;ICDAR2019 ArT&lt;/a&gt; and 3rd place of &lt;a href=&#34;https://rrc.cvc.uab.es/?ch=5&amp;amp;com=evaluation&amp;amp;task=2&#34;&gt;ICDAR2017 COCO-Text&lt;/a&gt;, &lt;a href=&#34;https://rrc.cvc.uab.es/files/ICDAR2019-ReCTS.pdf&#34;&gt;ICDAR2019 ReCTS (task1)&lt;/a&gt;. &lt;br&gt; The difference between our paper and ICDAR challenge is summarized &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/issues/13&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Updates&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Aug 3, 2020&lt;/strong&gt;: added &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/pull/209&#34;&gt;guideline to use Baidu warpctc&lt;/a&gt; which reproduces CTC results of our paper. &lt;br&gt; &lt;strong&gt;Dec 27, 2019&lt;/strong&gt;: added &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/issues/125&#34;&gt;FLOPS&lt;/a&gt; in our paper, and minor updates such as log_dataset.txt and &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/raw/86451088248e0490ff8b5f74d33f7d014f6c249a/test.py#L139-L165&#34;&gt;ICDAR2019-NormalizedED&lt;/a&gt;. &lt;br&gt; &lt;strong&gt;Oct 22, 2019&lt;/strong&gt;: added &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/issues/82&#34;&gt;confidence score&lt;/a&gt;, and arranged the output form of training logs. &lt;br&gt; &lt;strong&gt;Jul 31, 2019&lt;/strong&gt;: The paper is accepted at International Conference on Computer Vision (ICCV), Seoul 2019, as an oral talk. &lt;br&gt; &lt;strong&gt;Jul 25, 2019&lt;/strong&gt;: The code for floating-point 16 calculation, check &lt;a href=&#34;https://github.com/YacobBY&#34;&gt;@YacobBY&#39;s&lt;/a&gt; &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/pull/36&#34;&gt;pull request&lt;/a&gt; &lt;br&gt; &lt;strong&gt;Jul 16, 2019&lt;/strong&gt;: added &lt;a href=&#34;https://drive.google.com/drive/folders/192UfE9agQUMNq6AgU3_E05_FcPZK4hyt&#34;&gt;ST_spe.zip&lt;/a&gt; dataset, word images contain special characters in SynthText (ST) dataset, see &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/issues/7#issuecomment-511727025&#34;&gt;this issue&lt;/a&gt; &lt;br&gt; &lt;strong&gt;Jun 24, 2019&lt;/strong&gt;: added gt.txt of failure cases that contains path and label of each image, see &lt;a href=&#34;https://drive.google.com/open?id=1VAP9l5GL5fgptgKDLio_h3nMe7X9W0Mf&#34;&gt;image_release_190624.zip&lt;/a&gt; &lt;br&gt; &lt;strong&gt;May 17, 2019&lt;/strong&gt;: uploaded resources in Baidu Netdisk also, added &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark#run-demo-with-pretrained-model&#34;&gt;Run demo&lt;/a&gt;. (check &lt;a href=&#34;https://github.com/sharavsambuu&#34;&gt;@sharavsambuu&#39;s&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1PHnc_QYyf9b1_KJ1r15wYXaOXkdm1Mrk&#34;&gt;colab demo also&lt;/a&gt;) &lt;br&gt; &lt;strong&gt;May 9, 2019&lt;/strong&gt;: PyTorch version updated from 1.0.1 to 1.1.0, use torch.nn.CTCLoss instead of torch-baidu-ctc, and various minor updated.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Dependency&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;This work was tested with PyTorch 1.3.1, CUDA 10.1, python 3.6 and Ubuntu 16.04. &lt;br&gt; You may need &lt;code&gt;pip3 install torch==1.3.1&lt;/code&gt;. &lt;br&gt; In the paper, expriments were performed with &lt;strong&gt;PyTorch 0.4.1, CUDA 9.0&lt;/strong&gt;.&lt;/li&gt; &#xA; &lt;li&gt;requirements : lmdb, pillow, torchvision, nltk, natsort&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install lmdb pillow torchvision nltk natsort&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Download lmdb dataset for traininig and evaluation from &lt;a href=&#34;https://www.dropbox.com/sh/i39abvnefllx2si/AAAbAYRvxzRp3cIE5HzqUw3ra?dl=0&#34;&gt;here&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;data_lmdb_release.zip contains below. &lt;br&gt; training datasets : &lt;a href=&#34;http://www.robots.ox.ac.uk/~vgg/data/text/&#34;&gt;MJSynth (MJ)&lt;/a&gt;[1] and &lt;a href=&#34;http://www.robots.ox.ac.uk/~vgg/data/scenetext/&#34;&gt;SynthText (ST)&lt;/a&gt;[2] &lt;br&gt; validation datasets : the union of the training sets &lt;a href=&#34;http://rrc.cvc.uab.es/?ch=2&#34;&gt;IC13&lt;/a&gt;[3], &lt;a href=&#34;http://rrc.cvc.uab.es/?ch=4&#34;&gt;IC15&lt;/a&gt;[4], &lt;a href=&#34;http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K.html&#34;&gt;IIIT&lt;/a&gt;[5], and &lt;a href=&#34;http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset&#34;&gt;SVT&lt;/a&gt;[6].&lt;br&gt; evaluation datasets : benchmark evaluation datasets, consist of &lt;a href=&#34;http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K.html&#34;&gt;IIIT&lt;/a&gt;[5], &lt;a href=&#34;http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset&#34;&gt;SVT&lt;/a&gt;[6], &lt;a href=&#34;http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2003_Robust_Reading_Competitions&#34;&gt;IC03&lt;/a&gt;[7], &lt;a href=&#34;http://rrc.cvc.uab.es/?ch=2&#34;&gt;IC13&lt;/a&gt;[3], &lt;a href=&#34;http://rrc.cvc.uab.es/?ch=4&#34;&gt;IC15&lt;/a&gt;[4], &lt;a href=&#34;http://openaccess.thecvf.com/content_iccv_2013/papers/Phan_Recognizing_Text_with_2013_ICCV_paper.pdf&#34;&gt;SVTP&lt;/a&gt;[8], and &lt;a href=&#34;http://cs-chan.com/downloads_CUTE80_dataset.html&#34;&gt;CUTE&lt;/a&gt;[9].&lt;/p&gt; &#xA;&lt;h3&gt;Run demo with pretrained model&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download pretrained model from &lt;a href=&#34;https://drive.google.com/drive/folders/15WPsuPJDCzhp2SvYZLRj8mAlT3zmoAMW&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Add image files to test into &lt;code&gt;demo_image/&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Run demo.py (add &lt;code&gt;--sensitive&lt;/code&gt; option if you use case-sensitive model)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python3 demo.py \&#xA;--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \&#xA;--image_folder demo_image/ \&#xA;--saved_model TPS-ResNet-BiLSTM-Attn.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;prediction results&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;demo images&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://drive.google.com/open?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9&#34;&gt;TRBA (&lt;strong&gt;T&lt;/strong&gt;PS-&lt;strong&gt;R&lt;/strong&gt;esNet-&lt;strong&gt;B&lt;/strong&gt;iLSTM-&lt;strong&gt;A&lt;/strong&gt;ttn)&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://drive.google.com/open?id=1ajONZOgiG9pEYsQ-eBmgkVbMDuHgPCaY&#34;&gt;TRBA (case-sensitive version)&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_1.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;available&lt;/td&gt; &#xA;   &lt;td&gt;Available&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_2.jpg&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;shakeshack&lt;/td&gt; &#xA;   &lt;td&gt;SHARESHACK&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_3.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;london&lt;/td&gt; &#xA;   &lt;td&gt;Londen&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_4.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;greenstead&lt;/td&gt; &#xA;   &lt;td&gt;Greenstead&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_5.png&#34; width=&#34;300&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;toast&lt;/td&gt; &#xA;   &lt;td&gt;TOAST&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_6.png&#34; width=&#34;300&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;merry&lt;/td&gt; &#xA;   &lt;td&gt;MERRY&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_7.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;underground&lt;/td&gt; &#xA;   &lt;td&gt;underground&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_8.jpg&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;ronaldo&lt;/td&gt; &#xA;   &lt;td&gt;RONALDO&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_9.jpg&#34; width=&#34;300&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;bally&lt;/td&gt; &#xA;   &lt;td&gt;BALLY&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/demo_image/demo_10.jpg&#34; width=&#34;300&#34; height=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;university&lt;/td&gt; &#xA;   &lt;td&gt;UNIVERSITY&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Training and evaluation&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Train CRNN[10] model&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python3 train.py \&#xA;--train_data data_lmdb_release/training --valid_data data_lmdb_release/validation \&#xA;--select_data MJ-ST --batch_ratio 0.5-0.5 \&#xA;--Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Test CRNN[10] model. If you want to evaluate IC15-2077, check &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/raw/c27abe6b4c681e2ee0784ad966602c056a0dd3b5/dataset.py#L148&#34;&gt;data filtering part&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python3 test.py \&#xA;--eval_data data_lmdb_release/evaluation --benchmark_all_eval \&#xA;--Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC \&#xA;--saved_model saved_models/None-VGG-BiLSTM-CTC-Seed1111/best_accuracy.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Try to train and test our best accuracy model TRBA (&lt;strong&gt;T&lt;/strong&gt;PS-&lt;strong&gt;R&lt;/strong&gt;esNet-&lt;strong&gt;B&lt;/strong&gt;iLSTM-&lt;strong&gt;A&lt;/strong&gt;ttn) also. (&lt;a href=&#34;https://drive.google.com/drive/folders/15WPsuPJDCzhp2SvYZLRj8mAlT3zmoAMW&#34;&gt;download pretrained model&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python3 train.py \&#xA;--train_data data_lmdb_release/training --valid_data data_lmdb_release/validation \&#xA;--select_data MJ-ST --batch_ratio 0.5-0.5 \&#xA;--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0 python3 test.py \&#xA;--eval_data data_lmdb_release/evaluation --benchmark_all_eval \&#xA;--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \&#xA;--saved_model saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Arguments&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;--train_data&lt;/code&gt;: folder path to training lmdb dataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--valid_data&lt;/code&gt;: folder path to validation lmdb dataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--eval_data&lt;/code&gt;: folder path to evaluation (with test.py) lmdb dataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--select_data&lt;/code&gt;: select training data. default is MJ-ST, which means MJ and ST used as training data.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--batch_ratio&lt;/code&gt;: assign ratio for each selected data in the batch. default is 0.5-0.5, which means 50% of the batch is filled with MJ and the other 50% of the batch is filled ST.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--data_filtering_off&lt;/code&gt;: skip &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/raw/f2c54ae2a4cc787a0f5859e9fdd0e399812c76a3/dataset.py#L126-L146&#34;&gt;data filtering&lt;/a&gt; when creating LmdbDataset.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--Transformation&lt;/code&gt;: select Transformation module [None | TPS].&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--FeatureExtraction&lt;/code&gt;: select FeatureExtraction module [VGG | RCNN | ResNet].&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--SequenceModeling&lt;/code&gt;: select SequenceModeling module [None | BiLSTM].&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--Prediction&lt;/code&gt;: select Prediction module [CTC | Attn].&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--saved_model&lt;/code&gt;: assign saved model to evaluation.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;--benchmark_all_eval&lt;/code&gt;: evaluate with 10 evaluation dataset versions, same with Table 1 in our paper.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Download failure cases and cleansed label from &lt;a href=&#34;https://www.dropbox.com/s/5knh1gb1z593fxj/image_release_190624.zip?dl=0&#34;&gt;here&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;image_release.zip contains failure case images and benchmark evaluation images with cleansed label. &lt;img src=&#34;https://raw.githubusercontent.com/clovaai/deep-text-recognition-benchmark/master/figures/failure-case.jpg&#34; width=&#34;1000&#34; title=&#34;failure cases&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;When you need to train on your own dataset or Non-Latin language datasets.&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create your own lmdb dataset.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip3 install fire&#xA;python3 create_lmdb_dataset.py --inputPath data/ --gtFile data/gt.txt --outputPath result/&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The structure of data folder as below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;data&#xA;├── gt.txt&#xA;└── test&#xA;    ├── word_1.png&#xA;    ├── word_2.png&#xA;    ├── word_3.png&#xA;    └── ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;At this time, &lt;code&gt;gt.txt&lt;/code&gt; should be &lt;code&gt;{imagepath}\t{label}\n&lt;/code&gt; &lt;br&gt; For example&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;test/word_1.png Tiredness&#xA;test/word_2.png kills&#xA;test/word_3.png A&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Modify &lt;code&gt;--select_data&lt;/code&gt;, &lt;code&gt;--batch_ratio&lt;/code&gt;, and &lt;code&gt;opt.character&lt;/code&gt;, see &lt;a href=&#34;https://github.com/clovaai/deep-text-recognition-benchmark/issues/85&#34;&gt;this issue&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;This implementation has been based on these repository &lt;a href=&#34;https://github.com/meijieru/crnn.pytorch&#34;&gt;crnn.pytorch&lt;/a&gt;, &lt;a href=&#34;https://github.com/marvis/ocr_attention&#34;&gt;ocr_attention&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Reference&lt;/h2&gt; &#xA;&lt;p&gt;[1] M. Jaderberg, K. Simonyan, A. Vedaldi, and A. Zisserman. Synthetic data and artificial neural networks for natural scenetext recognition. In Workshop on Deep Learning, NIPS, 2014. &lt;br&gt; [2] A. Gupta, A. Vedaldi, and A. Zisserman. Synthetic data fortext localisation in natural images. In CVPR, 2016. &lt;br&gt; [3] D. Karatzas, F. Shafait, S. Uchida, M. Iwamura, L. G. i Big-orda, S. R. Mestre, J. Mas, D. F. Mota, J. A. Almazan, andL. P. De Las Heras. ICDAR 2013 robust reading competition. In ICDAR, pages 1484–1493, 2013. &lt;br&gt; [4] D. Karatzas, L. Gomez-Bigorda, A. Nicolaou, S. Ghosh, A. Bagdanov, M. Iwamura, J. Matas, L. Neumann, V. R.Chandrasekhar, S. Lu, et al. ICDAR 2015 competition on ro-bust reading. In ICDAR, pages 1156–1160, 2015. &lt;br&gt; [5] A. Mishra, K. Alahari, and C. Jawahar. Scene text recognition using higher order language priors. In BMVC, 2012. &lt;br&gt; [6] K. Wang, B. Babenko, and S. Belongie. End-to-end scenetext recognition. In ICCV, pages 1457–1464, 2011. &lt;br&gt; [7] S. M. Lucas, A. Panaretos, L. Sosa, A. Tang, S. Wong, andR. Young. ICDAR 2003 robust reading competitions. In ICDAR, pages 682–687, 2003. &lt;br&gt; [8] T. Q. Phan, P. Shivakumara, S. Tian, and C. L. Tan. Recognizing text with perspective distortion in natural scenes. In ICCV, pages 569–576, 2013. &lt;br&gt; [9] A. Risnumawan, P. Shivakumara, C. S. Chan, and C. L. Tan. A robust arbitrary text detection system for natural scene images. In ESWA, volume 41, pages 8027–8048, 2014. &lt;br&gt; [10] B. Shi, X. Bai, and C. Yao. An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition. In TPAMI, volume 39, pages2298–2304. 2017.&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;WebDemo : &lt;a href=&#34;https://demo.ocr.clova.ai/&#34;&gt;https://demo.ocr.clova.ai/&lt;/a&gt; &lt;br&gt; Combination of Clova AI detection and recognition, additional/advanced features used for KOR/JPN.&lt;/li&gt; &#xA; &lt;li&gt;Repo of detection : &lt;a href=&#34;https://github.com/clovaai/CRAFT-pytorch&#34;&gt;https://github.com/clovaai/CRAFT-pytorch&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please consider citing this work in your publications if it helps your research.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{baek2019STRcomparisons,&#xA;  title={What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis},&#xA;  author={Baek, Jeonghun and Kim, Geewook and Lee, Junyeop and Park, Sungrae and Han, Dongyoon and Yun, Sangdoo and Oh, Seong Joon and Lee, Hwalsuk},&#xA;  booktitle = {International Conference on Computer Vision (ICCV)},&#xA;  year={2019},&#xA;  pubstate={published},&#xA;  tppubtype={inproceedings}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;Feel free to contact us if there is any question: &lt;br&gt; for code/paper Jeonghun Baek &lt;a href=&#34;mailto:ku21fang@gmail.com&#34;&gt;ku21fang@gmail.com&lt;/a&gt;; for collaboration &lt;a href=&#34;mailto:hwalsuk.lee@navercorp.com&#34;&gt;hwalsuk.lee@navercorp.com&lt;/a&gt; (our team leader).&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Copyright (c) 2019-present NAVER Corp.&lt;/p&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0 (the &#34;License&#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &#34;AS IS&#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>cerlymarco/MEDIUM_NoteBook</title>
    <updated>2022-07-08T01:46:29Z</updated>
    <id>tag:github.com,2022-07-08:/cerlymarco/MEDIUM_NoteBook</id>
    <link href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Repository containing notebooks of my posts on Medium&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MEDIUM_NoteBook&lt;/h1&gt; &#xA;&lt;p&gt;Repository containing notebooks of my posts on &lt;a href=&#34;https://medium.com/@cerlymarco&#34;&gt;MEDIUM&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To be notified every time a new post is published, &lt;strong&gt;SUBSCRIBE &lt;a href=&#34;https://medium.com/subscribe/@cerlymarco&#34;&gt;HERE&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Do you enjoy my posts and appreciate my technical approach? &lt;strong&gt;I CAN WRITE FOR YOU&lt;/strong&gt;: &lt;a href=&#34;https://it.fiverr.com/share/775kKW&#34;&gt;I do reports, analyses and articles using machine learning&lt;/a&gt; (service offered on Fiverr).&lt;/p&gt; &#xA;&lt;h2&gt;Posts ordered by most recently publishing date&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Retrain, or not Retrain? Online Machine Learning with Gradient Boosting [&lt;a href=&#34;https://medium.com/towards-data-science/retrain-or-not-retrain-online-machine-learning-with-gradient-boosting-9ccb464415e7&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Refit_Online_Learning&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Data Drift Explainability: Interpretable Shift Detection with NannyML [&lt;a href=&#34;https://medium.com/towards-data-science/data-drift-explainability-interpretable-shift-detection-with-nannyml-83421319d05f&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NannyML_Drift_Detector&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Word2Vec with Time Series: A Transfer Learning Approach [&lt;a href=&#34;https://medium.com/towards-data-science/word2vec-with-time-series-a-transfer-learning-approach-58017e7a019d&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/TimeSeries_Word2Vec&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SHAP for Drift Detection: Effective Data Shift Monitoring [&lt;a href=&#34;https://medium.com/towards-data-science/shap-for-drift-detection-effective-data-shift-monitoring-c7fb9590adb0&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Shap_Drift_Detector&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting with Trees: Hybrid Classifiers for Time Series [&lt;a href=&#34;https://medium.com/towards-data-science/forecasting-with-trees-hybrid-classifiers-for-time-series-b2509abf15f8&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Hybrid_Trees_Classifiers&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Boruta SHAP for Temporal Feature Selection [&lt;a href=&#34;https://medium.com/towards-data-science/boruta-shap-for-temporal-feature-selection-96a7840c7713&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ShapBoruta_TemporalSelection&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Forecasting with Trees: Hybrid Modeling for Time Series [&lt;a href=&#34;https://medium.com/towards-data-science/forecasting-with-trees-hybrid-modeling-for-time-series-58590a113178&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Hybrid_Trees_Forecasting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Recursive Feature Selection: Addition or Elimination? [&lt;a href=&#34;https://towardsdatascience.com/recursive-feature-selection-addition-or-elimination-755e5d86a791&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Shap_RFA_RFE&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Improve Random Forest with Linear Models [&lt;a href=&#34;https://towardsdatascience.com/improve-random-forest-with-linear-models-1fa789691e18&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/LinearForest&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Is Gradient Boosting good as Prophet for Time Series Forecasting? [&lt;a href=&#34;https://towardsdatascience.com/is-gradient-boosting-good-as-prophet-for-time-series-forecasting-3dcbfd03775e&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Prophet_vs_GradientBoosting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Linear Boosting with Automated Features Engineering [&lt;a href=&#34;https://towardsdatascience.com/linear-boosting-with-automated-features-engineering-894962c3ba84&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/LinearBoosting_AutoFeatureEngine&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Improve Linear Regression for Time Series Forecasting [&lt;a href=&#34;https://towardsdatascience.com/improve-linear-regression-for-time-series-forecasting-e36f3c3e3534&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ModelTrees_TimeSeries&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Boruta and SHAP for better Feature Selection [&lt;a href=&#34;https://towardsdatascience.com/boruta-and-shap-for-better-feature-selection-20ea97595f4a&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ShapBoruta_FeatureSelection&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Explainable AI with Linear Trees [&lt;a href=&#34;https://towardsdatascience.com/explainable-ai-with-linear-trees-7e30a6f067d7&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ModelTrees_Explainability&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;SHAP for Feature Selection and HyperParameter Tuning [&lt;a href=&#34;https://towardsdatascience.com/shap-for-feature-selection-and-hyperparameter-tuning-a330ec0ea104&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Shap_FeatureSelection&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Model Tree: handle Data Shifts mixing Linear Model and Decision Tree [&lt;a href=&#34;https://towardsdatascience.com/model-tree-handle-data-shifts-mixing-linear-model-and-decision-tree-facfd642e42b&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ModelTrees_DataShifts&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Add Prediction Intervals to your Forecasting Model [&lt;a href=&#34;https://towardsdatascience.com/add-prediction-intervals-to-your-forecasting-model-531b7c2d386c&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Prediction_Intervals&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Linear Tree: the perfect mix of Linear Model and Decision Tree [&lt;a href=&#34;https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7&#34;&gt;post&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;ARIMA for Classification with Soft Labels [&lt;a href=&#34;https://towardsdatascience.com/arima-for-classification-with-soft-labels-29f3109d9840&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Classification_ARIMA&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Advanced Permutation Importance to Explain Predictions [&lt;a href=&#34;https://towardsdatascience.com/advanced-permutation-importance-to-explain-predictions-ead7de26eed4&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Advanced_Perm_Importance&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series Bootstrap in the age of Deep Learning [&lt;a href=&#34;https://towardsdatascience.com/time-series-bootstrap-in-the-age-of-deep-learning-b98aa2aa32c4&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/TimeSeries_Bootstrap&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anomaly Detection with Extreme Value Analysis [&lt;a href=&#34;https://towardsdatascience.com/anomaly-detection-with-extreme-value-analysis-b11ad19b601f&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_ExtremeValues&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series generation with VAE LSTM [&lt;a href=&#34;https://towardsdatascience.com/time-series-generation-with-vae-lstm-5a6426365a1c&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/VAE_TimeSeries&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Extreme Event Time Series Preprocessing [&lt;a href=&#34;https://towardsdatascience.com/extreme-event-time-series-preprocessing-90aa59d5630c&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Extreme_Event_PreProcessing&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;One-Class Neural Network in Keras [&lt;a href=&#34;https://towardsdatascience.com/one-class-neural-network-in-keras-249ff56201c0&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/OneClass_NeuralNetwork&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Real-Time Time Series Anomaly Detection [&lt;a href=&#34;https://towardsdatascience.com/real-time-time-series-anomaly-detection-981cf1e1ca13&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_RealTime&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Entropy Application in the Stock Market [&lt;a href=&#34;https://towardsdatascience.com/entropy-application-in-the-stock-market-b211914ed1f3&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Structural_Entropy&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series Smoothing for better Forecasting [&lt;a href=&#34;https://towardsdatascience.com/time-series-smoothing-for-better-forecasting-7fbf10428b2&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/TimeSeries_Smoothing_Forecasting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series Smoothing for better Clustering [&lt;a href=&#34;https://towardsdatascience.com/time-series-smoothing-for-better-clustering-121b98f308e8&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/TimeSeries_Smoothing_Clustering&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predictive Maintenance with ResNet [&lt;a href=&#34;https://towardsdatascience.com/predictive-maintenance-with-resnet-ebb4f4a0be3d&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Predictive_Maintenance_ResNet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Neural Networks Ensemble [&lt;a href=&#34;https://towardsdatascience.com/neural-networks-ensemble-33f33bea7df3&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NeuralNet_Ensemble&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anomaly Detection in Multivariate Time Series with VAR [&lt;a href=&#34;https://towardsdatascience.com/anomaly-detection-in-multivariate-time-series-with-var-2130f276e5e9&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_VAR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Corr2Vec: a WaveNet architecture for Feature Engineering in Financial Market [&lt;a href=&#34;https://towardsdatascience.com/corr2vec-a-wavenet-architecture-for-feature-engineering-in-financial-market-94b4f8279ba6&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Corr2Vec_WaveNet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Siamese and Dual BERT for Multi Text Classification [&lt;a href=&#34;https://towardsdatascience.com/siamese-and-dual-bert-for-multi-text-classification-c6552d435533&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Siamese_Dual_BERT&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series Forecasting with Graph Convolutional Neural Network [&lt;a href=&#34;https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Graph_TimeSeries_Forecasting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Neural Network Calibration with Keras [&lt;a href=&#34;https://towardsdatascience.com/neural-network-calibration-with-keras-76fb7c13a55&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NeuralNet_Calibration&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Combine LSTM and VAR for Multivariate Time Series Forecasting [&lt;a href=&#34;https://towardsdatascience.com/combine-lstm-and-var-for-multivariate-time-series-forecasting-abdcb3c7939b&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/LSTM_VAR&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Feature Importance with Time Series and Recurrent Neural Network [&lt;a href=&#34;https://towardsdatascience.com/feature-importance-with-time-series-and-recurrent-neural-network-27346d500b9c&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NeuralNetSeq_FeatureImportance&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Group2Vec for Advance Categorical Encoding [&lt;a href=&#34;https://towardsdatascience.com/group2vec-for-advance-categorical-encoding-54dfc7a08349&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Group2Vec&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Survival Analysis with Deep Learning in Keras [&lt;a href=&#34;https://towardsdatascience.com/survival-analysis-with-deep-learning-in-keras-443875c486f2&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Survival_NeuralNetwork&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Survival Analysis with LightGBM plus Poisson Regression [&lt;a href=&#34;https://towardsdatascience.com/survival-analysis-with-lightgbm-plus-poisson-regression-6b3cc897af82&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Survival_LGBM&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predictive Maintenance: detect Faults from Sensors with CRNN and Spectrograms [&lt;a href=&#34;https://towardsdatascience.com/predictive-maintenance-detect-faults-from-sensors-with-crnn-and-spectrograms-e1e4f8c2385d&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Predictive_Maintenance_CRNN&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Multi-Sample Dropout in Keras [&lt;a href=&#34;https://towardsdatascience.com/multi-sample-dropout-in-keras-ea8b8a9bfd83&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Multi_Sample_Dropout&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;When your Neural Net doesn’t know: a bayesian approach with Keras [&lt;a href=&#34;https://towardsdatascience.com/when-your-neural-net-doesnt-know-a-bayesian-approach-with-keras-4782c0818624&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NeuralNet_BayesUncertainty&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Dynamic Meta Embeddings in Keras [&lt;a href=&#34;https://towardsdatascience.com/dynamic-meta-embeddings-in-keras-42393d246963&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Dynamic_Meta_Embedding&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predictive Maintenance with LSTM Siamese Network [&lt;a href=&#34;https://towardsdatascience.com/predictive-maintenance-with-lstm-siamese-network-51ee7df29767&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Predictive_Maintenance_SiameseNet&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Text Data Augmentation makes your model stronger [&lt;a href=&#34;https://towardsdatascience.com/text-data-augmentation-makes-your-model-stronger-7232bd23704&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Text_Augmentation&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anomaly Detection with Permutation Undersampling and Time Dependency [&lt;a href=&#34;https://towardsdatascience.com/anomaly-detection-with-permutation-undersampling-and-time-dependency-5919e7c695d0&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_PermutationUndersampling&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time2Vec for Time Series features encoding [&lt;a href=&#34;https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Time2Vec&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Automate Data Cleaning with Unsupervised Learning [&lt;a href=&#34;https://towardsdatascience.com/automate-data-cleaning-with-unsupervised-learning-2046ef59ac17&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Unsupervised_Text_Cleaning&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;People Tracking with Machine Learning [&lt;a href=&#34;https://towardsdatascience.com/people-tracking-with-machine-learning-d6c54ce5bb8c&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/PeopleTracking&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Time Series Clustering and Dimensionality Reduction [&lt;a href=&#34;https://towardsdatascience.com/time-series-clustering-and-dimensionality-reduction-5b3b4e84f6a3&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/TimeSeries_Cluster&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anomaly Detection in Images [&lt;a href=&#34;https://towardsdatascience.com/anomaly-detection-in-images-777534980aeb&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_Image&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Feature Importance with Neural Network [&lt;a href=&#34;https://towardsdatascience.com/feature-importance-with-neural-network-346eb6205743&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/NeuralNet_FeatureImportance&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Anomaly Detection with LSTM in Keras [&lt;a href=&#34;https://towardsdatascience.com/anomaly-detection-with-lstm-in-keras-8d8d7e50ab1b&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Anomaly_Detection_LSTM&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Dress Segmentation with Autoencoder in Keras [&lt;a href=&#34;https://towardsdatascience.com/dress-segmentation-with-autoencoder-in-keras-497cf1fd169a&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Dress_Segmentation&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Extreme Event Forecasting with LSTM Autoencoders [&lt;a href=&#34;https://towardsdatascience.com/extreme-event-forecasting-with-lstm-autoencoders-297492485037&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Extreme_Event_Forecasting&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Zalando Dress Recommendation and Tagging [&lt;a href=&#34;https://towardsdatascience.com/zalando-dress-recomendation-and-tagging-f38e1cbfc4a9&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/ZALANDO_Recomendation_Tag&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Remaining Life Estimation with Keras [&lt;a href=&#34;https://towardsdatascience.com/remaining-life-estimation-with-keras-2334514f9c61&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Remaining_Life_Estimation&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Quality Control with Machine Learning [&lt;a href=&#34;https://towardsdatascience.com/quality-control-with-machine-learning-d7aab7382c1e&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Quality_Control&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predictive Maintenance: detect Faults from Sensors with CNN [&lt;a href=&#34;https://towardsdatascience.com/predictive-maintenance-detect-faults-from-sensors-with-cnn-6c6172613371&#34;&gt;post&lt;/a&gt;]|[&lt;a href=&#34;https://github.com/cerlymarco/MEDIUM_NoteBook/tree/master/Predictive_Maintenance&#34;&gt;code&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>