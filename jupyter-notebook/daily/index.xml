<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-17T01:38:09Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>km1994/LLMsNineStoryDemonTower</title>
    <updated>2023-05-17T01:38:09Z</updated>
    <id>tag:github.com,2023-05-17:/km1994/LLMsNineStoryDemonTower</id>
    <link href="https://github.com/km1994/LLMsNineStoryDemonTower" rel="alternate"></link>
    <summary type="html">&lt;p&gt;【LLMs九层妖塔】分享一下打怪(ChatGLM、Chinese-LLaMA-Alpaca、MiniGPT-4、FastChat、LLaMA、gpt4all等)实战与经验，&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLMsNineStoryDemonTower LLMs九层妖塔&lt;/h1&gt; &#xA;&lt;p&gt;【LLMs九层妖塔】分享一下打怪(ChatGLM、Chinese-LLaMA-Alpaca、MiniGPT-4、FastChat、LLaMA、gpt4all等)实战与经验，&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/km1994/LLMsNineStoryDemonTower/raw/main/mp4/LLMs%E4%B9%9D%E5%B1%82%E5%A6%96%E5%A1%94%E6%8C%91%E6%88%98%E8%B5%9B.mp4&#34; alt=&#34;LLMs九层妖塔 视频介绍&#34;&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/km1994/LLMsNineStoryDemonTower/raw/main/mp4/LLMs%E4%B9%9D%E5%B1%82%E5%A6%96%E5%A1%94%E6%8C%91%E6%88%98%E8%B5%9B.mp4&#34;&gt;LLMs九层妖塔 视频介绍 地址&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#llmsninestorydemontower-llms%E4%B9%9D%E5%B1%82%E5%A6%96%E5%A1%94&#34;&gt;LLMsNineStoryDemonTower LLMs九层妖塔&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#llms-%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E7%B3%BB%E5%88%97&#34;&gt;【LLMs 入门实战系列】&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%B8%80%E5%B1%82-chatglm-6b&#34;&gt;第一层 ChatGLM-6B&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E5%86%85%E5%AE%B9%E5%A4%A7%E7%BA%B2&#34;&gt;内容大纲&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%BA%8C%E5%B1%82-stanford-alpaca-7b&#34;&gt;第二层 Stanford Alpaca 7B&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%B8%89%E5%B1%82-chinese-llama-alpaca&#34;&gt;第三层 Chinese-LLaMA-Alpaca&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E5%9B%9B%E5%B1%82-%E5%B0%8F%E7%BE%8A%E9%A9%BC-vicuna&#34;&gt;第四层 小羊驼 Vicuna&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%BA%94%E5%B1%82-minigpt-4&#34;&gt;第五层 MiniGPT-4&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E5%85%AD%E5%B1%82-gpt4all&#34;&gt;第六层 GPT4ALL&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%B8%83%E5%B1%82-autogpt&#34;&gt;第七层 AutoGPT&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E5%85%AB%E5%B1%82-moss&#34;&gt;第八层 MOSS&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E5%AD%A6%E4%B9%A0%E7%BE%A4&#34;&gt;学习群&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E4%BC%98%E7%A7%80%E7%AC%94%E8%AE%B0&#34;&gt;优秀笔记&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E7%AC%AC%E4%B8%80%E5%B1%82&#34;&gt;第一层&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E4%BC%98%E7%A7%80%E7%AC%94%E8%AE%B0-1&#34;&gt;优秀笔记&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/#%E5%8F%82%E8%80%83&#34;&gt;参考&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;【LLMs 入门实战系列】&lt;/h2&gt; &#xA;&lt;h3&gt;第一层 ChatGLM-6B&lt;/h3&gt; &#xA;&lt;h4&gt;内容大纲&lt;/h4&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/ChatGLM-6B/induction.md&#34;&gt;【ChatGLM-6B入门-一】清华大学开源中文版ChatGLM-6B模型学习与实战&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：ChatGLM-6B 环境配置 和 部署&lt;/li&gt; &#xA;   &lt;li&gt;github 项目：&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;https://github.com/THUDM/ChatGLM-6B&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;https://huggingface.co/THUDM/chatglm-6b&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/ChatGLM-6B/ptuning.md&#34;&gt;【ChatGLM-6B入门-二】清华大学开源中文版ChatGLM-6B模型微调实战&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：ChatGLM-6B P-Tuning V2 微调：Fine-tuning the prefix encoder of the model.&lt;/li&gt; &#xA;   &lt;li&gt;github 项目：&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;https://github.com/THUDM/ChatGLM-6B&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;https://huggingface.co/THUDM/chatglm-6b&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/ChatGLM-6B/ptuning_in_my_data.md&#34;&gt;【ChatGLM-6B入门-三】ChatGLM 特定任务微调实战&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：对于 ChatGLM-6B 模型基于 &lt;a href=&#34;https://github.com/THUDM/P-tuning-v2&#34;&gt;P-Tuning v2&lt;/a&gt; 的特定任务微调实验，微调目标为自动生成的整数/小数加减乘除运算。&lt;/li&gt; &#xA;   &lt;li&gt;github 项目： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;https://github.com/THUDM/ChatGLM-6B&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/yongzhuo/chatglm-maths&#34;&gt;https://github.com/yongzhuo/chatglm-maths&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;https://huggingface.co/THUDM/chatglm-6b&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;训练数据集： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/BelleGroup/school_math_0.25M&#34;&gt;BelleGroup/school_math_0.25M&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/ChatGLM-6B/LoRA_finetune.md&#34;&gt;【ChatGLM-6B入门-四】ChatGLM + LoRA 进行finetune&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：ChatGLM-6B LoRA 微调：Fine-tuning the low-rank adapters of the model.&lt;/li&gt; &#xA;   &lt;li&gt;github 项目： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/mymusise/ChatGLM-Tuning&#34;&gt;https://github.com/mymusise/ChatGLM-Tuning&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/THUDM/chatglm-6b&#34;&gt;https://huggingface.co/THUDM/chatglm-6b&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://articles.zsxq.com/id_7rz5jtfguuc5.html&#34;&gt;【LLMs 入门实战 —— 十一 】基于 🤗PEFT 的高效 🤖ChatGLM-6B 微调&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;微调方式： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;ChatGLM-6B Freeze 微调：Fine-tuning the MLPs in the last n blocks of the model.&lt;/li&gt; &#xA;     &lt;li&gt;ChatGLM-6B P-Tuning V2 微调：Fine-tuning the prefix encoder of the model.&lt;/li&gt; &#xA;     &lt;li&gt;ChatGLM-6B LoRA 微调：Fine-tuning the low-rank adapters of the model.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://articles.zsxq.com/id_54vjwns5t6in.html&#34;&gt;【LLMs 入门实战 —— 十二 】基于 本地知识库 的高效 🤖langchain-ChatGLM &lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：langchain-ChatGLM是一个基于本地知识的问答机器人，使用者可以自由配置本地知识，用户问题的答案也是基于本地知识生成的。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://articles.zsxq.com/id_fw7vn0mhdsnq.html&#34;&gt;ChatGLM-6B 小编填坑记&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：ChatGLM-6B 在 部署和微调 过程中 会遇到很多坑，小编掉坑了很多次，为防止 后人和小编一样继续掉坑，小编索性把遇到的坑都填了。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://articles.zsxq.com/id_il58nxrs9jxr.html&#34;&gt;【LLMs学习】关于大模型实践的一些总结&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;第二层 Stanford Alpaca 7B&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/Stanford_Alpaca_7B/readme.md&#34;&gt;【LLMs 入门实战 —— 五 】Stanford Alpaca 7B 模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：本教程提供了对LLaMA模型进行微调的廉价亲民 LLMs 学习和微调 方式，主要介绍对于 Stanford Alpaca 7B 模型在特定任务上 的 微调实验，所用的数据为OpenAI提供的GPT模型API生成质量较高的指令数据（仅52k）。&lt;/li&gt; &#xA;   &lt;li&gt;github 项目： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/P01son/ChatLLaMA-zh-7B&#34;&gt;https://huggingface.co/P01son/ChatLLaMA-zh-7B&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第三层 Chinese-LLaMA-Alpaca&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/Chinese-LLaMA-Alpaca/readme.md&#34;&gt;【LLMs 入门实战 —— 六 】Chinese-LLaMA-Alpaca 模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：本教程主要介绍了 Chinese-ChatLLaMA,提供中文对话模型 ChatLLama 、中文基础模型 LLaMA-zh 及其训练数据。 模型基于 TencentPretrain 多模态预训练框架构建&lt;/li&gt; &#xA;   &lt;li&gt;github 项目： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/ydli-ai/Chinese-ChatLLaMA&#34;&gt;https://github.com/ydli-ai/Chinese-ChatLLaMA&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/decapoda-research/llama-7b-hf&#34;&gt;https://huggingface.co/decapoda-research/llama-7b-hf&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第四层 小羊驼 Vicuna&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/Vicuna/readme.md&#34;&gt;【LLMs 入门实战 —— 七 】小羊驼 Vicuna模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：UC伯克利学者联手CMU、斯坦福等，再次推出一个全新模型70亿/130亿参数的Vicuna，俗称「小羊驼」（骆马）。小羊驼号称能达到GPT-4的90%性能&lt;/li&gt; &#xA;   &lt;li&gt;github 项目： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;https://github.com/lm-sys/FastChat&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;huggingface Weights： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/lmsys/vicuna-7b-delta-v1.1&#34;&gt;https://huggingface.co/lmsys/vicuna-7b-delta-v1.1&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://huggingface.co/decapoda-research/llama-7b-hf&#34;&gt;https://huggingface.co/decapoda-research/llama-7b-hf&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第五层 MiniGPT-4&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/mingpt/readme.md&#34;&gt;【LLMs 入门实战 —— 八 】MiniGPT-4 模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍： MiniGPT-4，是来自阿卜杜拉国王科技大学的几位博士做的，它能提供类似 GPT-4 的图像理解与对话能力&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第六层 GPT4ALL&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_ff0w6czthq25.html&#34;&gt;【LLMs 入门实战 —— 八 】GPT4ALL 模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：一个 可以在自己笔记本上面跑起来的 Nomic AI 的助手式聊天机器人，成为贫民家孩子的 福音！&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第七层 AutoGPT&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_pli0z9916126.html&#34;&gt;AutoGPT 使用和部署&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：Auto-GPT是一个基于ChatGPT的工具，他能帮你自动完成各种任务，比如写代码、写报告、做调研等等。使用它时，你只需要告诉他要扮演的角色和要实现的目标，然后他就会利用ChatGPT和谷歌搜索等工具，不断“思考”如何接近目标并执行，你甚至可以看到他的思考过程。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;第八层 MOSS&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_4vwpxod23zrc.html&#34;&gt;【LLMs 入门实战 —— 十三 】MOSS 模型学习与实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;介绍：MOSS是一个支持中英双语和多种插件的开源对话语言模型，moss-moon系列模型具有160亿参数，在FP16精度下可在单张A100/A800或两张3090显卡运行，在INT4/8精度下可在单张3090显卡运行。MOSS基座语言模型在约七千亿中英文以及代码单词上预训练得到，后续经过对话指令微调、插件增强学习和人类偏好训练具备多轮对话能力及使用多种插件的能力。&lt;/li&gt; &#xA;   &lt;li&gt;局限性：由于模型参数量较小和自回归生成范式，MOSS仍然可能生成包含事实性错误的误导性回复或包含偏见/歧视的有害内容，请谨慎鉴别和使用MOSS生成的内容，请勿将MOSS生成的有害内容传播至互联网。若产生不良后果，由传播者自负。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;学习群&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/km1994/LLMsNineStoryDemonTower/main/img/20230516092740.jpg&#34; alt=&#34;学习群二维码&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;优秀笔记&lt;/h2&gt; &#xA;&lt;h3&gt;第一层&lt;/h3&gt; &#xA;&lt;h3&gt;优秀笔记&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/4QNgF6nAUo8imSaIB_OWmg&#34;&gt;杨夕&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_k2qzsps7zw21.html&#34;&gt;奔腾&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_zzfqt88sw4rl.html&#34;&gt;逸尘&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.zsxq.com/0dEp8PDcW&#34;&gt;此方一泉&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://t.csdn.cn/hWn9D&#34;&gt;vezel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/627358709&#34;&gt;徐生&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_velwvtmfhrwz.html&#34;&gt;多点微笑&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/627333187&#34;&gt;小固&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/627358709&#34;&gt;土狼&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Wesley12138/LLM&#34;&gt;0&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://t.zsxq.com/0dJhaaGRW&#34;&gt;Welch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://articles.zsxq.com/id_7g0g65fbsluo.html&#34;&gt;九猫&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;参考&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/THUDM/ChatGLM-6B&#34;&gt;ChatGLM-6B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca 7B&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;Chinese-LLaMA-Alpaca&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lm-sys/FastChat&#34;&gt;Vicuna&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Vision-CAIR/MiniGPT-4&#34;&gt;MiniGPT-4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;GPT4ALL&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;hhttps://github.com/Significant-Gravitas/Auto-GPT&#34;&gt;Auto-GPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OpenLMLab/MOSS/tree/main&#34;&gt;MOSS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>gw-odw/odw-2023</title>
    <updated>2023-05-17T01:38:09Z</updated>
    <id>tag:github.com,2023-05-17:/gw-odw/odw-2023</id>
    <link href="https://github.com/gw-odw/odw-2023" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Tutorials for GW Open Data Workshop, 2023&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;middle&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/share/odw-2023-logo.png&#34; width=&#34;70%&#34;&gt; &lt;/p&gt;&#xA;&lt;hr&gt; &#xA;&lt;h1&gt;GW Open Data Workshop #6&lt;/h1&gt; &#xA;&lt;p&gt;This repository contains the material to support &lt;a href=&#34;https://www.gw-openscience.org/odw/odw2023&#34;&gt;GW Open Data Workshop #6&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Firstly, we recommend taking a look at the setup guide, where you can find the information to configure the workspace where you are going to execute the tutorials.&lt;/p&gt; &#xA;&lt;p&gt;In the &lt;a href=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/Tutorials/&#34;&gt;Tutorials&lt;/a&gt; folder, you can find the various notebooks for the three days, divided on the base of their topics. There are also some quiz that you are asked to complete at the end of each session.&lt;/p&gt; &#xA;&lt;p&gt;For every question concerning the software setup, the tutorials, the workshop in general, or even for GW science questions, please use &lt;a href=&#34;https://ask.igwn.org/&#34;&gt;this forum&lt;/a&gt;. You can check if your question was already asked in the Open Data Workshop category and, if you can&#39;t find your answer, you can post a new question.&lt;/p&gt; &#xA;&lt;p&gt;Lastly, test yourself with the &lt;a href=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/Challenge/&#34;&gt;GW Data Challenge&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;Software setup&lt;/h2&gt; &#xA;&lt;p&gt;At the following link, several options are presented, with the indication of their difficulty and OS dependency. Feel free to pick the one that suits best for your needs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/setup.md&#34;&gt;Software Setup Instructions&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Hands-on sessions&lt;/h2&gt; &#xA;&lt;p&gt;The tutorials are divided into three folders for each one of the days of hands-on sessions. In there, you can find a summary of their topics.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/Tutorials/&#34;&gt;Tutorials&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Data Challenge&lt;/h2&gt; &#xA;&lt;p&gt;Here you can find a list of &#34;challenges&#34;, ordered by difficulty, which the participants can complete, as individuals or in teams, and submit their answers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/gw-odw/odw-2023/main/Challenge/&#34;&gt;Challenge&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>https-deeplearning-ai/tensorflow-2-public</title>
    <updated>2023-05-17T01:38:09Z</updated>
    <id>tag:github.com,2023-05-17:/https-deeplearning-ai/tensorflow-2-public</id>
    <link href="https://github.com/https-deeplearning-ai/tensorflow-2-public" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dlai_TF2&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Specialization Name:&lt;/strong&gt; TensorFlow: Data and Deployment Specialization&lt;/p&gt; &#xA;&lt;p&gt;Below is the list of assignments and ungraded labs course-wise.&lt;/p&gt; &#xA;&lt;h1&gt;C1 - Browser-based Models with TensorFlow.js&lt;/h1&gt; &#xA;&lt;h2&gt;Week 1&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Breast Cancer Classification &lt;em&gt;(C1_W1_Assignment.html)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;FirstHTML &lt;em&gt;(C1_W1_Lab_1_FirstHTML.html)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Iris Classifier &lt;em&gt;(C1_W1_Lab_2_iris_classifier.html)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 2&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fashion MNIST &lt;em&gt;(C1_W2_Assignment.js)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Lab&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;MNIST &lt;em&gt;(C1_W2_Lab_1_mnist.html)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 3&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Converting a Python Model to JavaScript &lt;em&gt;(C1_W3_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Lab&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Toxicity Classifier &lt;em&gt;(C1_W3_Lab_1_toxicity.html)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Image Classification Using MobileNet &lt;em&gt;(C1_W3_Lab_2_mobilenet.html)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Linear Model &lt;em&gt;(C1_W3_Lab_3A_linear_to_JavaScript.ipynb and C1_W3_Lab_3B_linear.html)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 4&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rock Paper Scissors &lt;em&gt;(C1_W4_Assignment.js)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Lab&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Rock Paper Scissors &lt;em&gt;(C1_W4_Lab_1_retrain.html)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;C2 - Device-based Models with TensorFlow Lite&lt;/h1&gt; &#xA;&lt;h2&gt;Week 1&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Train Your Own Model and Convert It to TFLite &lt;em&gt;(C2_W1_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Running TFLite Models &lt;em&gt;(C2_W1_Lab_1_Linear_Regression.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transfer Learning with TensorFlow Hub for TFLite &lt;em&gt;(C2_W1_Lab_2_Transfer_Learning.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 2 (Android)&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment (Optional)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rock, Paper &amp;amp; Scissors with TensorFlow Hub - TFLite &lt;em&gt;(C2_W2_Assignment.ipynb and C2_W2_Assignment_Solution.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cats vs Dogs&lt;/li&gt; &#xA; &lt;li&gt;Image Classification&lt;/li&gt; &#xA; &lt;li&gt;Object Detection&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Week 3 (iOS)&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment (Optional)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rock, Paper &amp;amp; Scissors with TensorFlow Hub - TFLite &lt;em&gt;(C2_W3_Assignment.ipynb and C2_W3_Assignment_Solution.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cats vs Dogs&lt;/li&gt; &#xA; &lt;li&gt;Image Classification&lt;/li&gt; &#xA; &lt;li&gt;Object Detection&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Week 4 (Raspberry Pi)&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment (Optional)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rock, Paper &amp;amp; Scissors with TensorFlow Hub - TFLite &lt;em&gt;(C2_W4_Assignment.py and C2_W2_Assignment_Solution.py)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Cats vs Dogs&lt;/li&gt; &#xA; &lt;li&gt;Image Classification&lt;/li&gt; &#xA; &lt;li&gt;Object Detection&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;C3 - Data Pipelines with TensorFlow Data Services&lt;/h1&gt; &#xA;&lt;h2&gt;Week 1&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TFDS with Rock, Paper and Scissors &lt;em&gt;(C3_W1_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;TFDS Hellow World &lt;em&gt;(C3_W1_Lab_1_tfds_hello_world.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Horses or Humans &lt;em&gt;(C3_W1_Lab_2_horses_or_humans.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 2&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Transfer Learning and Splits API &lt;em&gt;(C3_W2_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Exploring the Splits API &lt;em&gt;(C3_W2_Lab_1_splits_api.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;TFRecords &lt;em&gt;(C3_W2_Lab_2_tfrecords.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 3&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Classify Structured Data &lt;em&gt;(C3_W3_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Lab&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Classify structured data with feature columns &lt;em&gt;(C3_W3_Lab_1_feature_columns.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;tf.data: Build TensorFlow input pipelines &lt;em&gt;(C3_W3_Lab_2_data.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Load CSV data &lt;em&gt;(C3_W3_Lab_3_csv.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 4&lt;/h2&gt; &#xA;&lt;h3&gt;Assignments&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Parallelization with TFDS &lt;em&gt;(C3_W4_A1_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Adding a Dataset of your Own to TFDS &lt;em&gt;(C3_W4_A2_Assignment_Optional.ipynb and C3_W4_A2_Assignment_Optional_Solution.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;C4 - Advanced Deployment Scenarios with TensorFlow&lt;/h1&gt; &#xA;&lt;h2&gt;Week 1&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Train Your Own Model and Serve It With TensorFlow Serving &lt;em&gt;(C4_W1_Assignment.ipynb and C4_W1_Assignment_Solution.ipynb )&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Getting Started with TensorFlow Serving &lt;em&gt;(C4_W1_Lab_1_tfserving_hello_world.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Train and serve a TensorFlow model with TensorFlow Serving &lt;em&gt;(C4_W1_Lab_2_Train_and_serve_a_TensorFlow_model_with_TensorFlow_Serving.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 2&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Exporting an MNIST Classifier in SavedModel Format &lt;em&gt;(C4_W2_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Getting Started with TensorFlow Hub &lt;em&gt;(C4_W2_Lab_1_tfhub_basic_examples.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Text Classification &lt;em&gt;(C4_W2_Lab_2_text_classification.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transfer Learning with TensorFlow Hub &lt;em&gt;(C4_W2_Lab_3_transfer_learning.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Week 3&lt;/h2&gt; &#xA;&lt;h3&gt;Assignment&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;TensorBoard with Fashion MNIST &lt;em&gt;(C4_W3_Assignment.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Displaying image data in TensorBoard &lt;em&gt;(C4_W3_Lab_1_image_summaries.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Week 4&lt;/h2&gt; &#xA;&lt;h3&gt;Ungraded Labs&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Custom Federated Algorithms, Part 1: Introduction to the Federated Core &lt;em&gt;(C4_W4_Lab_1_custom_federated_algorithms.ipynb)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>