<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-23T01:38:29Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>lupantech/chameleon-llm</title>
    <updated>2023-04-23T01:38:29Z</updated>
    <id>tag:github.com,2023-04-23:/lupantech/chameleon-llm</id>
    <link href="https://github.com/lupantech/chameleon-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Codes for &#34;Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models&#34;.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;span&gt;ğŸ¦&lt;/span&gt; Chameleon: Plug-and-Play Compositional Reasoning with GPT-4&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Task-Science_Problems-blue&#34; alt=&#34;Science Problems&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Task-MathQA-blue&#34; alt=&#34;Science Problems&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Task-TableQA-blue&#34; alt=&#34;Science Problems&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Model-Tool_Use-green&#34; alt=&#34;Chain-of-Thought&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Model-GPT--4-green&#34; alt=&#34;GPT-4&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Model-LLMs-green&#34; alt=&#34;LLMs&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Code for the Paper &#34;&lt;a href=&#34;https://arxiv.org/abs/2304.09842&#34;&gt;Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models&lt;/a&gt;&#34;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;span&gt;ğŸ””&lt;/span&gt; If you have any questions or suggestions, please don&#39;t hesitate to let us know. You can directly email &lt;a href=&#34;https://lupantech.github.io/&#34;&gt;Pan Lu&lt;/a&gt; using the email address &lt;a href=&#34;mailto:lupantech@gmail.com&#34;&gt;lupantech@gmail.com&lt;/a&gt;, comment on the &lt;a href=&#34;https://twitter.com/lupantech/status/1648879085115052033&#34;&gt;Twitter&lt;/a&gt;, or post an issue on this repository.&lt;/p&gt; &#xA;&lt;p&gt;[&lt;a href=&#34;https://chameleon-llm.github.io/&#34;&gt;Project Page&lt;/a&gt;] [&lt;a href=&#34;https://arxiv.org/abs/2304.09842&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://twitter.com/lupantech/status/1648879085115052033&#34;&gt;Twitter&lt;/a&gt;] [&lt;a href=&#34;https://chameleon-llm.github.io/&#34;&gt;Linkedin&lt;/a&gt;]&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/chameleon-llm/chameleon-llm.github.io/main/images/logo.png&#34; width=&#34;10%&#34;&gt; &lt;br&gt; Tentative logo for &lt;b&gt;Chameleon&lt;/b&gt;. &lt;/p&gt; &#xA;&lt;h2&gt;ğŸ’¥ News ğŸ’¥&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.21]&lt;/strong&gt; Our work is the trending project on &lt;a href=&#34;https://trends.vercel.app&#34;&gt;https://trends.vercel.app&lt;/a&gt;. [&lt;a href=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/trend.png&#34;&gt;Link&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.20]&lt;/strong&gt; Huge thanks to &lt;a href=&#34;https://twitter.com/johnjnay/status/1649036276627132418&#34;&gt;John Nay&lt;/a&gt; for sharing our work on &lt;a href=&#34;https://twitter.com/johnjnay/status/1649036276627132418&#34;&gt;Twitter&lt;/a&gt;!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.19]&lt;/strong&gt; Our research is now listed on &lt;a href=&#34;https://paperswithcode.com/paper/chameleon-plug-and-play-compositional&#34;&gt;Papers with Code&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.19]&lt;/strong&gt; We appreciate &lt;a href=&#34;https://twitter.com/arankomatsuzaki/status/1648848332977221632&#34;&gt;Aran Komatsuzaki&lt;/a&gt; for featuring our work on &lt;a href=&#34;https://twitter.com/arankomatsuzaki/status/1648848332977221632&#34;&gt;Twitter&lt;/a&gt; in a timely manner!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.19]&lt;/strong&gt; Special thanks to &lt;a href=&#34;https://twitter.com/_akhaliq/status/1648851856930533378&#34;&gt;@_akhaliq&lt;/a&gt; for promptly sharing our work on &lt;a href=&#34;https://twitter.com/_akhaliq/status/1648851856930533378&#34;&gt;Twitter&lt;/a&gt;!&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.19]&lt;/strong&gt; Visit our project&#39;s homepage at &lt;a href=&#34;https://chameleon-llm.github.io/&#34;&gt;Chameleon-LLM&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;[2023.04.19]&lt;/strong&gt; Our paper is now accessible at &lt;a href=&#34;https://arxiv.org/abs/2304.09842&#34;&gt;https://arxiv.org/abs/2304.09842&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ¦&lt;/span&gt; About Chameleon&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chameleon&lt;/strong&gt; is a plug-and-play compositional reasoning framework that augments LLMs with various types of tools. &lt;strong&gt;Chameleon&lt;/strong&gt; synthesizes programs to compose various tools, including LLM models, off-the-shelf vision models, web search engines, Python functions, and rule-based modules tailored to user interests. Built on top of an LLM as a natural language planner, &lt;strong&gt;Chameleon&lt;/strong&gt; infers the appropriate sequence of tools to compose and execute in order to generate a final response.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/showcase_scienceqa.png&#34; alt=&#34;showcase_scienceqa&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We showcase the adaptability and effectiveness of &lt;strong&gt;Chameleon&lt;/strong&gt; on two tasks: &lt;a href=&#34;https://scienceqa.github.io/&#34;&gt;ScienceQA&lt;/a&gt; and &lt;a href=&#34;https://promptpg.github.io/&#34;&gt;TabMWP&lt;/a&gt;. Notably, &lt;strong&gt;Chameleon&lt;/strong&gt; with GPT-4 achieves an 86.54% accuracy on ScienceQA, significantly improving upon the best published few-shot model by 11.37%; using GPT-4 as the underlying LLM, &lt;strong&gt;Chameleon&lt;/strong&gt; achieves a 17.8% increase over the state-of-the-art model, leading to a 98.78% overall accuracy on TabMWP. Further studies suggest that using GPT-4 as a planner exhibits more consistent and rational tool selection and is able to infer potential constraints given the instructions, compared to other LLMs like ChatGPT.&lt;/p&gt; &#xA;&lt;p&gt;For more details, you can find our project page &lt;a href=&#34;https://chameleon-llm.github.io/&#34;&gt;here&lt;/a&gt; and our paper &lt;a href=&#34;https://arxiv.org/pdf/2304.09842.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;â­&lt;/span&gt; Star History&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://star-history.com/#lupantech/chameleon-llm&amp;amp;Date&#34;&gt;&lt;img src=&#34;https://api.star-history.com/svg?repos=lupantech/chameleon-llm&amp;amp;type=Date&#34; alt=&#34;Star History Chart&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ™ Requirements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;OpenAI API key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api.&#34;&gt;Bing Search API&lt;/a&gt; (If you want to enable the bing search module but the module is optional)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Install all required python dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python==3.8.10&#xA;huggingface-hub&#xA;numpy==1.23.2&#xA;openai==0.23.0&#xA;pandas==1.4.3&#xA;transformers==4.21.1&#xA;requests==2.28.1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install all required python dependencies (you can skip this step if you have set up the dependencies before and the verisons are not strictly required):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;âš ï¸ Configuration âš ï¸&lt;/h2&gt; &#xA;&lt;h3&gt;OpenAI API Key&lt;/h3&gt; &#xA;&lt;p&gt;Obtain your OpenAI API key from: &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;https://platform.openai.com/account/api-keys&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To use OpenAI API key for &lt;strong&gt;Chameleon&lt;/strong&gt;, you &lt;strong&gt;NEED&lt;/strong&gt; to have billing set up (AKA paid account).&lt;/p&gt; &#xA;&lt;p&gt;You can set up paid account at &lt;a href=&#34;https://platform.openai.com/account/billing/overview&#34;&gt;https://platform.openai.com/account/billing/overview&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Bing Search API Key (Optional)&lt;/h3&gt; &#xA;&lt;p&gt;Obtain your Bing Search API key from: &lt;a href=&#34;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api&#34;&gt;https://www.microsoft.com/en-us/bing/apis/bing-web-search-api&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Bing Search API key is &lt;strong&gt;optional&lt;/strong&gt;. Failure to set up this key will lead to a slight performance drop on the ScienceQA task.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ› &lt;/span&gt; Module Inventory&lt;/h2&gt; &#xA;&lt;h3&gt;Different Tools in Chameleon&lt;/h3&gt; &#xA;&lt;p&gt;Different types of tools in our module inventory:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/tools.png&#34; alt=&#34;tools&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Tool Subset&lt;/h3&gt; &#xA;&lt;p&gt;Tools used on ScienceQA and TabMWP, respectively. The reusable tools in two tasks are highlighted in green:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/tools_task.png&#34; alt=&#34;tools_task&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ¤– Run Chameleon on ScienceQA&lt;/h2&gt; &#xA;&lt;p&gt;Science Question Answering (&lt;a href=&#34;https://scienceqa.github.io/&#34;&gt;ScienceQA&lt;/a&gt;) is a multi-modal question-answering benchmark covering a wide range of scientific topics over diverse contexts. The ScienceQA dataset is provided in &lt;a href=&#34;https://github.com/lupantech/chameleon-llm/tree/main/data/scienceqa&#34;&gt;&lt;code&gt;data/scienceqa&lt;/code&gt;&lt;/a&gt;. For more details, you can explore the datatset and check out the &lt;a href=&#34;https://scienceqa.github.io/explore.html&#34;&gt;Explore&lt;/a&gt; page and &lt;a href=&#34;https://scienceqa.github.io/visualize.html&#34;&gt;Visualize&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;For the current version, the results for the &lt;code&gt;Image Captioner&lt;/code&gt; and &lt;code&gt;Text Detector&lt;/code&gt; are off-the-shelf and stored in &lt;code&gt;data/scienceqa/captions.json&lt;/code&gt; and &lt;code&gt;data/scienceqa/ocrs.json&lt;/code&gt;, respectively. The live calling these two modules are coming soon!&lt;/p&gt; &#xA;&lt;p&gt;To run &lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd run_scienceqa&#xA;&#xA;python run.py \&#xA;--model chameleon \&#xA;--label chameleon_gpt4 \&#xA;--policy_engine gpt-4 \&#xA;--kr_engine gpt-4 \&#xA;--qg_engine gpt-4 \&#xA;--sg_engine gpt-4 \&#xA;--test_split test \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will generate the predictions and save the results at &lt;code&gt;results/scienceqa/chameleon_gpt4_test.json&lt;/code&gt;, &lt;code&gt;results/scienceqa/chameleon_gpt4_test_cache.jsonl&lt;/code&gt;, and &lt;code&gt;results/scienceqa/chameleon_gpt4_test_cache.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We can get the accuracy metrics on average and across different question classes by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python evaluate.py \&#xA;--data_file ../data/scienceqa/problems.json \&#xA;--result_root ../results/scienceqa \&#xA;--result_files chameleon_chatgpt_test_cache.jsonl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run &lt;strong&gt;Chameleon&lt;/strong&gt; (ChatGPT):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model chameleon \&#xA;--label chameleon_gpt4 \&#xA;--policy_engine gpt-3.5-turbo \&#xA;--kr_engine gpt-3.5-turbo \&#xA;--qg_engine gpt-3.5-turbo \&#xA;--sg_engine gpt-3.5-turbo \&#xA;--test_split test \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our &lt;strong&gt;Chameleon&lt;/strong&gt; is a generalized form of the &lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;CoT (chain-of-thought)&lt;/a&gt; method, where the generated program is a sequence of &lt;code&gt;Solution Generator&lt;/code&gt; and &lt;code&gt;Answer Generator&lt;/code&gt;. By passing &lt;code&gt;--model&lt;/code&gt; as &lt;code&gt;cot&lt;/code&gt;, &lt;code&gt;modules&lt;/code&gt; is set as &lt;code&gt;[&#34;solution_generator&#34;, &#34;answer_generator&#34;]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To run CoT (chain-of-thought prompted) GPT-4:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model cot \&#xA;--label cot_gpt4 \&#xA;--sg_engine gpt-4 \&#xA;--test_split test \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run CoT (chain-of-thought prompted) ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model cot \&#xA;--label cot_chatgpt \&#xA;--sg_engine gpt-4 \&#xA;--test_split test \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¤– Run Chameleon on TabMWP&lt;/h2&gt; &#xA;&lt;p&gt;The TabMWP dataset contains 38,431 tabular math word problems. Each question in TabMWP is aligned with a tabular context, which is presented as an image, semi-structured text, and a structured table. The TabMWP dataset is provided in &lt;a href=&#34;https://github.com/lupantech/PromptPG/raw/main/data/tabmwp&#34;&gt;&lt;code&gt;data/tabmwp&lt;/code&gt;&lt;/a&gt;. For more details, you can explore the datatset and check out the &lt;a href=&#34;https://promptpg.github.io/explore.html&#34;&gt;Explore&lt;/a&gt; page and &lt;a href=&#34;https://promptpg.github.io/visualize.html&#34;&gt;Visualize&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;p&gt;To run &lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd run_tabmwp&#xA;&#xA;python run.py \&#xA;--model chameleon \&#xA;--label chameleon_gpt4 \&#xA;--test_split test \&#xA;--policy_engine gpt-4 \&#xA;--rl_engine gpt-4 \&#xA;--cl_engine gpt-4 \&#xA;--tv_engine gpt-4 \&#xA;--kr_engine gpt-4 \&#xA;--sg_engine gpt-4 \&#xA;--pg_engine gpt-4 \&#xA;--test_number -1 \&#xA;--rl_cell_threshold 18 \&#xA;--cl_cell_threshold 18&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;It will generate the predictions and save the results at &lt;code&gt;results/tabmwp/chameleon_gpt4_test.json&lt;/code&gt;, &lt;code&gt;results/tabmwp/chameleon_gpt4_test_cache.jsonl&lt;/code&gt;, and &lt;code&gt;results/tabmwp/chameleon_gpt4_test_cache.json&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We can get the accuracy metrics on average and across different question classes by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python evaluate.py \&#xA;--data_file ../data/tabmwp/problems_test.json \&#xA;--result_root ../results/tabmwp \&#xA;--result_files chameleon_chatgpt_test_cache.jsonl&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run &lt;strong&gt;Chameleon&lt;/strong&gt; (ChatGPT):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model chameleon \&#xA;--label chameleon_chatgpt \&#xA;--test_split test \&#xA;--policy_engine gpt-3.5-turbo \&#xA;--rl_engine gpt-3.5-turbo \&#xA;--cl_engine gpt-3.5-turbo \&#xA;--tv_engine gpt-3.5-turbo \&#xA;--kr_engine gpt-3.5-turbo \&#xA;--sg_engine gpt-3.5-turbo \&#xA;--pg_engine gpt-3.5-turbo \&#xA;--test_number -1 \&#xA;--rl_cell_threshold 18 \&#xA;--cl_cell_threshold 18&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run CoT (chain-of-thought prompted) GPT-4:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model cot \&#xA;--label cot_gpt4 \&#xA;--test_split test \&#xA;--sg_engine gpt-4 \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run CoT (chain-of-thought prompted) ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model cot \&#xA;--label cot_chatgpt \&#xA;--test_split test \&#xA;--sg_engine gpt-3.5-turbo \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Our &lt;strong&gt;Chameleon&lt;/strong&gt; is a generalized form of the &lt;a href=&#34;https://arxiv.org/abs/2211.12588&#34;&gt;PoT (program-of-thought)&lt;/a&gt; method, where the generated program is a sequence of &lt;code&gt;Program Generator&lt;/code&gt;, &lt;code&gt;Program Executor&lt;/code&gt;, and &lt;code&gt;Answer Generator&lt;/code&gt;. By passing &lt;code&gt;--model&lt;/code&gt; as &lt;code&gt;pot&lt;/code&gt;, &lt;code&gt;modules&lt;/code&gt; is set as &lt;code&gt;[&#34;program_generator&#34;, &#34;program_executor&#34;, &#34;answer_generator&#34;]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To run PoT (program-of-thought prompted) GPT-4:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model pot \&#xA;--label pot_gpt4 \&#xA;--test_split test \&#xA;--pg_engine gpt-4 \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To run PoT (program-of-thought prompted) ChatGPT:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python run.py \&#xA;--model pot \&#xA;--label pot_chatgpt \&#xA;--test_split test \&#xA;--pg_engine gpt-3.5-turbo \&#xA;--test_number -1&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ˜ˆ More Examples&lt;/h2&gt; &#xA;&lt;h3&gt;More examples on ScienceQA dataset&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/showcase_scienceqa_more.png&#34; alt=&#34;showcase_scienceqa_more&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4) is able to adapt to different input queries by generating programs that compose various tools and executing them sequentially to obtain the correct answers.&lt;/p&gt; &#xA;&lt;p&gt;For instance, the query above asks, â€œWhich animalâ€™s skin is adapted for survival in cold places?â€, which involves scientific terminology related to animal survival. Consequently, the planner decides to rely on the &lt;em&gt;Bing search&lt;/em&gt; engine for domain-specific knowledge, benefiting from the numerous online resources available.&lt;/p&gt; &#xA;&lt;h3&gt;More examples on TabMWP&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/showcase_tabmwp_long.png&#34; alt=&#34;showcase_tabmwp_long&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The adaptability and versatility of our &lt;strong&gt;Chameleon&lt;/strong&gt; for various queries are also observed on TabMWP, as illustrated in the examples in the figure above.&lt;/p&gt; &#xA;&lt;p&gt;The first example involves mathematical reasoning on a tax form. &lt;strong&gt;Chameleon&lt;/strong&gt; (1) calls the knowledge retrieval model to recall basic knowledge that assists in understanding such domain-specific tables, (2) describes the table in a more readable natural language format, and (3) finally relies on program-aided tools to perform precise computations.&lt;/p&gt; &#xA;&lt;p&gt;In the second example, the system generates Python code that closely aligns with the background knowledge provided by the knowledge retrieval model.&lt;/p&gt; &#xA;&lt;p&gt;The third example requires the system to locate the cell in a large tabular context given the input query. &lt;strong&gt;Chameleon&lt;/strong&gt; calls the row lookup model to help accurately locate the relevant rows and generate the language solution via an LLM model, instead of relying on program-based tools.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ“ˆ&lt;/span&gt; How Good is Chameleon?&lt;/h2&gt; &#xA;&lt;p&gt;Significant improvements are observed for &lt;strong&gt;Chameleon&lt;/strong&gt; over both fine-tuned models and few-shot prompted GPT-4/ChatGPT:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/results.png&#34; alt=&#34;results&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To visualize the predictions made by &lt;strong&gt;Chameleon&lt;/strong&gt;, simply execute the Jupyter Notebook corresponding to your specific task: &lt;code&gt;notebooks/results_viewer_[TASK].ipynb&lt;/code&gt;. This will provide an interactive and user-friendly way to explore the results generated by the model. Alternatively, explore our &lt;a href=&#34;https://chameleon-llm.github.io/&#34;&gt;project page&lt;/a&gt; for more information and options.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ°&lt;/span&gt; What Plans Are Chameleon Learning?&lt;/h2&gt; &#xA;&lt;h3&gt;Tool Use&lt;/h3&gt; &#xA;&lt;p&gt;Tools called in the generated programs from &lt;strong&gt;Chameleon&lt;/strong&gt; (ChatGPT) and &lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4) on ScienceQA:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/tool_call_scienceqa.png&#34; alt=&#34;tool_call_scienceqa&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Tools called in the generated programs from Chameleon (ChatGPT) and Chameleon (GPT-4) on TabMWP:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/tool_call_tabmwp.png&#34; alt=&#34;tool_call_tabmwp&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Transition Graph&lt;/h3&gt; &#xA;&lt;p&gt;Execute &lt;code&gt;notebooks/transition_[TASK]_[Model]_Engine.ipynb&lt;/code&gt; to visualize the module transition graph for programs generated on the test set.&lt;/p&gt; &#xA;&lt;p&gt;Transitions between modules in programs generated by &lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4) on ScienceQA. START is the start symbol, END is a terminal symbol and the others are non-terminal symbols.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/transition_scienceqa_gpt4.png&#34; width=&#34;45%&#34; height=&#34;45%&#34;&gt; &#xA;&lt;p&gt;Transitions between modules in programs generated by &lt;strong&gt;Chameleon&lt;/strong&gt; (GPT-4) on TabMWPQA. START is the start symbol, END is a terminal symbol and the others are non-terminal symbols.&lt;/p&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/lupantech/chameleon-llm/main/assets/transition_tabmwp_gpt4.png&#34; width=&#34;55%&#34; height=&#34;55%&#34;&gt; &#xA;&lt;h2&gt;&lt;span&gt;ğŸ˜¸&lt;/span&gt; Want to Develop A New Task?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Construct the module inventory&lt;/strong&gt;: Create prompts for LLM-based models within the &lt;code&gt;demos&lt;/code&gt; directory. Define the input, execution, and output for each module in &lt;code&gt;model.py&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Develop the LLM planner&lt;/strong&gt;: Provide a comprehensive description of the module inventory and include a few examples that demonstrate how to map queries to the target program.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Implement the data loader and evaluation method&lt;/strong&gt;: Define the data loader within &lt;code&gt;model.py&lt;/code&gt;. To modify the evaluation method, update the corresponding section in &lt;code&gt;main.py&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Enjoy the process&lt;/strong&gt;: With the groundwork in place, it&#39;s time to have fun and dive into the task at hand!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;span&gt;â˜•&lt;/span&gt; Stay Connected!&lt;/h2&gt; &#xA;&lt;p&gt;Fantastic! I&#39;m always open to engaging discussions, collaborations, or even just sharing a virtual coffee. To get in touch, visit &lt;a href=&#34;https://lupantech.github.io/&#34;&gt;Pan Lu&lt;/a&gt;&#39;s homepage for contact information.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;âœ…&lt;/span&gt; Cite&lt;/h2&gt; &#xA;&lt;p&gt;If you find &lt;strong&gt;Chameleon&lt;/strong&gt; useful for your your research and applications, please kindly cite using this BibTeX:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-latex&#34;&gt;@article{lu2023chameleon,&#xA;  title={Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},&#xA;  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},&#xA;  journal={arXiv preprint arXiv:2304.09842},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>datawhalechina/hugging-llm</title>
    <updated>2023-04-23T01:38:29Z</updated>
    <id>tag:github.com,2023-04-23:/datawhalechina/hugging-llm</id>
    <link href="https://github.com/datawhalechina/hugging-llm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;HuggingLLM, Hugging Future.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;HuggingLLM&lt;/h1&gt; &#xA;&lt;p&gt;éšç€ChatGPTçš„çˆ†ç«ï¼Œå…¶èƒŒåå…¶å®è•´å«ç€ä¸€ä¸ªåŸºæœ¬äº‹å®ï¼šAIèƒ½åŠ›å¾—åˆ°äº†æå¤§çªç ´â€”â€”å¤§æ¨¡å‹çš„èƒ½åŠ›æœ‰ç›®å…±ç¹ï¼Œæœªæ¥åªä¼šå˜å¾—æ›´å¼ºã€‚è¿™ä¸–ç•Œå”¯ä¸€ä¸å˜çš„å°±æ˜¯å˜ï¼Œé€‚åº”å˜åŒ–ã€æ‹¥æŠ±å˜åŒ–ã€å–œæ¬¢å˜åŒ–ï¼Œå¤©è¡Œå¥å›å­ä»¥è‡ªå¼ºä¸æ¯ã€‚æˆ‘ä»¬ç›¸ä¿¡æœªæ¥ä¼šæœ‰è¶Šæ¥è¶Šå¤šçš„å¤§æ¨¡å‹å‡ºç°ï¼ŒAIæ­£åœ¨é€æ¸å¹³æ°‘åŒ–ï¼Œå°†æ¥æ¯ä¸ªäººéƒ½å¯ä»¥åˆ©ç”¨å¤§æ¨¡å‹è½»æ¾åœ°åšå‡ºè‡ªå·±çš„AIäº§å“ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬æŠŠé¡¹ç›®èµ·åä¸ºHuggingLLMï¼Œæˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬æ­£åœ¨ç»å†ä¸€ä¸ªä¼Ÿå¤§çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ç›¸ä¿¡è¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ¯ä¸ªäººå…¨èº«å¿ƒæ‹¥æŠ±çš„æ—¶ä»£ï¼Œæˆ‘ä»¬æ›´åŠ ç›¸ä¿¡è¿™ä¸ªä¸–ç•Œå¿…å°†ä¼šå› æ­¤è€Œå˜å¾—æ›´åŠ ç¾å¥½ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å…³äºé¡¹ç›®&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;é¡¹ç›®ç®€ä»‹&lt;/strong&gt;ï¼šä»‹ç» ChatGPT åŸç†ã€ä½¿ç”¨å’Œåº”ç”¨ï¼Œé™ä½ä½¿ç”¨é—¨æ§›ï¼Œè®©æ›´å¤šæ„Ÿå…´è¶£çš„éNLPæˆ–ç®—æ³•ä¸“ä¸šäººå£«èƒ½å¤Ÿæ— éšœç¢ä½¿ç”¨LLMåˆ›é€ ä»·å€¼ã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ç«‹é¡¹ç†ç”±&lt;/strong&gt;ï¼šChatGPTæ”¹å˜äº†NLPè¡Œä¸šï¼Œç”šè‡³æ­£åœ¨æ”¹å˜æ•´ä¸ªäº§ä¸šã€‚æˆ‘ä»¬æƒ³å€Ÿè¿™ä¸ªé¡¹ç›®å°†ChatGPTä»‹ç»ç»™æ›´å¤šçš„äººï¼Œå°¤å…¶æ˜¯å¯¹æ­¤æ„Ÿå…´è¶£ã€æƒ³åˆ©ç”¨ç›¸å…³æŠ€æœ¯åšä¸€äº›æ–°äº§å“æˆ–åº”ç”¨çš„å­¦ä¹ è€…ï¼Œå°¤å…¶æ˜¯éæœ¬ä¸“ä¸šäººå‘˜ã€‚å¸Œæœ›æ–°çš„æŠ€æœ¯çªç ´èƒ½å¤Ÿæ›´å¤šåœ°æ”¹å–„æˆ‘ä»¬æ‰€å¤„çš„ä¸–ç•Œã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;é¡¹ç›®å—ä¼—&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;é¡¹ç›®é€‚åˆä»¥ä¸‹äººå‘˜ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;å¯¹ChatGPTæ„Ÿå…´è¶£ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;å¸Œæœ›åœ¨å®é™…ä¸­è¿ç”¨è¯¥æŠ€æœ¯åˆ›é€ æä¾›æ–°çš„æœåŠ¡æˆ–è§£å†³å·²æœ‰é—®é¢˜ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;æœ‰ä¸€å®šç¼–ç¨‹åŸºç¡€ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ä¸é€‚åˆä»¥ä¸‹éœ€æ±‚äººå‘˜ï¼š &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ç ”ç©¶å…¶åº•å±‚ç®—æ³•ç»†èŠ‚ï¼Œæ¯”å¦‚PPOæ€ä¹ˆå®ç°çš„ï¼Œèƒ½ä¸èƒ½æ¢æˆNLPOæˆ–ILQLï¼Œæ•ˆæœå¦‚ä½•ç­‰ã€‚&lt;/li&gt; &#xA;   &lt;li&gt;è‡ªå·±ä»å¤´åˆ°å°¾ç ”å‘ä¸€ä¸ª ChatGPTã€‚&lt;/li&gt; &#xA;   &lt;li&gt;å¯¹å…¶ä»–æŠ€æœ¯ç»†èŠ‚æ„Ÿå…´è¶£ã€‚&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å¦å¤–ï¼Œè¦è¯´æ˜çš„æ˜¯ï¼Œæœ¬é¡¹ç›®å¹¶ä¸æ˜¯ç‰¹åˆ«é’ˆå¯¹ç®—æ³•æˆ–NLPå·¥ç¨‹å¸ˆç­‰ä¸šå†…ä»ä¸šäººå‘˜è®¾è®¡çš„ï¼Œå½“ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡æœ¬é¡¹ç›®è·å¾—ä¸€å®šå—ç›Šã€‚&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;é¡¹ç›®äº®ç‚¹&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;èšç„¦äºå¦‚ä½•ä½¿ç”¨&lt;strong&gt;ChatGPTç›¸å…³API&lt;/strong&gt;åˆ›é€ æ–°çš„åŠŸèƒ½å’Œåº”ç”¨ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¯¹ç›¸å…³ä»»åŠ¡æœ‰è¯¦ç»†çš„èƒŒæ™¯å’Œç³»ç»Ÿè®¾è®¡ä»‹ç»ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æä¾›ç¤ºä¾‹ä»£ç å’Œå®ç°æµç¨‹ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å†…å®¹å¤§çº²&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;æœ¬æ•™ç¨‹å†…å®¹å½¼æ­¤ä¹‹é—´ç›¸å¯¹ç‹¬ç«‹ï¼Œå¤§å®¶å¯ä»¥é’ˆå¯¹ä»»ä¸€æ„Ÿå…´è¶£å†…å®¹é˜…è¯»æˆ–ä¸Šæ‰‹ï¼Œä¹Ÿå¯ä»å¤´åˆ°å°¾å­¦ä¹ ã€‚&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ChatGPT åŸºç¡€ç§‘æ™® @é•¿ç´ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;LM&lt;/li&gt; &#xA;   &lt;li&gt;Transformer&lt;/li&gt; &#xA;   &lt;li&gt;GPT&lt;/li&gt; &#xA;   &lt;li&gt;RLHF&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT ä½¿ç”¨æŒ‡å—ï¼šç›¸ä¼¼åŒ¹é… @é•¿ç´ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Embedding åŸºç¡€&lt;/li&gt; &#xA;   &lt;li&gt;API ä½¿ç”¨&lt;/li&gt; &#xA;   &lt;li&gt;QA ä»»åŠ¡&lt;/li&gt; &#xA;   &lt;li&gt;èšç±»ä»»åŠ¡&lt;/li&gt; &#xA;   &lt;li&gt;æ¨èåº”ç”¨&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT ä½¿ç”¨æŒ‡å—ï¼šå¥è¯åˆ†ç±» @é•¿ç´ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;NLU åŸºç¡€&lt;/li&gt; &#xA;   &lt;li&gt;API ä½¿ç”¨&lt;/li&gt; &#xA;   &lt;li&gt;æ–‡æ¡£é—®ç­”ä»»åŠ¡&lt;/li&gt; &#xA;   &lt;li&gt;åˆ†ç±»ä¸å®ä½“è¯†åˆ«å¾®è°ƒä»»åŠ¡&lt;/li&gt; &#xA;   &lt;li&gt;æ™ºèƒ½å¯¹è¯åº”ç”¨&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT ä½¿ç”¨æŒ‡å—ï¼šç¼–è¾‘ç”Ÿæˆ @ç‰ç³ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;æ–‡æœ¬æ‘˜è¦&lt;/li&gt; &#xA;   &lt;li&gt;æ–‡æœ¬çº é”™&lt;/li&gt; &#xA;   &lt;li&gt;æœºå™¨ç¿»è¯‘&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT ä½¿ç”¨æŒ‡å—ï¼šæ–‡æœ¬æ¨ç† @åæŒ¥ &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;ä»€ä¹ˆæ˜¯æ¨ç†&lt;/li&gt; &#xA;   &lt;li&gt;å¯¼å…¥ChatGPT&lt;/li&gt; &#xA;   &lt;li&gt;æµ‹è¯•ChatGPTæ¨ç†èƒ½åŠ›&lt;/li&gt; &#xA;   &lt;li&gt;è°ƒç”¨ChatGPTæ¨ç†èƒ½åŠ›&lt;/li&gt; &#xA;   &lt;li&gt;ChatGPTä»¥åŠGPT-4çš„æ¨ç†èƒ½åŠ›&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT å±€é™ä¸è¶³ @Carles &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;äº‹å®é”™è¯¯&lt;/li&gt; &#xA;   &lt;li&gt;å®æ—¶æ›´æ–°&lt;/li&gt; &#xA;   &lt;li&gt;èµ„æºè€—è´¹&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT å•†ä¸šåº”ç”¨ @Jason &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;èƒŒæ™¯&lt;/li&gt; &#xA;   &lt;li&gt;å·¥å…·åº”ç”¨ï¼šæœç´¢ã€åŠå…¬ã€æ•™è‚²&lt;/li&gt; &#xA;   &lt;li&gt;è¡Œä¸šåº”ç”¨ï¼šæ¸¸æˆã€éŸ³ä¹ã€é›¶å”®ç”µå•†ã€å¹¿å‘Šè¥é”€ã€åª’ä½“æ–°é—»ã€é‡‘èã€åŒ»ç–—ã€è®¾è®¡ã€å½±è§†ã€å·¥ä¸š&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;å¦‚ä½•å­¦ä¹ &lt;/h2&gt; &#xA;&lt;h3&gt;å­¦ä¹ æŒ‡å—&lt;/h3&gt; &#xA;&lt;p&gt;è¦å­¦ä¹ æœ¬æ•™ç¨‹å†…å®¹ï¼ˆä¸»è¦æ˜¯å››ä¸ªä½¿ç”¨æŒ‡å—ï¼‰ï¼Œéœ€å…·å¤‡ä»¥ä¸‹æ¡ä»¶ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;èƒ½å¤Ÿæ­£å¸¸ä½¿ç”¨OpenAIçš„APIï¼Œèƒ½å¤Ÿè°ƒç”¨æ¨¡å‹ï¼šgpt-3.5-turboã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¯ä»¥æ²¡æœ‰ç®—æ³•ç»éªŒï¼Œä½†åº”å…·å¤‡ä¸€å®šçš„ç¼–ç¨‹åŸºç¡€æˆ–å®é™…é¡¹ç›®ç»å†ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å­¦ä¹ æœŸé—´æœ‰è¶³å¤Ÿçš„æ—¶é—´ä¿è¯ï¼Œã€Šä½¿ç”¨æŒ‡å—ã€‹å­¦ä¹ å‘¨æœŸä¸º2-3å¤©ï¼Œé™¤ã€Šæ¨ç†Reasoningã€‹å¤–ï¼Œå…¶ä»–å‡éœ€è¦6-8å°æ—¶ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å­¦ä¹ å®Œæˆåï¼Œéœ€è¦æäº¤ä¸€ä¸ªå¤§ä½œä¸šï¼Œæ•´ä¸ªå­¦ä¹ æœŸé—´å°±ä¸€ä¸ªä»»åŠ¡ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ä»¥å…¶ä¸­ä»»ä¸€æ–¹å‘ä¸ºä¾‹ï¼šæè¿°åº”ç”¨å’Œè®¾è®¡æµç¨‹ï¼Œå®ç°åº”ç”¨ç›¸å…³åŠŸèƒ½ï¼Œå®Œæˆä¸€ä¸ªåº”ç”¨æˆ–Demoç¨‹åºã€‚&lt;/li&gt; &#xA; &lt;li&gt;æ–¹å‘åŒ…æ‹¬æ‰€æœ‰å†…å®¹ï¼Œæ¯”å¦‚ï¼šä¸€ä¸ªæ–°é—»æ¨èé˜…è¯»å™¨ã€ä¸€ä¸ªå¤šè½®çš„å®¢æœæœºå™¨äººã€Docé—®ç­”æœºå™¨äººã€æ¨¡å‹è¾“å‡ºå†…å®¹æ£€æµ‹å™¨ç­‰ç­‰ï¼Œé¼“åŠ±å¤§å®¶ååº”ç”¨æ–¹å‘ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;å­¦ä¹ è¯´æ˜&lt;/h3&gt; &#xA;&lt;p&gt;è¯·å­¦ä¹ è€…åŠ¡å¿…æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å­¦ä¹ æœ¬æ•™ç¨‹å¹¶ä¸èƒ½è®©ä½ æˆä¸ºç®—æ³•å·¥ç¨‹å¸ˆï¼Œå¦‚æœèƒ½æ¿€å‘èµ·ä½ çš„å…´è¶£ï¼Œæˆ‘ä»¬éå¸¸æ¬¢è¿ä½ å‚ä¸å­¦ä¹ DataWhaleæ›´å¤šç®—æ³•ç±»å¼€æºæ•™ç¨‹ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åœ¨å­¦ä¹ äº†æ•™ç¨‹ä¸­çš„ä¸€äº›çŸ¥è¯†å’Œä»»åŠ¡åï¼Œåƒä¸‡ä¸è¦è®¤ä¸ºè¿™äº›ä¸œè¥¿å®é™…ä¸Šå°±æ˜¯çœ‹åˆ°é‚£ä¹ˆç®€å•ã€‚ä¸€æ–¹é¢å®é™…æ“ä½œèµ·æ¥è¿˜æ˜¯ä¼šæœ‰å¾ˆå¤šé—®é¢˜ï¼Œå¦ä¸€æ–¹é¢æ¯ä¸ªçŸ¥è¯†å…¶å®æœ‰éå¸¸å¤šçš„ç»†èŠ‚ï¼Œè¿™åœ¨æœ¬æ•™ç¨‹ä¸­æ˜¯æ— æ³•æ¶‰åŠçš„ã€‚è¯·æŒç»­å­¦ä¹ ã€å¹¶å§‹ç»ˆå¯¹çŸ¥è¯†ä¿æŒæ•¬ç•ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æœ¬æ•™ç¨‹ä¸»è¦æ˜¯è´Ÿè´£å¼•å¯¼å…¥é—¨çš„ï¼Œé¼“åŠ±å¤§å®¶åœ¨äº†è§£äº†ç›¸å…³çŸ¥è¯†åï¼Œæ ¹æ®å®é™…æƒ…å†µæˆ–è‡ªå·±æ„æ„¿å¤§èƒ†å®è·µã€‚å®è·µå‡ºçœŸçŸ¥ï¼Œè„‘å­æƒ³ã€å˜´è¯´å’Œäº²è‡ªå¹²æ˜¯å®Œå…¨ä¸ä¸€æ ·çš„ã€‚&lt;/li&gt; &#xA; &lt;li&gt;ç”±äºåˆ›ä½œå›¢é˜Ÿæ°´å¹³å’Œç²¾åŠ›æœ‰é™ï¼Œéš¾å…ä¼šæœ‰ç–æ¼ï¼Œè¯·ä¸åæŒ‡æ­£ã€‚&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;æœ€åï¼Œç¥æ„¿å¤§å®¶éƒ½èƒ½å­¦æœ‰æ‰€å¾—ï¼ŒæœŸæœ›å¤§å®¶æœªæ¥èƒ½åšå‡ºä¸¾ä¸–ç©ç›®çš„äº§å“å’Œåº”ç”¨ã€‚&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; â€”â€”HuggingLLMå¼€æºé¡¹ç›®å…¨ä½“æˆå‘˜ &lt;/p&gt; &#xA;&lt;h2&gt;è‡´è°¢&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;æ ¸å¿ƒè´¡çŒ®è€…&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yam.gift/&#34;&gt;é•¿ç´-é¡¹ç›®è´Ÿè´£äºº&lt;/a&gt;ï¼ˆDataWhaleæˆå‘˜-AIç®—æ³•å·¥ç¨‹å¸ˆï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Sophia-Huang&#34;&gt;ç‰ç³&lt;/a&gt;ï¼ˆå†…å®¹åˆ›ä½œè€…-DataWhaleæˆå‘˜ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HhuiYi&#34;&gt;åæŒ¥&lt;/a&gt;ï¼ˆå†…å®¹åˆ›ä½œè€…-DataWhaleæˆå‘˜ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/AmourWaltz&#34;&gt;Carles&lt;/a&gt;ï¼ˆå†…å®¹åˆ›ä½œè€…ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/HeteroCat&#34;&gt;Jason&lt;/a&gt;ï¼ˆå†…å®¹åˆ›ä½œè€…ï¼‰&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Relph1119&#34;&gt;èƒ¡é”é”‹&lt;/a&gt;ï¼ˆDataWhaleæˆå‘˜-åä¸œäº¤é€šå¤§å­¦-ç³»ç»Ÿæ¶æ„è®¾è®¡å¸ˆï¼‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;å…¶ä»–&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ç‰¹åˆ«æ„Ÿè°¢ &lt;a href=&#34;https://github.com/Sm1les&#34;&gt;@Sm1les&lt;/a&gt;ã€&lt;a href=&#34;https://github.com/LSGOMYP&#34;&gt;@LSGOMYP&lt;/a&gt; å¯¹æœ¬é¡¹ç›®çš„å¸®åŠ©ä¸æ”¯æŒï¼›&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;å…³æ³¨æˆ‘ä»¬&lt;/h2&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;æ‰«æä¸‹æ–¹äºŒç»´ç å…³æ³¨å…¬ä¼—å·ï¼šDatawhale&lt;/p&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/datawhalechina/hugging-llm/main/resources/qrcode.jpeg&#34; width=&#34;180&#34; height=&#34;180&#34;&gt; &#xA;&lt;/div&gt; â€ƒâ€ƒDatawhaleï¼Œä¸€ä¸ªä¸“æ³¨äºAIé¢†åŸŸçš„å­¦ä¹ åœˆå­ã€‚åˆè¡·æ˜¯for the learnerï¼Œå’Œå­¦ä¹ è€…ä¸€èµ·æˆé•¿ã€‚ç›®å‰åŠ å…¥å­¦ä¹ ç¤¾ç¾¤çš„äººæ•°å·²ç»æ•°åƒäººï¼Œç»„ç»‡äº†æœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ ï¼Œæ•°æ®åˆ†æï¼Œæ•°æ®æŒ–æ˜ï¼Œçˆ¬è™«ï¼Œç¼–ç¨‹ï¼Œç»Ÿè®¡å­¦ï¼ŒMysqlï¼Œæ•°æ®ç«èµ›ç­‰å¤šä¸ªé¢†åŸŸçš„å†…å®¹å­¦ä¹ ï¼Œå¾®ä¿¡æœç´¢å…¬ä¼—å·Datawhaleå¯ä»¥åŠ å…¥æˆ‘ä»¬ã€‚ &#xA;&lt;h2&gt;LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;çŸ¥è¯†å…±äº«è®¸å¯åè®®&#34; style=&#34;border-width:0&#34; src=&#34;https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey&#34;&gt;&lt;/a&gt;&lt;br&gt;æœ¬ä½œå“é‡‡ç”¨&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®&lt;/a&gt;è¿›è¡Œè®¸å¯ã€‚&lt;/p&gt;</summary>
  </entry>
</feed>