<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-25T01:37:08Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>LC1332/Chinese-alpaca-lora</title>
    <updated>2023-03-25T01:37:08Z</updated>
    <id>tag:github.com,2023-03-25:/LC1332/Chinese-alpaca-lora</id>
    <link href="https://github.com/LC1332/Chinese-alpaca-lora" rel="alternate"></link>
    <summary type="html">&lt;p&gt;骆驼:A Chinese finetuned instruction LLaMA. Developed by 陈启源 @ 华中师范大学 &amp; 李鲁鲁 @ 商汤科技 &amp; 冷子昂 @ 商汤科技&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;骆驼(Luotuo): Chinese-alpaca-lora&lt;/h1&gt; &#xA;&lt;p&gt;骆驼(Luotuo) is the Chinese pinyin(pronunciation) of camel&lt;/p&gt; &#xA;&lt;p&gt;A Chinese finetuned instruction LLaMA. Developed by 冷子昂 @ 商汤科技, 陈启源 @ 华中师范大学(Third year undergraduate student) and 李鲁鲁 @ 商汤科技&lt;/p&gt; &#xA;&lt;p&gt;(email: &lt;a href=&#34;mailto:chengli@sensetime.com&#34;&gt;chengli@sensetime.com&lt;/a&gt;, &lt;a href=&#34;mailto:zaleng@bu.edu&#34;&gt;zaleng@bu.edu&lt;/a&gt;, &lt;a href=&#34;mailto:chenqiyuan1012@foxmail.com&#34;&gt;chenqiyuan1012@foxmail.com&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/camel_back.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;This is NOT an official product of SenseTime&lt;/p&gt; &#xA;&lt;p&gt;We named project in Luotuo(Camel) because both LLaMA and alpaca are all belongs to Artiodactyla-Camelidae(偶蹄目-骆驼科)&lt;/p&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;p&gt;[2023-3-24] We&#39;ve just released CamelBell(驼铃): tuning Chinese LLM with very few data on GLM-6B via LoRA, try &lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/TuoLing_evaluation_code.ipynb&#34;&gt;here&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/TuoLing_evaluation_code.ipynb&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; , we may create a new repo soon&lt;/p&gt; &#xA;&lt;p&gt;[2023-3-24] The Luotuo proj aim to study whether an En model cross-language learning to Ch via LoRA. We will soon release a Chinese LoRA project, CamelBell, which can be trained with less data based on a Chinese base model.&lt;/p&gt; &#xA;&lt;h2&gt;A Quick Start&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Colab Link&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;detail&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CamelBell quick evaluation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/TuoLing_evaluation_code.ipynb&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Tuoling specific Evaluation Code&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A quick evaluation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/evaluation_code.ipynb&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Evaluation code with standard HuggingFace pipeline&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bot with Interface&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/ChatLuotuo.ipynb&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Interactive Chatting Bot using Gradio&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Training Code&lt;/td&gt; &#xA;   &lt;td&gt;To be released&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Training code, run on colab&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Data Translation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/LC1332/Chinese-alpaca-lora/blob/main/notebook/translate_json_data.ipynb&#34; target=&#34;_parent&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Translation alpaca.json into Chinese&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Trained Model&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model Name&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Training Data and Setting&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/qychen/luotuo-lora-7b-0.1/tree/main&#34;&gt;luotuo-lora-7b-0.1&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Trained on Translated alpaca 52k data&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://huggingface.co/silk-road/luotuo-lora-7b-0.3&#34;&gt;luotuo-lora-7b-0.3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Trained on Translated alpaca 52k data + guanaco, 1 epoch&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;luotuo-lora-7b-0.9&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;(In Plan) cleaned alpaca 52k + full guanaco&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;luotuo-lora-7b-0.3 the performance seems have significant improvement than 0.1, even just after 1 epoch.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/0.3result_1epoch.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;But 1 epoch cost us 7 hours to train, which cost more than $10. We will keep continue tuning it later.&lt;/p&gt; &#xA;&lt;h2&gt;Qualitative Result(0.3)&lt;/h2&gt; &#xA;&lt;p&gt;Evaluation code are now in notebook/evaluation_code.ipynb&lt;/p&gt; &#xA;&lt;h3&gt;Good Examples&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 中国的首都在哪里？&#xA;Luotuo-Output: 中国的首都是北京。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 麦当劳是哪个国家的？&#xA;Luotuo-Output: 美国。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 2017年美国总统是谁&#xA;Luotuo-Output: 2017年美国总统是特朗普&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 华中师范大学在哪里&#xA;Luotuo-0.1-Output: 华中师范大学位于北京&#xA;Luotuo-0.3-Output: 华中师范大学在武汉市。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;this example failed in 0.1&lt;/p&gt; &#xA;&lt;h3&gt;Bad Examples&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 商汤科技是做什么的？&#xA;Luotuo-0.1-Output: 商汤科技是一种技术，它用于创建互联网应用程序和服务。&#xA;Luotuo-0.3-Output: 商汤科技是一种技术，它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的产品和服务，以增加产品和服务的吸引力。它可以用于创建新的&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;Input: 猫和狗的关系是什么&#xA;Luotuo-Output: 猫和狗之间的关系是友好的。它们通常在一起休息或玩耍。猫和狗之间的关系通常很好，它们通常在一起休息或玩耍。猫和狗之间的关系通常很好，它们通常在一起休息或玩耍。猫和狗之间的关系通常很好，它们通常在一起休息或玩耍。猫和狗之间的关系通常很好，它们通常在一起休息或玩耍。猫和狗之间的关系通常很好，它们通常在一起休息或玩耍。猫和狗之间的关系通常&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;p&gt;We have tuned a Chinese LLaMA model baed on &lt;a href=&#34;https://ai.facebook.com/blog/large-language-model-llama-meta-ai/&#34;&gt;LLaMA&lt;/a&gt;, &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;, &lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;Alpaca LoRA&lt;/a&gt;, &lt;a href=&#34;https://github.com/22-hours/cabrita&#34;&gt;cabrita&lt;/a&gt;, &lt;a href=&#34;https://github.com/masa3141/japanese-alpaca-lora&#34;&gt;Japanese-Alpaca-LoRA&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The training code in in cleaning, if you are in very hurry, check the Japanese project and simply change the json training data file name.&lt;/p&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;This is an inbuilding project&lt;/p&gt; &#xA;&lt;p&gt;The training code only made a slightly change on the Japanese-Alpaca-LoRA&lt;/p&gt; &#xA;&lt;p&gt;A. &lt;a href=&#34;https://huggingface.co/qychen/luotuo-lora-7b-0.1/tree/main&#34;&gt;0.1 version model&lt;/a&gt; was trained on translated data, which translate the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/alpaca_data.json&#34;&gt;alpaca_data.json&lt;/a&gt; to Chinese using ChatGPT API. We paid around US $30-45 to translate the full dataset to chinese. Translated data is available. (&lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/data/trans_chinese_alpaca_data.json&#34;&gt;trans_chinese_alpaca_data.json&lt;/a&gt;)&lt;/p&gt; &#xA;&lt;p&gt;B. We are also plan to consider the data in &lt;a href=&#34;https://guanaco-model.github.io/&#34;&gt;Guanaco&lt;/a&gt; hikariming&#39;s &lt;a href=&#34;https://github.com/hikariming/alpaca_chinese_dataset&#34;&gt;alpaca_chinese_dataset&lt;/a&gt; and carbonz0‘s &lt;a href=&#34;https://github.com/carbonz0/alpaca-chinese-dataset&#34;&gt;alpaca-chinese-dataset&lt;/a&gt;, may updated it into later version.&lt;/p&gt; &#xA;&lt;p&gt;We plan to upload two different models A and B, because the provider of B claim the clean data will bring significant improvement.&lt;/p&gt; &#xA;&lt;h2&gt;Sponsorships(赞助)&lt;/h2&gt; &#xA;&lt;p&gt;Top 3 Sponsors&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Time&lt;/th&gt; &#xA;   &lt;th&gt;Sponsor&lt;/th&gt; &#xA;   &lt;th&gt;Amount&lt;/th&gt; &#xA;   &lt;th&gt;Balance&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2023/3/24&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/pandodao/botastic&#34;&gt;yiplee&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;512&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2023/3/24&lt;/td&gt; &#xA;   &lt;td&gt;Hijun&lt;/td&gt; &#xA;   &lt;td&gt;500&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2023/3/24&lt;/td&gt; &#xA;   &lt;td&gt;倪**&lt;/td&gt; &#xA;   &lt;td&gt;500&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;balance = 1706 now. Detailed balance see in &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/data/Sponsorship_and_balance.md&#34;&gt;sponsorship_and_balance.md&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;这原本是我们的一个作业项目，我们原本计划训练到1.0为止。但是社区的热情超过了我们的想象。如果您愿意赞助我们的项目，可以&lt;/p&gt; &#xA;&lt;p&gt;扫描这个&lt;a href=&#34;https://s1.imagehub.cc/images/2023/03/23/fba44d198f0bb887089b4d8739363c0b.jpeg&#34;&gt;二维码&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;并且加这个&lt;a href=&#34;https://s1.imagehub.cc/images/2023/03/23/b69e4e47759132dd3d4bbafa7bd602aa.jpeg&#34;&gt;支付宝&lt;/a&gt;账号，留下您的姓名&lt;/p&gt; &#xA;&lt;p&gt;项目的资金流向将被公开，所有的资金将被用于数据的标注，训练算力的购买或者后续周边产品的发放。数据和算力的捐献也会一同总结在sponsorship的表格中。备用链接 &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/sponser_QR_code.jpeg&#34;&gt;二维码&lt;/a&gt; , &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/alipay_friend.jpeg&#34;&gt;支付宝&lt;/a&gt;账号&lt;/p&gt; &#xA;&lt;p&gt;This was originally an exercise project for us, and we originally planned to train until version 1.0. However, the enthusiasm of the community exceeded our expectations. If you are willing to sponsor our project, you can scan this &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/sponser_QR_code.jpeg&#34;&gt;QR code&lt;/a&gt; and add &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/image/alipay_friend.jpeg&#34;&gt;this Alipay account&lt;/a&gt;, leaving your name.&lt;/p&gt; &#xA;&lt;p&gt;All funds will be used for data annotation, purchase of training computing power, or distribution of subsequent peripheral products.&lt;/p&gt; &#xA;&lt;h2&gt;TODO and Be a Contributor&lt;/h2&gt; &#xA;&lt;p&gt;It seems that there are many follow-up tasks to be done after the basic version is completed. Many developers in the community have put forward more friendly suggestions, and I have put a longer TODO list in &lt;a href=&#34;https://raw.githubusercontent.com/LC1332/Chinese-alpaca-lora/main/data/TODO_list.md&#34;&gt;TODO_list.md&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;inbuilding project&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; translate alpaca json data into Chinese&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; finetuning with lora(model 0.1)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; release 0.1 model (model A)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; model to hugging face, GUI demo&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; train lora with more alpaca data(model 0.3)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; train lora with more alpaca data(model 0.9)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We plan to use this Luotuo project as the git repository for the entire Chinese LLM project. After the completion of the original Luotuo: LLaMA-LoRA, it will be migrated to Luotuo-vanilla. The CamelBell, Loulan, Silk-Road and other derivative Chinese language model projects will gradually be added to the Luotuo project.&lt;/p&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you find this project useful in your research, please consider citing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{leng2023luotuo-ch-alpaca,&#xA;  title={Luotuo: Evaluating Cross-En-Ch-lingual training of LLM via Low Rank Adaption},&#xA;  publisher = {GitHub},&#xA;  author={Ziang Leng, Qiyuan Chen and Cheng Li},&#xA;  url={https://github.com/LC1332/Chinese-alpaca-lora},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>wangxuqi/Prompt-Engineering-Guide-Chinese</title>
    <updated>2023-03-25T01:37:08Z</updated>
    <id>tag:github.com,2023-03-25:/wangxuqi/Prompt-Engineering-Guide-Chinese</id>
    <link href="https://github.com/wangxuqi/Prompt-Engineering-Guide-Chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Prompt工程师指南，源自英文版，但增加了AIGC的prompt部分，为了降低同学们的学习门槛，翻译更新&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prompt-Engineering-Guide-Chinese&lt;/h1&gt; &#xA;&lt;p&gt;Prompt工程师指南，源自于github上最火的英文指南，为了降低同学们的学习门槛 实时掌握最新学习内容，持续更新，欢迎共同添加更多的prompt指南&lt;/p&gt; &#xA;&lt;p&gt;Prompt工程是一种相对较新的学科，用于开发和优化提示，以有效地使用语言模型（LMs）进行各种应用和研究主题。Prompt工程技能有助于更好地理解大型语言模型（LLMs）的能力和局限性。研究人员使用Prompt工程来改善LLMs在各种常见和复杂任务上的能力，例如问答和算术推理。开发人员使用Prompt工程来设计强大且有效的提示技术，与LLMs和其他工具进行接口。&lt;/p&gt; &#xA;&lt;p&gt;出于对开发LLMs的高度兴趣，我们创建了这个新的Prompt工程指南，其中包含所有与Prompt工程相关的最新论文、学习指南、讲座、参考资料和工具。&lt;/p&gt; &#xA;&lt;p&gt;祝您愉快地进行Prompt工程！&lt;/p&gt; &#xA;&lt;h2&gt;&lt;/h2&gt; &#xA;&lt;h2&gt;指南&lt;/h2&gt; &#xA;&lt;p&gt;以下是我们开发的一系列Prompt工程指南。这些指南仍在不断完善中。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-intro.md&#34;&gt;Prompt工程-简介&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-basic-usage.md&#34;&gt;Prompt工程-基本提示&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-advanced-usage.md&#34;&gt;Prompt工程-高级提示&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-applications.md&#34;&gt;Prompt工程-应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-chatgpt.md&#34;&gt;Prompt工程-ChatGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-adversarial.md&#34;&gt;Prompt工程-对抗性提示&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-reliability.md&#34;&gt;Prompt工程-可靠性&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/guides/prompts-miscellaneous.md&#34;&gt;Prompt工程-其他主题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/pages/papers.mdx&#34;&gt;Prompt工程-论文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/pages/tools.mdx&#34;&gt;Prompt工程-工具&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/pages/datasets.mdx&#34;&gt;Prompt工程-数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/wangxuqi/Prompt-Engineering-Guide-Chinese/main/pages/readings.mdx&#34;&gt;Prompt工程-附加阅读&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lxe/simple-llama-finetuner</title>
    <updated>2023-03-25T01:37:08Z</updated>
    <id>tag:github.com,2023-03-25:/lxe/simple-llama-finetuner</id>
    <link href="https://github.com/lxe/simple-llama-finetuner" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Simple UI for LLaMA Model Finetuning&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🦙 Simple LLaMA Finetuner&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/lxe/simple-llama-finetuner/blob/master/Simple_LLaMA_FineTuner.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lxe/no-bugs&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/no-bugs-brightgreen.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/lxe/onehundred/tree/master&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/coverage-%F0%9F%92%AF-green.svg?sanitize=true&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Simple LLaMA Finetuner is a beginner-friendly interface designed to facilitate fine-tuning the &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA-7B&lt;/a&gt; language model using &lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;LoRA&lt;/a&gt; method via the &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT library&lt;/a&gt; on commodity NVIDIA GPUs. With small dataset and sample lengths of 256, you can even run this on a regular Colab Tesla T4 instance.&lt;/p&gt; &#xA;&lt;p&gt;With this intuitive UI, you can easily manage your dataset, customize parameters, train, and evaluate the model&#39;s inference capabilities.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zphang/minimal-llama/&#34;&gt;https://github.com/zphang/minimal-llama/&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;https://github.com/tloen/alpaca-lora&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;https://github.com/huggingface/peft&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Anthropic/hh-rlhf&#34;&gt;https://huggingface.co/datasets/Anthropic/hh-rlhf&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Features&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Simply paste datasets in the UI, separated by double blank lines&lt;/li&gt; &#xA; &lt;li&gt;Adjustable parameters for fine-tuning and inference&lt;/li&gt; &#xA; &lt;li&gt;Beginner-friendly UI with explanations for each parameter&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TODO&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Accelerate / DeepSpeed&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Load other models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; More dataset preparation tools&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linux or WSL&lt;/li&gt; &#xA; &lt;li&gt;Modern NVIDIA GPU with &amp;gt;16 GB of VRAM (but it might be possible to run with less for smaller sample lengths)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Usage&lt;/h3&gt; &#xA;&lt;p&gt;I recommend using a virtual environment to install the required packages. Conda preferred.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -n llama-finetuner python=3.10&#xA;conda activate llama-finetuner&#xA;conda install -y cuda -c nvidia/label/cuda-11.7.0&#xA;conda install -y pytorch=1.13.1 pytorch-cuda=11.7 -c pytorch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;On WSL, you might need to install CUDA manually by following &lt;a href=&#34;https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;Distribution=WSL-Ubuntu&amp;amp;target_version=2.0&amp;amp;target_type=deb_local&#34;&gt;these steps&lt;/a&gt;, then running the following before you launch:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;export LD_LIBRARY_PATH=/usr/lib/wsl/lib&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Clone the repository and install the required packages.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/lxe/simple-llama-finetuner.git&#xA;cd simple-llama-finetuner&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Launch it&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python main.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Open &lt;a href=&#34;http://127.0.0.1:7860/&#34;&gt;http://127.0.0.1:7860/&lt;/a&gt; in your browser. Prepare your training data by separating each sample with 2 blank lines. Paste the whole training dataset into the textbox. Specify the model name in the &#34;LoRA Model Name&#34; textbox, then click train. You might need to adjust the max sequence length and batch size to fit your GPU memory. The model will be saved in the &lt;code&gt;lora-{your model name}&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;p&gt;After training is done, navigate to &#34;Inference&#34; tab, click &#34;Reload Models&#34;, select your model, and play with it.&lt;/p&gt; &#xA;&lt;p&gt;Have fun!&lt;/p&gt; &#xA;&lt;h2&gt;Screenshots&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1486609/226793136-84531388-4081-49bb-b982-3f47e6ec25cd.png&#34; alt=&#34;Image1&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1486609/226809466-b1eb6f3f-4049-4a41-a2e3-52b06a6e1230.png&#34; alt=&#34;Image2&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;MIT License&lt;/p&gt; &#xA;&lt;p&gt;Copyright (c) 2023 Aleksey Smolenchuk&lt;/p&gt; &#xA;&lt;p&gt;Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &#34;Software&#34;), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&lt;/p&gt; &#xA;&lt;p&gt;The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&lt;/p&gt; &#xA;&lt;p&gt;THE SOFTWARE IS PROVIDED &#34;AS IS&#34;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&lt;/p&gt;</summary>
  </entry>
</feed>