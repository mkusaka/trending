<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-11-16T01:31:37Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>IBM/data-prep-kit</title>
    <updated>2024-11-16T01:31:37Z</updated>
    <id>tag:github.com,2024-11-16:/IBM/data-prep-kit</id>
    <link href="https://github.com/IBM/data-prep-kit" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Open source project for data preparation of LLM application builders&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Data Prep Kit&lt;/h1&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;!--?  [![Status](https://img.shields.io/badge/status-active-success.svg)]() ?--&gt; &#xA; &lt;!--?  [![GitHub Issues](https://img.shields.io/github/issues/kylelobo/The-Documentation-Compendium.svg)](https://github.com/IBM/data-prep-kit/issues) ?--&gt; &#xA; &lt;!--?  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/kylelobo/The-Documentation-Compendium.svg)](https://github.com/IBM/data-prep-kit/pulls) ?--&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Data Prep Kit is a community project to democratize and accelerate unstructured data preparation for LLM app developers. With the explosive growth of LLM-enabled use cases, developers are faced with the enormous challenge of preparing use case-specific unstructured data to fine-tune, instruct-tune the LLMs or to build RAG applications for LLMs. As the variety of use cases grow, so does the need to support:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;New ways of transforming the data to enhance the performance of the resulting LLMs for each specific use case.&lt;/li&gt; &#xA; &lt;li&gt;A large variety in the scale of data to be processed, from laptop-scale to datacenter-scale&lt;/li&gt; &#xA; &lt;li&gt;Support for different data modalities including language, code, vision, multimodal etc&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Data Prep Kit offers implementations of commonly needed data preparation steps, called &lt;em&gt;modules&lt;/em&gt; or &lt;em&gt;transforms&lt;/em&gt;, for both Code and Language modalities, with vision to extend to images, speech and multimodal data. The goal is to offer high-level APIs for developers to quickly get started in working with their data, without needing expertise in the underlying runtimes and frameworks.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/Data-prep-kit-diagram.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;üìù Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/#about&#34;&gt;About&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/#gettingstarted&#34;&gt;Getting Started&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/#laptop_cluster&#34;&gt;Scaling transforms from laptop to cluster&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/repo.md&#34;&gt;Repository Use and Navigation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/CONTRIBUTING.md&#34;&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/resources.md&#34;&gt;Resources (papers, talks, presentations and tutorials)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/#citations&#34;&gt;Citations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üìñ About &lt;a name=&#34;about&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Data Prep Kit is a toolkit for streamlining data preparation for developers looking to build LLM-enabled applications via fine-tuning, RAG or instruction-tuning. Data Prep Kit contributes a set of modules that the developer can get started with to easily build data pipelines suitable for their use case. These modules have been tested while producing pre-training datasets for the &lt;a href=&#34;https://huggingface.co/ibm-granite&#34;&gt;Granite open source LLM models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The modules are built on common frameworks (for Spark and Ray), called the &lt;em&gt;data processing library&lt;/em&gt; that allows the developers to build new custom modules that readily scale across a variety of runtimes.&lt;/p&gt; &#xA;&lt;p&gt;Features of the toolkit:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It aims to accelerate unstructured data prep for the &#34;long tail&#34; of LLM use cases.&lt;/li&gt; &#xA; &lt;li&gt;It offers a growing set of &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms&#34;&gt;module&lt;/a&gt; implementations across multiple runtimes, targeting laptop-scale to datacenter-scale processing.&lt;/li&gt; &#xA; &lt;li&gt;It provides a growing set of &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples&#34;&gt;sample data processing pipelines&lt;/a&gt; that can be used for real enterprise use cases.&lt;/li&gt; &#xA; &lt;li&gt;It provides the &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/data-processing-lib/ray&#34;&gt;Data processing library&lt;/a&gt; to enable contribution of new custom modules targeting new use cases.&lt;/li&gt; &#xA; &lt;li&gt;It uses &lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/v1/introduction/&#34;&gt;Kubeflow Pipelines&lt;/a&gt;-based &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/doc/simple_transform_pipeline.md&#34;&gt;workflow automation&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Data modalities supported &lt;em&gt;today&lt;/em&gt;: Code and Natural Language.&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started &lt;a name=&#34;gettingstarted&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;h3&gt;Fastest way to experience Data Prep Kit&lt;/h3&gt; &#xA;&lt;p&gt;With no setup necessary, let&#39;s use a Google Colab friendly notebook to try Data Prep Kit. This is a simple transform to extract content from PDF files: &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/Run_your_first_transform_colab.ipynb&#34;&gt;examples/notebooks/Run_your_first_transform_colab.ipynb&lt;/a&gt; | &lt;a href=&#34;https://colab.research.google.com/github/IBM/data-prep-kit/blob/dev/examples/notebooks/Run_your_first_transform_colab.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;. (&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/google-colab.md&#34;&gt;Here&lt;/a&gt; are some tips for running Data Prep Kit transforms on Google Colab. For this simple example, these tips are either already taken care of, or are not needed.)&lt;/p&gt; &#xA;&lt;h3&gt;Create a Virtual Environment&lt;/h3&gt; &#xA;&lt;p&gt;To run on a local machine, follow these steps to quickly set up and deploy the Data Prep Kit in your virtual Python environment.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n data-prep-kit -y python=3.11&#xA;conda activate data-prep-kit&#xA;python --version&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Check if the python version is 3.11.&lt;/p&gt; &#xA;&lt;p&gt;If you are using a linux system, install gcc using the below commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install gcc_linux-64&#xA;conda install gxx_linux-64&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, install the data prep toolkit library. This library installs both the python and ray versions of the transforms. For better management of dependencies, it is recommended to install the same tagged version of both the library and the transform.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip3 install  &#39;data-prep-toolkit[ray]==0.2.2.dev1&#39;&#xA;pip3 install  &#39;data-prep-toolkit-transforms[ray,all]==0.2.2.dev1&#39;&#xA;pip3 install jupyterlab   ipykernel  ipywidgets&#xA;&#xA;## install custom kernel&#xA;python -m ipykernel install --user --name=data-prep-kit --display-name &#34;dataprepkit&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Test, your installation. If you are able to import these data-prep-kit libraries successfully in python, your installation has succeeded.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## start python interpreter&#xA;$   python&#xA;&#xA;# import DPK libraries&#xA;&amp;gt;&amp;gt;&amp;gt; from data_processing_ray.runtime.ray import RayTransformLauncher&#xA;&amp;gt;&amp;gt;&amp;gt; from data_processing.runtime.pure_python import PythonTransformLauncher&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If there are no errors, you are good to go!&lt;/p&gt; &#xA;&lt;h3&gt;Run your first transform locally&lt;/h3&gt; &#xA;&lt;p&gt;Let&#39;s try the same simple transform to extract content from PDF files on a local machine.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Local Notebook versions&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can try either one or both of the following two versions:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Option 1: Pure python notebook: &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/Run_your_first_transform_python.ipynb&#34;&gt;examples/notebooks/Run_your_first_transform_python.ipynb&lt;/a&gt; - easiest to get started&lt;/li&gt; &#xA; &lt;li&gt;Option 2: Ray version: This one uses Ray framework for parallel execution while still allowing local processing - &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/Run_your_first_transform_ray.ipynb&#34;&gt;examples/notebooks/Run_your_first_transform_ray.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To run the notebooks, launch jupyter from the same virtual environment you created using the command below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;jupyter lab&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;After opening the jupyter notebook, change the kernel to &lt;code&gt;dataprepkit&lt;/code&gt;, so all libraries will be properly loaded.&lt;/p&gt; &#xA;&lt;p&gt;Explore more examples &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Run your first data prep pipeline&lt;/h3&gt; &#xA;&lt;p&gt;Now that you have run a single transform, the next step is to explore how to put these transforms together to run a data prep pipeline for an end to end use case like fine tuning model or building a RAG application. This &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/fine%20tuning/code/sample-notebook.ipynb&#34;&gt;notebook&lt;/a&gt; gives an example of how to build an end to end data prep pipeline for fine tuning for code LLMs. You can also explore how to build a RAG pipeline &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples/notebooks/rag&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Current list of transforms&lt;/h3&gt; &#xA;&lt;p&gt;The matrix below shows the the combination of modules and supported runtimes. All the modules can be accessed &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms&#34;&gt;here&lt;/a&gt; and can be combined to form data processing pipelines, as shown in the &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/examples&#34;&gt;examples&lt;/a&gt; folder.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Modules&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Python-only&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Ray&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Spark&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;KFP on Ray&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Data Ingestion&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/README.md&#34;&gt;Code (from zip) to Parquet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/pdf2parquet/python/README.md&#34;&gt;PDF to Parquet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/html2parquet/python/README.md&#34;&gt;HTML to Parquet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Universal (Code &amp;amp; Language)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/ededup/ray/README.md&#34;&gt;Exact dedup filter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/fdedup/ray/README.md&#34;&gt;Fuzzy dedup filter&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/doc_id/ray/README.md&#34;&gt;Unique ID annotation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/filter/python/README.md&#34;&gt;Filter on annotations&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/profiler/ray/README.md&#34;&gt;Profiler&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/resize/python/README.md&#34;&gt;Resize&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/hap/python/README.md&#34;&gt;HAP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/tokenization/python/README.md&#34;&gt;Tokenizer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Language-only&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/lang_id/python/README.md&#34;&gt;Language identification&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/doc_quality/python/README.md&#34;&gt;Document quality&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/doc_chunk/python/README.md&#34;&gt;Document chunking for RAG&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/text_encoder/python/README.md&#34;&gt;Text encoder&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/pii_redactor/python/README.md&#34;&gt;PII Annotator/Redactor&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Code-only&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/proglang_select/python/README.md&#34;&gt;Programming language annotation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code_quality/python/README.md&#34;&gt;Code quality annotation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/malware/python/README.md&#34;&gt;Malware annotation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/header_cleanser/python/README.md&#34;&gt;Header cleanser&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/repo_level_ordering/ray/README.md&#34;&gt;Semantic file ordering&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/license_select/python/README.md&#34;&gt;License Select Annotation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;span&gt;‚úÖ&lt;/span&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Contributors are welcome to add new modules to expand to other data modalities as well as add runtime support for existing modules!&lt;/p&gt; &#xA;&lt;h3&gt;Add your own transform&lt;/h3&gt; &#xA;&lt;p&gt;At the core of the framework, is a data processing library, that provides a systematic way to implement the data processing modules. The library is python-based and enables the application of &#34;transforms&#34; to a one or more input data files to produce one or more output data files. We use the popular &lt;a href=&#34;https://arrow.apache.org/docs/python/parquet.html&#34;&gt;parquet&lt;/a&gt; format to store the data (code or language). Every parquet file follows a set &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/code/code2parquet/python/README.md&#34;&gt;schema&lt;/a&gt;. A user can use one or more transforms (or modules) as discussed above to process their data. A transform can follow one of the two patterns: annotator or filter.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Annotator&lt;/strong&gt; An annotator transform adds information during the processing by adding one more columns to the parquet files. The annotator design also allows a user to verify the results of the processing before the actual filtering of the data.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter&lt;/strong&gt; A filter transform processes the data and outputs the transformed data, e.g., exact deduplication. A general purpose &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/filter&#34;&gt;SQL-based filter transform&lt;/a&gt; enables a powerful mechanism for identifying columns and rows of interest for downstream processing.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For a new module to be added, a user can pick the right design based on the processing to be applied. More details &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;One can leverage Python-based processing logic and the Data Processing Library to easily build and contribute new transforms. We have provided an &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/noop&#34;&gt;example transform&lt;/a&gt; that can serve as a template to add new simple transforms. Follow the step by step &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/data-processing-lib/doc/simplest-transform-tutorial.md&#34;&gt;tutorial&lt;/a&gt; to help you add your own new transform.&lt;/p&gt; &#xA;&lt;p&gt;For a deeper understanding of the library&#39;s architecture, its transforms, and available runtimes, we encourage the reader to consult the comprehensive &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/data-processing-lib/doc/overview.md&#34;&gt;overview document&lt;/a&gt; alongside dedicated sections on &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/data-processing-lib/doc/transforms.md&#34;&gt;transforms&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/data-processing-lib/doc/transform-runtimes.md&#34;&gt;runtimes&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Additionally, check out our &lt;a href=&#34;https://www.youtube.com/watch?v=0WUMG6HIgMg&#34;&gt;video tutorial&lt;/a&gt; for a visual, example-driven guide on adding custom modules.&lt;/p&gt; &#xA;&lt;h2&gt;üíª -&amp;gt; üñ•Ô∏è‚òÅÔ∏è From laptop to cluster &lt;a name=&#34;laptop_cluster&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Data-prep-kit provides the flexibility to transition your projects from proof-of-concept (PoC) stage to full-scale production mode, offering all the necessary tools to run your data transformations at high volume. In this section, we enable you how to run your transforms at scale and how to automate them.&lt;/p&gt; &#xA;&lt;h3&gt;Scaling of Transforms&lt;/h3&gt; &#xA;&lt;p&gt;To enable processing of large data volumes leveraging multi-mode clusters, &lt;a href=&#34;https://docs.ray.io/en/latest/index.html&#34;&gt;Ray&lt;/a&gt; or &lt;a href=&#34;https://spark.apache.org&#34;&gt;Spark&lt;/a&gt; wrappers are provided, to readily scale out the Python implementations.&lt;/p&gt; &#xA;&lt;p&gt;A generalized workflow is shown &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/data-processing.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Automation&lt;/h3&gt; &#xA;&lt;p&gt;The toolkit also supports transform execution automation based on &lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/v1/introduction/&#34;&gt;Kubeflow pipelines&lt;/a&gt; (KFP), tested on a locally deployed &lt;a href=&#34;https://kind.sigs.k8s.io/&#34;&gt;Kind cluster&lt;/a&gt; and external OpenShift clusters. There is an automation to create a Kind cluster and deploy all required components on it. The KFP implementation is based on the &lt;a href=&#34;https://docs.ray.io/en/master/cluster/kubernetes/getting-started.html&#34;&gt;KubeRay Operator&lt;/a&gt; for creating and managing the Ray cluster and &lt;a href=&#34;https://github.com/ray-project/kuberay/tree/master/apiserver&#34;&gt;KubeRay API server&lt;/a&gt; to interact with the KubeRay operator. An additional &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/kfp_support_lib&#34;&gt;framework&lt;/a&gt; along with several &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/kfp_ray_components&#34;&gt;kfp components&lt;/a&gt; is used to simplify the pipeline implementation.&lt;/p&gt; &#xA;&lt;p&gt;A simple transform pipeline &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/doc/simple_transform_pipeline.md&#34;&gt;tutorial&lt;/a&gt; explains the pipeline creation and execution. In addition, if you want to combine several transformers in a single pipeline, you can look at &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/doc/multi_transform_pipeline.md&#34;&gt;multi-steps pipeline&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;When you finish working with the cluster, and want to clean up or destroy it. See the &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/kfp/doc/setup.md#cleanup&#34;&gt;clean up the cluster&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Run your first transform using command line options&lt;/h3&gt; &#xA;&lt;p&gt;You can run transforms via docker image or using virtual environments. This &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/quick-start/run-transform-venv.md&#34;&gt;document&lt;/a&gt; shows how to run a transform using virtual environment. You can follow this &lt;a href=&#34;https://raw.githubusercontent.com/IBM/data-prep-kit/dev/doc/quick-start/run-transform-image.md&#34;&gt;document&lt;/a&gt; to run using docker image.&lt;/p&gt; &#xA;&lt;h2&gt;Citations &lt;a name=&#34;citations&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you use Data Prep Kit in your research, please cite our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;@misc{wood2024dataprepkitgettingdataready,&#xA;      title={Data-Prep-Kit: getting your data ready for LLM application development}, &#xA;      author={David Wood and Boris Lublinsky and Alexy Roytman and Shivdeep Singh &#xA;      and Abdulhamid Adebayo and Revital Eres and Mohammad Nassar and Hima Patel &#xA;      and Yousaf Shah and Constantin Adam and Petros Zerfos and Nirmit Desai &#xA;      and Daiki Tsuzuku and Takuya Goto and Michele Dolfi and Saptha Surendran &#xA;      and Paramesvaran Selvam and Sungeun An and Yuan Chi Chang and Dhiraj Joshi &#xA;      and Hajar Emami-Gohari and Xuan-Hong Dang and Yan Koyfman and Shahrokh Daijavad},&#xA;      year={2024},&#xA;      eprint={2409.18164},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.AI},&#xA;      url={https://arxiv.org/abs/2409.18164}, &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Snowflake-Labs/snowflake-demo-notebooks</title>
    <updated>2024-11-16T01:31:37Z</updated>
    <id>tag:github.com,2024-11-16:/Snowflake-Labs/snowflake-demo-notebooks</id>
    <link href="https://github.com/Snowflake-Labs/snowflake-demo-notebooks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Collection of Snowflake Notebook demos, tutorials, and examples&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Snowflake Notebook Demos&lt;/h1&gt; &#xA;&lt;p&gt;Snowflake Notebooks is your familiar, interactive development environment to perform Data Science, Data Engineering, and AI/ML workloads end-to-end in Snowflake. Write Python &amp;amp; SQL in the same interface.&lt;/p&gt; &#xA;&lt;p&gt;This repo contains a collection of Snowflake Notebook demos, tutorials, and examples. Browse each folder to access the notebook files associated with each demo. Here is a list of notebooks you can find in this repo.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/create-sf-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: center;&#34;&gt; &lt;h4&gt;Getting Started&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/My%20First%20Notebook%20Project/My%20First%20Notebook%20Project.ipynb&#34;&gt;My First Notebook Project&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=tpg35YgA9Gk&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Visual%20Data%20Stories%20with%20Snowflake%20Notebooks/Visual%20Data%20Stories%20with%20Snowflake%20Notebooks.ipynb&#34;&gt;Visual Data Stories With Snowflake Notebooks&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=WJUNTudCsYM&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Reference%20cells%20and%20variables/Reference%20cells%20and%20variables.ipynb&#34;&gt;Reference cells and variables&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/data-science-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;h4&gt;Data Administration&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/MFA_Audit_of_Users/MFA_Audit_of_Users_with_Streamlit_in_Snowflake_Notebooks.ipynb&#34;&gt;Multi-Factor Authentication Audit of Users with Streamlit in Snowflake Notebooks&lt;/a&gt; &lt;a href=&#34;https://youtu.be/WojbkHRCiHU&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Query_Performance_Insights/Automated_Query_Performance_Insights_in_Snowflake_Notebooks.ipynb&#34;&gt;Automated Query Performance Insights in Snowflake Notebooks&lt;/a&gt; &lt;a href=&#34;https://youtu.be/h_pb4qdTfzg&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Query_Performance_Insights_using_Streamlit/Build_an_Interactive_Query_Performance_App_with_Streamlit.ipynb&#34;&gt;Interactive Query Performance App in Snowflake Notebooks using Streamlit&lt;/a&gt; &lt;a href=&#34;https://youtu.be/vdW8xZYBOI0&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Monitoring_Table_Size_with_Streamlit/Monitoring_Table_Size_with_Streamlit.ipynb&#34;&gt;Monitoring the Table Size in Snowflake Notebooks with Streamlit&lt;/a&gt; &lt;a href=&#34;https://youtu.be/ANlzffewNGk&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Role_Based_Access_Auditing_with_Streamlit/Role_Based_Access_Auditing_with_Streamlit.ipynb&#34;&gt;Role-Based Access Auditing in Snowflake Notebooks with Streamlit&lt;/a&gt; &lt;/li&gt;&#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Warehouse_Utilization_with_Streamlit/Warehouse_Utilization_with_Streamlit.ipynb&#34;&gt;Warehouse Utilization in Snowflake Notebooks with Streamlit&lt;/a&gt; &lt;a href=&#34;https://youtu.be/fpVAe0BHc7Q&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/data-science-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;h4&gt;Data Science&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Dashboard_with_Streamlit/Build_a_Dashboard_with_Streamlit_in_Snowflake_Notebooks.ipynb&#34;&gt;Dashboard In Snowflake Notebooks Using Streamlit&lt;/a&gt; &lt;a href=&#34;https://youtu.be/LrQwXQm28qE&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Telco%20Churn%20Data%20Analysis/Telco%20Churn%20Data%20Analysis.ipynb&#34;&gt;Data Analysis and Churn Prediction using Snowflake Notebooks&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=eqb5RdmpW8c&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Ingest%20Public%20JSON/Ingest%20Public%20JSON.ipynb&#34;&gt;How to Ingest JSON Data from Public Endpoint&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Load%20CSV%20from%20S3/Load%20CSV%20from%20S3.ipynb&#34;&gt;How to load CSV files from S3 stage&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/create-sf-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;h4&gt;Data Engineering&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Create%20and%20Manage%20Snowflake%20Objects%20like%20a%20Pro/Create%20and%20Manage%20Snowflake%20Objects%20like%20a%20Pro.ipynb&#34;&gt;Create and Manage Snowflake Objects Like a Pro&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=Dj8aAoEOfrw&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Data%20Engineering%20Pipelines%20with%20Snowpark%20Python/Data%20Engineering%20Pipelines%20with%20Snowpark%20Python.ipynb&#34;&gt;Data Engineering Pipelines with Snowpark Python&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=mpstEt0fU8U&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Creating%20Snowflake%20Object%20using%20Python%20API/Creating%20Snowflake%20Object%20using%20Python%20API.ipynb&#34;&gt;Creating Snowflake Object using Python API&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/ml-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;h4&gt;Machine Learning&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/tree/main/End-to-End%20Machine%20Learning%20with%20Snowpark%20ML&#34;&gt;End-to-End Machine Learning with Snowpark ML&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=LeSGBW0YoLg&#34;&gt;üé•&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Hyperparameter%20Tuning%20with%20sklearn/Hyperparameter%20Tuning%20with%20sklearn.ipynb&#34;&gt;Hyperparameter Tuning with sklearn&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Getting%20Started%20with%20Snowflake%20Cortex%20ML-Based%20Functions/Getting%20Started%20with%20Snowflake%20Cortex%20ML-Based%20Functions.ipynb&#34;&gt;Getting Started with Snowflake Cortex ML-Based Functions&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Feature%20Store%20API%20Overview/Feature%20Store%20API%20Overview.ipynb&#34;&gt;Feature Store API Overview&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/End-to-end%20ML%20with%20Feature%20Store%20and%20Model%20Registry/End-to-end%20ML%20with%20Feature%20Store%20and%20Model%20Registry.ipynb&#34;&gt;End-to-end ML with Feature Store and Model Registry&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Manage%20features%20in%20DBT%20with%20Feature%20Store/Manage%20features%20in%20DBT%20with%20Feature%20Store.ipynb&#34;&gt;Manage features in DBT with Feature Store&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/ML%20Lineage%20Workflows/ML%20Lineage%20Workflows.ipynb&#34;&gt;ML Lineage Workflows&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;img src=&#34;https://docs.snowflake.com/_images/develop-sf-notebooks-tile.png&#34; alt=&#34;Image&#34; style=&#34;width:100px&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;vertical-align: top;&#34;&gt; &lt;h4&gt;Using Notebooks&lt;/h4&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Import%20Package%20from%20Stage/Import%20Package%20from%20Stage.ipynb&#34;&gt;Import Custom Package from Stage into Notebook&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Working%20with%20Files/Working%20with%20Files.ipynb&#34;&gt;How to work with Files in Snowflake Notebooks&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Navigating%20and%20Browsing%20Files/Navigating%20and%20Browsing%20Files.ipynb&#34;&gt;Navigating and Browsing Files in Snowflake Notebooks&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-notebooks/raw/main/Access%20External%20Endpoints/Access%20External%20Endpoints.ipynb&#34;&gt;Access External Endpoints&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Load demo notebooks to Snowflake&lt;/h2&gt; &#xA;&lt;p&gt;The notebook files are available for download as &lt;code&gt;.ipynb&lt;/code&gt; files. To load the demo notebooks into your Snowflake Notebook, follow these steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;On Github, click into each folder containing the tutorial and the corresponding &lt;code&gt;.ipynb file&lt;/code&gt;, such as &lt;a href=&#34;https://github.com/Snowflake-Labs/notebook-demo/raw/main/My%20First%20Notebook%20Project/My%20First%20Notebook%20Project.ipynb&#34;&gt;this&lt;/a&gt;. Download the file by clicking on the &lt;code&gt;Download raw file&lt;/code&gt; from the top right.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to the Snowflake web interface, &lt;a href=&#34;https://app.snowflake.com&#34;&gt;Snowsight&lt;/a&gt;, on your browser.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Navigate to &lt;code&gt;Project&lt;/code&gt; &amp;gt; &lt;code&gt;Notebooks&lt;/code&gt; from the left menu bar.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Import the .ipynb file you&#39;ve download into your Snowflake Notebook by using the &lt;code&gt;Import from .ipynb&lt;/code&gt; button located on the top right of the Notebooks page.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Select the file from your local directory and press &lt;code&gt;Open&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A &lt;code&gt;Create Notebook&lt;/code&gt; dialog will show up. Select a database, schema, and warehouse for the Notebook and click &lt;code&gt;Create&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Resources&lt;/h2&gt; &#xA;&lt;p&gt;Here are some resources to learn more about Snowflake Notebooks:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.snowflake.com/LIMITEDACCESS/snowsight-notebooks/ui-snowsight-notebooks-about&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLavJpcg8cl1Efw8x_fBKmfA2AMwjUaeBI&#34;&gt;YouTube Playlist&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://developers.snowflake.com/solutions/?_sft_technology=notebooks&#34;&gt;Solution Center&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;All code and notebooks included in this repo is available with an Apache 2.0 license.&lt;/p&gt; &#xA;&lt;h2&gt;Other links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Interested in developing and running interactive Streamlit apps in Snowflake? Check out the &lt;a href=&#34;https://github.com/Snowflake-Labs/snowflake-demo-streamlit/&#34;&gt;Streamlit in Snowflake Demo Repo&lt;/a&gt; to learn more!&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>