<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-09T01:38:30Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>openvinotoolkit/openvino_notebooks</title>
    <updated>2022-11-09T01:38:30Z</updated>
    <id>tag:github.com,2022-11-09:/openvinotoolkit/openvino_notebooks</id>
    <link href="https://github.com/openvinotoolkit/openvino_notebooks" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üìö Jupyter notebook tutorials for OpenVINO‚Ñ¢&lt;/p&gt;&lt;hr&gt;&lt;p&gt;English | &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/raw/main/README_cn.md&#34;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;üìö OpenVINO‚Ñ¢ Notebooks&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Apache License Version 2.0&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/actions/workflows/nbval.yml?query=event%3Apush&#34;&gt;&lt;img src=&#34;https://github.com/openvinotoolkit/openvino_notebooks/actions/workflows/nbval.yml/badge.svg?event=push&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/actions/workflows/docker.yml?query=event%3Apush&#34;&gt;&lt;img src=&#34;https://github.com/openvinotoolkit/openvino_notebooks/actions/workflows/docker.yml/badge.svg?event=push&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;A collection of ready-to-run Jupyter notebooks for learning and experimenting with the OpenVINO‚Ñ¢ Toolkit. The notebooks provide an introduction to OpenVINO basics and teach developers how to leverage our API for optimized deep learning inference.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;NOTE: The main branch of this repository was updated to support the new OpenVINO 2022.2 release.&lt;/strong&gt; To upgrade to the new release version, please run &lt;code&gt;pip install --upgrade -r requirements.txt&lt;/code&gt; in your &lt;code&gt;openvino_env&lt;/code&gt; virtual environment. If you need to install for the first time, see the &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-installation-guide&#34;&gt;Installation Guide&lt;/a&gt; section below. If you wish to use the previous Long Term Support (LTS) version of OpenVINO check out the &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/tree/2021.4&#34;&gt;2021.4 branch&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you need help, please start a GitHub &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/discussions&#34;&gt;Discussion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-installation-guide&#34;&gt;‚û§ üìù Installation Guide&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Ubuntu&#34;&gt;Ubuntu&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/macOS&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Red-Hat-and-CentOS&#34;&gt;Red Hat&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Red-Hat-and-CentOS&#34;&gt;CentOS&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/AzureML&#34;&gt;Azure ML&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Docker&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/SageMaker&#34;&gt;Amazon SageMaker&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-getting-started&#34;&gt;‚û§ üöÄ Getting Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-first-steps&#34;&gt;First steps with OpenVINO&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-convert--optimize&#34;&gt;Convert &amp;amp; Optimize&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-model-demos&#34;&gt;Model Demos&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-model-training&#34;&gt;Model Training&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-live-demos&#34;&gt;Live Demos&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-system-requirements&#34;&gt;‚û§ ‚öôÔ∏è System Requirements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-run-the-notebooks&#34;&gt;‚û§ üíª Run the Notebooks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-cleaning-up&#34;&gt;‚û§ üßπ Cleaning Up&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-troubleshooting&#34;&gt;‚û§ ‚ö†Ô∏è Troubleshooting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-contributors&#34;&gt;‚û§ üßë‚Äçüíª Contributors&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-faq&#34;&gt;‚û§ ‚ùì FAQ&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-installation-guide&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;üìù Installation Guide&lt;/h2&gt; &#xA;&lt;p&gt;OpenVINO Notebooks require Python and Git. To get started, select the guide for your operating system or environment:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Windows&#34;&gt;Windows&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Ubuntu&#34;&gt;Ubuntu&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/macOS&#34;&gt;macOS&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Red-Hat-and-CentOS&#34;&gt;Red Hat&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Red-Hat-and-CentOS&#34;&gt;CentOS&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/AzureML&#34;&gt;Azure ML&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/Docker&#34;&gt;Docker&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/wiki/SageMaker&#34;&gt;Amazon SageMaker&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-getting-started&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;The Jupyter notebooks are categorized into four classes, select one related to your needs or give them all a try. Good Luck!&lt;/p&gt; &#xA;&lt;div id=&#34;-first-steps&#34;&gt;&lt;/div&gt; &#xA;&lt;h3&gt;üíª First steps&lt;/h3&gt; &#xA;&lt;p&gt;Brief tutorials that demonstrate how to use OpenVINO&#39;s Python API for inference.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/001-hello-world/&#34;&gt;001-hello-world&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F001-hello-world%2F001-hello-world.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/002-openvino-api/&#34;&gt;002-openvino-api&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F002-openvino-api%2F002-openvino-api.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/003-hello-segmentation/&#34;&gt;003-hello-segmentation&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F003-hello-segmentation%2F003-hello-segmentation.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/004-hello-detection/&#34;&gt;004-hello-detection&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F004-hello-detection%2F004-hello-detection.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Classify an image with OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;Learn the OpenVINO Python API&lt;/td&gt; &#xA;   &lt;td&gt;Semantic segmentation with OpenVINO&lt;/td&gt; &#xA;   &lt;td&gt;Text detection with OpenVINO&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/127170593-86976dc3-e5e4-40be-b0a6-206379cd7df5.jpg&#34; width=&#34;140&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127787560-d8ec4d92-b4a0-411f-84aa-007e90faba98.png&#34; width=&#34;250&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/128290691-e2eb875c-775e-4f4d-a2f4-15134044b4bb.png&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/128489933-bf215a3f-06fa-4918-8833-cb0bf9fb1cc7.jpg&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;div id=&#34;-convert--optimize&#34;&gt;&lt;/div&gt; &#xA;&lt;h3&gt;‚åö Convert &amp;amp; Optimize&lt;/h3&gt; &#xA;&lt;p&gt;Tutorials that explain how to optimize and quantize models with OpenVINO tools.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/101-tensorflow-to-openvino/&#34;&gt;101-tensorflow-to-openvino&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F101-tensorflow-to-openvino%2F101-tensorflow-to-openvino.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/102-pytorch-onnx-to-openvino/&#34;&gt;102-pytorch-onnx-to-openvino&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/103-paddle-onnx-to-openvino-classification/&#34;&gt;103-paddle-onnx-to-openvino&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F103-paddle-onnx-to-openvino-classification%2F103-paddle-onnx-to-openvino-classification.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/104-model-tools/&#34;&gt;104-model-tools&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F104-model-tools%2F104-model-tools.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convert TensorFlow models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;td&gt;Convert PyTorch models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;td&gt;Convert PaddlePaddle models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;td&gt;Download, convert and benchmark models from Open Model Zoo&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127779167-9d33dcc6-9001-4d74-a089-8248310092fe.png&#34; width=&#34;250&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127779246-32e7392b-2d72-4a7d-b871-e79e7bfdd2e9.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127779326-dc14653f-a960-4877-b529-86908a6f2a61.png&#34; width=&#34;300&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/157541917-c5455105-b0d9-4adf-91a7-fbc142918015.png&#34; width=&#34;150&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;More amazing notebooks here!&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt; Click here to show complete list! &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Notebook&lt;/th&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/101-tensorflow-to-openvino/&#34;&gt;101-tensorflow-to-openvino&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F101-tensorflow-to-openvino%2F101-tensorflow-to-openvino.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Convert TensorFlow models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/102-pytorch-onnx-to-openvino/&#34;&gt;102-pytorch-onnx-to-openvino&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Convert PyTorch models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/103-paddle-onnx-to-openvino/&#34;&gt;103-paddle-onnx-to-openvino&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F103-paddle-onnx-to-openvino%2F103-paddle-onnx-to-openvino-classification.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Convert PaddlePaddle models to OpenVINO IR&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/104-model-tools/&#34;&gt;104-model-tools&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F104-model-tools%2F104-model-tools.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Download, convert and benchmark models from Open Model Zoo&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/105-language-quantize-bert/&#34;&gt;105-language-quantize-bert&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Optimize and quantize a pre-trained BERT model&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/106-auto-device/&#34;&gt;106-auto-device&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F106-auto-device%2F106-auto-device.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Demonstrate how to use AUTO Device&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/107-speech-recognition-quantization/&#34;&gt;107-speech-recognition-quantization&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Optimize and quantize a pre-trained Wav2Vec2 speech model&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/110-ct-segmentation-quantize/&#34;&gt;110-ct-segmentation-quantize&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Quantize a kidney segmentation model and show live inference&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/111-detection-quantization/&#34;&gt;111-detection-quantization&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Quantize an object detection model&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/112-pytorch-post-training-quantization-nncf/&#34;&gt;112-pytorch-post-training-quantization-nncf&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Use Neural Network Compression Framework (NNCF) to quantize PyTorch model in post-training mode (without model fine-tuning)&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/113-image-classification-quantization/&#34;&gt;113-image-classification-quantization&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F113-image-classification-quantization%2F113-image-classification-quantization.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Quantize mobilenet image classification&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/114-quantization-simplified-mode/&#34;&gt;114-quantization-simplified-mode&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F114-quantization-simplified-mode%2F114-quantization-simplified-mode.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Quantize Image Classification Models with POT in Simplified Mode&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/115-async-api/&#34;&gt;115-async-api&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F115-async-api%2F115-async-api.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Use Asynchronous Execution to Improve Data Pipelining&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-model-demos&#34;&gt;&lt;/div&gt; &#xA;&lt;h3&gt;üéØ Model Demos&lt;/h3&gt; &#xA;&lt;p&gt;Demos that demonstrate inference on a particular model.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/210-ct-scan-live-inference/&#34;&gt;210-ct-scan-live-inference&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F210-ct-scan-live-inference%2F210-ct-scan-live-inference.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/211-speech-to-text/&#34;&gt;211-speech-to-text&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F211-speech-to-text%2F211-speech-to-text.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/213-question-answering/&#34;&gt;213-question-answering&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F213-question-answering%2F213-question-answering.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/208-optical-character-recognition/&#34;&gt;208-optical-character-recognition&lt;/a&gt;&lt;br&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/209-handwritten-ocr/&#34;&gt;209-handwritten-ocr&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F209-handwritten-ocr%2F209-handwritten-ocr.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Show live inference on segmentation of CT-scan data&lt;/td&gt; &#xA;   &lt;td&gt;Run inference on speech-to-text recognition model&lt;/td&gt; &#xA;   &lt;td&gt;Answer your questions basing on a context&lt;/td&gt; &#xA;   &lt;td&gt;Annotate text on images using text recognition resnet&lt;/td&gt; &#xA;   &lt;td&gt;OCR for handwritten simplified Chinese and Japanese&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/134784204-cf8f7800-b84c-47f5-a1d8-25a9afab88f8.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/140987347-279de058-55d7-4772-b013-0f2b12deaa61.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/152571639-ace628b2-e3d2-433e-8c28-9a5546d76a86.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/129315292-a37266dc-dfb2-4749-bca5-2ac9c1e93d64.jpg&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img width=&#34;425&#34; alt=&#34;handwritten_simplified_chinese_test&#34; src=&#34;https://user-images.githubusercontent.com/36741649/132660640-da2211ec-c389-450e-8980-32a75ed14abb.png&#34;&gt; &lt;br&gt; ÁöÑ‰∫∫‰∏ç‰∏Ä‰∫ÜÊòØ‰ªñÊúâ‰∏∫Âú®Ë¥£Êñ∞‰∏≠‰ªªËá™‰πãÊàë‰ª¨&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;More amazing notebooks here!&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt; Click here to show complete list! &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Notebook&lt;/th&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Preview&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/201-vision-monodepth/&#34;&gt;201-vision-monodepth&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F201-vision-monodepth%2F201-vision-monodepth.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Monocular depth estimation with images and video&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127752390-f6aa371f-31b5-4846-84b9-18dd4f662406.gif&#34; width=&#34;250&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/202-vision-superresolution/&#34;&gt;202-vision-superresolution-image&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F202-vision-superresolution%2F202-vision-superresolution-image.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Upscale raw images with a super resolution model&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/170005347-e4409f9e-ec34-416b-afdf-a9d8185929ca.jpg&#34; width=&#34;70&#34;&gt;‚Üí&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/170005347-e4409f9e-ec34-416b-afdf-a9d8185929ca.jpg&#34; width=&#34;130&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/202-vision-superresolution/&#34;&gt;202-vision-superresolution-video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F202-vision-superresolution%2F202-vision-superresolution-video.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Turn 360p into 1080p video using a super resolution model&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127269258-a8e2c03e-731e-4317-b5b2-ed2ee767ff5e.gif&#34; width=&#34;80&#34;&gt;‚Üí&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127269258-a8e2c03e-731e-4317-b5b2-ed2ee767ff5e.gif&#34; width=&#34;125&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/203-meter-reader/&#34;&gt;203-meter-reader&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F203-meter-reader%2F203-meter-reader.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;PaddlePaddle pre-trained models to read industrial meter&#39;s value&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91237924/166135627-194405b0-6c25-4fd8-9ad1-83fb3a00a081.jpg&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/204-named-entity-recognition/&#34;&gt;204-named-entity-recognition&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F204-named-entity-recognition%2F204-named-entity-recognition.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Perform named entity recognition on simple text&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/33627846/169470030-0370963e-6ad8-49e3-be7a-f02a2c677733.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/205-vision-background-removal/&#34;&gt;205-vision-background-removal&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F205-vision-background-removal%2F205-vision-background-removal.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Remove and replace the background in an image using salient object detection&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/125184237-f4b6cd00-e1d0-11eb-8e3b-d92c9a728372.png&#34; width=&#34;455&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/206-vision-paddlegan-anime/&#34;&gt;206-vision-paddlegan-anime&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F206-vision-paddlegan-anime%2F206-vision-paddlegan-anime.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Turn an image into anime using a GAN&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127788059-1f069ae1-8705-4972-b50e-6314a6f36632.jpeg&#34; width=&#34;100&#34;&gt;‚Üí&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/125184441-b4584e80-e1d2-11eb-8964-d8131cd97409.png&#34; width=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/207-vision-paddlegan-superresolution/&#34;&gt;207-vision-paddlegan-superresolution&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F207-vision-paddlegan-superresolution%2F207-vision-paddlegan-superresolution.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Upscale small images with superresolution using a PaddleGAN model&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/208-optical-character-recognition/&#34;&gt;208-optical-character-recognition&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Annotate text on images using text recognition resnet&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/129315292-a37266dc-dfb2-4749-bca5-2ac9c1e93d64.jpg&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/209-handwritten-ocr/&#34;&gt;209-handwritten-ocr&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F209-handwritten-ocr%2F209-handwritten-ocr.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;OCR for handwritten simplified Chinese and Japanese&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img width=&#34;425&#34; alt=&#34;handwritten_simplified_chinese_test&#34; src=&#34;https://user-images.githubusercontent.com/36741649/132660640-da2211ec-c389-450e-8980-32a75ed14abb.png&#34;&gt; &lt;br&gt; ÁöÑ‰∫∫‰∏ç‰∏Ä‰∫ÜÊòØ‰ªñÊúâ‰∏∫Âú®Ë¥£Êñ∞‰∏≠‰ªªËá™‰πãÊàë‰ª¨&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/210-ct-scan-live-inference/&#34;&gt;210-ct-scan-live-inference&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F210-ct-scan-live-inference%2F210-ct-scan-live-inference.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Show live inference on segmentation of CT-scan data&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/77325899/154280563-0e94f972-2d1a-44f9-a894-1b61699d1781.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/211-speech-to-text/&#34;&gt;211-speech-to-text&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F211-speech-to-text%2F211-speech-to-text.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Run inference on speech-to-text recognition model&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/36741649/140987347-279de058-55d7-4772-b013-0f2b12deaa61.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/212-onnx-style-transfer/&#34;&gt;212-onnx-style-transfer&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F212-onnx-style-transfer%2F212-onnx-style-transfer.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Transform images to five different styles with neural style transfer&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/77325899/147358090-ff5b21f5-0efb-4aff-8444-9d07add49b92.png&#34; width=&#34;100&#34;&gt;‚Üí&lt;img src=&#34;https://user-images.githubusercontent.com/77325899/147358009-0cf10d51-3150-40cb-a776-074558b98da5.png&#34; width=&#34;100&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/213-question-answering/&#34;&gt;213-question-answering&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F213-question-answering%2F213-question-answering.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Answer your questions basing on a context&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/152571639-ace628b2-e3d2-433e-8c28-9a5546d76a86.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/214-vision-paddle-classification/&#34;&gt;214-vision-paddle-classification&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F214-vision-paddle-classification%2F214-vision-paddle-classification.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;PaddlePaddle Image Classification with OpenVINO&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/215-image-inpainting/&#34;&gt;215-image-inpainting&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F215-image-inpainting%2F215-image-inpainting.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Fill missing pixels with image in-painting&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/167121084-ec58fbdb-b269-4de2-9d4c-253c5b95de1e.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/216-license-plate-recognition/&#34;&gt;216-license-plate-recognition&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F216-license-plate-recognition%2F216-license-plate-recognition.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Recognize Chinese license plates in traffic&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/70456146/162759539-4a0a996f-dabe-40ea-98d6-85b4dce8511d.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/217-vision-deblur/&#34;&gt;217-vision-deblur&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/217-vision-deblur?labpath=notebooks%2F217-vision-deblur%2F217-vision-deblur.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Deblur Images with DeblurGAN-v2&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/41332813/158430181-05d07f42-cdb8-4b7a-b7dc-e7f7d9391877.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/218-vehicle-detection-and-recognition/&#34;&gt;218-vehicle-detection-and-recognition&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F218-vehicle-detection-and-recognition%2F218-vehicle-detection-and-recognition.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Use pre-trained models to detect and recognize vehicles and their attributes with OpenVINO&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/47499836/163544861-fa2ad64b-77df-4c16-b065-79183e8ed964.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/219-knowledge-graphs-conve/&#34;&gt;219-knowledge-graphs-conve&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F219-knowledge-graphs-conve%2F219-knowledge-graphs-conve.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Optimize the knowledge graph embeddings model (ConvE) with OpenVINO&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/220-yolov5-accuracy-check-and-quantization&#34;&gt;220-yolov5-accuracy-check-and-quantization&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Quantize the Ultralytics YOLOv5 model and check accuracy using the OpenVINO POT API&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/44352144/177097174-cfe78939-e946-445e-9fce-d8897417ef8e.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/221-machine-translation&#34;&gt;221-machine-translation&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F221-machine-translation%2F221-machine-translation.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Real-time translation from English to German&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/222-vision-image-colorization/&#34;&gt;222-vision-image-colorization&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F222-vision-image-colorization%2F222-vision-image-colorization.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Use pre-trained models to colorize black &amp;amp; white images using OpenVINO&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/18904157/166343139-c6568e50-b856-4066-baef-5cdbd4e8bc18.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/223-gpt2-text-prediction/&#34;&gt;223-gpt2-text-prediction&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;left&#34;&gt;Use GPT-2 to perform text prediction on an input sequence&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/91228207/185105225-0f996b0b-0a3b-4486-872d-364ac6fab68b.png&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-model-training&#34;&gt;&lt;/div&gt; &#xA;&lt;h3&gt;üèÉ Model Training&lt;/h3&gt; &#xA;&lt;p&gt;Tutorials that include code to train neural networks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Notebook&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Preview&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/301-tensorflow-training-openvino/&#34;&gt;301-tensorflow-training-openvino&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Train a flower classification model from TensorFlow, then convert to OpenVINO IR&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127779607-8fa34947-1c35-4260-8d04-981c41a2a2cc.png&#34; width=&#34;390&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/301-tensorflow-training-openvino/&#34;&gt;301-tensorflow-training-openvino-pot&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Use Post-training Optimization Tool (POT) to quantize the flowers model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/302-pytorch-quantization-aware-training/&#34;&gt;302-pytorch-quantization-aware-training&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Use Neural Network Compression Framework (NNCF) to quantize PyTorch model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/305-tensorflow-quantization-aware-training/&#34;&gt;305-tensorflow-quantization-aware-training&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Use Neural Network Compression Framework (NNCF) to quantize TensorFlow model&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;div id=&#34;-live-demos&#34;&gt;&lt;/div&gt; &#xA;&lt;h3&gt;üì∫ Live Demos&lt;/h3&gt; &#xA;&lt;p&gt;Live inference demos that run on a webcam or video files.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/401-object-detection-webcam/&#34;&gt;401-object-detection-webcam&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F401-object-detection-webcam%2F401-object-detection.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/402-pose-estimation-webcam/&#34;&gt;402-pose-estimation-webcam&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F402-pose-estimation-webcam%2F402-pose-estimation.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/403-action-recognition-webcam/&#34;&gt;403-action-recognition-webcam&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?filepath=notebooks%2F403-action-recognition-webcam%2F403-action-recognition-webcam.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/405-paddle-ocr-webcam/&#34;&gt;405-paddle-ocr-webcam&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://mybinder.org/v2/gh/openvinotoolkit/openvino_notebooks/HEAD?labpath=notebooks%2F405-paddle-ocr-webcam%2F405-paddle-ocr-webcam.ipynb&#34;&gt;&lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;Binder&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Object detection with a webcam or video file&lt;/td&gt; &#xA;   &lt;td&gt;Human pose estimation with a webcam or video file&lt;/td&gt; &#xA;   &lt;td&gt;Human action recognition with a webcam or video file&lt;/td&gt; &#xA;   &lt;td&gt;OCR with a webcam or video file&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/141471665-82b28c86-cf64-4bfe-98b3-c314658f2d96.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/138267961-41d754e7-59db-49f6-b700-63c3a636fad7.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/151552326-642d6e49-f5a0-4fc1-bf14-ae3f457e1fec.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yoyowz/classification/master/images/paddleocr.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;If you run into issues, please check the &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-troubleshooting&#34;&gt;troubleshooting section&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-faq&#34;&gt;FAQs&lt;/a&gt; or start a GitHub &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/discussions&#34;&gt;discussion&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Notebooks with a &lt;img src=&#34;https://mybinder.org/badge_logo.svg?sanitize=true&#34; alt=&#34;binder logo&#34;&gt; button can be run without installing anything. &lt;a href=&#34;https://mybinder.org/&#34;&gt;Binder&lt;/a&gt; is a free online service with limited resources. For the best performance, please follow the &lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-installation-guide&#34;&gt;Installation Guide&lt;/a&gt; and run the notebooks locally.&lt;/p&gt; &#xA;&lt;p&gt;You will have a lot of fun with this section:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/201-vision-monodepth/&#34;&gt;Vision-monodepth&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/210-ct-scan-live-inference/&#34;&gt;CT-scan-live-inference&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/401-object-detection-webcam/&#34;&gt;Object-detection-webcam&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/402-pose-estimation-webcam/&#34;&gt;Pose-estimation-webcam&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/notebooks/403-action-recognition-webcam/&#34;&gt;Action-recognition-webcam&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/127752390-f6aa371f-31b5-4846-84b9-18dd4f662406.gif&#34; width=&#34;250&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/134784204-cf8f7800-b84c-47f5-a1d8-25a9afab88f8.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/141471665-82b28c86-cf64-4bfe-98b3-c314658f2d96.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/4547501/138267961-41d754e7-59db-49f6-b700-63c3a636fad7.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/151552326-642d6e49-f5a0-4fc1-bf14-ae3f457e1fec.gif&#34; width=&#34;225&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-system-requirements&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;‚öôÔ∏è System Requirements&lt;/h2&gt; &#xA;&lt;p&gt;The notebooks run almost anywhere ‚Äî your laptop, a cloud VM, or even a Docker container. The table below lists the supported operating systems and Python versions. &lt;strong&gt;Note:&lt;/strong&gt; Python 3.10 is not supported yet.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Supported Operating System&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;Python Version (64-bit)&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ubuntu 18.04 LTS, 64-bit&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Ubuntu 20.04 LTS, 64-bit&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Red Hat Enterprise Linux 8, 64-bit&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;CentOS 7, 64-bit&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;macOS 10.15.x versions&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows 10, 64-bit Pro, Enterprise or Education editions&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Windows Server 2016 or higher&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;3.6, 3.7, 3.8, 3.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-run-the-notebooks&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;üíª Run the Notebooks&lt;/h2&gt; &#xA;&lt;h3&gt;To Launch a Single Notebook&lt;/h3&gt; &#xA;&lt;p&gt;If you wish to launch only one notebook, like the Monodepth notebook, run the command below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter 201-vision-monodepth.ipynb&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;To Launch all Notebooks&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter lab notebooks&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In your browser, select a notebook from the file browser in Jupyter Lab using the left sidebar. Each tutorial is located in a subdirectory within the &lt;code&gt;notebooks&lt;/code&gt; directory.&lt;/p&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/15709723/120527271-006fd200-c38f-11eb-9935-2d36d50bab9f.gif&#34;&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-cleaning-up&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;üßπ Cleaning Up&lt;/h2&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;Shut Down Jupyter Kernel&lt;/summary&gt; &#xA; &lt;p&gt;To end your Jupyter session, press &lt;code&gt;Ctrl-c&lt;/code&gt;. This will prompt you to &lt;code&gt;Shutdown this Jupyter server (y/[n])?&lt;/code&gt; enter &lt;code&gt;y&lt;/code&gt; and hit &lt;code&gt;Enter&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;Deactivate Virtual Environment&lt;/summary&gt; &#xA; &lt;p&gt;To deactivate your virtualenv, simply run &lt;code&gt;deactivate&lt;/code&gt; from the terminal window where you activated &lt;code&gt;openvino_env&lt;/code&gt;. This will deactivate your environment.&lt;/p&gt; &#xA; &lt;p&gt;To reactivate your environment, run &lt;code&gt;source openvino_env/bin/activate&lt;/code&gt; on Linux or &lt;code&gt;openvino_env\Scripts\activate&lt;/code&gt; on Windows, then type &lt;code&gt;jupyter lab&lt;/code&gt; or &lt;code&gt;jupyter notebook&lt;/code&gt; to launch the notebooks again.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;Delete Virtual Environment _(Optional)_&lt;/summary&gt; &#xA; &lt;p&gt;To remove your virtual environment, simply delete the &lt;code&gt;openvino_env&lt;/code&gt; directory:&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;On Linux and macOS:&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rm -rf openvino_env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;On Windows:&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rmdir /s openvino_env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;details&gt; &#xA; &lt;summary&gt;Remove openvino_env Kernel from Jupyter&lt;/summary&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter kernelspec remove openvino_env&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-troubleshooting&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;‚ö†Ô∏è Troubleshooting&lt;/h2&gt; &#xA;&lt;p&gt;If these tips do not solve your problem, please open a &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/discussions&#34;&gt;discussion topic&lt;/a&gt; or create an &lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/issues&#34;&gt;issue&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;To check some common installation problems, run &lt;code&gt;python check_install.py&lt;/code&gt;. This script is located in the openvino_notebooks directory. Please run it after activating the &lt;code&gt;openvino_env&lt;/code&gt; virtual environment.&lt;/li&gt; &#xA; &lt;li&gt;If you get an &lt;code&gt;ImportError&lt;/code&gt;, doublecheck that you installed the Jupyter kernel. If necessary, choose the openvino_env kernel from the &lt;em&gt;Kernel-&amp;gt;Change Kernel&lt;/em&gt; menu) in Jupyter Lab or Jupyter Notebook&lt;/li&gt; &#xA; &lt;li&gt;If OpenVINO is installed globally, do not run installation commands in a terminal where setupvars.bat or setupvars.sh are sourced.&lt;/li&gt; &#xA; &lt;li&gt;For Windows installation, we recommend using &lt;em&gt;Command Prompt (cmd.exe)&lt;/em&gt;, not &lt;em&gt;PowerShell&lt;/em&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/main/#-contributors&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-contributors&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;üßë‚Äçüíª Contributors&lt;/h2&gt; &#xA;&lt;a href=&#34;https://github.com/openvinotoolkit/openvino_notebooks/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=openvinotoolkit/openvino_notebooks&#34;&gt; &lt;/a&gt; &#xA;&lt;p&gt;Made with &lt;a href=&#34;https://contrib.rocks&#34;&gt;contributors-img&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/10940214/155750931-fc094349-b6ec-4e1f-9f9a-113e67941119.jpg&#34; alt=&#34;-----------------------------------------------------&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;div id=&#34;-faq&#34;&gt;&lt;/div&gt; &#xA;&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.openvino.ai/2022.1/openvino_docs_OV_UG_supported_plugins_Supported_Devices.html&#34;&gt;Which devices does OpenVINO support?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/system-requirements.html&#34;&gt;What is the first CPU generation you support with OpenVINO?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/internet-of-things/ai-in-production/success-stories.html&#34;&gt;Are there any success stories about deploying real-world solutions with OpenVINO?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;* Other names and brands may be claimed as the property of others.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>microsoft/dotnetconf-studentzone</title>
    <updated>2022-11-09T01:38:30Z</updated>
    <id>tag:github.com,2022-11-09:/microsoft/dotnetconf-studentzone</id>
    <link href="https://github.com/microsoft/dotnetconf-studentzone" rel="alternate"></link>
    <summary type="html">&lt;p&gt;.NET Student Zone .NET Conference 2022&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/images/EventCard_10banner.png&#34; alt=&#34;BannerImage&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;.NET Conf 2022 Student Zone&lt;/h1&gt; &#xA;&lt;h2&gt;‚≠êNovember 7, 2022‚≠ê&lt;/h2&gt; &#xA;&lt;p&gt;Are you a student wanting to learn .NET? We have a pre-conference day with a ton of content you don&#39;t want to miss! &lt;strong&gt;You will walk away with a project portfolio on your very own portfolio website&lt;/strong&gt; ‚Äì don&#39;t worry, we will build it right along with you. We will have two sessions, a midday session at 12:00 PM UTC and an evening session at 10:30 PM UTC.&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#net-conference-2022-student-zone&#34;&gt;.NET Conference 2022 Student Zone&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#november-7-2022&#34;&gt;‚≠êNovember 7, 2022‚≠ê&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#what-is-the-net-conf-student-zone&#34;&gt;What is the .NET Conf Student Zone?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#when-is-the-student-zone&#34;&gt;When is the Student Zone?&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#register-for-the-event&#34;&gt;Register for the event&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#join-the-challenge-to-win-swag-&#34;&gt;Join the challenge to win SWAG üéÅüéâ&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#more-event-and-setup-information&#34;&gt;More Event and Setup Information&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#agenda&#34;&gt;Agenda&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#using-this-repo-and-development-container&#34;&gt;Using this repo and development container&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#github-codespaces&#34;&gt;GitHub Codespaces&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#vs-code-remote---containers&#34;&gt;VS Code Remote - Containers&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#student-resources&#34;&gt;Student Resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#learning-resources&#34;&gt;Learning Resources&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#speakers&#34;&gt;Speakers&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/#trademarks&#34;&gt;Trademarks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What is the .NET Conf Student Zone?&lt;/h2&gt; &#xA;&lt;p&gt;As part of &lt;a href=&#34;https://www.dotnetconf.net/&#34;&gt;.NET Conf this year&lt;/a&gt;, we are hosting a .NET Student Zone on Monday, November 7! This is a livestreamed event where experts will introduce you to .NET and and build awesome, follow-along projects. You will walk away with a project portfolio on your very own portfolio website. In total the event will be 4+ hours of content.&lt;/p&gt; &#xA;&lt;h2&gt;When is the Student Zone?&lt;/h2&gt; &#xA;&lt;p&gt;‚≠ê&lt;strong&gt;November 7, 2022&lt;/strong&gt;‚≠ê&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Session 1&lt;/strong&gt; (12:00PM UTC | 07:00AM EST): Europe, Middle East, Africa, Asia Pacific Timezones&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Session 2&lt;/strong&gt; (10:30PM UTC | 05:30PM EST): North and South America Timezones&lt;/p&gt; &#xA;&lt;h2&gt;Register for the event&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://aka.ms/dotnetstudentemea&#34;&gt;Session 1 - Europe, Middle East, Africa, Asia Pacific - Register Now&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://aka.ms/dotnetstudentamerica&#34;&gt;Session 2 - North and South America - Register Now&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Join the challenge to win SWAG üéÅüéâ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://aka.ms/dotnetstudententry&#34;&gt;Join the .NET Conf Student Zone Microsoft Learn, Cloud Skills Challenge and Win Swag&lt;/a&gt; After enjoying the .NET Conf Student Zone, you will be ready to complete the .NET Conf Student Zone Cloud Skills Challenge. The challenge is open to all students who registered for .NET Conf on November 7 and three lucky winners will get a .NET Conf SWAG bag!&lt;/p&gt; &#xA;&lt;h2&gt;Digital Swag for the .NET Conf Student Zone üéÅüéâ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://aka.ms/vscodepet&#34;&gt;Download .NET Bot digital pet for VSCode&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/images/dotnetbotpet.jpg&#34; alt=&#34;DotNetPet&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Puts a small, .NET Bot, bored cat, an enthusiastic dog, a feisty snake, a rubber duck, or Clippy üìé in your VS Code editor to boost productivity.&lt;/p&gt; &#xA;&lt;h1&gt;More Event and Setup Information&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/images/EventCard_10Speaker.png&#34; alt=&#34;SpeakerBanner&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Agenda&lt;/h2&gt; &#xA;&lt;p&gt;In each session, you will build an app or project to add to your .NET portfolio. You will build web apps, a mobile app, an ML project, and more!&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Session Title&lt;/th&gt; &#xA;   &lt;th&gt;Speaker(s)&lt;/th&gt; &#xA;   &lt;th&gt;Tools&lt;/th&gt; &#xA;   &lt;th&gt;Session Code&lt;/th&gt; &#xA;   &lt;th&gt;Video&lt;/th&gt; &#xA;   &lt;th&gt;Presentation&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Welcome to the Student Zone!&lt;/td&gt; &#xA;   &lt;td&gt;Scott Hanselman, Katie Savage&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=90&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Create a GitHub Profile&lt;/td&gt; &#xA;   &lt;td&gt;Bethany Jepchumba&lt;/td&gt; &#xA;   &lt;td&gt;GitHub&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Create%20a%20GitHub%20Profile&#34;&gt;Create a GitHub Profile&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=972&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Coming Soon&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Build your Project Portfolio website with .NET&lt;/td&gt; &#xA;   &lt;td&gt;Matt Soucoup&lt;/td&gt; &#xA;   &lt;td&gt;Blazor&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Build%20your%20Project%20Portfolio%20website%20with%20.NET/README.md&#34;&gt;Project Portfolio with Blazor Session&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=2596&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Coming Soon&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Detect water bottle consumption from IoT sensors&lt;/td&gt; &#xA;   &lt;td&gt;Krzysztof Wicher&lt;/td&gt; &#xA;   &lt;td&gt;IoT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Using%20IOT%20and%20.NET/README.md&#34;&gt;IOT Session&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=5091&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/raw/main/decks/Using-IOT-and-NET.pdf&#34;&gt;Presentation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Use machine learning to estimate future water consumption&lt;/td&gt; &#xA;   &lt;td&gt;Carlotta Castelluccio&lt;/td&gt; &#xA;   &lt;td&gt;ML.NET&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Using%20ML.NET%20for%20Machine%20Learning/README.md&#34;&gt;ML.NET Session&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=8147&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/raw/main/decks/DotNet_StudentZone%20-%20Use%20ML%20to%20estimate%20water%20consumption.pdf&#34;&gt;Presentation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Add a backend to your website&lt;/td&gt; &#xA;   &lt;td&gt;Chris Noring&lt;/td&gt; &#xA;   &lt;td&gt;Minimal API&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Add%20a%20backend%20to%20your%20website/README.md&#34;&gt;Adding Backend&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=8147&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Coming Soon&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Build a mobile app to track water consumption&lt;/td&gt; &#xA;   &lt;td&gt;Someleze Diko&lt;/td&gt; &#xA;   &lt;td&gt;.NET MAUI&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/microsoft/dotnetconf-studentzone/main/Using%20.NET%20MAUI%20to%20Build%20a%20Mobile%20App/Readme.md&#34;&gt;using .NET MAUI to Build a Mobile App&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=11774&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/raw/main/decks/Using-NET-MAUI-to-create-a-Mobile-App.pdf&#34;&gt;Presentation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Build a water consumption tracker website&lt;/td&gt; &#xA;   &lt;td&gt;Justin Yoo&lt;/td&gt; &#xA;   &lt;td&gt;Blazor&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Using%20.NET%20Blazor%20to%20Build%20a%20Web%20App/README.md&#34;&gt;Blazor Session&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=14022&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;em&gt;Coming Soon&lt;/em&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Ace your next assignment with .NET&lt;/td&gt; &#xA;   &lt;td&gt;Diego Colombo&lt;/td&gt; &#xA;   &lt;td&gt;Visual Studio&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/tree/main/Next%20Steps%20Getting%20Top%20Marks%20for%20your%20next%20assignment/README.md&#34;&gt;.NET and TDD Session&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://youtu.be/SCJu7YPNtdQ?t=16397&#34;&gt;Watch On-Demand&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/dotnetconf-studentzone/raw/main/decks/Next%20Steps%20Getting%20Top%20Marks%20for%20your%20next%20assignment.pdf&#34;&gt;Presentation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Using this repo and development container&lt;/h2&gt; &#xA;&lt;h3&gt;GitHub Codespaces&lt;/h3&gt; &#xA;&lt;p&gt;Follow these steps to open this sample in a Codespace:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Click the Code drop-down menu and select the &lt;strong&gt;Open with Codespaces&lt;/strong&gt; option.&lt;/li&gt; &#xA; &lt;li&gt;Select &lt;strong&gt;+ New codespace&lt;/strong&gt; at the bottom on the pane.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;For more info, check out the &lt;a href=&#34;https://docs.github.com/en/free-pro-team@latest/github/developing-online-with-codespaces/creating-a-codespace#creating-a-codespace&#34;&gt;GitHub documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;VS Code Remote - Containers&lt;/h3&gt; &#xA;&lt;p&gt;Follow these steps to open this sample in a container using the VS Code Remote - Containers extension:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;If this is your first time using a development container, please ensure your system meets the pre-reqs (i.e. have Docker installed) in the &lt;a href=&#34;https://aka.ms/vscode-remote/containers/getting-started&#34;&gt;getting started steps&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To use this repository, you can either open the repository in an isolated Docker volume:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Press &lt;kbd&gt;F1&lt;/kbd&gt; and select the &lt;strong&gt;Remote-Containers: Try a Sample...&lt;/strong&gt; command.&lt;/li&gt; &#xA;   &lt;li&gt;Choose the &#34;Python&#34; sample, wait for the container to start, and try things out! &#xA;    &lt;blockquote&gt; &#xA;     &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Under the hood, this will use the &lt;strong&gt;Remote-Containers: Clone Repository in Container Volume...&lt;/strong&gt; command to clone the source code in a Docker volume instead of the local filesystem. &lt;a href=&#34;https://docs.docker.com/storage/volumes/&#34;&gt;Volumes&lt;/a&gt; are the preferred mechanism for persisting container data.&lt;/p&gt; &#xA;    &lt;/blockquote&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Or open a locally cloned copy of the code:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Clone this repository to your local filesystem.&lt;/li&gt; &#xA;   &lt;li&gt;Press &lt;kbd&gt;F1&lt;/kbd&gt; and select the &lt;strong&gt;Remote-Containers: Open Folder in Container...&lt;/strong&gt; command.&lt;/li&gt; &#xA;   &lt;li&gt;Select the cloned copy of this folder, wait for the container to start, and try things out!&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rebuild or update your container&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;You may want to make changes to your container, such as installing a different version of a software or forwarding a new port. You&#39;ll rebuild your container for your changes to take effect.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Open browser automatically:&lt;/strong&gt; As an example change, let&#39;s update the &lt;code&gt;portsAttributes&lt;/code&gt; in the &lt;code&gt;.devcontainer/devcontainer.json&lt;/code&gt; file to open a browser when our port is automatically forwarded.&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Open the &lt;code&gt;.devcontainer/devcontainer.json&lt;/code&gt; file.&lt;/li&gt; &#xA;   &lt;li&gt;Modify the &lt;code&gt;&#34;onAutoForward&#34;&lt;/code&gt; attribute in your &lt;code&gt;portsAttributes&lt;/code&gt; from &lt;code&gt;&#34;notify&#34;&lt;/code&gt; to &lt;code&gt;&#34;openBrowser&#34;&lt;/code&gt;.&lt;/li&gt; &#xA;   &lt;li&gt;Press &lt;kbd&gt;F1&lt;/kbd&gt; and select the &lt;strong&gt;Remote-Containers: Rebuild Container&lt;/strong&gt; or &lt;strong&gt;Codespaces: Rebuild Container&lt;/strong&gt; command so the modifications are picked up.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Student Resources&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/learnstudent&#34;&gt;Microsoft Student Resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/dotnetstudentcsc&#34;&gt;.NET Student Zone Cloud Skills Challenge&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/azure4student&#34;&gt;Azure for Student&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/GitHubStudentPack&#34;&gt;GitHub Student Developer Pack&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Learning Resources&lt;/h1&gt; &#xA;&lt;p&gt;Want more .NET Learning resources?&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/mslearn-dotnet&#34;&gt;Learn more C# and .NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/dotnetvideos&#34;&gt;Beginner video series&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aka.ms/mslearn-dotnet&#34;&gt;.NET Learning Paths on Microsoft Learn&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/blazorvideos&#34;&gt;Beginner Videos on Blazor, .NET MAUI, ML.NET, and more&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/dotnetdoc&#34;&gt;.NET Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/MAUIcrossplat&#34;&gt;.NET MAUI&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/blazorwebapp&#34;&gt;Blazor Web Applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/dotnetminimalapi&#34;&gt;Minimal APIs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/trainmldotnet&#34;&gt;ML.NET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://aka.ms/dotnetIOT&#34;&gt;.NET IoT&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Watch &lt;a href=&#34;https://www.dotnetconf.net/&#34;&gt;.NET Conf&lt;/a&gt;! Sessions start November 8th.&lt;/p&gt; &#xA;&lt;h2&gt;Speakers&lt;/h2&gt; &#xA;&lt;p&gt;&lt;b&gt;Scott Hanselman&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Scott has been a developer for 30 years and has been blogging at hanselman.com for 20 years! He works in Open Source on .NET and the Azure Cloud for Microsoft out of his home office in Portland, Oregon. Scott has been podcasting for over 800 episodes of hanselminutes.com over 15 years and 700 episodes of azurefriday.com. He&#39;s written a number of technical books and spoken in person to over one million developers worldwide! He&#39;s also on TikTok, which was very likely a huge mistake.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Katie Savage &lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Katie is a Product Manager on the DevDiv Community Team at Microsoft. Her focus is on students, career switchers, and new developers using C# and .NET! Before joining the Community Team, Katie was involved in Computer Science education as an intern with Microsoft MakeCode. These experience, as well as her involvement in Girls Who Code, have grown Katie‚Äôs passion for Computer Science education.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Bethany Jepchumba&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Bethany Jepchumba is an Academic Cloud Advocate at Microsoft, focused on Data Machine Learning and AI. Prior to joining the role, she was a Gold Microsoft Learn Student Ambassador. She comes from a community of marathon runners but decided to run code instead.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Matt Soucoup&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Matt is a Principal Cloud Developer Advocate for .NET at Microsoft spreading the love of developing for Azure with .NET. Matt&#39;s been a professional developer for over 20 years and wants to make your experience creating apps delightful. Matt blogs at codemillmatt.com, podcasts at dotnetmauipodcast.com and is just a Bing search away.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Krzysztof Wicher&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Krzysztof is a developer on the .NET team, currently working on System.Text.Json and one of the owners of the .NET IoT v-team. He&#39;s also one of the people who make .NET more secure. Before joining Microsoft, he studied control engineering and robotics.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Carlotta Castelluccio&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Carlotta Castelluccio is an Academic Cloud Advocate at Microsoft, focused on Machine Learning and AI. She works on skilling and engaging educational communities to create and grow with Azure Cloud, by contributing to technical learning content and supporting students and educators in their learning journey with Microsoft technologies. Before joining the Cloud Advocacy team, she has been working as an Azure and AI consultant in Microsoft Industry Solutions team, involved in customer-face engagements focused on Conversational AI solutions.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Chris Noring&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Chris is a Senior Academic cloud advocate at Microsoft, focused on App Dev. Chris also manages the feedback process as well as the academic learn portfolio. He‚Äôs a prolific speaker and published author on Go and JavaScript.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Someleze Diko&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Someleze is a Microsoft Academic Cloud Advocate that is enthusiastic about upskilling people from different communities using the different technologies at his disposal through being involved with initiatives that upskill and empower people.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Justin Yoo&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Justin is a Senior Cloud Advocate at Microsoft, specializing in Azure, .NET and Fusion Development. His main interests are app modernisation using Azure PaaS, Serverless, .NET and Power Platform.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;b&gt;Diego Colombo&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;I have spent most of my life building tools and frameworks for a wide set of industries: robotics, video games, finance, and developer tools. Creating next generation tools to enable developers and researcher to achieve their goals is my drive and passion, today I am lucky enough to work with the .NET Interactive team on modern developer experiences. I have contributed to the Microsoft XNA framework, Microsoft Robotics Studio, .NET interactive and other initiatives. My Academic background is rooted in Robotics and Realtime graphics, with a PhD on Realtime metaprogramming, I am still active giving some guest lectures and collaborating with external research partners on scientific publications. I have studied in Pisa and IMT Lucca and worked in very diverse companies, from start-up to corporation. Today I work on .NET Interactive and Polyglot Notebooks, bringing new workflows and tools to my friends out there. The .NET is vast and infinite.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Trademarks&lt;/h1&gt; &#xA;&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href=&#34;https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general&#34;&gt;Microsoft&#39;s Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.&lt;/p&gt;</summary>
  </entry>
</feed>