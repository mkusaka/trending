<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-12T01:44:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Kulbear/deep-learning-coursera</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/Kulbear/deep-learning-coursera</id>
    <link href="https://github.com/Kulbear/deep-learning-coursera" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deep Learning Specialization by Andrew Ng on Coursera.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deep Learning Specialization on Coursera&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Master Deep Learning, and Break into AI&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Instructor: &lt;a href=&#34;http://www.andrewng.org/&#34;&gt;Andrew Ng&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;This repo contains all my work for this specialization. All the code base, quiz questions, screenshot, and images, are taken from, unless specified, &lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization on Coursera&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What I want to say&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;VERBOSE CONTENT WARNING: YOU CAN JUMP TO THE NEXT SECTION IF YOU WANT&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;As a CS major student and a long-time self-taught learner, I have completed many CS related MOOCs on Coursera, Udacity, Udemy, and Edx. I do understand the hard time you spend on understanding new concepts and debugging your program. There are discussion forums on most MOOC platforms, however, even a question with detailed description may need some time to be answered. Here I released these solutions, which are &lt;strong&gt;only for your reference purpose&lt;/strong&gt;. It may help you to save some time. And I hope you don&#39;t copy any part of the code (the programming assignments are fairly easy if you read the instructions carefully), see the quiz solutions before you start your own adventure. This course is almost the simplest deep learning course I have ever taken, but the simplicity is based on the fabulous course content and structure. It&#39;s a treasure given by deeplearning.ai team.&lt;/p&gt; &#xA;&lt;p&gt;Currently, this repo has 3 major parts you may be interested in and I will give a list here.&lt;/p&gt; &#xA;&lt;h2&gt;Programming Assignments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb&#34;&gt;Week 2 - PA 1 - Logistic Regression with a Neural Network mindset&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Planar%20data%20classification%20with%20one%20hidden%20layer.ipynb&#34;&gt;Week 3 - PA 2 - Planar data classification with one hidden layer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step.ipynb&#34;&gt;Week 4 - PA 3 - Building your Deep Neural Network: Step by StepÂ¶&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20-%20Application.ipynb&#34;&gt;Week 4 - PA 4 - Deep Neural Network for Image Classification: Application&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Initialization.ipynb&#34;&gt;Week 1 - PA 1 - Initialization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Regularization.ipynb&#34;&gt;Week 1 - PA 2 - Regularization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Gradient%20Checking.ipynb&#34;&gt;Week 1 - PA 3 - Gradient Checking&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Optimization%20methods.ipynb&#34;&gt;Week 2 - PA 4 - Optimization Methods&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Tensorflow%20Tutorial.ipynb&#34;&gt;Week 3 - PA 5 - TensorFlow Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;There is no PA for this course. But this course comes with very interesting case study quizzes.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 4: Convolutional Neural Networks&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Step%20by%20Step%20-%20v1.ipynb&#34;&gt;Week 1 - PA 1 - Convolutional Model: step by step&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Application%20-%20v1.ipynb&#34;&gt;Week 1 - PA 2 - Convolutional Model: application&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Keras%20-%20Tutorial%20-%20Happy%20House%20v1.ipynb&#34;&gt;Week 2 - PA 1 - Keras - Tutorial - Happy House&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Residual%20Networks%20-%20v1.ipynb&#34;&gt;Week 2 - PA 2 - Residual Networks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 5: Sequence Models&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Sequence%20Models/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step%20-%20v2.ipynb&#34;&gt;Week 1 - PA 1 - Building a Recurrent Neural Network - Step by Step&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb&#34;&gt;Week 1 - PA 2 - Character level language model - Dinosaurus land&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quiz Solutions&lt;/h2&gt; &#xA;&lt;p&gt;There are concerns that some people may use the content here to quickly ace the course so I&#39;ll no longer update any quiz solution.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md&#34;&gt;Week 1 Quiz - Introduction to deep learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%202%20Quiz%20-%20Neural%20Network%20Basics.md&#34;&gt;Week 2 Quiz - Neural Network Basics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%203%20Quiz%20-%20%20Shallow%20Neural%20Networks.md&#34;&gt;Week 3 Quiz - Shallow Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%204%20Quiz%20-%20Key%20concepts%20on%20Deep%20Neural%20Networks.md&#34;&gt;Week 4 Quiz - Key concepts on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%201%20Quiz%20-%20Practical%20aspects%20of%20deep%20learning.md&#34;&gt;Week 1 Quiz - Practical aspects of deep learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%202%20Quiz%20-%20Optimization%20algorithms.md&#34;&gt;Week 2 Quiz - Optimization algorithms&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%203%20Quiz%20-%20Hyperparameter%20tuning%2C%20Batch%20Normalization%2C%20Programming%20Frameworks.md&#34;&gt;Week 3 Quiz - Hyperparameter tuning, Batch Normalization, Programming Frameworks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).md&#34;&gt;Week 1 Quiz - Bird recognition in the city of Peacetopia (case study)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).md&#34;&gt;Week 2 Quiz - Autonomous driving (case study)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;del&gt;- Course 4: Convolutional Neural Networks&lt;/del&gt; &lt;del&gt;- Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;## Important Slide Notes&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;I screenshotted some important slide page and store them into GitHub issues. It seems not very helpful for everyone since I only keep those I think may be useful to me.&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/1&#34;&gt;Screenshots for Course 1: Neural Networks and Deep Learning&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/2&#34;&gt;Screenshots for Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/3&#34;&gt;Screenshots for Course 3: Structuring Machine Learning Projects&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/14&#34;&gt;Screenshots for Course 4: Convolutional Neural Networks&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- Screenshots for Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Milestones&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2017-08-17&lt;/strong&gt;: Finished the first-released 3 courses, YAY! ð&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>intel-analytics/BigDL</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/intel-analytics/BigDL</id>
    <link href="https://github.com/intel-analytics/BigDL" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Building Large-Scale AI Applications for Distributed Big Data&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/docs/readthedocs/image/bigdl_logo.jpg&#34; height=&#34;140px&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Building Large-Scale AI Applications for Distributed Big Data&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;BigDL makes it easy for data scientists and data engineers to build end-to-end, distributed AI applications. The &lt;strong&gt;BigDL 2.0&lt;/strong&gt; release combines the &lt;a href=&#34;https://github.com/intel-analytics/BigDL/tree/branch-0.14&#34;&gt;original BigDL&lt;/a&gt; and &lt;a href=&#34;https://github.com/intel-analytics/analytics-zoo&#34;&gt;Analytics Zoo&lt;/a&gt; projects, providing the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-dllib&#34;&gt;DLlib&lt;/a&gt;: distributed deep learning library for Apache Spark &lt;em&gt;(i.e., the original BigDL framework with Keras-style API and Spark ML pipeline support)&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-orca&#34;&gt;Orca&lt;/a&gt;: seamlessly scale out TensorFlow and PyTorch pipelines for distributed Big Data&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-rayonspark&#34;&gt;RayOnSpark&lt;/a&gt;: run Ray programs directly on Big Data clusters&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-chronos&#34;&gt;Chronos&lt;/a&gt;: scalable time series analysis using AutoML&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#ppml-privacy-preserving-machine-learning&#34;&gt;PPML&lt;/a&gt;: privacy preserving big data analysis and machine learning (&lt;em&gt;experimental&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Nano/Overview/nano.html&#34;&gt;Nano&lt;/a&gt;: automatically accelerate TensorFlow and PyTorch pipelines by applying model CPU optimizations&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more information, you may &lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;read the docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;You can use BigDL on &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/colab.html&#34;&gt;Google Colab&lt;/a&gt; without any installation. BigDL also includes a set of &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/notebooks.html&#34;&gt;notebooks&lt;/a&gt; that you can directly open and run in Colab.&lt;/p&gt; &#xA;&lt;p&gt;To install BigDL, we recommend using &lt;a href=&#34;https://docs.conda.io/projects/conda/en/latest/user-guide/install/&#34;&gt;conda&lt;/a&gt; environments.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n my_env &#xA;conda activate my_env&#xA;pip install bigdl &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install latest nightly build, use &lt;code&gt;pip install --pre --upgrade bigdl&lt;/code&gt;; see &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/python.html&#34;&gt;Python&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/scala.html&#34;&gt;Scala&lt;/a&gt; user guide for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with DLlib&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;DLlib&lt;/strong&gt; is a distributed deep learning library for Apache Spark; with DLlib, users can write distributed deep learning applications as standard Spark programs (using either Scala or Python APIs).&lt;/p&gt; &#xA;&lt;p&gt;First, call &lt;code&gt;initNNContext&lt;/code&gt; at the beginning of the code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.intel.analytics.bigdl.dllib.NNContext&#xA;val sc = NNContext.initNNContext()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, define the BigDL model using Keras-style API:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val input = Input[Float](inputShape = Shape(10))  &#xA;val dense = Dense[Float](12).inputs(input)  &#xA;val output = Activation[Float](&#34;softmax&#34;).inputs(dense)  &#xA;val model = Model(input, output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that, use &lt;code&gt;NNEstimator&lt;/code&gt; to train/predict/evaluate the model using Spark Dataframes and ML pipelines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val trainingDF = spark.read.parquet(&#34;train_data&#34;)&#xA;val validationDF = spark.read.parquet(&#34;val_data&#34;)&#xA;val scaler = new MinMaxScaler().setInputCol(&#34;in&#34;).setOutputCol(&#34;value&#34;)&#xA;val estimator = NNEstimator(model, CrossEntropyCriterion())  &#xA;        .setBatchSize(size).setOptimMethod(new Adam()).setMaxEpoch(epoch)&#xA;val pipeline = new Pipeline().setStages(Array(scaler, estimator))&#xA;&#xA;val pipelineModel = pipeline.fit(trainingDF)  &#xA;val predictions = pipelineModel.transform(validationDF)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/DLlib/Overview/nnframes.html&#34;&gt;NNframes&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/DLlib/Overview/keras-api.html&#34;&gt;Keras API&lt;/a&gt; user guides for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with Orca&lt;/h2&gt; &#xA;&lt;p&gt;Most AI projects start with a Python notebook running on a single laptop; however, one usually needs to go through a mountain of pains to scale it to handle larger data set in a distributed fashion. The &lt;em&gt;&lt;strong&gt;Orca&lt;/strong&gt;&lt;/em&gt; library seamlessly scales out your single node TensorFlow or PyTorch notebook across large clusters (so as to process distributed Big Data).&lt;/p&gt; &#xA;&lt;p&gt;First, initialize &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html&#34;&gt;Orca Context&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context, OrcaContext&#xA;&#xA;# cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;sc = init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, perform &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/data-parallel-processing.html&#34;&gt;data-parallel processing in Orca&lt;/a&gt; (supporting standard Spark Dataframes, TensorFlow Dataset, PyTorch DataLoader, Pandas, Pillow, etc.):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pyspark.sql.functions import array&#xA;&#xA;spark = OrcaContext.get_spark_session()&#xA;df = spark.read.parquet(file_path)&#xA;df = df.withColumn(&#39;user&#39;, array(&#39;user&#39;)) \  &#xA;       .withColumn(&#39;item&#39;, array(&#39;item&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, use &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/distributed-training-inference.html&#34;&gt;sklearn-style Estimator APIs in Orca&lt;/a&gt; to perform distributed &lt;em&gt;TensorFlow&lt;/em&gt;, &lt;em&gt;PyTorch&lt;/em&gt; or &lt;em&gt;Keras&lt;/em&gt; training and inference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tensorflow import keras&#xA;from bigdl.orca.learn.tf.estimator import Estimator&#xA;&#xA;user = keras.layers.Input(shape=[1])  &#xA;item = keras.layers.Input(shape=[1])  &#xA;feat = keras.layers.concatenate([user, item], axis=1)  &#xA;predictions = keras.layers.Dense(2, activation=&#39;softmax&#39;)(feat)  &#xA;model = keras.models.Model(inputs=[user, item], outputs=predictions)  &#xA;model.compile(optimizer=&#39;rmsprop&#39;,  &#xA;              loss=&#39;sparse_categorical_crossentropy&#39;,  &#xA;              metrics=[&#39;accuracy&#39;])&#xA;&#xA;est = Estimator.from_keras(keras_model=model)  &#xA;est.fit(data=df,  &#xA;        batch_size=64,  &#xA;        epochs=4,  &#xA;        feature_cols=[&#39;user&#39;, &#39;item&#39;],  &#xA;        label_cols=[&#39;label&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/QuickStart/orca-tf-quickstart.html&#34;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/QuickStart/orca-pytorch-quickstart.html&#34;&gt;PyTorch&lt;/a&gt; quickstart, as well as the &lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;document website&lt;/a&gt;, for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with RayOnSpark&lt;/h2&gt; &#xA;&lt;p&gt;Ray is an open source distributed framework for emerging AI applications. &lt;em&gt;&lt;strong&gt;RayOnSpark&lt;/strong&gt;&lt;/em&gt; allows users to directly run Ray programs on existing Big Data clusters, and directly write Ray code inline with their Spark code (so as to process the in-memory Spark RDDs or DataFrames).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context&#xA;&#xA;# cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;sc = init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2, init_ray_on_spark=True) &#xA;&#xA;import ray&#xA;&#xA;@ray.remote&#xA;class Counter(object):&#xA;      def __init__(self):&#xA;          self.n = 0&#xA;&#xA;      def increment(self):&#xA;          self.n += 1&#xA;          return self.n&#xA;&#xA;counters = [Counter.remote() for i in range(5)]&#xA;print(ray.get([c.increment.remote() for c in counters]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the RayOnSpark &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Ray/Overview/ray.html&#34;&gt;user guide&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Ray/QuickStart/ray-quickstart.html&#34;&gt;quickstart&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with Chronos&lt;/h2&gt; &#xA;&lt;p&gt;Time series prediction takes observations from previous time steps as input and predicts the values at future time steps. The &lt;em&gt;&lt;strong&gt;Chronos&lt;/strong&gt;&lt;/em&gt; library makes it easy to build end-to-end time series analysis by applying AutoML to extremely large-scale time series prediction.&lt;/p&gt; &#xA;&lt;p&gt;To train a time series model with AutoML, first initialize &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html&#34;&gt;Orca Context&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context&#xA;&#xA;#cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2, init_ray_on_spark=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, create &lt;em&gt;TSDataset&lt;/em&gt; for your data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.chronos.data import TSDataset&#xA;&#xA;tsdata_train, tsdata_valid, tsdata_test\&#xA;        = TSDataset.from_pandas(df, &#xA;                                dt_col=&#34;dt_col&#34;, &#xA;                                target_col=&#34;target_col&#34;, &#xA;                                with_split=True, &#xA;                                val_ratio=0.1, &#xA;                                test_ratio=0.1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, create an &lt;em&gt;AutoTSEstimator&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.chronos.autots import AutoTSEstimator&#xA;&#xA;autotsest = AutoTSEstimator(model=&#39;lstm&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, call &lt;code&gt;fit&lt;/code&gt; on &lt;em&gt;AutoTSEstimator&lt;/em&gt;, which applies AutoML to find the best model and hyper-parameters; it returns a &lt;em&gt;TSPipeline&lt;/em&gt; which can be used for prediction or evaluation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#train a pipeline with AutoML support&#xA;ts_pipeline = autotsest.fit(data=tsdata_train,&#xA;                            validation_data=tsdata_valid)&#xA;&#xA;#predict&#xA;ts_pipeline.predict(tsdata_test)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the Chronos &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Chronos/Overview/chronos.html&#34;&gt;user guide&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Chronos/QuickStart/chronos-autotsest-quickstart.html&#34;&gt;example&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;PPML (Privacy Preserving Machine Learning)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;BigDL PPML&lt;/strong&gt;&lt;/em&gt; provides a &lt;em&gt;Trusted Cluster Environment&lt;/em&gt; for protecting the end-to-end Big Data AI pipeline. It combines various low level hardware and software security technologies (e.g., Intel SGX, LibOS such as Graphene and Occlum, Federated Learning, etc.), and allows users to run unmodified Big Data analysis and ML/DL programs (such as Apache Spark, Apache Flink, Tensorflow, PyTorch, etc.) in a secure fashion on (private or public) cloud.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/PPML/Overview/ppml.html&#34;&gt;PPML user guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;More information&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;Document Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:bigdl-user-group+subscribe@googlegroups.com&#34;&gt;Mail List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/bigdl-user-group&#34;&gt;User Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Application/powered-by.html&#34;&gt;Powered-By&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Application/presentations.html&#34;&gt;Presentations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citing BigDL&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;ve found BigDL useful for your project, you may cite the &lt;a href=&#34;https://arxiv.org/abs/1804.05839&#34;&gt;paper&lt;/a&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{SOCC2019_BIGDL,&#xA;  title={BigDL: A Distributed Deep Learning Framework for Big Data},&#xA;  author={Dai, Jason (Jinquan) and Wang, Yiheng and Qiu, Xin and Ding, Ding and Zhang, Yao and Wang, Yanzhang and Jia, Xianyan and Zhang, Li (Cherry) and Wan, Yan and Li, Zhichao and Wang, Jiao and Huang, Shengsheng and Wu, Zhongyuan and Wang, Yang and Yang, Yuhao and She, Bowen and Shi, Dongjie and Lu, Qi and Huang, Kai and Song, Guoqiong},&#xA;  booktitle={Proceedings of the ACM Symposium on Cloud Computing},&#xA;  publisher={Association for Computing Machinery},&#xA;  pages={50--60},&#xA;  year={2019},&#xA;  series={SoCC&#39;19},&#xA;  doi={10.1145/3357223.3362707},&#xA;  url={https://arxiv.org/pdf/1804.05839.pdf}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Fafa-DL/Lhy_Machine_Learning</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/Fafa-DL/Lhy_Machine_Learning</id>
    <link href="https://github.com/Fafa-DL/Lhy_Machine_Learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;æå®æ¯2021æ¥å­£æºå¨å­¦ä¹ è¯¾ç¨è¯¾ä»¶åä½ä¸&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;æå®æ¯2021/2022æ¥å­£æºå¨å­¦ä¹ è¯¾ç¨è¯¾ä»¶åä½ä¸&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Fafa-DL/readme-data/main/Bilibili.png&#34; alt=&#34;BILIBILI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;éç£é¡»ç¥&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;ï¼éç£é¡»ç¥ï¼ç»ä¸è¯´æï¼ä¸ºæ¹ä¾¿ææç½è¯¾èµæä¸ä¼è´¨çµå­ä¹¦ç±çå®æ¶æ´æ°ç»´æ¤ï¼åå»ºäºä¸ä¸ªå¨çº¿å®æ¶ç½çæä»¶å¤¹ï¼æ¾å¨å¬ä¼å·ãå¥é½ä¼ä¸ç¹çç ç©¶çãï¼æ¬èè¯¾å¯¹åºåºå·ã05ãã&#xA;&#xA;UPå°2021&amp;amp;2022ææä½ä¸çæ°æ®èµææ´çæåå¥½äºï¼ç±äºæä»¶å¤ªå¤§ï¼å·²åæ­¥æ¾å¨ä¸è¿°ææå¨çº¿ç½çã&#xA;&#xA;å¨çº¿ç½çè½æ»¡è¶³è¯¥è¯¾ç¨æéèµæçå¨é¨éæ±ï¼é¾æ¥ææä¹ä¼åæ¶æ´æ°ï¼ç¥å¤§å®¶å­¦ä¹ é¡ºå©ã&#xA;&#xA;2022ä»å¨2021åºç¡ä¸è¿è¡å°è¡¥åï¼2021åå®¹åæäºåç½®ç¥è¯ï¼UPä¼å¨è§é¢æ é¢æä¸2022çæ ç­¾ï¼&#xA;&#xA;ppt/pdfæ¯æç´é¾ä¸è½½ã&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;æ´æ°æ¥å¿&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ¥æ&lt;/th&gt; &#xA;   &lt;th&gt;é¡¹ç®&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/03/16&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW1ãHW2ï¼åæ­¥æ´æ°å©æèä¾&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/03/26&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW3ãHW4è¯¾ä»¶ãä»£ç ãèä¾ï¼releaseé¡µåå¸HW1-HW4æ°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/01&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°éä¿®åå®¹To Learn Moreï¼åºæ¬æ¯æèå¸ä»å¹´ä¸æç®è®²èä»¥åè®²è¿çç¥è¯ç¹(æ§è§é¢)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/09&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°GAN å HW05&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/16&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Self-Supervised Learning å HW06&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/30&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Explainable AI&amp;amp;Adversarial Attack å HW07&amp;amp;HW08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/06&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Domain Adaptation å HW09&amp;amp;HW10&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/21&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°RL å HW11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/28&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Quantum ML&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/04&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Life-Long&amp;amp;Compression å HW12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/11&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Meta Learning å HW13&amp;amp;HW14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/18&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW15ï¼éçæèå¸è¯¾ç¨ç»è¯­è§é¢ä¸ä¼ ï¼2021æºå¨å­¦ä¹ åºæ¬ç»æå¦&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/12/20&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Githubæçï¼å é¤repoä¸­çppt/pdfç´æ¥æä¾ä¸è½½é¾æ¥ï¼æ»èµææ¾å¥&lt;a href=&#34;https://pan.baidu.com/s/13cxyIbvF0bEyytANLf58NQ&#34;&gt;ç¾åº¦äºç-æåç ï¼sv1i&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/17&lt;/td&gt; &#xA;   &lt;td&gt;2022æ¥å­£æºå¨å­¦ä¹ è¯¾ç¨ä»å¨21åºç¡ä¸è¿è¡å°è¡¥åï¼UPåæ­¥æ´æ°å®ç½è¡¥ååå®¹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/21&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 1:Introductionof Deep Learningè¡¥ååå®¹ï¼Githubæçå¤§æ´æ°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/25&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 2:What to do if my network fails to trainè¡¥ååå®¹ä¸HW2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/05&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 3:Images inputï¼HW3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/13&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 4 Sequence as inputï¼HW4&lt;br&gt;UPå°2021&amp;amp;2022ææä½ä¸çæ°æ®èµææ´çæåå¥½æ¾å¨å¬ä¼å·ãå¥é½ä¼ä¸ç¹çç ç©¶çã&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/18&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 5 Sequence to sequenceï¼HW5ï¼ç¸åºDataæ¾å¨å¬ä¼å·ç»´æ¤çç½çä¸­&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/05&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 7ä»¥åHW6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/16&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/23&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/30&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°Lecture 9 &amp;amp; Lecture10ï¼HW9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/06&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW10&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/13&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW11ï¼é¨åLecture10æå­¦è§é¢&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/24&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/30&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW13&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/06/10&lt;/td&gt; &#xA;   &lt;td&gt;æ´æ°HW14ãHW15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Bç«ä¸»é¡µ&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;å¥é½ä¼ä¸ç¹çç ç©¶ç&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æºè½ææ¯æ¢è®¨ç¾¤1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=lY5KVICA&#34;&gt;78174903&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æºè½ææ¯æ¢è®¨ç¾¤2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=ZCDCT3xV&#34;&gt;571218304&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æºè½ææ¯æ¢è®¨ç¾¤3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=bakez5Yz&#34;&gt;584723646&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;åç§°&lt;/th&gt; &#xA;   &lt;th&gt;é¡¹ç®&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021è¯¾ç¨ä¸»é¡µ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html&#34;&gt;æå®æ¯2021æ¥å­£æºå¨å­¦ä¹ &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022è¯¾ç¨ä¸»é¡µ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;&gt;æå®æ¯2022æ¥å­£æºå¨å­¦ä¹ &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bç«è§é¢åé&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN&#34;&gt;(å¼ºæ¨)æå®æ¯2021æ¥æºå¨å­¦ä¹ è¯¾ç¨&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021è§é¢åèµæç®å½&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Fafa-DL/Lhy_Machine_Learning/tree/main/2021%20ML&#34;&gt;é¾æ¥&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022è§é¢åèµæç®å½&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Fafa-DL/Lhy_Machine_Learning/tree/main/2022%20ML&#34;&gt;é¾æ¥&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç« è&lt;/th&gt; &#xA;   &lt;th&gt;2021åç½®ç¥è¯&lt;/th&gt; &#xA;   &lt;th&gt;2022è¡¥å&lt;/th&gt; &#xA;   &lt;th&gt;éä¿®&lt;/th&gt; &#xA;   &lt;th&gt;ä½ä¸&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=3&#34;&gt;ï¼ä¸ï¼æºå¨å­¦ä¹ åºæ¬æ¦å¿µç®ä»&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=4&#34;&gt;ï¼ä¸ï¼æºå¨å­¦ä¹ åºæ¬æ¦å¿µç®ä»&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=1&#34;&gt;2022-æºå¨å­¦ä¹ ç¸å³è§å®&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=5&#34;&gt;2022-Colabæå­¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=6&#34;&gt;2022-Pytorch Tutorial 1&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=7&#34;&gt;2022-Pytorch Tutorial 2&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/rule%20(v2).pdf&#34;&gt;Rules&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/introduction%20(v2).pdf&#34;&gt;Chinese class course intro&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Pytorch%20Tutorial%201.pdf&#34;&gt;Pytorch Tutorial 1&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Pytorch%20Tutorial%202.pdf&#34;&gt;Pytorch Tutorial 2&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Colab%20Tutorial%202022.pdf&#34;&gt;Colab Tutorial&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/EnvironmentSetup.pdf&#34;&gt;Environment Setup&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=13&#34;&gt;æ·±åº¦å­¦ä¹ ç®ä»&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=14&#34;&gt;ååä¼ æ­&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=15&#34;&gt;é¢æµ-å®å¯æ¢¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=16&#34;&gt;åç±»-å®å¯æ¢¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=17&#34;&gt;é»è¾åå½&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=11&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/HW01.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1FTcG6CE-HILnvFztEFKdauMlPKfQvm5Z#scrollTo=YdttVRkAfu2t&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/t/a3ebd5b5542f0f55e828d4f00de8e59a&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=19&#34;&gt;ï¼ä¸ï¼å±é¨æå°å¼ (local minima) ä¸éç¹ (saddle point)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=20&#34;&gt;ï¼äºï¼æ¹æ¬¡ (batch) ä¸å¨é (momentum)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=21&#34;&gt;ï¼ä¸ï¼èªå¨è°æ´å­¦ä¹ ç (Learning Rate)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=22&#34;&gt;ï¼åï¼æå¤±å½æ° (Loss) ä¹å¯è½æå½±å&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=23&#34;&gt;2022-åæ¢å®å¯æ¢¦ãæ°ç å®è´åç±»å¨ â æµè°æºå¨å­¦ä¹ åç&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/theory%20(v7).pdf&#34;&gt;Theory&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=24&#34;&gt;Gradient Descent (Demo by AOE)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=26&#34;&gt; Beyond Adam (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=27&#34;&gt; Beyond Adam (part 2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=28&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw2_slides%202022.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1hmTFJ8hdcnqRz_0oJSXjTGhZLVU-bS1a?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw2&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=31&#34;&gt;å·ç§¯ç¥ç»ç½ç»CNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=32&#34;&gt;ä¸ºä»ä¹ç¨äºéªè¯éè¿æ¯è¿æå&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=33&#34;&gt;é±¼ä¸çæå¯ä»¥å¼å¾çæºå¨å­¦ä¹ &lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/validation.pdf&#34;&gt;Validation&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/whydeep%20(v3).pdf&#34;&gt;Why Deep&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=34&#34;&gt;Spatial Transformer Layer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=35&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW3%20-%20Image%20Classification.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/15hMu9YiYjE_6HY99UXon2vKGk2KwugWu&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw3b&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=41&#34;&gt;èªæ³¨æåæºå¶(Self-attention)ï¼ä¸ï¼&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=42&#34;&gt;èªæ³¨æåæºå¶(Self-attention)ï¼ä¸ï¼&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=40&#34;&gt;RNN(part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=41&#34;&gt;RNN(part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=42&#34;&gt;GNN(part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=43&#34;&gt;GNN(part 2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=45&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW4.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gC2Gojv9ov9MUQ1a1WDpVBD6FOcLZsog?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw4&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=48&#34;&gt;ç±»ç¥ç»ç½ç»è®­ç»ä¸èµ·æ¥æä¹åï¼äºï¼æ¹æ¬¡æ åå&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=49&#34;&gt;Transformerï¼ä¸ï¼&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=50&#34;&gt;Transformerï¼ä¸ï¼&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=51&#34;&gt;åå¼åæ ·ç¥å¥çèªæ³¨æåæºå¶ (Self-attention) åå&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/xformer%20(v8).pdf&#34;&gt;xformer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=52&#34;&gt;NAT model&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=53&#34;&gt;Pointer network&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=54&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/HW05.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Tlyk2vCBQ8ZCuDQcCSEWTLzr1_xYF9CL#scrollTo=Le4RFWXxjmm0&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw5/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=58&#34;&gt;GANï¼ä¸ï¼åºæ¬æ¦å¿µä»ç»&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=59&#34;&gt;GANï¼äºï¼çè®ºä»ç»ä¸WGAN&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=60&#34;&gt;GANï¼ä¸ï¼çæå¨æè½è¯ä¼°ä¸æ¡ä»¶å¼çæ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=61&#34;&gt;GANï¼åï¼Cycle GAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=62&#34;&gt;Theory of GAN (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=63&#34;&gt;Theory of GAN (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=64&#34;&gt;Theory of GAN (part 3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=65&#34;&gt;Deep Generative Model (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=66&#34;&gt;Deep Generative Model (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=67&#34;&gt;FLOW-based Model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=70&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW6.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/10lHBPFoNhTiiPe-yZ7SwAV1wwrkGc4En?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 7&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=71&#34;&gt;èªçç£å­¦ä¹ ï¼ä¸ï¼èéº»è¡ä¸è¿å»çå·¨äºº&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=72&#34;&gt;èªçç£å­¦ä¹ ï¼äºï¼BERTç®ä»&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=73&#34;&gt;èªçç£å­¦ä¹ ï¼ä¸ï¼BERTçå¥é»è½¶äº&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=74&#34;&gt;èªçç£å­¦ä¹ ï¼åï¼GPTçéæ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=75&#34;&gt;å¦ä½ææçä½¿ç¨èªç£å¯¼å¼æ¨¡å&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=76&#34;&gt;è¯­é³ä¸å½±åä¸çç¥å¥èªç£å¯¼å¼å­¦ä¹ æ¨¡å&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/PLM.pdf&#34;&gt;Recent Advance of Self-supervied learning for NLP&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/SSL_speech_image%20(v9).pdf&#34;&gt;SSL for Speech and Image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=77&#34;&gt;BERT (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=78&#34;&gt;BERT (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=80&#34;&gt;GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=82&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw7_slides.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1QloQ42zYwX_ETAs2GIkeh8qFj0UjHXfH?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw7&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=83&#34;&gt;èªç¼ç å¨ (Auto-encoder) (ä¸) â åºæ¬æ¦å¿µ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=84&#34;&gt;èªç¼ç å¨ (Auto-encoder) (ä¸) â é¢ç»åå£°å¨ä¸æ´å¤åºç¨&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=85&#34;&gt;Anomaly Detection (1_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=86&#34;&gt;Anomaly Detection (2_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=87&#34;&gt;Anomaly Detection (3_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=88&#34;&gt;Anomaly Detection (4_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=89&#34;&gt;Anomaly Detection (5_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=90&#34;&gt;Anomaly Detection (6_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=91&#34;&gt;Anomaly Detection (7_7)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=92&#34;&gt;PCA&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=93&#34;&gt;t-SNE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=95&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20Homework%208%20Anomaly%20Detection.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/16J23Uqkclro8zvp5Y1EXFtEWOvMA9YXC#scrollTo=JoW1UrrxgI_U&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw8/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 9&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=96&#34;&gt;æºå¨å­¦ä¹ çå¯è§£éæ§ (ä¸) â ä¸ºä»ä¹ç¥ç»ç½ç»å¯ä»¥æ­£ç¡®åè¾¨å®å¯æ¢¦åæ°ç å®è´&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=77&#34;&gt;æºå¨å­¦ä¹ çå¯è§£éæ§ (ä¸) âæºå¨å¿ä¸­çç«é¿ä»ä¹æ ·å­&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=98&#34;&gt;èªç¶è¯­è¨å¤çä¸çå¯¹æå¼æ»å» Part1&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Attacks-in-NLP-Draft.pdf&#34;&gt;Adversarial Attack for NLP&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=100&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW9.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1DvQX9apokZHZNfZeG7brJS6XbsGpPFYU?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 10&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=101&#34;&gt;æ¥èªäººç±»çæ¶ææ»å» (Adversarial Attack) (ä¸) â åºæ¬æ¦å¿µ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=102&#34;&gt;2021 - æ¥èªäººç±»çæ¶ææ»å» (Adversarial Attack) (ä¸) â ç±»ç¥ç»ç½ç»è½å¦èº²è¿äººç±»æ·±ä¸è§åºçæ¶æ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=103&#34;&gt;èªç¶è¯­è¨å¤çä¸çå¯¹æå¼æ»å» Part2&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=104&#34;&gt;èªç¶è¯­è¨å¤çä¸çå¯¹æå¼æ»å» Part3&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=105&#34;&gt;èªç¶è¯­è¨å¤çä¸çæ¨¡ä»¿æ»å» (Imitation Attack) ä»¥ååé¨æ»å» (Backdoor Attack)&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Attacks-in-NLP-Draft.pdf&#34;&gt;Adversarial Attack for NLP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=106&#34;&gt;More about Adversarial Attack (1_2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=107&#34;&gt;More about Adversarial Attack (2_2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=109&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW10%20Adversarial%20Attack.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1BcYS4bAInDCTo4Ilsc6w4o_SEoFTuHSO?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw10/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 11&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=110&#34;&gt; æ¦è¿°é¢åèªéåº (Domain Adaptation)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=111&#34;&gt;æ¶æèªç£å¯¼å¼å­¦ä¹ æ¨¡å BERTçä¸ä¸ªæäº&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/More%20self-supervised%20(v2).pdf&#34;&gt;More about self-supervised learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=113&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw11_slides%20(ML2022).pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1N2MceW-Z8olOSQpF-TGvqBq83tRdMOzu&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022-spring-hw11&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 12&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=114&#34;&gt;ï¼ä¸ï¼å¢å¼ºå¼å­¦ä¹ åæºå¨å­¦ä¹ ä¸æ ·é½æ¯ä¸ä¸ªæ­¥éª¤&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=115&#34;&gt;ï¼äºï¼Policy Gradient ä¸ä¿®è¯¾å¿æ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=116&#34;&gt;ï¼ä¸ï¼Actor-Critic&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=117&#34;&gt;ï¼åï¼åé¦éå¸¸ç½è§çæåæä¹åï¼æºå¨çææ¢æ­¢æ¸´&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=118&#34;&gt;ï¼äºï¼å¦ä½ä»ç¤ºèä¸­å­¦ä¹ ï¼éåå¢å¼·å¼å­¦ä¹  (Inverse RL)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=120&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw12_RL_slides_english_version.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/11NS001dD653xCsxypBCohnvsI-CKs64o&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw12/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 13&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=122&#34;&gt;ç¥ç»ç½ç»åç¼© (ä¸) - ç±»ç¥ç»ç½ç»åªæ(Pruning) ä¸å¤§ä¹éåè¯´(Lottery Ticket Hypothesis)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=123&#34;&gt;ç¥ç»ç½ç»åç¼© (äº) - ä»åç§ä¸åçé¢åä¾åç¼©ç¥ç»ç½ç»&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=125&#34;&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=124&#34;&gt;Q-learning (Basic Idea)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=125&#34;&gt;Proximal Policy Optimization (Advanced Tips)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=127&#34;&gt;Proximal Policy Optimization (Continuous Action)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=128&#34;&gt;Geometry of Loss Surfaces (Conjecture)&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=130&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW13.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1S7J12rzL4m5BjSk0QqYw2cnrcqP46VuV#scrollTo=k_UqVZtpSz5Z&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw13&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 14&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=131&#34;&gt;æºå¨ç»èº«å­¦ä¹  (ä¸) - ä¸ºä»ä¹ä»æ¥çäººå·¥æºè½æ æ³æä¸ºå¤©ç½ï¼ç¾é¾æ§éå¿(Catastrophic Forgetting)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=132&#34;&gt;æºå¨çµèº«å­¦ä¹  (äº) - ç¾é¾æ§éå¿(Catastrophic Forgetting)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=134&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Homework%2014%20%20Regularization-based%20%20Lifelong%20Learning.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/11XAhRjXoiQhGfs0LMw6qD2eqPVsPQUxn?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;[Submission]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 15&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=135&#34;&gt;åå­¦ä¹  Meta Learning (ä¸) - åå­¦ä¹ åæºå¨å­¦ä¹ ä¸æ ·ä¹æ¯ä¸åæ­¥éª¤)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=136&#34;&gt;åå­¦ä¹  Meta Learning (äº) - ä¸ç©çå¯ Meta&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=137&#34;&gt;MAML (1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=138&#34;&gt;MAML (2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=139&#34;&gt;MAML (3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=140&#34;&gt;MAML (4)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=141&#34;&gt;MAML (5)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=142&#34;&gt;MAML (6)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=143&#34;&gt;MAML (7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=144&#34;&gt;MAML (8)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=145&#34;&gt;MAML (9)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=146&#34;&gt;Gradient Descent as LSTM (1_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=147&#34;&gt;Gradient Descent as LSTM (2_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=148&#34;&gt;Gradient Descent as LSTM (3_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=149&#34;&gt;Metric-based (1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=150&#34;&gt;Metric-based (2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=151&#34;&gt;Metric-based (3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=152&#34;&gt;Train+Test as RNN&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=153&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/ML2022%20HW15%20Meta%20Learning.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1oKRpCYcU7P6qXHna05Kd9EkG6h1HtxdN?usp=sharingg&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw15&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Fafa-DL/readme-data/main/gzh.jpg&#34; alt=&#34;BILIBILI&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>