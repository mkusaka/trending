<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-20T01:34:45Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>kuleshov/cornell-cs5785-2020-applied-ml</title>
    <updated>2022-12-20T01:34:45Z</updated>
    <id>tag:github.com,2022-12-20:/kuleshov/cornell-cs5785-2020-applied-ml</id>
    <link href="https://github.com/kuleshov/cornell-cs5785-2020-applied-ml" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Teaching materials for the applied machine learning course at Cornell Tech (online edition)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Applied Machine Learning (Cornell CS5785)&lt;/h1&gt; &#xA;&lt;p&gt;This repo contains executable course notes and slides for the Applied ML course at Cornell and Cornell Tech.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?feature=player_embedded&amp;amp;v=vcE9WGbi4QY&#xA;&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/vcE9WGbi4QY/2.jpg&#34; width=&#34;240&#34; height=&#34;180&#34; border=&#34;10&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;These materials accompany a set of Youtube &lt;a href=&#34;https://www.youtube.com/watch?v=vcE9WGbi4QY&amp;amp;list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83&#34;&gt;lecture videos&lt;/a&gt; from the Fall 2020 edition of the course.&lt;/p&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;p&gt;This repo is organized as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;.&#xA;‚îú‚îÄ‚îÄ README.md&#xA;‚îú‚îÄ‚îÄ notebooks             # Notebooks and slides&#xA;‚îî‚îÄ‚îÄ requirements.txt      # Packages needed for your virtualenv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;You should be able to run all the contents of this repo using the packages provided in &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;In a new &lt;code&gt;virtualenv&lt;/code&gt;, run this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Feedback&lt;/h2&gt; &#xA;&lt;p&gt;Please send feedback to &lt;a href=&#34;https://www.cs.cornell.edu/~kuleshov/&#34;&gt;Volodymyr Kuleshov&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>SkalskiP/sport</title>
    <updated>2022-12-20T01:34:45Z</updated>
    <id>tag:github.com,2022-12-20:/SkalskiP/sport</id>
    <link href="https://github.com/SkalskiP/sport" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Examples of Computer Vision usage in sports ‚öΩüèÉ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;‚öΩ Football Players Tracking with YOLOv5 + ByteTrack&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=QCG8QMhga9k&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/youtube.svg?sanitize=true&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://blog.roboflow.com/track-football-players/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg?sanitize=true&#34; alt=&#34;Roboflow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/roboflow-ai/notebooks/raw/main/notebooks/how-to-track-football-players.ipynb&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;I have long been fascinated by the use of Computer Vision in sports. After all, it is a combination of two things I love. Almost three years ago, I wrote a post on my personal blog in which I tried‚Ää‚Äî‚Ääat that time, still using YOLOv3‚Ää‚Äî‚Ääto &lt;a href=&#34;https://towardsdatascience.com/chess-rolls-or-basketball-lets-create-a-custom-object-detection-model-ef53028eac7d&#34;&gt;detect and classify basketball players on the court&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;FIFA World Cup 2022 has motivated me to revisit this idea. This time I used a combination of &lt;a href=&#34;https://github.com/ultralytics/yolov5&#34;&gt;YOLOv5&lt;/a&gt; and &lt;a href=&#34;https://github.com/ifzhang/ByteTrack&#34;&gt;ByteTrack&lt;/a&gt; to track football players on the field. This blog post accompanies the Roboflow video where I talk through how to track players on a football field.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&#34;&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;ü§∏ 3D Football Players Pose Estimation with YOLOv7&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AWjKfjDGiYE&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/youtube.svg?sanitize=true&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/SkalskiP/sport/tree/master/football-players-pose-estimation&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/github.svg?sanitize=true&#34; alt=&#34;GitHub&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;I was watching a FIFA 2022 World Cup match the other day, and one of the things that caught my eye was VAR - Video Assistant Referee, or to be more precise, the part of it responsible for analyzing whether a player was on the offside. I did a little &lt;a href=&#34;https://www.youtube.com/watch?v=WycjDx6giVE&#34;&gt;research&lt;/a&gt; and found that the system performs pose estimation on multiple cameras at once. I decided to check how difficult it would be to reproduce it at home using two cameras and &lt;a href=&#34;https://github.com/WongKinYiu/yolov7&#34;&gt;YOLOv7&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/26109316/207677038-20f951a6-e469-4b3f-a934-66e036fcff69.mp4&#34;&gt;https://user-images.githubusercontent.com/26109316/207677038-20f951a6-e469-4b3f-a934-66e036fcff69.mp4&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>