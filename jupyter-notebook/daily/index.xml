<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-10-01T01:31:57Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>modelscope/facechain</title>
    <updated>2024-10-01T01:31:57Z</updated>
    <id>tag:github.com,2024-10-01:/modelscope/facechain</id>
    <link href="https://github.com/modelscope/facechain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;FaceChain is a deep-learning toolchain for generating your Digital-Twin.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;br&gt; &lt;img src=&#34;https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif&#34; width=&#34;400&#34;&gt; &lt;br&gt; &lt;/p&gt;&#xA;&lt;h1&gt;FaceChain&lt;/h1&gt; &#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://trendshift.io/repositories/1185&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://trendshift.io/api/badge/repositories/1185&#34; alt=&#34;modelscope%2Ffacechain | Trendshift&#34; style=&#34;width: 250px; height: 55px;&#34; width=&#34;250&#34; height=&#34;55&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We provide training scripts for new styles, offering an automatic training for new style LoRas as well as the corresponding style prompts, along with the one click call in Infinite Style Portrait generation tab! (July 3rd, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🚀🚀🚀 We are launching [FACT] into the main branch, offering a 10-second impressive speed and seamless integration with standard ready-to-use LoRas and ControlNets, along with improved instruction-following capabilities ! The original train-based FaceChain is moved to (&lt;a href=&#34;https://github.com/modelscope/facechain/tree/v3.0.0&#34;&gt;https://github.com/modelscope/facechain/tree/v3.0.0&lt;/a&gt; ). (May 28th, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Our work &lt;a href=&#34;https://arxiv.org/abs/2403.01901&#34;&gt;FaceChain-ImagineID&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2403.06775&#34;&gt;FaceChain-SuDe&lt;/a&gt; got accepted to CVPR 2024 ! (February 27th, 2024 UTC)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Introduction&lt;/h1&gt; &#xA;&lt;p&gt;如果您熟悉中文，可以阅读&lt;a href=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/README_ZH.md&#34;&gt;中文版本的README&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;p&gt;FaceChain is a novel framework for generating identity-preserved human portraits. In the newest FaceChain FACT (Face Adapter with deCoupled Training) version, with only 1 photo and 10 seconds, you can generate personal portraits in different settings (multiple styles now supported!). FaceChain has both high controllability and authenticity in portrait generation, including text-to-image and inpainting based pipelines, and is seamlessly compatible with ControlNet and LoRAs. You may generate portraits via FaceChain&#39;s Python scripts, or via the familiar Gradio interface, or via sd webui. FaceChain is powered by &lt;a href=&#34;https://github.com/modelscope/modelscope&#34;&gt;ModelScope&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; ModelScope Studio &lt;a href=&#34;https://modelscope.cn/studios/CVstudio/FaceChain-FACT&#34;&gt;🤖&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&amp;nbsp; ｜API &lt;a href=&#34;https://help.aliyun.com/zh/dashscope/developer-reference/facechain-quick-start&#34;&gt;🔥&lt;/a&gt;&lt;a&gt;&lt;/a&gt;&amp;nbsp; | SD WebUI | HuggingFace Space &lt;a href=&#34;https://huggingface.co/spaces/modelscope/FaceChain-FACT&#34;&gt;🤗&lt;/a&gt;&amp;nbsp; &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://facechain-fact.github.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Project-Page-Green&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://youtu.be/DHqEl0qwi-M?si=y6VpInXdhIX0HpbI&#34;&gt;&lt;img src=&#34;https://badges.aleen42.com/src/youtube.svg?sanitize=true&#34; alt=&#34;YouTube&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/git_cover.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We provide training scripts for new styles, offering an automatic training for new style LoRas as well as the corresponding style prompts, along with the one click call in Infinite Style Portrait generation tab! (July 3rd, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🚀🚀🚀 We are launching [FACT], offering a 10-second impressive speed and seamless integration with standard ready-to-use LoRas and ControlNets, along with improved instruction-following capabilities ! (May 28th, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Our work &lt;a href=&#34;https://arxiv.org/abs/2403.01901&#34;&gt;FaceChain-ImagineID&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2403.06775&#34;&gt;FaceChain-SuDe&lt;/a&gt; got accepted to CVPR 2024 ! (February 27th, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🏆🏆🏆Alibaba Annual Outstanding Open Source Project, Alibaba Annual Open Source Pioneer (Yang Liu, Baigui Sun). (January 20th, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Our work &lt;a href=&#34;https://github.com/henryqin1997/InfoBatch&#34;&gt;InfoBatch&lt;/a&gt; co-authored with NUS team got accepted to ICLR 2024(Oral)! (January 16th, 2024 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🏆OpenAtom&#39;s 2023 Rapidly Growing Open Source Projects Award. (December 20th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add SDXL pipeline🔥🔥🔥, image detail is improved obviously. (November 22th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Support super resolution🔥🔥🔥, provide multiple resolution choice (512&lt;em&gt;512, 768&lt;/em&gt;768, 1024&lt;em&gt;1024, 2048&lt;/em&gt;2048). (November 13th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🏆FaceChain has been selected in the &lt;a href=&#34;https://www.benchcouncil.org/evaluation/opencs/annual.html#Institutions&#34;&gt;BenchCouncil Open100 (2022-2023)&lt;/a&gt; annual ranking. (November 8th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add virtual try-on module. (October 27th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add wanx version &lt;a href=&#34;https://tongyi.aliyun.com/wanxiang/app/portrait-gallery&#34;&gt;online free app&lt;/a&gt;. (October 26th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;🏆1024 Programmer&#39;s Day AIGC Application Tool Most Valuable Business Award. (2023-10-24, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Support FaceChain in stable-diffusion-webui🔥🔥🔥. (October 13th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;High performance inpainting for single &amp;amp; double person, Simplify User Interface. (September 09th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;More Technology Details can be seen in &lt;a href=&#34;https://arxiv.org/abs/2308.14256&#34;&gt;Paper&lt;/a&gt;. (August 30th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add validate &amp;amp; ensemble for Lora training, and InpaintTab(hide in gradio for now). (August 28th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add pose control module. (August 27th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add robust face lora training module, enhance the performance of one pic training &amp;amp; style-lora blending. (August 27th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;HuggingFace Space is available now! You can experience FaceChain directly with &lt;a href=&#34;https://huggingface.co/spaces/modelscope/FaceChain&#34;&gt;🤗&lt;/a&gt; (August 25th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Add awesome prompts! Refer to: &lt;a href=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/awesome-prompts-facechain.txt&#34;&gt;awesome-prompts-facechain&lt;/a&gt; (August 18th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Support a series of new style models in a plug-and-play fashion. (August 16th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Support customizable prompts. (August 16th, 2023 UTC)&lt;/li&gt; &#xA; &lt;li&gt;Colab notebook is available now! You can experience FaceChain directly with &lt;a href=&#34;https://colab.research.google.com/github/modelscope/facechain/blob/main/facechain_demo.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;. (August 15th, 2023 UTC)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;To-Do List&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Develop RLHF methods, make its quality more higher.&lt;/li&gt; &#xA; &lt;li&gt;Support more beauty-retouch effects.&lt;/li&gt; &#xA; &lt;li&gt;Provide more funny apps.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Citation&lt;/h1&gt; &#xA;&lt;p&gt;Please cite FaceChain in your publications if it helps your research&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{liu2023facechain,&#xA;  title={FaceChain: A Playground for Identity-Preserving Portrait Generation},&#xA;  author={Liu, Yang and Yu, Cheng and Shang, Lei and Wu, Ziheng and &#xA;          Wang, Xingjun and Zhao, Yuze and Zhu, Lin and Cheng, Chen and &#xA;          Chen, Weitao and Xu, Chao and Xie, Haoyu and Yao, Yuan and &#xA;          Zhou,  Wenmeng and Chen Yingda and Xie, Xuansong and Sun, Baigui},&#xA;  journal={arXiv preprint arXiv:2308.14256},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Compatibility Verification&lt;/h2&gt; &#xA;&lt;p&gt;We have verified e2e execution on the following environment:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;python: py3.8, py3.10&lt;/li&gt; &#xA; &lt;li&gt;pytorch: torch2.0.0, torch2.0.1&lt;/li&gt; &#xA; &lt;li&gt;CUDA: 11.7&lt;/li&gt; &#xA; &lt;li&gt;CUDNN: 8+&lt;/li&gt; &#xA; &lt;li&gt;OS: Ubuntu 20.04, CentOS 7.9&lt;/li&gt; &#xA; &lt;li&gt;GPU: Nvidia-A10 24G&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Memory Optimization&lt;/h2&gt; &#xA;&lt;p&gt;Jemalloc are recommanded to install for optimizing the memory from above 30G to below 20G. Here is an example for installing Jemalloc in Modelscope notebook.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;apt-get install -y libjemalloc-dev&#xA;export LD_PRELOAD=/lib/x86_64-linux-gnu/libjemalloc.so&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Installation Guide&lt;/h2&gt; &#xA;&lt;p&gt;The following installation methods are supported:&lt;/p&gt; &#xA;&lt;h3&gt;1. ModelScope notebook【recommended】&lt;/h3&gt; &#xA;&lt;p&gt;The ModelScope Notebook offers a free-tier that allows ModelScope user to run the FaceChain application with minimum setup, refer to &lt;a href=&#34;https://modelscope.cn/my/mynotebook/preset&#34;&gt;ModelScope Notebook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Step1: 我的notebook -&amp;gt; PAI-DSW -&amp;gt; GPU环境&#xA;# Note: Please use: ubuntu20.04-py38-torch2.0.1-tf1.15.5-modelscope1.8.1&#xA;&#xA;# Step2: Entry the Notebook cell，clone FaceChain from github:&#xA;!GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1&#xA;&#xA;# Step3: Change the working directory to facechain, and install the dependencies:&#xA;import os&#xA;os.chdir(&#39;/mnt/workspace/facechain&#39;)    # You may change to your own path&#xA;print(os.getcwd())&#xA;&#xA;!pip3 install gradio==3.47.1&#xA;!pip3 install controlnet_aux==0.0.6&#xA;!pip3 install python-slugify&#xA;!pip3 install diffusers==0.29.0&#xA;!pip3 install peft==0.11.1&#xA;&#xA;# Step4: Start the app service, click &#34;public URL&#34; or &#34;local URL&#34;, upload your images to &#xA;# train your own model and then generate your digital twin.&#xA;!python3 app.py&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, you may also purchase a &lt;a href=&#34;https://www.aliyun.com/activity/bigdata/pai/dsw&#34;&gt;PAI-DSW&lt;/a&gt; instance (using A10 resource), with the option of ModelScope image to run FaceChain following similar steps.&lt;/p&gt; &#xA;&lt;h3&gt;2. Docker&lt;/h3&gt; &#xA;&lt;p&gt;If you are familiar with using docker, we recommend to use this way:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Step1: Prepare the environment with GPU on local or cloud, we recommend to use Alibaba Cloud ECS, refer to: https://www.aliyun.com/product/ecs&#xA;&#xA;# Step2: Download the docker image (for installing docker engine, refer to https://docs.docker.com/engine/install/）&#xA;# For China Mainland users:&#xA;docker pull registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.7.1-py38-torch2.0.1-tf1.15.5-1.8.1&#xA;# For users outside China Mainland:&#xA;docker pull registry.us-west-1.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.7.1-py38-torch2.0.1-tf1.15.5-1.8.1&#xA;&#xA;# Step3: run the docker container&#xA;docker run -it --name facechain -p 7860:7860 --gpus all registry.cn-hangzhou.aliyuncs.com/modelscope-repo/modelscope:ubuntu20.04-cuda11.7.1-py38-torch2.0.1-tf1.15.5-1.8.1 /bin/bash&#xA;# Note: you may need to install the nvidia-container-runtime, follow the instructions:&#xA;# 1. Install nvidia-container-runtime：https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html&#xA;# 2. sudo systemctl restart docker&#xA;&#xA;# Step4: Install the gradio in the docker container:&#xA;pip3 install gradio==3.47.1&#xA;pip3 install controlnet_aux==0.0.6&#xA;pip3 install python-slugify&#xA;pip3 install diffusers==0.29.0&#xA;pip3 install peft==0.11.1&#xA;&#xA;# Step5 clone facechain from github&#xA;GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/modelscope/facechain.git --depth 1&#xA;cd facechain&#xA;python3 app.py&#xA;# Note: FaceChain currently assume single-GPU, if your environment has multiple GPU, please use the following instead:&#xA;# CUDA_VISIBLE_DEVICES=0 python3 app.py&#xA;&#xA;# Step6&#xA;Run the app server: click &#34;public URL&#34; --&amp;gt; in the form of: https://xxx.gradio.live&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. stable-diffusion-webui&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Select the &lt;code&gt;Extensions Tab&lt;/code&gt;, then choose &lt;code&gt;Install From URL&lt;/code&gt; (official plugin integration is intergrated, please install from URL currently). &lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/sdwebui_install.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Switch to &lt;code&gt;Installed&lt;/code&gt;, check the FaceChain plugin, then click &lt;code&gt;Apply and restart UI&lt;/code&gt;. It may take a while for installing the dependencies and downloading the models. Make sure that the &#34;CUDA Toolkit&#34; is installed correctly, otherwise the &#34;mmcv&#34; package cannot be successfully installed. &lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/sdwebui_restart.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;After the page refreshes, the appearance of the &lt;code&gt;FaceChain&lt;/code&gt; Tab indicates a successful installation. &lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/sdwebui_success.jpg&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Script Execution&lt;/h1&gt; &#xA;&lt;p&gt;FaceChain supports direct inference in the python environment. When inferring for Infinite Style Portrait generation, please edit the code in run_inference.py:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Use pose control, default False&#xA;use_pose_model = False&#xA;# The path of the input image containing ID information for portrait generation&#xA;input_img_path = &#39;poses/man/pose2.png&#39;&#xA;# The path of the image for pose control, only effective when using pose control&#xA;pose_image = &#39;poses/man/pose1.png&#39;&#xA;# The number of images to generate in inference&#xA;num_generate = 5&#xA;# The weight for the style model, see styles for detail&#xA;multiplier_style = 0.25&#xA;# Specify a folder to save the generated images, this parameter can be modified as needed&#xA;output_dir = &#39;./generated&#39;&#xA;# The index of the chosen base model, see facechain/constants.py for detail&#xA;base_model_idx = 0&#xA;# The index of the style model, see styles for detail&#xA;style_idx = 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python run_inference.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find the generated personal digital image photos in the &lt;code&gt;output_dir&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;When inferring for Fixed Templates Portrait generation, please edit the code in run_inference_inpaint.py.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Number of faces for the template image&#xA;num_faces = 1&#xA;# Index of face for inpainting, counting from left to right&#xA;selected_face = 1&#xA;# The strength for inpainting, you do not need to change the parameter&#xA;strength = 0.6&#xA;# The path of the template image&#xA;inpaint_img = &#39;poses/man/pose1.png&#39;&#xA;# The path of the input image containing ID information for portrait generation&#xA;input_img_path = &#39;poses/man/pose2.png&#39;&#xA;# The number of images to generate in inference&#xA;num_generate = 1&#xA;# Specify a folder to save the generated images, this parameter can be modified as needed&#xA;output_dir = &#39;./generated_inpaint&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then execute:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python run_inference_inpaint.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can find the generated personal digital image photos in the &lt;code&gt;output_dir&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Algorithm Introduction&lt;/h1&gt; &#xA;&lt;p&gt;The capability of AI portraits generation comes from the large generative models like Stable Diffusion and its fine-tuning techniques. Due to the strong generalization capability of large models, it is possible to perform downstream tasks by fine-tuning on specific types of data and tasks, while preserving the model&#39;s overall ability of text following and image generation. The technical foundation of train-based and train-free AI portraits generation comes from applying different fine-tuning tasks to generative models. Currently, most existing AI portraits tools adopt a two-stage “train then generate” pipeline, where the fine-tuning task is “to generate portrait photos of a fixed character ID”, and the corresponding training data are multiple images of the fixed character ID. The effectiveness of such train-based pipeline depends on the scale of the training data, thus requiring certain image data support and training time, which also increases the cost for users.&lt;/p&gt; &#xA;&lt;p&gt;Different from train-based pipeline, train-free pipeline adjusts the fine-tuning task to “generate portrait photos of a specified character ID”, meaning that the character ID image (face photo) is used as an additional input, and the output is a portrait photo preserving the input ID. Such a pipeline completely separates offline training from online inference, allowing users to generate portraits directly based on the fine-tuned model with only one photo in just 10 seconds, avoiding the cost for extensive data and training time. The fine-tuning task of train-free AI portraits generation is based on the adapter module. Face photos are processed through an image encoder with fixed weights and a parameter-efficient feature projection layer to obtain aligned features, and are then fed into the U-Net model of Stable Diffusion through attention mechanism similar as text conditions. At this point, face information as an independent branch condition is fed into the model alongside text information for inference, thereby enabling the generated images to maintain ID fidelity.&lt;/p&gt; &#xA;&lt;p&gt;The basic algorithm based on face adapter is capable of achieving train-free AI portraits, but still requires certain adjustments to further improve its effectiveness. Existing train-free portrait tools generally suffer from the following issues: poor image quality of portraits, inadequate text following and style retention abilities in portraits, poor controllability and richness of portrait faces, and poor compatibility with extensions like ControlNet and style Lora. To address these issues, FaceChain attribute them to the fact that the fine-tuning tasks for existing train-free AI portrait tools have coupled with too much information beyond character IDs, and propose FaceChain Face Adapter with Decoupled Training (FaceChain FACT) to solve these problems. By fine-tuning the Stable Diffusion model on millions of portrait data, FaceChain FACT can achieve high-quality portrait image generation for specified character IDs. The entire framework of FaceChain FACT is shown in the figure below.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/framework.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The decoupled training of FaceChain FACT consists of two parts: decoupling face from image, and decoupling ID from face. Existing methods often treat denoising portrait images as the fine-tuning task, which makes the model hard to accurately focus on the face area, thereby affecting the text-to-image ability of the base Stable Diffusion model. FaceChain FACT draws on the sequential processing and regional control advantages of face-swapping algorithms and implements the fine-tuning method for decoupling faces from images from both structural and training strategy aspects. Structurally, unlike existing methods that use a parallel cross-attention mechanism to process face and text information, FaceChain FACT adopts a sequential processing approach as an independent adapter layer inserted into the original Stable Diffusion&#39;s blocks. This way, face adaptation acts as an independent step similar to face-swapping during the denoising process, avoiding interference between face and text conditions. In terms of training strategy, besides the original MSE loss function, FaceChain FACT introduces the Face Adapting Incremental Regularization (FAIR) loss function, which controls the feature increment of the face adaptation step in the adapter layer to focus on the face region. During inference, users can flexibly adjust the generated effects by modifying the weight of the face adapter, balancing fidelity and generalization of the face while maintaining the text-to-image ability of Stable Diffusion. The FAIR loss function is formulated as follows:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/FAIR.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Furthermore, addressing the issue of poor controllability and richness of generated faces, FaceChain FACT proposes a training method for decoupling ID from face, so that the portrait process only preserves the character ID rather than the entire face. Firstly, to better extract the ID information from the face while maintaining certain key facial details, and to better adapt to the structure of Stable Diffusion, FaceChain FACT employs a face feature extractor based on the Transformer architecture, which is pre-trained on a large-scale face dataset. All tokens from the penultimate layer are subsequently fed into a simple attention query model for feature projection, thereby ensuring that the extracted ID features meet the aforementioned requirements. Additionally, during the training process, FaceChain FACT uses the Classifier Free Guidance (CFG) method to perform random shuffle and drop for different portrait images of the same ID, thus ensuring that the input face images and the target images used for denoising may have different faces with the same ID, thus further preventing the model from overfitting to non-ID information of the face. As such, FaceChain FACT possesses high compatibility with the massive exquisite styles of FaceChain, which is shown as follows.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/modelscope/facechain/main/resources/generated_examples.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Model List&lt;/h2&gt; &#xA;&lt;p&gt;The models used in FaceChain:&lt;/p&gt; &#xA;&lt;p&gt;[1] Face recognition model TransFace：&lt;a href=&#34;https://www.modelscope.cn/models/iic/cv_vit_face-recognition&#34;&gt;https://www.modelscope.cn/models/iic/cv_vit_face-recognition&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2] Face detection model DamoFD：&lt;a href=&#34;https://modelscope.cn/models/damo/cv_ddsar_face-detection_iclr23-damofd&#34;&gt;https://modelscope.cn/models/damo/cv_ddsar_face-detection_iclr23-damofd&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[3] Human parsing model M2FP：&lt;a href=&#34;https://modelscope.cn/models/damo/cv_resnet101_image-multiple-human-parsing&#34;&gt;https://modelscope.cn/models/damo/cv_resnet101_image-multiple-human-parsing&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[4] Skin retouching model ABPN：&lt;a href=&#34;https://www.modelscope.cn/models/damo/cv_unet_skin_retouching_torch&#34;&gt;https://www.modelscope.cn/models/damo/cv_unet_skin_retouching_torch&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[5] Face fusion model：&lt;a href=&#34;https://www.modelscope.cn/models/damo/cv_unet_face_fusion_torch&#34;&gt;https://www.modelscope.cn/models/damo/cv_unet_face_fusion_torch&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[6] FaceChain FACT model: &lt;a href=&#34;https://www.modelscope.cn/models/yucheng1996/FaceChain-FACT&#34;&gt;https://www.modelscope.cn/models/yucheng1996/FaceChain-FACT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[7] Face attribute recognition model FairFace: &lt;a href=&#34;https://modelscope.cn/models/damo/cv_resnet34_face-attribute-recognition_fairface&#34;&gt;https://modelscope.cn/models/damo/cv_resnet34_face-attribute-recognition_fairface&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;More Information&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modelscope/modelscope/&#34;&gt;ModelScope library&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;​ ModelScope Library provides the foundation for building the model-ecosystem of ModelScope, including the interface and implementation to integrate various models into ModelScope.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelscope.cn/docs/ModelScope%E6%A8%A1%E5%9E%8B%E6%8E%A5%E5%85%A5%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88&#34;&gt;Contribute models to ModelScope&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;This project is licensed under the &lt;a href=&#34;https://github.com/modelscope/modelscope/raw/master/LICENSE&#34;&gt;Apache License (Version 2.0)&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>bansalkanav/Ultimate-Data-Science-Toolkit---From-Python-Basics-to-GenerativeAI</title>
    <updated>2024-10-01T01:31:57Z</updated>
    <id>tag:github.com,2024-10-01:/bansalkanav/Ultimate-Data-Science-Toolkit---From-Python-Basics-to-GenerativeAI</id>
    <link href="https://github.com/bansalkanav/Ultimate-Data-Science-Toolkit---From-Python-Basics-to-GenerativeAI" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Getting started with Machine Learning and Deep Learning&lt;/h1&gt; &#xA;&lt;h3&gt;Star this repo if you find it useful &lt;span&gt;⭐&lt;/span&gt;&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning&#34;&gt;&lt;img src=&#34;https://badges.frapsoft.com/os/v1/open-source.svg?v=103&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Built%20by-developers%20%3C%2F%3E-0059b3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=yellow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Maintained%3F-yes-brightgreen.svg?v=103&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/raw/master/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-GPL-blue.svg?v=103&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/graphs/contributors&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/bansalkanav/Machine_Learning_and_Deep_Learning?color=brightgreen&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/bansalkanav/Machine_Learning_and_Deep_Learning?color=0059b3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/bansalkanav/Machine_Learning_and_Deep_Learning?color=yellow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/bansalkanav/Machine_Learning_and_Deep_Learning?color=0059b3&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/issues?q=is%3Aissue+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-closed-raw/bansalkanav/Machine_Learning_and_Deep_Learning?color=yellow&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/bansalkanav/Machine_Learning_and_Deep_Learning?color=brightgreen&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/pulls?q=is%3Apr+is%3Aclosed&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr-closed-raw/bansalkanav/Machine_Learning_and_Deep_Learning?color=0059b3&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 1 - Python Programming &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/01.%20Intro%20to%20Python&#34;&gt;Intro to Python&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Applications and Features of Python, Hello World Program, &lt;strong&gt;Identifiers&lt;/strong&gt; and Rules to define identifiers, &lt;strong&gt;Data Types&lt;/strong&gt; (numeric, boolean, strings, list, tuple, set and dict), Comments, Input and Output, &lt;strong&gt;Operators&lt;/strong&gt; - Arithmatic, Reltaional, Equality, Logical, Bitwise, Assignment, Ternary, Identity and Membership&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/02.%20Data%20Structures&#34;&gt;Data Structures in Python (Strings, List, Tuple, Set, Dictionary)&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Strings&lt;/strong&gt; - Creating a string, Indexing, Slicing, Split, Join, etc, &lt;strong&gt;List&lt;/strong&gt; - Initialization, Indexing, Slicing, Sorting, Appending, etc, &lt;strong&gt;Tuple&lt;/strong&gt; - Initialization, Indexing, Slicing, Count, Index, etc, &lt;strong&gt;Set&lt;/strong&gt; - Initialization, Unordered Sequence, Set Opertaions, etc, &lt;strong&gt;Dictionary&lt;/strong&gt; - Initialization, Updating, Keys, Values, Items, etc&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/03.%20Control%20Statements&#34;&gt;Control Statements (Conditionals and Loops)&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Conditional Statements&lt;/strong&gt; - Introducing Indentation, if statement, if...else statement, if..elif...else statement, Nested if else statement, &lt;strong&gt;Loops&lt;/strong&gt; - while loops, while...else loop, Membership operator, for loop, for...else loop, Nested Loops, Break and Continue Statement, Why else?&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/04.%20Functions%20and%20Modules&#34;&gt;Functions and Modules&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Functions&lt;/strong&gt; - Introduction to Python Functions, Function Definition and Calling, Functions with Arguments/Parameters, Return Statement, Scope of a Variable, Global Variables, &lt;strong&gt;Modules&lt;/strong&gt; - Introduction to Modules, Importing a Module, Aliasing, from...import statement, import everything, Some important modules - math, platform, random, webbrowser, etc&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/05.%20Object%20Oriented%20Programming&#34;&gt;Object Oriented Programming&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Classes and Objects&lt;/strong&gt; - Creating a class, Instantiating an Object, &lt;strong&gt;Constructor&lt;/strong&gt;, Class Members - Variables and Mentods, &lt;strong&gt;Types of Variables&lt;/strong&gt; - Instance, Static and Local Variables, &lt;strong&gt;Types of Methods&lt;/strong&gt; - Instance, Class and Static Methods, &lt;strong&gt;Access Modifiers&lt;/strong&gt; - Public, Private and Protected, &lt;strong&gt;Pillars of Object Oriented Programming&lt;/strong&gt; - Inheritance, Polymorphism, Abstraction and Encapsulation, &lt;strong&gt;Setters and Getters&lt;/strong&gt;, &lt;strong&gt;Inheritance vs Association&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/06.%20Exception%20Handling&#34;&gt;Exception Handling&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Errors vs Exception, Syntax and Indentation Errors, &lt;strong&gt;try...except&lt;/strong&gt; block, Control Flow in try...except block, try with multiple except, &lt;strong&gt;finally&lt;/strong&gt; block, try...except...else, Nested try...except...finally, &lt;strong&gt;User Defined Exception&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/07.%20File%20Handling&#34;&gt;File Handling&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Introduction to File Handling, Opening and Closing a File, File Object Properties, Read Data from Text Files, Write Data to Text Files, &lt;strong&gt;with&lt;/strong&gt; statement, Renaming and Deleting Files&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/08.%20Web%20API&#34;&gt;Web API&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Application Programming Interface&lt;/strong&gt;, Indian Space Station API, API Request, Status Code, Query Parameters, Getting JSON from an API Request, Working with JSON - dump and load, Working with Twitter API&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/09.%20Databases&#34;&gt;Databases&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Introduction to Databases, &lt;strong&gt;SQLite3&lt;/strong&gt; - Connecting Python with SQLite3, Performing CRUD Opertations, &lt;strong&gt;MySQL&lt;/strong&gt; - Connecting Python with MySQL, Performing CRUD Opertations, &lt;strong&gt;MongoDB&lt;/strong&gt; - Connecting Python with MongoDB, Performing CRUD Opertations, &lt;strong&gt;Object Relation Mapping&lt;/strong&gt; - SQLAlchemy ORM, CRUD operations and Complex DB operations&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/10.%20Adv%20Topics%20(List%20Comprehension%2C%20Lambda%2C%20Filter%2C%20Map%20and%20Reduce)&#34;&gt;List Comprehension, Lambda, Filter, Map, Reduce&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;List Comprehension, Anonymous Functions, Filter, Map, Reduce, Function Aliasing&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%201%20-%20Python%20Programming/11.%20Problem%20Solving%20for%20Interviews&#34;&gt;Problem Solving for Interviews&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Swapping two numbers, Factorial of a number, Prime Number, Fibbonnacci Sequence, Armstrong Number, Palindrome Number, etc&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 2 - Python for Data Analysis &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/01.%20Data%20Analytics%20Framework&#34;&gt;Data Analytics Framework&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Data Collection, Business Understanding, &lt;strong&gt;Exploratory Data Analysis&lt;/strong&gt;, Data Preparation, Model Building, Model Evaluation, Deployment, Understanding Cross Industry Standard Process for Data Mining (&lt;strong&gt;CRISP-DM&lt;/strong&gt;) and Microsoft&#39;s Team Data Science Process (&lt;strong&gt;TDSP&lt;/strong&gt;)&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/02.%20Numpy&#34;&gt;Numpy&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Array Oriented Numerical Computations using &lt;strong&gt;Numpy&lt;/strong&gt;, Creating a Numpy Array, Basic Operations on Numpy Array - Check Dimensions, Shape, Datatypes and ItemSize, &lt;strong&gt;Why Numpy&lt;/strong&gt;, Various ways to create Numpy Array, Numpy arange() function, &lt;strong&gt;Numpy Random Module&lt;/strong&gt; - rand(), randn(), randint(), uniform(), etc, Indexing and Slicing in Numpy Arrays, Applying &lt;strong&gt;Mathematical Operations&lt;/strong&gt; on Numpy Array - add(), subtract(), multiply(), divide(), dot(), matmul(), sum(), log(), exp(), etc, &lt;strong&gt;Statistical Operations&lt;/strong&gt; on Numpy Array - min(), max(), mean(), median(), var(), std(), corrcoef(), etc, &lt;strong&gt;Reshaping&lt;/strong&gt; a Numpy Array, Miscellaneous Topics - Linspace, Sorting, Stacking, Concatenation, Append, Where and &lt;strong&gt;Numpy Broadcasting&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/03.%20Pandas%20for%20Beginners&#34;&gt;Pandas for Beginners&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Pandas Data Structures - Series, Dataframe and Panel, &lt;strong&gt;Creating a Series&lt;/strong&gt;, Data Access, &lt;strong&gt;Creating a Dataframe&lt;/strong&gt; using Tuples and Dictionaries, &lt;strong&gt;DataFrame Attributes&lt;/strong&gt; - columns, shape, dtypes, axes, values, etc, &lt;strong&gt;DataFrame Methods&lt;/strong&gt; - head(), tail(), info(), describe(), &lt;strong&gt;Working with .csv and .xlsx&lt;/strong&gt; - read_csv() and read_excel(), &lt;strong&gt;DataFrame to .csv and .xlsx&lt;/strong&gt; - to_csv() and to_excel()&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/04.%20Advance%20Pandas%20Operations&#34;&gt;Advance Pandas Operations&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/05.%20Case%20Study%20-%20Pandas%20Manipulation&#34;&gt;Case Study - Pandas Manipulation&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/06.%20Missing%20Value%20Treatment&#34;&gt;Missing Value Treatment&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/07.%20Visuallization%20Basics%20-%20Matplotlib%20and%20Seaborn&#34;&gt;Visuallization Basics - Matplotlib and Seaborn&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/08.%20Case%20Study%20-%20Covid_19_TimeSeries&#34;&gt;Case Study - Covid_19_TimeSeries&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/09.%20Plotly%20and%20Express&#34;&gt;Plotly and Express&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%202%20-%20Python%20for%20Data%20Analysis/10.%20Coming%20Soon&#34;&gt;Outliers - Coming Soon&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 3 - Statistics for Data Analysis &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%203%20-%20Statistics%20for%20Data%20Analysis/1.%20Normal%20Distributions&#34;&gt;Normal Distribution&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%203%20-%20Statistics%20for%20Data%20Analysis/2.%20Central%20Limit%20Theorem&#34;&gt;Central Limit Theorem&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%203%20-%20Statistics%20for%20Data%20Analysis/3.%20Hypothesis%20Testing&#34;&gt;Hypothesis Testing&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%203%20-%20Statistics%20for%20Data%20Analysis/4.%20Chi%20Square%20Test&#34;&gt;Chi Square Testing&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%203%20-%20Statistics%20for%20Data%20Analysis/5.%20Performing%20Statistical%20Test&#34;&gt;Performing Statistical Test&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 4 - Machine Learning &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/01.%20Data%20Preparation%20and%20Modelling%20with%20sklearn&#34;&gt;Data Preparation and Modelling with SKLearn&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/02.%20Working%20with%20Text%20Data&#34;&gt;Working with Text Data&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/03.%20Working%20with%20Image%20Data&#34;&gt;Working with Image Data&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms&#34;&gt;Supervised ML Algorithms&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/01.%20K%20-%20NN&#34;&gt;K - Nearest Neighbours&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/02.%20Linear%20Regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/03.%20Logistic%20Regression&#34;&gt;Logistic Regression&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/04.%20Gradient%20Descent&#34;&gt;Gradient Descent&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/05.%20Decision%20Trees&#34;&gt;Decision Trees&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/06.%20Support%20Vector%20Machines&#34;&gt;Support Vector Machines&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/07.%20ML%20Models%20with%20Feature%20Engineering&#34;&gt;Models with Feature Engineering&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/08.%20Hyperparameter%20Tuning&#34;&gt;Hyperparameter Tuning&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/04.%20Supervised%20ML%20Algorithms/09.%20Ensembles&#34;&gt;Ensembles&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;li&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/05.%20Unsupervised%20ML%20Algorithms&#34;&gt;Unsupervised ML Algorithms&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/05.%20Unsupervised%20ML%20Algorithms/01.%20Clustering&#34;&gt;Clustering&lt;/a&gt;&lt;br&gt; - &lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%204%20-%20Machine%20Learning/05.%20Unsupervised%20ML%20Algorithms/02.%20PCA&#34;&gt;Principal Component Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 5 - MLOPs &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%205%20-%20MLOPs/1.%20Model%20Serialization%20and%20Deserialization&#34;&gt;Model Serialization and Deserialization&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%205%20-%20MLOPs/2.%20Application%20Integration&#34;&gt;Application Integration&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%205%20-%20MLOPs/3.%20Experiment%20Tracking%20and%20Model%20Management&#34;&gt;MLFlow - Experiment Tracking and Model Management&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%205%20-%20MLOPs/4.%20Orchestrate%20ML%20Pipeline&#34;&gt;Prefect - Orchestrate ML Pipeline&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 6 - Case Studies &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/1.%20Car%20Price%20Prediction&#34;&gt;Car Price Prediction (Regression)&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/2.%20Airline%20Sentiment%20Analyser&#34;&gt;Airline Sentiment Analysis (NLP - Classification)&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/3.%20Adult%20Income%20Prediction&#34;&gt;Adult Income Prediction (Classification)&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/4.%20web_app&#34;&gt;Web App Development + Serialization and Deserialization&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/5.%20AWS%20Deployment&#34;&gt;AWS Deployment&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/6.%20Streamlit%20Heroku%20Deployment&#34;&gt;Streamlit Heroku Deployment&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/7.%20Customer%20Segmentation&#34;&gt;Customer Segmentation&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%206%20-%20Case%20Studies/8.%20Regex%20and%20Webscrapping&#34;&gt;Web Scrapping&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;h2&gt;Module 7 - Deep Learning &lt;/h2&gt; &lt;/summary&gt; &#xA; &lt;table&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;Topic Name&lt;/th&gt; &#xA;    &lt;th align=&#34;center&#34;&gt;What&#39;s Covered&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%207%20-%20Deep%20Learning/01.%20Introduction%20to%20Deep%20Learning&#34;&gt;Introduction to Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%207%20-%20Deep%20Learning/02.%20Training%20Deep%20Neural%20Network&#34;&gt;Training a Deep Neural Network + TensorFlow.Keras&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%207%20-%20Deep%20Learning/03.%20Convolutional%20Neural%20Network&#34;&gt;Convolutional Neural Network + TensorFlow.Keras&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/bansalkanav/Machine_Learning_and_Deep_Learning/tree/master/Module%207%20-%20Deep%20Learning/04.%20Auto%20Encoder%20(Deep%20Generative%20Models)&#34;&gt;Auto Encoders for Image Compression&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Recurrent Neural Network (Coming Soon)&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;What&#39;s Covered&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/details&gt;</summary>
  </entry>
</feed>