<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-01-16T01:36:40Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>erachelson/RLclass_MVA</title>
    <updated>2024-01-16T01:36:40Z</updated>
    <id>tag:github.com,2024-01-16:/erachelson/RLclass_MVA</id>
    <link href="https://github.com/erachelson/RLclass_MVA" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;RL class @ MVA&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the website of the reinforcement learning class for the &lt;a href=&#34;https://www.master-mva.com/&#34;&gt;MVA master program&lt;/a&gt;.&lt;br&gt; This class is joint work between &lt;a href=&#34;https://people.isae-supaero.fr/emmanuel-rachelson&#34;&gt;Emmanuel Rachelson&lt;/a&gt; (first 6 sessions) and &lt;a href=&#34;https://emiliekaufmann.github.io/&#34;&gt;Emilie Kaufmann&lt;/a&gt; (2 last ones).&lt;/p&gt; &#xA;&lt;h2&gt;Syllabus&lt;/h2&gt; &#xA;&lt;p&gt;This class aims at providing a comprehensive and modern introduction to reinforcement learning concepts and algorithms. It endeavors to provide a solid formal basis on foundational notions of reinforcement learning (MDP modeling, convergence properties of dynamic programming and stochastic gradient descent, stochastic bandits, etc.), in order to move in a principled manner towards state-of-the-art algorithms (including deep RL ones).&lt;br&gt; The class is structured around a series of chapters, each covered in an independent notebook.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chapter 0: Reinforcement Learning class introduction; key intuitions&lt;/strong&gt;&lt;br&gt; Class rules, general definition of RL, position in the ML landscape, first elements of vocabulary.&lt;br&gt; &lt;strong&gt;Chapter 1: Modeling sequential decision problems with Markov Decision Processes&lt;/strong&gt;&lt;br&gt; MDP definition, policies and value functions, definition of optimality, state distributions, horizon.&lt;br&gt; &lt;strong&gt;Chapter 2: Characterizing value functions: the Bellman equations&lt;/strong&gt;&lt;br&gt; State-action value functions, dynamic programming evaluation and optimality Bellman equations, value iteration, (modified) policy iteration, asynchronous dynamic programming, linear programming.&lt;br&gt; &lt;strong&gt;Chapter 3: Learning value functions&lt;/strong&gt;&lt;br&gt; Approximate value and policy iteration, AVI as a series of supervised learning problems, stochastic gradient descent for AVI, temporal difference methods, Q-learning, fitted Q-iteration. Overview of key intrinsic challenges in RL.&lt;br&gt; &lt;strong&gt;Chapter 4: Deep Q-Networks&lt;/strong&gt;&lt;br&gt; Neural network architecture for value functions, DQN, improvements on DQN.&lt;br&gt; &lt;strong&gt;Chapter 5: Continuous actions in DQN algorithms&lt;/strong&gt;&lt;br&gt; From DDPG to SAC.&lt;br&gt; &lt;strong&gt;Chapter 6: Direct policy search and policy gradient methods&lt;/strong&gt;&lt;br&gt; Policy gradient theorem, REINFORCE, A2C, PPO, evolutionary RL.&lt;br&gt; &lt;strong&gt;Chapter 7: Stochastic bandits&lt;/strong&gt;&lt;br&gt; Regret. Explore Then Comit. UCB. Thompson Sampling. Contextual bandits. Bandits beyond RL.&lt;br&gt; &lt;strong&gt;Chapter 8: Bandit tools for Reinforcement Learning&lt;/strong&gt;&lt;br&gt; Exploration in RL. (Bandit based) Monte Carlo Tree Search. UCT, Alpha Zero.&lt;/p&gt; &#xA;&lt;p&gt;##&amp;nbsp;Class material&lt;/p&gt; &#xA;&lt;p&gt;Notebooks for the first 6 chapters are accessible at &lt;a href=&#34;https://github.com/erachelson/RLclass_MVA&#34;&gt;https://github.com/erachelson/RLclass_MVA&lt;/a&gt;. Please download the latest version before class.&lt;/p&gt; &#xA;&lt;h2&gt;Schedule for 2023-24&lt;/h2&gt; &#xA;&lt;p&gt;The schedule is designed around 3-hours sessions. It might be adjusted depending on the progression of classes.&lt;/p&gt; &#xA;&lt;p&gt;Session 1: chapters 0 and 1.&lt;br&gt; Session 2: chapter 2 and 3.&lt;br&gt; Session 3: chapter 4.&lt;br&gt; Session 4: chapter 5.&lt;br&gt; Session 5: chapter 6.&lt;br&gt; Session 6 is kept unassigned for now, to preserve the possibility to use it as a buffer to avoid rushing through previous sessions.&lt;br&gt; Session 7 and 8: stochastic bandits, monte carlo tree search and alphaGo.&lt;/p&gt; &#xA;&lt;h2&gt;Homework&lt;/h2&gt; &#xA;&lt;p&gt;Each notebook contains homework that help play with the concepts introduced in class, to better grasp them. Most exercises come with solutions. The homework also introduces additional important notions. They are a full and important part to reach the class goals. Often, the provided answer reaches out further than the plain question asked and provides comments, additional insights, or external references.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation&lt;/h2&gt; &#xA;&lt;p&gt;The final grade will be composed of three parts (coefficients TBD).&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Between session 2 and session 6 (included), a short mandatory online 10-15 minutes quiz will be run at the beginning of class, on the contents of the previous session. These quizes will be graded and will count towards the final grade.&lt;/li&gt; &#xA; &lt;li&gt;An implementation project around session 6 will also be graded.&lt;/li&gt; &#xA; &lt;li&gt;An independent assignment on the last two sessions will finally be graded.&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>ashishpatel26/LLM-Engineering-Crash-Course</title>
    <updated>2024-01-16T01:36:40Z</updated>
    <id>tag:github.com,2024-01-16:/ashishpatel26/LLM-Engineering-Crash-Course</id>
    <link href="https://github.com/ashishpatel26/LLM-Engineering-Crash-Course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;LLM Engineering CrashCourse&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM-Engineering-Crash-Course&lt;/h1&gt; &#xA;&lt;h2&gt;Prerequisite Course&lt;/h2&gt; &#xA;&lt;h4&gt;1. NLP Crash Course (6th January,2024 - 13th January, 2024)&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Day 1: Foundations of NLP (6th January,2024)&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Topic&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Session 1: Introduction to NLP&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Defining NLP and real-world applications&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Evolution and trends in NLP&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Applications, case studies, challenges, and limitations&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Session 2: Fundamentals of Language Analysis&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Levels of language analysis: morphology, syntax, semantics, pragmatics&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/blob/main/NLPCrashCourse/Session2/2_1_Levels_of_language_analysis.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Text representation: Bag-of-words, TF-IDF, word embeddings&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/blob/main/NLPCrashCourse/Session2/2_2_Text_representation.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Language modeling: N-grams, RNNs, LSTMs, GRUs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/blob/main/NLPCrashCourse/Session2/2_3_Language_modeling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Day 2: Advanced NLP Techniques(13th January, 2024)&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Session 3: Lexical and Syntactic Processing&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Lexical processing techniques: tokenization, normalization&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Syntactic processing: parsing with dependency grammar, constituency parsing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Session 4: Semantic and Pragmatic Processing&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Semantic processing: word sense disambiguation, textual entailment&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Pragmatic processing: building dialogue systems, analyzing discourse&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Session 5: Applications in Real-world Scenarios&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Text representation and embeddings: Word2Vec, GloVe, BERT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Language modeling techniques: Transformers, attention mechanisms&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Text classification, sentiment analysis, machine translation, and text summarization&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/ashishpatel26/LLM-Engineering-Crash-Course/&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Main Course&lt;/h2&gt; &#xA;&lt;h4&gt;2.LLM Engineering Beginner to Advance Course&lt;/h4&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Continue...!!!&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;</summary>
  </entry>
</feed>