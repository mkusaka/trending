<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-18T01:43:36Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>czy36mengfei/tensorflow2_tutorials_chinese</title>
    <updated>2022-08-18T01:43:36Z</updated>
    <id>tag:github.com,2022-08-18:/czy36mengfei/tensorflow2_tutorials_chinese</id>
    <link href="https://github.com/czy36mengfei/tensorflow2_tutorials_chinese" rel="alternate"></link>
    <summary type="html">&lt;p&gt;tensorflow2中文教程，持续更新(当前版本:tensorflow2.0)，tag: tensorflow 2.0 tutorials&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tensorflow2_tutorials_chinese&lt;/h1&gt; &#xA;&lt;p&gt;tensorflow2中文教程，持续更新（不定期更新）&lt;/p&gt; &#xA;&lt;p&gt;tensorflow 2.0 正式版已上线， 后面将持续根据TensorFlow2的相关教程和学习资料。&lt;/p&gt; &#xA;&lt;p&gt;最新tensorflow教程和相关资源，请关注微信公众号：DoitNLP， 后面我会在DoitNLP上，持续更新深度学习、NLP、Tensorflow的相关教程和前沿资讯，它将成为我们一起学习tensorflow的大本营。&lt;/p&gt; &#xA;&lt;p&gt;当前tensorflow版本：tensorflow2.0&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;最全Tensorflow 2.0 教程持续更新：&lt;/strong&gt; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/59507137&#34;&gt;https://zhuanlan.zhihu.com/p/59507137&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;本教程主要由tensorflow2.0官方教程的个人学习复现笔记整理而来，并借鉴了一些keras构造神经网络的方法，中文讲解，方便喜欢阅读中文教程的朋友，tensorflow官方教程：&lt;a href=&#34;https://www.tensorflow.org&#34;&gt;https://www.tensorflow.org&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58825020&#34;&gt;TensorFlow 2.0 教程- Keras 快速入门&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58825710&#34;&gt;TensorFlow 2.0 教程-keras 函数api&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58826227&#34;&gt;TensorFlow 2.0 教程-使用keras训练模型&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59481536&#34;&gt;TensorFlow 2.0 教程-用keras构建自己的网络层&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59481985&#34;&gt;TensorFlow 2.0 教程-keras模型保存和序列化&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59482373&#34;&gt;TensorFlow 2.0 教程-eager模式&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59482589&#34;&gt;TensorFlow 2.0 教程-Variables&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59482934&#34;&gt;TensorFlow 2.0 教程--AutoGraph&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;TensorFlow 2.0 深度学习实践&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59506238&#34;&gt;TensorFlow2.0 教程-图像分类&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59506402&#34;&gt;TensorFlow2.0 教程-文本分类&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59506543&#34;&gt;TensorFlow2.0 教程-过拟合和欠拟合&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60232704&#34;&gt;TensorFlow2.0教程-结构化数据分类&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60238056&#34;&gt;TensorFlow2.0教程-回归&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60485936&#34;&gt;TensorFlow2.0教程-保持和读取模型&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;TensorFlow 2.0 基础网络结构&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60899040&#34;&gt;TensorFlow2教程-基础MLP网络&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60900318&#34;&gt;TensorFlow2教程-MLP及深度学习常见技巧&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60900649&#34;&gt;TensorFlow2教程-基础CNN网络&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60900902&#34;&gt;TensorFlow2教程-CNN变体网络&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60901179&#34;&gt;TensorFlow2教程-文本卷积&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60966714&#34;&gt;TensorFlow2教程-LSTM和GRU&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61077346&#34;&gt;TensorFlow2教程-自编码器&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61080045&#34;&gt;TensorFlow2教程-卷积自编码器&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61224215&#34;&gt;TensorFlow2教程-词嵌入&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61280722&#34;&gt;TensorFlow2教程-DCGAN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61400276&#34;&gt;TensorFlow2教程-使用Estimator构建Boosted trees&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;TensorFlow 2.0 安装&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61472293&#34;&gt;TensorFlow2教程-Ubuntu安装TensorFlow 2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62036280&#34;&gt;TensorFlow2教程-Windows安装tensorflow2.0&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;完整tensorflow2.0教程代码请看&lt;a href=&#34;https://github.com/czy36mengfei/tensorflow2_tutorials_chinese&#34;&gt;tensorflow2.0：中文教程tensorflow2_tutorials_chinese(欢迎star)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;更多TensorFlow 2.0 入门教程请持续关注专栏：&lt;a href=&#34;https://zhuanlan.zhihu.com/c_1091021863043624960&#34;&gt;Tensorflow2教程&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;深度学习入门书籍和资源推荐：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65371424&#34;&gt;https://zhuanlan.zhihu.com/p/65371424&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>parrt/dtreeviz</title>
    <updated>2022-08-18T01:43:36Z</updated>
    <id>tag:github.com,2022-08-18:/parrt/dtreeviz</id>
    <link href="https://github.com/parrt/dtreeviz" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A python library for decision tree visualization and model interpretation.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;dtreeviz : Decision Tree Visualization&lt;/h1&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;A python library for decision tree visualization and model interpretation. Currently supports &lt;a href=&#34;https://scikit-learn.org/stable&#34;&gt;scikit-learn&lt;/a&gt;, &lt;a href=&#34;https://xgboost.readthedocs.io/en/latest&#34;&gt;XGBoost&lt;/a&gt;, &lt;a href=&#34;https://spark.apache.org/mllib/&#34;&gt;Spark MLlib&lt;/a&gt;, and &lt;a href=&#34;https://lightgbm.readthedocs.io/en/latest/&#34;&gt;LightGBM&lt;/a&gt; trees. With 1.3, we now provide one- and two-dimensional feature space illustrations for classifiers (any model that can answer &lt;code&gt;predict_probab()&lt;/code&gt;); see &lt;a href=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/README.md#classification-boundaries-in-feature-space&#34;&gt;below&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Authors:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://parrt.cs.usfca.edu&#34;&gt;Terence Parr&lt;/a&gt;, a professor in the &lt;a href=&#34;https://www.usfca.edu/arts-sciences/graduate-programs/data-science&#34;&gt;University of San Francisco&#39;s data science program&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/tudor-lapusan-5902593b/&#34;&gt;Tudor Lapusan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/groverpr&#34;&gt;Prince Grover&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://explained.ai/decision-tree-viz/index.html&#34;&gt;How to visualize decision trees&lt;/a&gt; for deeper discussion of our decision tree visualization library and the visual design decisions we made.&lt;/p&gt; &#xA;&lt;h3&gt;Feedback&lt;/h3&gt; &#xA;&lt;p&gt;We welcome info from users on how they use dtreeviz, what features they&#39;d like, etc... via &lt;a href=&#34;mailto:parrt@cs.usfca.edu&#34;&gt;email (to parrt)&lt;/a&gt; or via an &lt;a href=&#34;https://github.com/parrt/dtreeviz/issues&#34;&gt;issue&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Quick start&lt;/h2&gt; &#xA;&lt;p&gt;Jump right into the examples using this &lt;a href=&#34;https://colab.research.google.com/github/parrt/dtreeviz/blob/master/notebooks/examples.ipynb&#34;&gt;Colab notebook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Take a look in &lt;a href=&#34;https://github.com/parrt/dtreeviz/tree/master/notebooks&#34;&gt;notebooks&lt;/a&gt;! Here we have a specific notebook for all supported ML libraries and more.&lt;/p&gt; &#xA;&lt;h2&gt;Discussion&lt;/h2&gt; &#xA;&lt;p&gt;Decision trees are the fundamental building block of &lt;a href=&#34;http://explained.ai/gradient-boosting/index.html&#34;&gt;gradient boosting machines&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Random_forest&#34;&gt;Random Forests&lt;/a&gt;(tm), probably the two most popular machine learning models for structured data. Visualizing decision trees is a tremendous aid when learning how these models work and when interpreting models. Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn&#39;t find a library that visualizes how decision nodes split up the feature space. It is also uncommon for libraries to support visualizing a specific feature vector as it weaves down through a tree&#39;s decision nodes; we could only find one image showing this.&lt;/p&gt; &#xA;&lt;p&gt;So, we&#39;ve created a general package for decision tree visualization and model interpretation, which we&#39;ll be using heavily in an upcoming &lt;a href=&#34;https://mlbook.explained.ai/&#34;&gt;machine learning book&lt;/a&gt; (written with &lt;a href=&#34;http://www.fast.ai/about/#jeremy&#34;&gt;Jeremy Howard&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;The visualizations are inspired by an educational animation by &lt;a href=&#34;http://www.r2d3.us/&#34;&gt;R2D3&lt;/a&gt;; &lt;a href=&#34;http://www.r2d3.us/visual-intro-to-machine-learning-part-1/&#34;&gt;A visual introduction to machine learning&lt;/a&gt;. With &lt;code&gt;dtreeviz&lt;/code&gt;, you can visualize how the feature space is split up at decision nodes, how the training samples get distributed in leaf nodes, how the tree makes predictions for a specific observation and more. These operations are critical to for understanding how classification or regression decision trees work. If you&#39;re not familiar with decision trees, check out &lt;a href=&#34;https://course18.fast.ai/ml.html&#34;&gt;fast.ai&#39;s Introduction to Machine Learning for Coders MOOC&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Install&lt;/h2&gt; &#xA;&lt;p&gt;Install anaconda3 on your system, if not already done.&lt;/p&gt; &#xA;&lt;p&gt;You might verify that you do not have conda-installed graphviz-related packages installed because dtreeviz needs the pip versions; you can remove them from conda space by doing:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda uninstall python-graphviz&#xA;conda uninstall graphviz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install (Python &amp;gt;=3.6 only), do this (from Anaconda Prompt on Windows!):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install dtreeviz             # install dtreeviz for sklearn&#xA;pip install dtreeviz[xgboost]    # install XGBoost related dependency&#xA;pip install dtreeviz[pyspark]    # install pyspark related dependency&#xA;pip install dtreeviz[lightgbm]   # install LightGBM related dependency&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This should also pull in the &lt;code&gt;graphviz&lt;/code&gt; Python library (&amp;gt;=0.9), which we are using for platform specific stuff.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Limitations.&lt;/strong&gt; Only svg files can be generated at this time, which reduces dependencies and dramatically simplifies install process.&lt;/p&gt; &#xA;&lt;p&gt;Please email &lt;a href=&#34;mailto:parrt@cs.usfca.edu&#34;&gt;Terence&lt;/a&gt; with any helpful notes on making dtreeviz work (better) on other platforms. Thanks!&lt;/p&gt; &#xA;&lt;p&gt;For your specific platform, please see the following subsections.&lt;/p&gt; &#xA;&lt;h3&gt;Mac&lt;/h3&gt; &#xA;&lt;p&gt;Make sure to have the latest XCode installed and command-line tools installed. You can run &lt;code&gt;xcode-select --install&lt;/code&gt; from the command-line to install those if XCode is already installed. You also have to sign the XCode license agreement, which you can do with &lt;code&gt;sudo xcodebuild -license&lt;/code&gt; from command-line. The brew install shown next needs to build graphviz, so you need XCode set up properly.&lt;/p&gt; &#xA;&lt;p&gt;You need the graphviz binary for &lt;code&gt;dot&lt;/code&gt;. Make sure you have latest version (verified on 10.13, 10.14):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew reinstall graphviz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Just to be sure, remove &lt;code&gt;dot&lt;/code&gt; from any anaconda installation, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rm ~/anaconda3/bin/dot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From command line, this command&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dot -Tsvg&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;should work, in the sense that it just stares at you without giving an error. You can hit control-C to escape back to the shell. Make sure that you are using the right &lt;code&gt;dot&lt;/code&gt; as installed by brew:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ which dot&#xA;/usr/local/bin/dot&#xA;$ ls -l $(which dot)&#xA;lrwxr-xr-x  1 parrt  wheel  33 May 26 11:04 /usr/local/bin/dot@ -&amp;gt; ../Cellar/graphviz/2.40.1/bin/dot&#xA;$&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Limitations.&lt;/strong&gt; Jupyter notebook has a bug where they do not show .svg files correctly, but Juypter Lab has no problem.&lt;/p&gt; &#xA;&lt;h3&gt;Linux (Ubuntu 18.04)&lt;/h3&gt; &#xA;&lt;p&gt;To get the &lt;code&gt;dot&lt;/code&gt; binary do:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install graphviz&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Limitations.&lt;/strong&gt; The &lt;code&gt;view()&lt;/code&gt; method works to pop up a new window and images appear inline for jupyter notebook but not jupyter lab (It gets an error parsing the SVG XML.) The notebook images also have a font substitution from the Arial we use and so some text overlaps. Only .svg files can be generated on this platform.&lt;/p&gt; &#xA;&lt;h3&gt;Windows 10&lt;/h3&gt; &#xA;&lt;p&gt;(Make sure to &lt;code&gt;pip install graphviz&lt;/code&gt;, which is common to all platforms, and make sure to do this from Anaconda Prompt on Windows!)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://graphviz.gitlab.io/_pages/Download/Download_windows.html&#34;&gt;Download graphviz-2.38.msi&lt;/a&gt; and update your &lt;code&gt;Path&lt;/code&gt; environment variable. Add &lt;code&gt;C:\Program Files (x86)\Graphviz2.38\bin&lt;/code&gt; to User path and &lt;code&gt;C:\Program Files (x86)\Graphviz2.38\bin\dot.exe&lt;/code&gt; to System Path. It&#39;s windows so you might need a reboot after updating that environment variable. You should see this from the Anaconda Prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(base) C:\Users\Terence Parr&amp;gt;where dot&#xA;C:\Program Files (x86)\Graphviz2.38\bin\dot.exe&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(Do not use &lt;code&gt;conda install -c conda-forge python-graphviz&lt;/code&gt; as you get an old version of &lt;code&gt;graphviz&lt;/code&gt; python library.)&lt;/p&gt; &#xA;&lt;p&gt;Verify from the Anaconda Prompt that this works (capital &lt;code&gt;-V&lt;/code&gt; not lowercase &lt;code&gt;-v&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dot -V&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If it doesn&#39;t work, you have a &lt;code&gt;Path&lt;/code&gt; problem. I found the following test programs useful. The first one sees if Python can find &lt;code&gt;dot&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os&#xA;import subprocess&#xA;proc = subprocess.Popen([&#39;dot&#39;,&#39;-V&#39;])&#xA;print( os.getenv(&#39;Path&#39;) )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The following version does the same thing except uses &lt;code&gt;graphviz&lt;/code&gt; Python libraries backend support utilities, which is what we use in dtreeviz:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import graphviz.backend as be&#xA;cmd = [&#34;dot&#34;, &#34;-V&#34;]&#xA;stdout, stderr = be.run(cmd, capture_output=True, check=True, quiet=False)&#xA;print( stderr )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you are having issues with run command you can try copying the following files from: &lt;a href=&#34;https://github.com/xflr6/graphviz/tree/master/graphviz&#34;&gt;https://github.com/xflr6/graphviz/tree/master/graphviz&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Place them in the AppData\Local\Continuum\anaconda3\Lib\site-packages\graphviz folder.&lt;/p&gt; &#xA;&lt;p&gt;Clean out the &lt;strong&gt;pycache&lt;/strong&gt; directory too.&lt;/p&gt; &#xA;&lt;p&gt;Jupyter Lab and Jupyter notebook both show the inline .svg images well.&lt;/p&gt; &#xA;&lt;h3&gt;Verify graphviz installation&lt;/h3&gt; &#xA;&lt;p&gt;Try making text file &lt;code&gt;t.dot&lt;/code&gt; with content &lt;code&gt;digraph T { A -&amp;gt; B }&lt;/code&gt; (paste that into a text editor, for example) and then running this from the command line:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dot -Tsvg -o t.svg t.dot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That should give a simple &lt;code&gt;t.svg&lt;/code&gt; file that opens properly. If you get errors from &lt;code&gt;dot&lt;/code&gt;, it will not work from the dtreeviz python code. If it can&#39;t find &lt;code&gt;dot&lt;/code&gt; then you didn&#39;t update your &lt;code&gt;PATH&lt;/code&gt; environment variable or there is some other install issue with &lt;code&gt;graphviz&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Limitations&lt;/h3&gt; &#xA;&lt;p&gt;Finally, don&#39;t use IE to view .svg files. Use Edge as they look much better. I suspect that IE is displaying them as a rasterized not vector images. Only .svg files can be generated on this platform.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;&lt;code&gt;dtree&lt;/code&gt;: Main function to create decision tree visualization. Given a decision tree regressor or classifier, creates and returns a tree visualization using the graphviz (DOT) language.&lt;/p&gt; &#xA;&lt;h3&gt;Required libraries&lt;/h3&gt; &#xA;&lt;p&gt;Basic libraries and imports that will (might) be needed to generate the sample visualizations shown in examples below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;from sklearn.datasets import *&#xA;from sklearn import tree&#xA;from dtreeviz.trees import *&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Regression decision tree&lt;/h3&gt; &#xA;&lt;p&gt;The default orientation of tree is top down but you can change it to left to right using &lt;code&gt;orientation=&#34;LR&#34;&lt;/code&gt;. &lt;code&gt;view()&lt;/code&gt; gives a pop up window with rendered graphviz object.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;regr = tree.DecisionTreeRegressor(max_depth=2)&#xA;boston = load_boston()&#xA;regr.fit(boston.data, boston.target)&#xA;&#xA;viz = dtreeviz(regr,&#xA;               boston.data,&#xA;               boston.target,&#xA;               target_name=&#39;price&#39;,&#xA;               feature_names=boston.feature_names)&#xA;              &#xA;viz.view()              &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/boston-TD-2.svg?sanitize=true&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h3&gt;Classification decision tree&lt;/h3&gt; &#xA;&lt;p&gt;An additional argument of &lt;code&gt;class_names&lt;/code&gt; giving a mapping of class value with class name is required for classification trees.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;classifier = tree.DecisionTreeClassifier(max_depth=2)  # limit depth of tree&#xA;iris = load_iris()&#xA;classifier.fit(iris.data, iris.target)&#xA;&#xA;viz = dtreeviz(classifier, &#xA;               iris.data, &#xA;               iris.target,&#xA;               target_name=&#39;variety&#39;,&#xA;               feature_names=iris.feature_names, &#xA;               class_names=[&#34;setosa&#34;, &#34;versicolor&#34;, &#34;virginica&#34;]  # need class_names for classifier&#xA;              )  &#xA;              &#xA;viz.view() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/iris-TD-2.svg?sanitize=true&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h3&gt;Prediction path&lt;/h3&gt; &#xA;&lt;p&gt;Highlights the decision nodes in which the feature value of single observation passed in argument &lt;code&gt;X&lt;/code&gt; falls. Gives feature values of the observation and highlights features which are used by tree to traverse path.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;regr = tree.DecisionTreeRegressor(max_depth=2)  # limit depth of tree&#xA;diabetes = load_diabetes()&#xA;regr.fit(diabetes.data, diabetes.target)&#xA;X = diabetes.data[np.random.randint(0, len(diabetes.data)),:]  # random sample from training&#xA;&#xA;viz = dtreeviz(regr,&#xA;               diabetes.data, &#xA;               diabetes.target, &#xA;               target_name=&#39;value&#39;, &#xA;               orientation =&#39;LR&#39;,  # left-right orientation&#xA;               feature_names=diabetes.feature_names,&#xA;               X=X)  # need to give single observation for prediction&#xA;              &#xA;viz.view()  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/diabetes-LR-2-X.svg?sanitize=true&#34; width=&#34;100%&#34; height=&#34;50%&#34;&gt; &#xA;&lt;p&gt;If you want to visualize just the prediction path, you need to set parameter &lt;em&gt;show_just_path=True&lt;/em&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;dtreeviz(regr,&#xA;        diabetes.data, &#xA;        diabetes.target, &#xA;        target_name=&#39;value&#39;, &#xA;        orientation =&#39;TD&#39;,  # top-down orientation&#xA;        feature_names=diabetes.feature_names,&#xA;        X=X, # need to give single observation for prediction&#xA;        show_just_path=True     &#xA;        )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94368231-b17ce900-00eb-11eb-8e2d-89a0e927e494.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h4&gt;Explain prediction path&lt;/h4&gt; &#xA;&lt;p&gt;These visualizations are useful to explain to somebody, without machine learning skills, why your model made that specific prediction. &lt;br&gt; In case of &lt;code&gt;explanation_type=plain_english&lt;/code&gt;, it searches in prediction path and find feature value ranges.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;X = dataset[features].iloc[10]&#xA;print(X)&#xA;Pclass              3.0&#xA;Age                 4.0&#xA;Fare               16.7&#xA;Sex_label           0.0&#xA;Cabin_label       145.0&#xA;Embarked_label      2.0&#xA;&#xA;print(explain_prediction_path(tree_classifier, X, feature_names=features, explanation_type=&#34;plain_english&#34;))&#xA;2.5 &amp;lt;= Pclass &#xA;Age &amp;lt; 36.5&#xA;Fare &amp;lt; 23.35&#xA;Sex_label &amp;lt; 0.5&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In case of &lt;code&gt;explanation_type=sklearn_default&lt;/code&gt; (available only for scikit-learn), we can visualize the features&#39; importance involved in prediction path only. Features&#39; importance is calculated based on mean decrease in impurity. &lt;br&gt; Check &lt;a href=&#34;https://explained.ai/rf-importance/index.html&#34;&gt;Beware Default Random Forest Importances&lt;/a&gt; article for a comparison between features&#39; importance based on mean decrease in impurity vs permutation importance.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;explain_prediction_path(tree_classifier, X, feature_names=features, explanation_type=&#34;sklearn_default&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94448483-9d042380-01b3-11eb-95f6-a973f1b7092a.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h3&gt;Decision tree without scatterplot or histograms for decision nodes&lt;/h3&gt; &#xA;&lt;p&gt;Simple tree without histograms or scatterplots for decision nodes. Use argument &lt;code&gt;fancy=False&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;classifier = tree.DecisionTreeClassifier(max_depth=4)  # limit depth of tree&#xA;cancer = load_breast_cancer()&#xA;classifier.fit(cancer.data, cancer.target)&#xA;&#xA;viz = dtreeviz(classifier,&#xA;              cancer.data,&#xA;              cancer.target,&#xA;              target_name=&#39;cancer&#39;,&#xA;              feature_names=cancer.feature_names, &#xA;              class_names=[&#34;malignant&#34;, &#34;benign&#34;],&#xA;              fancy=False )  # fance=False to remove histograms/scatterplots from decision nodes&#xA;              &#xA;viz.view() &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/breast_cancer-TD-4-simple.svg?sanitize=true&#34; width=&#34;60%&#34;&gt; &#xA;&lt;p&gt;For more examples and different implementations, please see the jupyter &lt;a href=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/notebooks/examples.ipynb&#34;&gt;notebook&lt;/a&gt; full of examples.&lt;/p&gt; &#xA;&lt;h3&gt;Regression univariate feature-target space&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/178777/49105092-9b264d80-f234-11e8-9d67-cc58c47016ca.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd&#xA;import matplotlib.pyplot as plt&#xA;from sklearn.tree import DecisionTreeRegressor&#xA;from dtreeviz.trees import *&#xA;&#xA;df_cars = pd.read_csv(&#34;cars.csv&#34;)&#xA;X, y = df_cars[[&#39;WGT&#39;]], df_cars[&#39;MPG&#39;]&#xA;&#xA;dt = DecisionTreeRegressor(max_depth=3, criterion=&#34;mae&#34;)&#xA;dt.fit(X, y)&#xA;&#xA;fig = plt.figure()&#xA;ax = fig.gca()&#xA;rtreeviz_univar(dt, X, y, &#39;WGT&#39;, &#39;MPG&#39;, ax=ax)&#xA;plt.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Regression bivariate feature-target space&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/178777/49104999-4edb0d80-f234-11e8-9010-73b7c0ba5fb9.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mpl_toolkits.mplot3d import Axes3D&#xA;from sklearn.tree import DecisionTreeRegressor&#xA;from dtreeviz.trees import *&#xA;&#xA;df_cars = pd.read_csv(&#34;cars.csv&#34;)&#xA;X = df_cars[[&#39;WGT&#39;,&#39;ENG&#39;]]&#xA;y = df_cars[&#39;MPG&#39;]&#xA;&#xA;dt = DecisionTreeRegressor(max_depth=3, criterion=&#34;mae&#34;)&#xA;dt.fit(X, y)&#xA;&#xA;figsize = (6,5)&#xA;fig = plt.figure(figsize=figsize)&#xA;ax = fig.add_subplot(111, projection=&#39;3d&#39;)&#xA;&#xA;t = rtreeviz_bivar_3D(dt,&#xA;                      X, y,&#xA;                      feature_names=[&#39;Vehicle Weight&#39;, &#39;Horse Power&#39;],&#xA;                      target_name=&#39;MPG&#39;,&#xA;                      fontsize=14,&#xA;                      elev=20,&#xA;                      azim=25,&#xA;                      dist=8.2,&#xA;                      show={&#39;splits&#39;,&#39;title&#39;},&#xA;                      ax=ax)&#xA;plt.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Regression bivariate feature-target space heatmap&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/178777/49107627-08d57800-f23b-11e8-85a2-ab5894055092.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.tree import DecisionTreeRegressor&#xA;from dtreeviz.trees import *&#xA;&#xA;df_cars = pd.read_csv(&#34;cars.csv&#34;)&#xA;X = df_cars[[&#39;WGT&#39;,&#39;ENG&#39;]]&#xA;y = df_cars[&#39;MPG&#39;]&#xA;&#xA;dt = DecisionTreeRegressor(max_depth=3, criterion=&#34;mae&#34;)&#xA;dt.fit(X, y)&#xA;&#xA;t = rtreeviz_bivar_heatmap(dt,&#xA;                           X, y,&#xA;                           feature_names=[&#39;Vehicle Weight&#39;, &#39;Horse Power&#39;],&#xA;                           fontsize=14)&#xA;&#xA;plt.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Classification univariate feature-target space&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/178777/49105084-9497d600-f234-11e8-9097-56835558c1a6.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.tree import DecisionTreeClassifier&#xA;from dtreeviz.trees import *&#xA;&#xA;know = pd.read_csv(&#34;knowledge.csv&#34;)&#xA;class_names = [&#39;very_low&#39;, &#39;Low&#39;, &#39;Middle&#39;, &#39;High&#39;]&#xA;know[&#39;UNS&#39;] = know[&#39;UNS&#39;].map({n: i for i, n in enumerate(class_names)})&#xA;&#xA;X = know[[&#39;PEG&#39;]]&#xA;y = know[&#39;UNS&#39;]&#xA;&#xA;dt = DecisionTreeClassifier(max_depth=3)&#xA;dt.fit(X, y)&#xA;&#xA;ct = ctreeviz_univar(dt, X, y,&#xA;                     feature_names = [&#39;PEG&#39;],&#xA;                     class_names=class_names,&#xA;                     target_name=&#39;Knowledge&#39;,&#xA;                     nbins=40, gtype=&#39;strip&#39;,&#xA;                     show={&#39;splits&#39;,&#39;title&#39;})&#xA;plt.tight_layout()&#xA;plt.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Classification bivariate feature-target space&lt;/h3&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/178777/49105085-9792c680-f234-11e8-8af5-bc2fde950ab1.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn.tree import DecisionTreeClassifier&#xA;from dtreeviz.trees import *&#xA;&#xA;know = pd.read_csv(&#34;knowledge.csv&#34;)&#xA;print(know)&#xA;class_names = [&#39;very_low&#39;, &#39;Low&#39;, &#39;Middle&#39;, &#39;High&#39;]&#xA;know[&#39;UNS&#39;] = know[&#39;UNS&#39;].map({n: i for i, n in enumerate(class_names)})&#xA;&#xA;X = know[[&#39;PEG&#39;,&#39;LPR&#39;]]&#xA;y = know[&#39;UNS&#39;]&#xA;&#xA;dt = DecisionTreeClassifier(max_depth=3)&#xA;dt.fit(X, y)&#xA;&#xA;ct = ctreeviz_bivar(dt, X, y,&#xA;                    feature_names = [&#39;PEG&#39;,&#39;LPR&#39;],&#xA;                    class_names=class_names,&#xA;                    target_name=&#39;Knowledge&#39;)&#xA;plt.tight_layout()&#xA;plt.show()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Leaf node purity&lt;/h3&gt; &#xA;&lt;p&gt;Leaf purity affects prediction confidence. &lt;br&gt; For classification leaf purity is calculated based on majority target class (gini, entropy) and for regression is calculated based on target variance values. &lt;br&gt; Leaves with low variance among the target values (regression) or an overwhelming majority target class (classification) are much more reliable predictors. When we have a decision tree with a high depth, it can be difficult to get an overview about all leaves purities. That&#39;s why we created a specialized visualization only for leaves purities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;display_type&lt;/em&gt; can take values &#39;plot&#39; (default), &#39;hist&#39; or &#39;text&#39;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;viz_leaf_criterion(tree_classifier, display_type = &#34;plot&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94367215-f271ff00-00e5-11eb-802c-d5f486c45ab4.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h3&gt;Leaf node samples&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s also important to take a look at the number of samples from leaves. For example, we can have a leaf with a good purity but very few samples, which is a sign of overfitting. The ideal scenario would be to have a leaf with good purity which is based on a significant number of samples.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;display_type&lt;/em&gt; can take values &#39;plot&#39; (default), &#39;hist&#39; or &#39;text&#39;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;viz_leaf_samples(tree_classifier, dataset[features], display_type=&#39;plot&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94367931-264f2380-00ea-11eb-9588-525c58528c1e.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h4&gt;Leaf node samples for classification&lt;/h4&gt; &#xA;&lt;p&gt;This is a specialized visualization for classification. It helps also to see the distribution of target class values from leaf samples.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctreeviz_leaf_samples(tree_classifier, dataset[features], dataset[target])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94368065-eccae800-00ea-11eb-8fd6-250192ad6471.png&#34; width=&#34;30%&#34;&gt; &#xA;&lt;h3&gt;Leaf plots&lt;/h3&gt; &#xA;&lt;p&gt;Visualize leaf target distribution for regression decision trees.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;viz_leaf_target(tree_regressor, dataset[features_reg], dataset[target_reg], features_reg, target_reg)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img src=&#34;https://user-images.githubusercontent.com/12815158/94445430-19950300-01b0-11eb-9a5a-8f1672f11d94.png&#34; width=&#34;20%&#34;&gt; &#xA;&lt;h2&gt;Classification boundaries in feature space&lt;/h2&gt; &#xA;&lt;p&gt;With 1.3, we have introduced method &lt;code&gt;clfviz()&lt;/code&gt; that illustrates one and two-dimensional feature space for classifiers, including colors the represent probabilities, decision boundaries, and misclassified entities. This method works with any model that answers method &lt;code&gt;predict_proba()&lt;/code&gt; (and we also support Keras), so any model from scikit-learn should work. If you let us know about incompatibilities, we can support more models. There are lots of options would you can check out in the &lt;a href=&#34;https://github.com/parrt/dtreeviz/raw/master/dtreeviz/classifiers.py&#34;&gt;api documentation&lt;/a&gt;. See &lt;a href=&#34;https://github.com/parrt/dtreeviz/tree/master/notebooks/classifier-decision-boundaries.ipynb&#34;&gt;classifier-decision-boundaries.ipynb&lt;/a&gt; and &lt;a href=&#34;https://github.com/parrt/dtreeviz/tree/master/notebooks/classifier-boundary-animations.ipynb&#34;&gt;classifier-boundary-animations.ipynb&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clfviz(rf, X, y, feature_names=[&#39;x1&#39;, &#39;x2&#39;], markers=[&#39;o&#39;,&#39;X&#39;,&#39;s&#39;,&#39;D&#39;], target_name=&#39;smiley&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;30%&#34; src=&#34;https://user-images.githubusercontent.com/178777/113516349-a12c4780-952e-11eb-86f3-0ae457eb500f.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clfviz(rf,x,y,feature_names=[&#39;f27&#39;],target_name=&#39;cancer&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;30%&#34; src=&#34;https://user-images.githubusercontent.com/178777/113516364-b608db00-952e-11eb-91cf-efe2386622f1.png&#34;&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;clfviz(rf,x,y,&#xA;       feature_names=[&#39;x2&#39;],&#xA;       target_name = &#39;smiley&#39;,&#xA;       colors={&#39;scatter_marker_alpha&#39;:.2})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;img width=&#34;30%&#34; src=&#34;https://user-images.githubusercontent.com/178777/113516379-d5076d00-952e-11eb-955e-1dd7c09f2f29.png&#34;&gt; &#xA;&lt;p&gt;Sometimes it&#39;s helpful to see animations that change some of the hyper parameters. If you look in notebook &lt;a href=&#34;https://github.com/parrt/dtreeviz/tree/master/notebooks/classifier-boundary-animations.ipynb&#34;&gt;classifier-boundary-animations.ipynb&lt;/a&gt;, you will see code that generates animations such as the following (animated png files):&lt;/p&gt; &#xA;&lt;p&gt;&lt;img width=&#34;30%&#34; src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/smiley-dtree-maxdepth.png&#34;&gt;&amp;nbsp;&lt;img width=&#34;30%&#34; src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/smiley-numtrees.png&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Visualization methods setup&lt;/h2&gt; &#xA;&lt;p&gt;Starting with dtreeviz 1.0 version, we refactored the concept of ShadowDecTree. If we want to add a new ML library in dtreeviz, we just need to add a new implementation of ShadowDecTree API, like ShadowSKDTree, ShadowXGBDTree or ShadowSparkTree.&lt;/p&gt; &#xA;&lt;p&gt;Initializing a ShadowSKDTree object:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;sk_dtree = ShadowSKDTree(tree_classifier, dataset[features], dataset[target], features, target, [0, 1])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Once we have the object initialized, we can used it to create all the visualizations, like :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;dtreeviz(sk_dtree)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;viz_leaf_samples(sk_dtree)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;viz_leaf_criterion(sk_dtree)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;In this way, we reduced substantially the list of parameters required for each visualization and it&#39;s also more efficient in terms of computing power.&lt;/p&gt; &#xA;&lt;p&gt;You can check the &lt;a href=&#34;https://github.com/parrt/dtreeviz/tree/master/notebooks&#34;&gt;notebooks&lt;/a&gt; section for more examples of using ShadowSKDTree, ShadowXGBDTree or ShadowSparkTree.&lt;/p&gt; &#xA;&lt;h2&gt;Install dtreeviz locally&lt;/h2&gt; &#xA;&lt;p&gt;Make sure to follow the install guidelines above.&lt;/p&gt; &#xA;&lt;p&gt;To push the &lt;code&gt;dtreeviz&lt;/code&gt; library to your local egg cache (force updates) during development, do this (from anaconda prompt on Windows):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python setup.py install -f&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;E.g., on Terence&#39;s box, it add &lt;code&gt;/Users/parrt/anaconda3/lib/python3.6/site-packages/dtreeviz-0.3-py3.6.egg&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Customize colors&lt;/h2&gt; &#xA;&lt;p&gt;Each function has an optional parameter &lt;code&gt;colors&lt;/code&gt; which allows passing a dictionary of colors which is used in the plot. For an example of each parameter have a look at this &lt;a href=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/notebooks/colors.ipynb&#34;&gt;notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dtreeviz.trees.dtreeviz(regr,&#xA;                        boston.data,&#xA;                        boston.target,&#xA;                        target_name=&#39;price&#39;,&#xA;                        feature_names=boston.feature_names,&#xA;                        colors={&#39;scatter_marker&#39;: &#39;#00ff00&#39;})&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;would paint the scatter (dots) in red.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/testing/samples/colors_scatter_marker.svg?sanitize=true&#34; alt=&#34;Green plot&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Parameters&lt;/h3&gt; &#xA;&lt;p&gt;The colors are defined in &lt;code&gt;colors.py&lt;/code&gt;, all options and default parameters are shown below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    COLORS = {&#39;scatter_edge&#39;: GREY,         &#xA;              &#39;scatter_marker&#39;: BLUE,&#xA;              &#39;split_line&#39;: GREY,&#xA;              &#39;mean_line&#39;: &#39;#f46d43&#39;,&#xA;              &#39;axis_label&#39;: GREY,&#xA;              &#39;title&#39;: GREY,&#xA;              &#39;legend_title&#39;: GREY,&#xA;              &#39;legend_edge&#39;: GREY,&#xA;              &#39;edge&#39;: GREY,&#xA;              &#39;color_map_min&#39;: &#39;#c7e9b4&#39;,&#xA;              &#39;color_map_max&#39;: &#39;#081d58&#39;,&#xA;              &#39;classes&#39;: color_blind_friendly_colors,&#xA;              &#39;rect_edge&#39;: GREY,&#xA;              &#39;text&#39;: GREY,&#xA;              &#39;highlight&#39;: HIGHLIGHT_COLOR,&#xA;              &#39;wedge&#39;: WEDGE_COLOR,&#xA;              &#39;text_wedge&#39;: WEDGE_COLOR,&#xA;              &#39;arrow&#39;: GREY,&#xA;              &#39;node_label&#39;: GREY,&#xA;              &#39;tick_label&#39;: GREY,&#xA;              &#39;leaf_label&#39;: GREY,&#xA;              &#39;pie&#39;: GREY,&#xA;              }&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The color needs be in a format &lt;a href=&#34;https://matplotlib.org/2.0.2/api/colors_api.html&#34;&gt;matplotlib&lt;/a&gt; can interpret, e.g. a html hex like &lt;code&gt;&#39;#eeefff&#39;&lt;/code&gt; .&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;classes&lt;/code&gt; needs to be a list of lists of colors with a minimum length of your number of colors. The index is the number of classes and the list with this index needs to have the same amount of colors.&lt;/p&gt; &#xA;&lt;h2&gt;Useful Resources&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://explained.ai/decision-tree-viz/index.html&#34;&gt;How to visualize decision trees&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://explained.ai/gradient-boosting/index.html&#34;&gt;How to explain gradient boosting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlbook.explained.ai/&#34;&gt;The Mechanics of Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.r2d3.us/&#34;&gt;Animation by R2D3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.r2d3.us/visual-intro-to-machine-learning-part-1/&#34;&gt;A visual introductionn to machine learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://course18.fast.ai/ml.html&#34;&gt;fast.ai&#39;s Introduction to Machine Learning for Coders MOOC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Stef van den Elzen&#39;s &lt;a href=&#34;http://alexandria.tue.nl/extra1/afstversl/wsk-i/elzen2011.pdf&#34;&gt;Interactive Construction, Analysis and Visualization of Decision Trees&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Some similar feature-space visualizations in &lt;a href=&#34;https://github.com/EE2dev/publications/raw/master/cooperativeClassification.pdf&#34;&gt;Towards an effective cooperation of the user and the computer for classification, SIGKDD 2000&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.bigml.com/2012/01/23/beautiful-decisions-inside-bigmls-decision-trees/&#34;&gt;Beautiful Decisions: Inside BigML’s Decision Trees&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&#34;SunBurst&#34; approach to tree visualization: &lt;a href=&#34;https://www.cc.gatech.edu/~john.stasko/papers/ijhcs00.pdf&#34;&gt;An evaluation of space-filling information visualizations for depicting hierarchical structures&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://parrt.cs.usfca.edu/&#34;&gt;&lt;strong&gt;Terence Parr&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/tudor-lapusan-5902593b/&#34;&gt;Tudor Lapusan&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/groverpr/&#34;&gt;&lt;strong&gt;Prince Grover&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;See also the list of &lt;a href=&#34;https://github.com/parrt/dtreeviz/graphs/contributors&#34;&gt;contributors&lt;/a&gt; who participated in this project.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;This project is licensed under the terms of the MIT license, see &lt;a href=&#34;https://raw.githubusercontent.com/parrt/dtreeviz/master/LICENSE&#34;&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Deploy&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ python setup.py sdist upload&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>enpeizhao/CVprojects</title>
    <updated>2022-08-18T01:43:36Z</updated>
    <id>tag:github.com,2022-08-18:/enpeizhao/CVprojects</id>
    <link href="https://github.com/enpeizhao/CVprojects" rel="alternate"></link>
    <summary type="html">&lt;p&gt;computer vision projects | 计算机视觉等好玩的AI项目&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;计算机视觉小项目&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;请仅做个人学习、研究使用&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h3&gt;一、微信答疑、交流：&lt;/h3&gt; &#xA;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_5862.JPG?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt; &#xA;&lt;h3&gt;二、观看项目实际运行视频：&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;抖音&lt;/th&gt; &#xA;   &lt;th&gt;B站&lt;/th&gt; &#xA;   &lt;th&gt;快手&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_5859.JPG?x-oss-process=style/wp&#34; style=&#34;width:200px&#34;&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&#34;https://www.douyin.com/user/MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2?enter_from=search_result&amp;amp;enter_method=search_result&amp;amp;extra_params=%7B%22search_params%22%3A%7B%22search_type%22%3A%22user%22%2C%22search_id%22%3A%22202111241756340101512071374A007D0F%22%2C%22search_keyword%22%3A%22enpe%22%2C%22search_result_id%22%3A%221205502393189652%22%7D%7D&#34;&gt;网页版抖音&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_7117.PNG?x-oss-process=style/wp&#34;&gt;&lt;br&gt;&lt;a href=&#34;https://space.bilibili.com/1355276754&#34;&gt;网页版B站&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_5858.JPG?x-oss-process=style/wp&#34; style=&#34;width:200px&#34;&gt;&lt;br&gt;&lt;a href=&#34;https://www.kuaishou.com/profile/3x54fkprp4xtu4a&#34;&gt;网页版快手&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;三、项目列表&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;名称与在线播放地址&lt;/th&gt; &#xA;   &lt;th&gt;截图&lt;/th&gt; &#xA;   &lt;th&gt;方法&lt;/th&gt; &#xA;   &lt;th&gt;难度&lt;/th&gt; &#xA;   &lt;th&gt;代码地址&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;26.UNet医学图片分割&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgimage%20(1).png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;UNet&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/26.UNet%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&#34;&gt;codes/26.UNet医学图像分割&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;25.swin-transformer路面分割&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220728172209.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Swin-transfomer&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/25.swin-transformer%E8%B7%AF%E9%9D%A2%E5%88%86%E5%89%B2&#34;&gt;codes/25.swin-transformer路面分割&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;24.Web以图搜图系统&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220715195118.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;metric-learning、docker、torchserve、tfservering&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/24.web%E4%BB%A5%E5%9B%BE%E6%90%9C%E5%9B%BE&#34;&gt;codes/24.web以图搜图&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;23.facenet 戴口罩的人脸识别&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_7913.PNG?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;facenet、inception resnet、人脸识别&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/23.facenet%E6%88%B4%E5%8F%A3%E7%BD%A9%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&#34;&gt;codes/23.facenet戴口罩的人脸识别&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;22.openvino树莓派扑克牌检测&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220617173131.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Openvino、YOLOV5、树莓派&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/22.openvino%E6%89%91%E5%85%8B%E7%89%8C%E6%A3%80%E6%B5%8B&#34;&gt;codes/22.openvino扑克牌检测&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;21.GAN老照片上色并动起来&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_7673.jpg?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;GAN风格化、超分辨率、first order model&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/21.GAN%E8%80%81%E7%85%A7%E7%89%87%E4%B8%8A%E8%89%B2%E5%8A%A8%E8%B5%B7%E6%9D%A5&#34;&gt;codes/21.GAN老照片上色动起来&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;20.骨骼点动态动作识别&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220518201724.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;姿态估计、DTW&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/20.%E9%AA%A8%E9%AA%BC%E7%82%B9%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB&#34;&gt;codes/20.骨骼点动作识别&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;19.OCR车牌识别&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220504215359.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;目标检测、OCR文字识别&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/19.OCR%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB&#34;&gt;codes/19.OCR车牌识别&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;18.YOLOv5 + Deepsort 车辆追踪及速度分析&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220418170339.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;YOLOv5、Deepsort、目标追踪、速度估计&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/18.deepsort%20%E9%81%93%E8%B7%AF%E8%BD%A6%E8%BE%86%E5%88%86%E6%9E%90&#34;&gt;codes/18.deepsort 道路车辆分析&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;17.YOLOv5 jetson nano 工地防护检测&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220404103032.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;YOLOv5、Jetson Nano、tensoRT、Deepstream&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/17.YOLOv5%20jetson%20nano%20%E5%B7%A5%E5%9C%B0%E9%98%B2%E6%8A%A4%E6%A3%80%E6%B5%8B&#34;&gt;codes/17.YOLOv5 jetson nano 工地防护检测&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;16.树莓派口罩规范佩戴检测&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220319164803.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;树莓派、CNN卷积神经网络，模型压缩&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/16.%E5%8F%A3%E7%BD%A9%E8%A7%84%E8%8C%83%E4%BD%A9%E6%88%B4%E6%A3%80%E6%B5%8B&#34;&gt;codes/16.口罩规范佩戴检测&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7071609658661752068?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;15.防挡弹幕&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220305205805.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;图像分割&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/15.%E9%98%B2%E6%8C%A1%E5%BC%B9%E5%B9%95&#34;&gt;codes/15.防挡弹幕&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7066620595206622503?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;14.人脸考勤机&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20220220094051.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;人脸检测与识别&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/14.%E4%BA%BA%E8%84%B8%E8%80%83%E5%8B%A4%E6%9C%BA&#34;&gt;codes/14.人脸考勤机&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7060352692807306507?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;13.毛笔书体检测与识别&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_63991.jpeg?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;OpenCV形态学、HOG、SVM&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/13.%E4%B9%A6%E6%B3%95%E4%B9%A6%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB&#34;&gt;codes/13.书法书体检测与识别&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7045886695211879691?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;11.AI分析看电视行为&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_6178.PNG?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;人脸检测与识别、姿态、距离估计&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/11.watch_tv&#34;&gt;codes/11.watch_tv&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7042602099925912869?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;10.AI虚拟鼠标&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_6083.PNG?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;手部姿态估计、静态动作&lt;/td&gt; &#xA;   &lt;td&gt;⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/10.virtual_mouse&#34;&gt;codes/10.virtual_mouse&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7040350760705510663?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;9.AI 虚拟点读机&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20211211154451.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;目标检测、OCR&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/9.virtual%20reader&#34;&gt;codes/9.virtual reader&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7036367345970875687?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;8. 火影结印识别&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20211201102837.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;手部3D姿态估计、GCN&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/tree/main/codes/8.%E7%BB%93%E5%8D%B0%E8%AF%86%E5%88%AB&#34;&gt;codes/8.结印识别&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7033012599729999137?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;7.虚拟拖放 Python + opencv&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20211120135236.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;手部姿态估计、静态动作&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/raw/main/codes/7.virtual_drag_drop&#34;&gt;codes/7.virtual_drag_drop.py&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7031539631594163469?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;6.Python手势控制电脑音量&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/img20211120135209.png?x-oss-process=style/wp&#34; style=&#34;width:200px;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;手部姿态估计、静态动作&lt;/td&gt; &#xA;   &lt;td&gt;⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/raw/main/codes/6.hand_control_volume&#34;&gt;codes/6.hand_control_volume.py&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.douyin.com/video/7016958202713771278?modeFrom=userPost&amp;amp;secUid=MS4wLjABAAAAPIrmWhFY-OHt5X8GZcHGqwDo3J29gYHcgG-QebKIDd4Wu_f4dwM2hNoEYyQBcim2&#34;&gt;5.手势暂停、播放电视&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;img src=&#34;https://enpei-md.oss-cn-hangzhou.aliyuncs.com/imgIMG_5885.jpg?x-oss-process=style/wp&#34; style=&#34;width:200px&#34;&gt;&lt;/td&gt; &#xA;   &lt;td&gt;手部姿态估计、静态动作、Home assistant&lt;/td&gt; &#xA;   &lt;td&gt;⭐️⭐️⭐️&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/enpeizhao/CVprojects/raw/main/codes/5.hand_pause_atv/&#34;&gt;codes/5.hand_pause_atv/handRemote.py&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>