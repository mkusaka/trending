<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-13T01:44:54Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rasbt/deeplearning-models</title>
    <updated>2022-08-13T01:44:54Z</updated>
    <id>tag:github.com,2022-08-13:/rasbt/deeplearning-models</id>
    <link href="https://github.com/rasbt/deeplearning-models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of various deep learning architectures, models, and tips&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deep Learning Models&lt;/h1&gt; &#xA;&lt;p&gt;A collection of various deep learning architectures, models, and tips for TensorFlow and PyTorch in Jupyter Notebooks.&lt;/p&gt; &#xA;&lt;h2&gt;Traditional Machine Learning&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Perceptron&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/basic-ml/perceptron.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/basic-ml/perceptron.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Logistic Regression&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/basic-ml/logistic-regression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/basic-ml/logistic-regression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Softmax Regression (Multinomial Logistic Regression)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/basic-ml/softmax-regression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/basic-ml/softmax-regression.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Softmax Regression with MLxtend&#39;s plot_decision_regions on Iris&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/basic-ml/softmax-regression-mlxtend-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Multilayer Perceptrons&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multilayer Perceptron&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/mlp/mlp-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mlp/mlp-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mlp/mlp-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multilayer Perceptron with Dropout&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/mlp/mlp-dropout.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mlp/mlp-dropout.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mlp/mlp-dropout.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multilayer Perceptron with Batch Normalization&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/mlp/mlp-batchnorm.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mlp/mlp-batchnorm.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mlp/mlp-batchtnorm.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multilayer Perceptron with Backpropagation from Scratch&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mlp/mlp-fromscratch__sigmoid-mse.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mlp/mlp-fromscratch__sigmoid-mse.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Convolutional Neural Networks&lt;/h2&gt; &#xA;&lt;h4&gt;Basic&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Neural Network&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/cnn/cnn-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CNN with He Initialization&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-he-init.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-he-init.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Concepts&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Replacing Fully-Connnected by Equivalent Convolutional Layers&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/fc-to-conv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h4&gt;AlexNet&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AlexNet Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-alexnet-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-alexnet-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;AlexNet with Grouped Convolutions Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-alexnet-grouped-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-alexnet-grouped-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;DenseNet&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Daset&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DenseNet-121 Digit Classifier Trained on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-densenet121-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-densenet121-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;DenseNet-121 Image Classifier Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-densenet121-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-densenet121-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Fully Convolutional&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&#34;All Convolutionl Net&#34; -- A Fully Convolutional Neural Network&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-allconv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-allconv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;LeNet&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LeNet-5 on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-lenet5-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-lenet5-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LeNet-5 on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-lenet5-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-lenet5-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LeNet-5 on QuickDraw&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-lenet5-quickdraw.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-lenet5-quickdraw.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MobileNet&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MobileNet-v2 on Cifar-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-mobilenet-v2-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-mobilenet-v2-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MobileNet-v3 small on Cifar-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-mobilenet-v3-small-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-mobilenet-v3-small-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MobileNet-v3 large on Cifar-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-mobilenet-v3-large-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-mobilenet-v3-large-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Network in Network&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Network in Network Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-nin-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/nin-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;VGG&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Neural Network VGG-16 Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-vgg16.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-vgg16.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/cnn/cnn-vgg16.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VGG-16 Smile Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-vgg16-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-vgg16-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;VGG-16 Dogs vs Cats Classifier&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-vgg16-cats-dogs.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Neural Network VGG-19&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/cnn/cnn-vgg19.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-vgg19.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;ResNet&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet and Residual Blocks&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/resnet-ex-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-18 Digit Classifier Trained on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet18-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-18 Gender Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet18-celeba-dataparallel.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-34 Digit Classifier Trained on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet34-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-34 Object Classifier Trained on QuickDraw&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet34-quickdraw.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-34 Gender Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet34-celeba-dataparallel.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-50 Digit Classifier Trained on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet50-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-50 Gender Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet50-celeba-dataparallel.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-101 Gender Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet101-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-101 Trained on CIFAR-10&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet101-cifar10.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ResNet-152 Gender Classifier Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet152-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Ordinal Regression and Deep Learning&lt;/h2&gt; &#xA;&lt;p&gt;Please note that the following notebooks below provide reference implementations to use the respective methods. They are not performance benchmarks.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baseline multilayer perceptron&lt;/td&gt; &#xA;   &lt;td&gt;Cement&lt;/td&gt; &#xA;   &lt;td&gt;A baseline multilayer perceptron for classification trained with the standard cross entropy loss&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/ordinal/baseline_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/ordinal/baseline-light_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CORAL multilayer perceptron&lt;/td&gt; &#xA;   &lt;td&gt;Cement&lt;/td&gt; &#xA;   &lt;td&gt;Implementation of &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S016786552030413X&#34;&gt;Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation&lt;/a&gt; 2020&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/ordinal/CORAL_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/ordinal/CORAL-light_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;CORN multilayer perceptron&lt;/td&gt; &#xA;   &lt;td&gt;Cement&lt;/td&gt; &#xA;   &lt;td&gt;Implementation of &lt;a href=&#34;https://arxiv.org/abs/2111.08851&#34;&gt;Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities&lt;/a&gt; 2022&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/ordinal/CORN_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/ordinal/CORN-light_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Binary extension multilayer perceptron&lt;/td&gt; &#xA;   &lt;td&gt;Cement&lt;/td&gt; &#xA;   &lt;td&gt;Implementation of &lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Niu_Ordinal_Regression_With_CVPR_2016_paper.pdf&#34;&gt;Ordinal Regression with Multiple Output CNN for Age Estimation&lt;/a&gt; 2016&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/ordinal/niu2016_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/ordinal/niu2016-light_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Reformulated squared-error multilayer perceptron&lt;/td&gt; &#xA;   &lt;td&gt;Cement&lt;/td&gt; &#xA;   &lt;td&gt;Implementation of &lt;a href=&#34;https://arxiv.org/abs/1612.00775&#34;&gt;A simple squared-error reformulation for ordinal classification&lt;/a&gt; 2016&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/ordinal/beckham2016_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/ordinal/beckham2016-light_cement.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Normalization Layers&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BatchNorm before and after Activation for Network-in-Network CIFAR-10 Classifier&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/nin-cifar10_batchnorm.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Filter Response Normalization for Network-in-Network CIFAR-10 Classifier&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/nin-cifar10_filter-response-norm.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Metric Learning&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Siamese Network with Multilayer Perceptrons&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/metric/siamese-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Autoencoders&lt;/h2&gt; &#xA;&lt;h4&gt;Fully-connected Autoencoders&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Autoencoder (MNIST)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/autoencoder/ae-basic.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Autoencoder (MNIST) + Scikit-Learn Random Forest Classifier&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-basic-with-rf.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/autoencoder/ae-basic-with-rf.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Convolutional Autoencoders&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Deconvolutions / Transposed Convolutions&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-deconv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/autoencoder/ae-deconv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Deconvolutions and Continuous Jaccard Distance&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-deconv-jaccard.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Deconvolutions (without pooling operations)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-deconv-nopool.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/autoencoder/ae-conv-nneighbor.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Autoencoder with Nearest-neighbor Interpolation -- Trained on Quickdraw&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-conv-nneighbor-quickdraw-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Variational Autoencoders&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Variational Autoencoder&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-var.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Variational Autoencoder&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-conv-var.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Conditional Variational Autoencoders&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Conditional Variational Autoencoder (with labels in reconstruction loss)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-cvae.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Conditional Variational Autoencoder (without labels in reconstruction loss)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-cvae_no-out-concat.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Conditional Variational Autoencoder (with labels in reconstruction loss)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-cnn-cvae.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Conditional Variational Autoencoder (without labels in reconstruction loss)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/autoencoder/ae-cnn-cvae_no-out-concat.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Generative Adversarial Networks (GANs)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fully Connected GAN on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/gan.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/gan/gan.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Fully Connected Wasserstein GAN on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/wgan-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional GAN on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/gan-conv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/gan/gan-conv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional GAN on MNIST with Label Smoothing&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/gan-conv-smoothing.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/gan/gan-conv-smoothing.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Convolutional Wasserstein GAN on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/dc-wgan-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deep Convolutional GAN (DCGAN) on Cats and Dogs Images&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/dcgan-cats-and-dogs.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deep Convolutional GAN (DCGAN) on CelebA Face Images&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gan/dcgan-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Graph Neural Networks (GNNs)&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Most Basic Graph Neural Network with Gaussian Filter on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gnn/gnn-basic-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Basic Graph Neural Network with Edge Prediction on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gnn/gnn-basic-edge-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Basic Graph Neural Network with Spectral Graph Convolution on MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/gnn/gnn-basic-graph-spectral-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Recurrent Neural Networks (RNNs)&lt;/h2&gt; &#xA;&lt;h4&gt;Many-to-one: Sentiment Analysis / Classification&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A simple single-layer RNN (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_simple_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A simple single-layer RNN with packed sequences to ignore padding characters (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_simple_packed_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RNN with LSTM cells (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_lstm_packed_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RNN with LSTM cells (IMDB) and pre-trained GloVe word vectors&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_lstm_packed_imdb-glove.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RNN with LSTM cells and Own Dataset in CSV Format (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RNN with GRU cells (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_gru_packed_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Multilayer bi-directional RNN (IMDB)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_lstm_bi_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bidirectional Multi-layer RNN with LSTM with Own Dataset in CSV Format (AG News)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_bi_multilayer_lstm_own_csv_agnews.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Many-to-Many / Sequence-to-Sequence&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;A simple character RNN to generate new text (Charles Dickens)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Model Evaluation&lt;/h2&gt; &#xA;&lt;h3&gt;K-Fold Cross-Validation&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baseline CNN&lt;/td&gt; &#xA;   &lt;td&gt;MNIST&lt;/td&gt; &#xA;   &lt;td&gt;A simple baseline with traditional train/validation/test splits&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/kfold/baseline-cnn-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/kfold/baseline-light-cnn-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;K-fold with &lt;code&gt;pl_cross&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;MNIST&lt;/td&gt; &#xA;   &lt;td&gt;A 5-fold cross-validation run using the &lt;code&gt;pl_cross&lt;/code&gt; library&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch-lightning_ipynb/kfold/kfold-light-cnn-mnist.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/PyTorch-Lightning-blueviolet&#34; alt=&#34;PyTorch Lightning&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Tips and Tricks&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Cyclical Learning Rate&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/tricks/cyclical-learning-rate.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Annealing with Increasing the Batch Size (w. CIFAR-10 &amp;amp; AlexNet)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/tricks/cnn-alexnet-cifar10-batchincrease.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient Clipping (w. MLP on MNIST)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/tricks/gradclipping_mlp.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Transfer Learning&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Transfer Learning Example (VGG16 pre-trained on ImageNet for Cifar-10)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/transfer/transferlearning-vgg16-cifar10-1.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Visualization and Interpretation&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vanilla Loss Gradient (wrt Inputs) Visualization (Based on a VGG16 Convolutional Neural Network for Kaggle&#39;s Cats and Dogs Images)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/viz/cnns/cats-and-dogs/cnn-viz-grad__vgg16-cats-dogs.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Guided Backpropagation (Based on a VGG16 Convolutional Neural Network for Kaggle&#39;s Cats and Dogs Images)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/viz/cnns/cats-and-dogs/cnn-viz-guided-backprop__vgg16-cats-dogs.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;PyTorch Workflows and Mechanics&lt;/h2&gt; &#xA;&lt;h4&gt;PyTorch Lightning Examples&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MLP in Lightning with TensorBoard -- continue training the last model&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/lightning/lightning-mlp.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MLP in Lightning with TensorBoard -- checkpointing best model&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/lightning/lightning-mlp-best-model&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Custom Datasets&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Custom Data Loader Example for PNG Files&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-dataloader-png/custom-dataloader-example.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- CSV files converted to HDF5&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-csv.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Face Images from CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-celeba.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from Quickdraw&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-quickdraw.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Drawings from the Street View House Number (SVHN) Dataset&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-svhn.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Asian Face Dataset (AFAD)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-afad.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Dating Historical Color Images&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader_dating-historical-color-images.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using PyTorch Dataset Loading Utilities for Custom Datasets -- Fashion MNIST&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/custom-data-loader-quickdraw.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Training and Preprocessing&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generating Validation Set Splits&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/validation-splits.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Dataloading with Pinned Memory&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-resnet34-cifar10-pinmem.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Standardizing Images&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-standardized.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Image Transformation Examples&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/torchvision-transform-examples.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Char-RNN with Own Text File&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/char_rnn-charlesdickens.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sentiment Classification RNN with Own CSV File&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/rnn/rnn_lstm_packed_own_csv_imdb.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Improving Memory Efficiency&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gradient Checkpointing Demo (Network-in-Network trained on CIFAR-10)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/gradient-checkpointing-nin.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Parallel Computing&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using Multiple GPUs with DataParallel -- VGG-16 Gender Classifier on CelebA&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/cnn/cnn-vgg16-celeba-data-parallel.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Distribute a Model Across Multiple GPUs with Pipeline Parallelism (VGG-16 Example)&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/model-pipeline-vgg16.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Other&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PyTorch with and without Deterministic Behavior -- Runtime Benchmark&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/deterministic_benchmark.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Sequential API and hooks&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/mlp-sequential.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Weight Sharing Within a Layer&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/cnn-weight-sharing.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Plotting Live Training Performance in Jupyter Notebooks with just Matplotlib&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/plot-jupyter-matplotlib.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Autograd&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Getting Gradients of an Intermediate Variable in PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/mechanics/manual-gradients.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;TensorFlow Workflows and Mechanics&lt;/h2&gt; &#xA;&lt;h4&gt;Custom Datasets&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chunking an Image Dataset for Minibatch Training using NumPy NPZ Archives&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/image-data-chunking-npz.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Storing an Image Dataset for Minibatch Training using HDF5&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/image-data-chunking-hdf5.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using Input Pipelines to Read Data from TFRecords Files&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/tfrecords.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using Queue Runners to Feed Images Directly from Disk&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/file-queues.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Using TensorFlow&#39;s Dataset API&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/dataset-api.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;Training and Preprocessing&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Dataset&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Saving and Loading Trained Models -- from TensorFlow Checkpoint Files and NumPy NPZ Archives&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;TBD&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/tensorflow1_ipynb/mechanics/saving-and-reloading-models.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Tensor-Flow1.0-orange&#34; alt=&#34;TensorFlow&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Related Libraries&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Title&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;   &lt;th&gt;Notebooks&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TorchMetrics&lt;/td&gt; &#xA;   &lt;td&gt;How do we use it, and what&#39;s the difference between .update() and .forward()?&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/deeplearning-models/master/pytorch_ipynb/related-libraries/torchmetrics-update-forward.ipynb&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Py-Torch-red&#34; alt=&#34;PyTorch&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
  <entry>
    <title>CompVis/stable-diffusion</title>
    <updated>2022-08-13T01:44:54Z</updated>
    <id>tag:github.com,2022-08-13:/CompVis/stable-diffusion</id>
    <link href="https://github.com/CompVis/stable-diffusion" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;Stable Diffusion was made possible thanks to a collaboration with &lt;a href=&#34;https://stability.ai/&#34;&gt;Stability AI&lt;/a&gt; and &lt;a href=&#34;https://runwayml.com/&#34;&gt;Runway&lt;/a&gt; and builds upon our previous work:&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.10752&#34;&gt;&lt;strong&gt;High-Resolution Image Synthesis with Latent Diffusion Models&lt;/strong&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/rromb&#34;&gt;Robin Rombach&lt;/a&gt;*, &lt;a href=&#34;https://github.com/ablattmann&#34;&gt;Andreas Blattmann&lt;/a&gt;*, &lt;a href=&#34;https://github.com/qp-qp&#34;&gt;Dominik Lorenz&lt;/a&gt;, &lt;a href=&#34;https://github.com/pesser&#34;&gt;Patrick Esser&lt;/a&gt;, &lt;a href=&#34;https://hci.iwr.uni-heidelberg.de/Staff/bommer&#34;&gt;Björn Ommer&lt;/a&gt;&lt;br&gt;&lt;/p&gt; &#xA;&lt;p&gt;which is available on &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/txt2img/merged-0006.png&#34; alt=&#34;txt2img-stable2&#34;&gt; &lt;a href=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/#stable-diffusion-v1&#34;&gt;Stable Diffusion&lt;/a&gt; is a latent text-to-image diffusion model. Thanks to a generous compute donation from &lt;a href=&#34;https://stability.ai/&#34;&gt;Stability AI&lt;/a&gt; and support from &lt;a href=&#34;https://laion.ai/&#34;&gt;LAION&lt;/a&gt;, we were able to train a Latent Diffusion Model on 512x512 images from a subset of the &lt;a href=&#34;https://laion.ai/blog/laion-5b/&#34;&gt;LAION-5B&lt;/a&gt; database. Similar to Google&#39;s &lt;a href=&#34;https://arxiv.org/abs/2205.11487&#34;&gt;Imagen&lt;/a&gt;, this model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM. See &lt;a href=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/#stable-diffusion-v1&#34;&gt;this section&lt;/a&gt; below and the &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion&#34;&gt;model card&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;A suitable &lt;a href=&#34;https://conda.io/&#34;&gt;conda&lt;/a&gt; environment named &lt;code&gt;ldm&lt;/code&gt; can be created and activated with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f environment.yaml&#xA;conda activate ldm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can also update an existing &lt;a href=&#34;https://github.com/CompVis/latent-diffusion&#34;&gt;latent diffusion&lt;/a&gt; environment by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda install pytorch torchvision -c pytorch&#xA;pip install transformers==4.19.2&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Stable Diffusion v1&lt;/h2&gt; &#xA;&lt;p&gt;Stable Diffusion v1 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 860M UNet and CLIP ViT-L/14 text encoder for the diffusion model. The model was pretrained on 256x256 images and then finetuned on 512x512 images.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Note: Stable Diffusion v1 is a general text-to-image diffusion model and therefore mirrors biases and (mis-)conceptions that are present in its training data. Details on the training procedure and data, as well as the intended use of the model can be found in the corresponding &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion&#34;&gt;model card&lt;/a&gt;. Research into the safe deployment of general text-to-image models is an ongoing effort. To prevent misuse and harm, we currently provide access to the checkpoints only for &lt;a href=&#34;https://stability.ai/academia-access-form&#34;&gt;academic research purposes upon request&lt;/a&gt;. &lt;strong&gt;This is an experiment in safe and community-driven publication of a capable and general text-to-image model. We are working on a public release with a more permissive license that also incorporates ethical considerations.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://stability.ai/academia-access-form&#34;&gt;Request access to Stable Diffusion v1 checkpoints for academic research&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Weights&lt;/h3&gt; &#xA;&lt;p&gt;We currently provide three checkpoints, &lt;code&gt;sd-v1-1.ckpt&lt;/code&gt;, &lt;code&gt;sd-v1-2.ckpt&lt;/code&gt; and &lt;code&gt;sd-v1-3.ckpt&lt;/code&gt;, which were trained as follows,&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;sd-v1-1.ckpt&lt;/code&gt;: 237k steps at resolution &lt;code&gt;256x256&lt;/code&gt; on &lt;a href=&#34;https://huggingface.co/datasets/laion/laion2B-en&#34;&gt;laion2B-en&lt;/a&gt;. 194k steps at resolution &lt;code&gt;512x512&lt;/code&gt; on &lt;a href=&#34;https://huggingface.co/datasets/laion/laion-high-resolution&#34;&gt;laion-high-resolution&lt;/a&gt; (170M examples from LAION-5B with resolution &lt;code&gt;&amp;gt;= 1024x1024&lt;/code&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sd-v1-2.ckpt&lt;/code&gt;: Resumed from &lt;code&gt;sd-v1-1.ckpt&lt;/code&gt;. 515k steps at resolution &lt;code&gt;512x512&lt;/code&gt; on &#34;laion-improved-aesthetics&#34; (a subset of laion2B-en, filtered to images with an original size &lt;code&gt;&amp;gt;= 512x512&lt;/code&gt;, estimated aesthetics score &lt;code&gt;&amp;gt; 5.0&lt;/code&gt;, and an estimated watermark probability &lt;code&gt;&amp;lt; 0.5&lt;/code&gt;. The watermark estimate is from the LAION-5B metadata, the aesthetics score is estimated using an &lt;a href=&#34;https://github.com/christophschuhmann/improved-aesthetic-predictor&#34;&gt;improved aesthetics estimator&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;sd-v1-3.ckpt&lt;/code&gt;: Resumed from &lt;code&gt;sd-v1-2.ckpt&lt;/code&gt;. 195k steps at resolution &lt;code&gt;512x512&lt;/code&gt; on &#34;laion-improved-aesthetics&#34; and 10% dropping of the text-conditioning to improve &lt;a href=&#34;https://arxiv.org/abs/2207.12598&#34;&gt;classifier-free guidance sampling&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Evaluations with different classifier-free guidance scales (1.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0) and 50 PLMS sampling steps show the relative improvements of the checkpoints: &lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/v1-variants-scores.jpg&#34; alt=&#34;sd evaluation results&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Text-to-Image with Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/txt2img/merged-0005.png&#34; alt=&#34;txt2img-stable2&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/txt2img/merged-0007.png&#34; alt=&#34;txt2img-stable2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Stable Diffusion is a latent diffusion model conditioned on the (non-pooled) text embeddings of a CLIP ViT-L/14 text encoder.&lt;/p&gt; &#xA;&lt;p&gt;After &lt;a href=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/#weights&#34;&gt;obtaining the weights&lt;/a&gt;, link them&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir -p models/ldm/stable-diffusion-v1/&#xA;ln -s &amp;lt;path/to/model.ckpt&amp;gt; models/ldm/stable-diffusion-v1/model.ckpt &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and sample with&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/txt2img.py --prompt &#34;a photograph of an astronaut riding a horse&#34; --plms &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, this uses a guidance scale of &lt;code&gt;--scale 7.5&lt;/code&gt;, &lt;a href=&#34;https://github.com/CompVis/latent-diffusion/pull/51&#34;&gt;Katherine Crowson&#39;s implementation&lt;/a&gt; of the &lt;a href=&#34;https://arxiv.org/abs/2202.09778&#34;&gt;PLMS&lt;/a&gt; sampler, and renders images of size 512x512 (which it was trained on) in 50 steps. All supported arguments are listed below (type &lt;code&gt;python scripts/txt2img.py --help&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commandline&#34;&gt;usage: txt2img.py [-h] [--prompt [PROMPT]] [--outdir [OUTDIR]] [--skip_grid] [--skip_save] [--ddim_steps DDIM_STEPS] [--plms] [--laion400m] [--fixed_code] [--ddim_eta DDIM_ETA] [--n_iter N_ITER] [--H H] [--W W] [--C C] [--f F] [--n_samples N_SAMPLES] [--n_rows N_ROWS]&#xA;                  [--scale SCALE] [--from-file FROM_FILE] [--config CONFIG] [--ckpt CKPT] [--seed SEED] [--precision {full,autocast}]&#xA;&#xA;optional arguments:&#xA;  -h, --help            show this help message and exit&#xA;  --prompt [PROMPT]     the prompt to render&#xA;  --outdir [OUTDIR]     dir to write results to&#xA;  --skip_grid           do not save a grid, only individual samples. Helpful when evaluating lots of samples&#xA;  --skip_save           do not save individual samples. For speed measurements.&#xA;  --ddim_steps DDIM_STEPS&#xA;                        number of ddim sampling steps&#xA;  --plms                use plms sampling&#xA;  --laion400m           uses the LAION400M model&#xA;  --fixed_code          if enabled, uses the same starting code across samples&#xA;  --ddim_eta DDIM_ETA   ddim eta (eta=0.0 corresponds to deterministic sampling&#xA;  --n_iter N_ITER       sample this often&#xA;  --H H                 image height, in pixel space&#xA;  --W W                 image width, in pixel space&#xA;  --C C                 latent channels&#xA;  --f F                 downsampling factor&#xA;  --n_samples N_SAMPLES&#xA;                        how many samples to produce for each given prompt. A.k.a. batch size&#xA;  --n_rows N_ROWS       rows in the grid (default: n_samples)&#xA;  --scale SCALE         unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))&#xA;  --from-file FROM_FILE&#xA;                        if specified, load prompts from this file&#xA;  --config CONFIG       path to config which constructs model&#xA;  --ckpt CKPT           path to checkpoint of model&#xA;  --seed SEED           the seed (for reproducible sampling)&#xA;  --precision {full,autocast}&#xA;                        evaluate at this precision&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note: The inference config for all v1 versions is designed to be used with EMA-only checkpoints. For this reason &lt;code&gt;use_ema=False&lt;/code&gt; is set in the configuration, otherwise the code will try to switch from non-EMA to EMA weights. If you want to examine the effect of EMA vs no EMA, we provide &#34;full&#34; checkpoints which contain both types of weights. For these, &lt;code&gt;use_ema=False&lt;/code&gt; will load and use the non-EMA weights.&lt;/p&gt; &#xA;&lt;h3&gt;Image Modification with Stable Diffusion&lt;/h3&gt; &#xA;&lt;p&gt;By using a diffusion-denoising mechanism as first proposed by &lt;a href=&#34;https://arxiv.org/abs/2108.01073&#34;&gt;SDEdit&lt;/a&gt;, the model can be used for different tasks such as text-guided image-to-image translation and upscaling. Similar to the txt2img sampling script, we provide a script to perform image modification with Stable Diffusion.&lt;/p&gt; &#xA;&lt;p&gt;The following describes an example where a rough sketch made in &lt;a href=&#34;https://www.pinta-project.com/&#34;&gt;Pinta&lt;/a&gt; is converted into a detailed artwork.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/img2img.py --prompt &#34;A fantasy landscape, trending on artstation&#34; --init-img &amp;lt;path-to-img.jpg&amp;gt; --strength 0.8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here, strength is a value between 0.0 and 1.0, that controls the amount of noise that is added to the input image. Values that approach 1.0 allow for lots of variations but will also produce images that are not semantically consistent with the input. See the following example.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg&#34; alt=&#34;sketch-in&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Outputs&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/mountains-3.png&#34; alt=&#34;out3&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/mountains-2.png&#34; alt=&#34;out2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;This procedure can, for example, also be used to upscale samples from the base model.&lt;/p&gt; &#xA;&lt;h2&gt;Comments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Our codebase for the diffusion models builds heavily on &lt;a href=&#34;https://github.com/openai/guided-diffusion&#34;&gt;OpenAI&#39;s ADM codebase&lt;/a&gt; and &lt;a href=&#34;https://github.com/lucidrains/denoising-diffusion-pytorch&#34;&gt;https://github.com/lucidrains/denoising-diffusion-pytorch&lt;/a&gt;. Thanks for open-sourcing!&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;The implementation of the transformer encoder is from &lt;a href=&#34;https://github.com/lucidrains/x-transformers&#34;&gt;x-transformers&lt;/a&gt; by &lt;a href=&#34;https://github.com/lucidrains?tab=repositories&#34;&gt;lucidrains&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;BibTeX&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{rombach2021highresolution,&#xA;      title={High-Resolution Image Synthesis with Latent Diffusion Models}, &#xA;      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},&#xA;      year={2021},&#xA;      eprint={2112.10752},&#xA;      archivePrefix={arXiv},&#xA;      primaryClass={cs.CV}&#xA;}&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>evandroagnes/python-dev-stuff</title>
    <updated>2022-08-13T01:44:54Z</updated>
    <id>tag:github.com,2022-08-13:/evandroagnes/python-dev-stuff</id>
    <link href="https://github.com/evandroagnes/python-dev-stuff" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python development files and templates.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Python development stuff&lt;/h1&gt; &#xA;&lt;p&gt;Python codes and templates for use and testing.&lt;/p&gt; &#xA;&lt;h3&gt;Before you start...&lt;/h3&gt; &#xA;&lt;p&gt;I strongly recommend to use a python virtual environment with every project that you are working to avoid problems with python and library versions. See &lt;a href=&#34;https://www.freecodecamp.org/news/how-to-manage-python-dependencies-using-virtual-environments/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>