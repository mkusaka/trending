<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-12-30T01:36:55Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>juanmanzanero/fastest-lap</title>
    <updated>2022-12-30T01:36:55Z</updated>
    <id>tag:github.com,2022-12-30:/juanmanzanero/fastest-lap</id>
    <link href="https://github.com/juanmanzanero/fastest-lap" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fastest-lap is a vehicle dynamics simulator. It can be used to understand vehicle dynamics, to learn about driving techniques, to design car prototypes, or just for fun!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Fastest-lap üèÅüèé&lt;/h1&gt; &#xA;&lt;p&gt;Fastest-lap is a vehicle dynamics simulator. It can be used to understand vehicle dynamics, to learn about driving techniques, to design car prototypes, or just for fun!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/macos.yml&#34;&gt;&lt;img src=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/macos.yml/badge.svg?sanitize=true&#34; alt=&#34;MacOS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/linux.yml&#34;&gt;&lt;img src=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/linux.yml/badge.svg?sanitize=true&#34; alt=&#34;Linux&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/windows.yml&#34;&gt;&lt;img src=&#34;https://github.com/juanmanzanero/fastest-lap/actions/workflows/windows.yml/badge.svg?sanitize=true&#34; alt=&#34;Windows&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://fastest-lap.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/fastest-lap/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codecov.io/gh/juanmanzanero/fastest-lap&#34;&gt;&lt;img src=&#34;https://codecov.io/gh/juanmanzanero/fastest-lap/branch/main/graph/badge.svg?token=YOS7XJ8ZGP&#34; alt=&#34;codecov&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/26557659/173203219-077be886-7c84-49a8-a4c7-762c9f6933f7.png&#34; alt=&#34;test&#34;&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://pbs.twimg.com/media/FLbX1kTWQAArl-O?format=jpg&amp;amp;name=large&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;What can be done&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/tree/main/examples/python/kart/gg-diagram&#34;&gt;Numerical G-G diagram&lt;/a&gt;: given a vehicle, and a speed, to compute its ax-ay diagram. The G-G diagram is a useful technique in vehicle design and parameters exploration.&lt;/p&gt; &lt;p&gt;This is solved as an optimization problem: for a given lateral acceleration, find the minimum/maximum feasible longitudinal acceleration.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/tree/main/examples/python/f1/optimal-laptime&#34;&gt;Optimal laptime simulation&lt;/a&gt;: given a vehicle, and a circuit, to compute the optimal controls that minimize the laptime.&lt;/p&gt; &lt;p&gt;This problem is solved using a first order collocation method, the trapezoidal rule, with higher-order methods planned to be implemented soon. The NLP is solved using &lt;a href=&#34;https://github.com/coin-or/Ipopt&#34;&gt;Ipopt&lt;/a&gt;, and &lt;a href=&#34;https://github.com/coin-or/CppAD&#34;&gt;CppAD&lt;/a&gt; to enhance its performance (a lap-time around Circuit de Catalunya can be obtained with 500 points in approximately 1 minute).&lt;/p&gt; &lt;p&gt;This is not a quasi-steady-state simulation. The model solves the fully transient states as in the dynamic equations without steady-state assumptions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/26557659/163474269-5c195f4b-2109-419d-af49-7b7fa86a603d.mp4&#34;&gt;https://user-images.githubusercontent.com/26557659/163474269-5c195f4b-2109-419d-af49-7b7fa86a603d.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;The approach&lt;/h3&gt; &#xA;&lt;p&gt;The core of the software is a C++ library, that can be used through a Python API. Full documentation is not yet available but some examples can be found in &lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/tree/main/examples/python&#34;&gt;examples/python&lt;/a&gt;. Fastest-lap is very efficient, being able to compute a full optimal lap in less than 1 minute.&lt;/p&gt; &#xA;&lt;h3&gt;Dynamic models&lt;/h3&gt; &#xA;&lt;p&gt;The code implements two car models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://web.archive.org/web/20200320055720id_/https://ora.ox.ac.uk/objects/uuid:ce1a7106-0a2c-41af-8449-41541220809f/download_file?safe_filename=Perantoni%2Band%2BLimebeer%252C%2BOptimal%2Bcontrol%2Bfor%2Ba%2BFormula%2BOne%2Bcar%2Bwith%2Bvariable%2Bparameters.pdf&amp;amp;file_format=application%2Fpdf&amp;amp;type_of_work=Journal+article&#34;&gt;3DOF car model&lt;/a&gt; (longitudinal, lateral, and yaw), currently used for F1 simulations. The default parameters used can be found in &lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/raw/main/database/limebeer-2014-f1.xml&#34;&gt;./database/limebeer-2014-f1.xml&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/00423114.2015.1125514&#34;&gt;6DOF car model&lt;/a&gt; (longitudinal, lateral, vertial, yaw, pitch and roll), currently used for Go-kart simulations. The default parameters used can be found in &lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/raw/main/database/roberto-lot-kart-2016.xml&#34;&gt;./database/roberto-lot-2016-kart.xml&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Circuits&lt;/h3&gt; &#xA;&lt;p&gt;Circuits are modeled from paths created from google earth, for example, the right track limit of Catalunya is included in this repository (&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/raw/main/database/google_earth/Catalunya_right.kml&#34;&gt;database/google_earth/Catalunya_right.kml&lt;/a&gt;). Circuits are then preprocessed with a tool included herein to extract a reference line, its curvature, and the distance to the left/right track limits (&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/raw/main/database/catalunya_discrete.xml&#34;&gt;database/catalunya_discrete.xml&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;h3&gt;Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;Fastest-lap uses several open-source libraries:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/coin-or/Ipopt&#34;&gt;Ipopt&lt;/a&gt;: Interior Point OPTimizer, is an open source software package for large-scale nonlinear optimization. Used within this project to obtain the solution to optimal laptime problems written as NLP (Non-linear programming problem).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/coin-or/CppAD&#34;&gt;CppAD&lt;/a&gt;: C++ Algorithmic Differentiation. Distributed alongside Ipopt, it is used to compute analytical derivatives.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/leethomason/tinyxml2&#34;&gt;Tinyxml2&lt;/a&gt;: TinyXML-2 is a simple, small, efficient, C++ XML parser, used to read XML files (e.g. model parameters, tracks,...)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/juanmanzanero/logger-cpp&#34;&gt;logger-cpp&lt;/a&gt;: a simple logger in C++, to handle print levels, and other interesting add-ons&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/juanmanzanero/lion-cpp&#34;&gt;lion-cpp&lt;/a&gt;: lightweigh interfaces for optimization and numerics, a C++ package manager for all the libraries mentioned above, plus other numerical methods such as mechanical frames, vector algebra, and Runge--Kutta schemes&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;h4&gt;Windows 10&lt;/h4&gt; &#xA;&lt;p&gt;Precompiled binaries are available to download for every release.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/juanmanzanero/fastest-lap/releases/tag/v0.1&#34;&gt;v0.1&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Download and unzip. The contents of the zip folder are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;bin: the dynamic libraries. Fastest-lap C++ core is there. If fastest-lap is used from MATLAB, point &lt;code&gt;loadlibrary()&lt;/code&gt; to this directory.&lt;/li&gt; &#xA; &lt;li&gt;include: fastestlapc.h and fastest_lap.py. To use python scripts, make sure this folder is on the &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;examples: python notebook examples.&lt;/li&gt; &#xA; &lt;li&gt;database: car and track data&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Mac and Linux&lt;/h4&gt; &#xA;&lt;p&gt;This project uses CMake to build the source code and produce the binaries.&lt;/p&gt; &#xA;&lt;p&gt;The canonical steps to compile a CMake project are: (assume &lt;code&gt;$FASTESTLAP&lt;/code&gt; is the source code top level.)&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Create a build folder.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;mkdir ${FASTESTLAP}/build&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;From the build folder, run cmake&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd ${FASTESTLAP}/build &amp;amp;&amp;amp; cmake ..&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The options available for cmake are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;-DCMAKE_BUILD_TYPE=Debug/Release&#xA;-DCMAKE_INSTALL_PREFIX=/path/to/install/dir&#xA;-DCODE_COVERAGE=Yes/No: enables code coverage (if so, use with -DCMAKE_BUILD_TYPE=Debug)&#xA;-DBUILD_DOC=Yes/No: builds doxygen documentation&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;At this stage, CMake will download and install all the thirdparty dependencies.&lt;/p&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Compile&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;Test (optional but recommended)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;ctest --verbose&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;5&#34;&gt; &#xA; &lt;li&gt;Install (optional)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Linux&lt;/h4&gt; &#xA;&lt;p&gt;A Docker build environment is provided and can be used to compile the shared library and generate the Python bindings.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;sh ./src/scripts/linux/docker_compile.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Documentation&lt;/h3&gt; &#xA;&lt;p&gt;Read the latest fastest-lap &lt;a href=&#34;http://fastest-lap.readthedocs.io/&#34;&gt;online documentation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;References&lt;/h3&gt; &#xA;&lt;p&gt;[1] &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/00423114.2016.1213861&#34;&gt;Tremlett, A. J., and D. J. N. Limebeer. &#34;Optimal tyre usage for a formula one car.&#34; Vehicle System Dynamics 54.10 (2016): 1448-1473.&lt;/a&gt;&lt;br&gt; [2] &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/00423114.2015.1125514&#34;&gt;Lot, Roberto, and Nicola Dal Bianco. &#34;Lap time optimisation of a racing go-kart.&#34; Vehicle System Dynamics 54.2 (2016): 210-230.&lt;/a&gt;&lt;br&gt; [3] &lt;a href=&#34;https://journals.sagepub.com/doi/pdf/10.1177/0954407017728158?casa_token=KJUTgUXmw7UAAAAA:rpL6chgRsgy6e8KagZ50jVeLOmITur5phRQYuh_PIY-WW7mMbEHSp-VCWvz3-wZ2FxkeeyhJR_t2&#34;&gt;Dal Bianco, Nicola, Roberto Lot, and Marco Gadola. &#34;Minimum time optimal control simulation of a GP2 race car.&#34; Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering 232.9 (2018): 1180-1195.&lt;/a&gt;&lt;br&gt; [4] &lt;a href=&#34;https://www.worldscientific.com/doi/abs/10.1142/S1758825117500685&#34;&gt;Lot, Roberto, and Matteo Massaro. &#34;A symbolic approach to the multibody modeling of road vehicles.&#34; International Journal of Applied Mechanics 9.05 (2017): 1750068.&lt;/a&gt;&lt;br&gt; [5] &lt;a href=&#34;https://www.tandfonline.com/doi/abs/10.1080/00423110903514236&#34;&gt;Kelly, Daniel P., and Robin S. Sharp. &#34;Time-optimal control of the race car: a numerical method to emulate the ideal driver.&#34; Vehicle System Dynamics 48.12 (2010): 1461-1474.&lt;/a&gt;&lt;br&gt; [6] &lt;a href=&#34;https://www.researchgate.net/publication/336880897_Path_Planning_and_Control_of_Self-Driving_Vehicles_at_the_Limits_of_Handling&#34;&gt;Piccinini, Mattia. &#34;Path planning and control of self-driving vehicles at the limits of handling&#34;&lt;/a&gt;&lt;br&gt; [7] &lt;a href=&#34;https://dspace.lib.cranfield.ac.uk/handle/1826/1091&#34;&gt;Casanova, D. &#34;On minimum time vehicle manoeuvring: the theoretical optimal lap&#34;&lt;/a&gt;&lt;br&gt; [8] &lt;a href=&#34;https://web.archive.org/web/20200320055720id_/https://ora.ox.ac.uk/objects/uuid:ce1a7106-0a2c-41af-8449-41541220809f/download_file?safe_filename=Perantoni%2Band%2BLimebeer%252C%2BOptimal%2Bcontrol%2Bfor%2Ba%2BFormula%2BOne%2Bcar%2Bwith%2Bvariable%2Bparameters.pdf&amp;amp;file_format=application%2Fpdf&amp;amp;type_of_work=Journal+article&#34;&gt;Perantoni, G. et al. &#34;Optimal Control for a Formula One Car with Variable Parameters&#34;&lt;/a&gt;&lt;br&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ARM-software/mango</title>
    <updated>2022-12-30T01:36:55Z</updated>
    <id>tag:github.com,2022-12-30:/ARM-software/mango</id>
    <link href="https://github.com/ARM-software/mango" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Parallel Hyperparameter Tuning in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Mango: A parallel hyperparameter tuning library&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Mango&lt;/strong&gt; is a python library to find the optimal hyperparameters for machine learning classifiers. Mango enables parallel optimization over complex search spaces of continuous/discrete/categorical values.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Check out the quick 12 seconds demo&lt;/strong&gt; of Mango approximating a complex decision boundary of SVM&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://youtu.be/hFmSdDLLUfY&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/documents/demo_video.png&#34; alt=&#34;AirSim Drone Demo Video&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Mango has the following salient features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Easily define complex search spaces compatible with the scikit-learn.&lt;/li&gt; &#xA; &lt;li&gt;A novel state-of-the-art gradient-free optimizer for continuous/discrete/categorical values.&lt;/li&gt; &#xA; &lt;li&gt;Modular design to schedule objective function on local, cluster, or cloud infrastructure.&lt;/li&gt; &#xA; &lt;li&gt;Failure detection in the application layer for scalability on commodity hardware.&lt;/li&gt; &#xA; &lt;li&gt;New features are continuously added due to the testing and usage in production settings.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Index&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#setup&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#getting-started&#34;&gt;Getting started &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#knnexample&#34;&gt;Hyperparameter tuning example &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#DomainSpace&#34;&gt;Search space definitions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#scheduler&#34;&gt;Scheduler&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#MangoConfigurations&#34;&gt;Optional configurations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#AdditionalFeatures&#34;&gt;Additional features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#CASHFeature&#34;&gt;CASH feature&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ARM-software/mango/tree/master/examples/THIN-Bayes&#34;&gt;Platform-aware neural architecture search&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/documents/Mango_github_slides.pdf&#34;&gt;Mango introduction slides&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/documents/Mango_cogml_slides.pdf&#34;&gt;Mango production usage slides&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#CorePapers&#34;&gt;Core Mango research papers to cite&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/ARM-software/mango/master/#ApplicationPapers&#34;&gt;novel applications built over Mango&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;!--&#xA;11. [Mango paper (ICASSP 2020)](https://arxiv.org/pdf/2005.11394.pdf) &amp; [Mango paper (CogMI 2021)](https://github.com/ARM-software/mango/blob/master/documents/Mango_CogMI_paper.pdf).&#xA;--&gt; &#xA;&lt;!--&#xA;7. [Schedule Objective Function on Celery](#Celery)&#xA;8. [Algorithms](#mangoAlgorithms)&#xA;9. [ Tune Hyperparameters of Facebook Prophet ](https://github.com/ARM-software/mango/blob/master/examples/Prophet_Classifier.ipynb)&#xA;10. [ Tune Hyperparameters of xgboost XGBRegressor ](https://github.com/ARM-software/mango/blob/master/examples/Xgboost_Example.ipynb)&#xA;11. [ Tune Hyperparameters of xgboost XGBClassifier ](https://github.com/ARM-software/mango/blob/master/examples/Xgboost_XGBClassifier.ipynb)&#xA;12. [Tune Hyperparameters of SVM](https://github.com/ARM-software/mango/blob/master/examples/SVM_Example.ipynb)&#xA;13. [ More Examples](https://github.com/ARM-software/mango/tree/master/examples)&#xA;14. [ Contact &amp; Questions ](#contactDetails)&#xA;--&gt; &#xA;&lt;p&gt;&lt;a name=&#34;setup&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1. Installation&lt;/h2&gt; &#xA;&lt;p&gt;Using &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install arm-mango&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;From source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/ARM-software/mango.git&#xA;$ cd mango&#xA;$ pip3 install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;!--&#xA;- Mango requires scikit-learn and is developed for python 3, some other packages are installed which required to optimize xgboost classifiers and fbprophet.&#xA;!--&gt; &#xA;&lt;p&gt;&lt;a name=&#34;getting-started&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2. Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;Mango is straightforward to use. Following example minimizes the quadratic function whose input is an integer between -10 and 10.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango import scheduler, Tuner&#xA;&#xA;# Search space&#xA;param_space = dict(x=range(-10,10))&#xA;&#xA;# Quadratic objective Function&#xA;@scheduler.serial&#xA;def objective(x):&#xA;    return x * x&#xA;&#xA;# Initialize and run Tuner&#xA;tuner = Tuner(param_space, objective)&#xA;results = tuner.minimize()&#xA;&#xA;print(f&#39;Optimal value of parameters: {results[&#34;best_params&#34;]} and objective: {results[&#34;best_objective&#34;]}&#39;)```&#xA;# =&amp;gt; Optimal value of parameters: {&#39;x&#39;: 0}  and objective: 0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;knnexample&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3. Hyperparameter Tuning Example&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn import datasets&#xA;from sklearn.neighbors import KNeighborsClassifier&#xA;from sklearn.model_selection import cross_val_score&#xA;&#xA;from mango import Tuner, scheduler&#xA;&#xA;# search space for KNN classifier&#39;s hyperparameters&#xA;# n_neighbors can vary between 1 and 50, with different choices of algorithm&#xA;param_space = dict(n_neighbors=range(1, 50),&#xA;                   algorithm=[&#39;auto&#39;, &#39;ball_tree&#39;, &#39;kd_tree&#39;, &#39;brute&#39;])&#xA;&#xA;&#xA;@scheduler.serial&#xA;def objective(**params):&#xA;    X, y = datasets.load_breast_cancer(return_X_y=True)&#xA;    clf = KNeighborsClassifier(**params)&#xA;    score = cross_val_score(clf, X, y, scoring=&#39;accuracy&#39;).mean()&#xA;    return score&#xA;&#xA;&#xA;tuner = Tuner(param_space, objective)&#xA;results = tuner.maximize()&#xA;print(&#39;best parameters:&#39;, results[&#39;best_params&#39;])&#xA;print(&#39;best accuracy:&#39;, results[&#39;best_objective&#39;])&#xA;# =&amp;gt; best parameters: {&#39;algorithm&#39;: &#39;auto&#39;, &#39;n_neighbors&#39;: 11}&#xA;# =&amp;gt; best accuracy: 0.931486122714193&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that best parameters may be different but accuracy should be ~ 0.9315. More examples are available in the &lt;code&gt;examples&lt;/code&gt; directory (&lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/Prophet_Classifier.ipynb&#34;&gt;Facebook&#39;s Prophet&lt;/a&gt;, &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/Xgboost_XGBClassifier.ipynb&#34;&gt;XGBoost&lt;/a&gt;, &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/SVM_Example.ipynb&#34;&gt;SVM&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a name=&#34;DomainSpace&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;4. Search Space&lt;/h2&gt; &#xA;&lt;p&gt;The search space defines the range and distribution of input parameters to the objective function. Mango search space is compatible with scikit-learn&#39;s parameter space definitions used in &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html&#34;&gt;RandomizedSearchCV&lt;/a&gt; or &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34;&gt;GridSearchCV&lt;/a&gt;. The search space is defined as a dictionary with keys being the parameter names (string) and values being list of discreet choices, range of integers or the distributions. Example of some common search spaces are:&lt;/p&gt; &#xA;&lt;h3&gt;Integer&lt;/h3&gt; &#xA;&lt;p&gt;Following space defines &lt;code&gt;x&lt;/code&gt; as an integer parameters with values in &lt;code&gt;range(-10, 11)&lt;/code&gt; (11 is not included):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;param_space = dict(x=range(-10, 11)) #=&amp;gt; -10, -9, ..., 10&#xA;# you can use steps for sparse ranges&#xA;param_space = dict(x=range(0, 101, 10)) #=&amp;gt; 0, 10, 20, ..., 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Integers are uniformly sampled from the given range and are assumed to be ordered and treated as continuous variables.&lt;/p&gt; &#xA;&lt;h3&gt;Categorical&lt;/h3&gt; &#xA;&lt;p&gt;Discreet categories can be defined as lists. For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# string&#xA;param_space = dict(color=[&#39;red&#39;, &#39;blue&#39;, &#39;green&#39;])&#xA;# float&#xA;param_space = dict(v=[0.2, 0.1, 0.3])&#xA;# mixed&#xA;param_space = dict(max_features=[&#39;auto&#39;, 0.2, 0.3])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Lists are uniformly sampled and are assumed to be unordered. They are one-hot encoded internally.&lt;/p&gt; &#xA;&lt;h3&gt;Distributions&lt;/h3&gt; &#xA;&lt;p&gt;All the distributions supported by &lt;a href=&#34;https://docs.scipy.org/doc/scipy/reference/stats.html&#34;&gt;&lt;code&gt;scipy.stats&lt;/code&gt;&lt;/a&gt; are supported. In general, distributions must provide a &lt;code&gt;rvs&lt;/code&gt; method for sampling.&lt;/p&gt; &#xA;&lt;h4&gt;Uniform distribution&lt;/h4&gt; &#xA;&lt;p&gt;Using &lt;code&gt;uniform(loc, scale)&lt;/code&gt; one obtains the uniform distribution on &lt;code&gt;[loc, loc + scale]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import uniform&#xA;&#xA;# uniformly distributed between -1 and 1&#xA;param_space = dict(a=uniform(-1, 2))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Log uniform distribution&lt;/h4&gt; &#xA;&lt;p&gt;We have added &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/mango/domain/distribution.py&#34;&gt;loguniform&lt;/a&gt; distribution by extending the &lt;code&gt;scipy.stats.distributions&lt;/code&gt; constructs. Using &lt;code&gt;loguniform(loc, scale)&lt;/code&gt; one obtains the loguniform distribution on &lt;code&gt;[10&lt;sup&gt;loc&lt;/sup&gt;, 10&lt;sup&gt;loc + scale&lt;/sup&gt;]&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango.domain.distribution import loguniform&#xA;&#xA;# log uniformly distributed between 10^-3 and 10^-1&#xA;param_space = dict(learning_rate=loguniform(-3, 2))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Hyperparameter search space examples&lt;/h3&gt; &#xA;&lt;p&gt;Example hyperparameter search space for &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html&#34;&gt;Random Forest Classifier&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;param_space =  dict(&#xA;    max_features=[&#39;sqrt&#39;, &#39;log2&#39;, .1, .3, .5, .7, .9],&#xA;    n_estimators=range(10, 1000, 50), # 10 to 1000 in steps of 50&#xA;    bootstrap=[True, False],&#xA;    max_depth=range(1, 20),&#xA;    min_samples_leaf=range(1, 10)&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example search space for &lt;a href=&#34;https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier&#34;&gt;XGBoost Classifier&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import uniform&#xA;from mango.domain.distribution import loguniform&#xA;&#xA;param_space = {&#xA;    &#39;n_estimators&#39;: range(10, 2001, 100), # 10 to 2000 in steps of 100&#xA;    &#39;max_depth&#39;: range(1, 15), # 1 to 14&#xA;    &#39;reg_alpha&#39;: loguniform(-3, 6),  # 10^-3 to 10^3&#xA;    &#39;booster&#39;: [&#39;gbtree&#39;, &#39;gblinear&#39;],&#xA;    &#39;colsample_bylevel&#39;: uniform(0.05, 0.95), # 0.05 to 1.0&#xA;    &#39;colsample_bytree&#39;: uniform(0.05, 0.95), # 0.05 to 1.0&#xA;    &#39;learning_rate&#39;: loguniform(-3, 3),  # 0.001 to 1&#xA;    &#39;reg_lambda&#39;: loguniform(-3, 6),  # 10^-3 to 10^3&#xA;    &#39;min_child_weight&#39;: loguniform(0, 2), # 1 to 100&#xA;    &#39;subsample&#39;: uniform(0.1, 0.89) # 0.1 to 0.99&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Example search space for &lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&#34;&gt;SVM&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import uniform&#xA;from mango.domain.distribution import loguniform&#xA;&#xA;param_dict = {&#xA;    &#39;kernel&#39;: [&#39;rbf&#39;, &#39;sigmoid&#39;],&#xA;    &#39;gamma&#39;: uniform(0.1, 4), # 0.1 to 4.1&#xA;    &#39;C&#39;: loguniform(-7, 8) # 10^-7 to 10&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;scheduler&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5. Scheduler&lt;/h2&gt; &#xA;&lt;p&gt;Mango is designed to take advantage of distributed computing. The objective function can be scheduled to run locally or on a cluster with parallel evaluations. Mango is designed to allow the use of any distributed computing framework (like Celery or Kubernetes). The &lt;code&gt;scheduler&lt;/code&gt; module comes with some pre-defined schedulers.&lt;/p&gt; &#xA;&lt;h3&gt;Serial scheduler&lt;/h3&gt; &#xA;&lt;p&gt;Serial scheduler runs locally with one objective function evaluation at a time&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango import scheduler&#xA;&#xA;@scheduler.serial&#xA;def objective(x):&#xA;    return x * x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Parallel scheduler&lt;/h3&gt; &#xA;&lt;p&gt;Parallel scheduler runs locally and uses &lt;code&gt;joblib&lt;/code&gt; to evaluate the objective functions in parallel&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango import scheduler&#xA;&#xA;@scheduler.parallel(n_jobs=2)&#xA;def objective(x):&#xA;    return x * x&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;n_jobs&lt;/code&gt; specifies the number of parallel evaluations. &lt;code&gt;n_jobs = -1&lt;/code&gt; uses all the available cpu cores on the machine. See &lt;a href=&#34;https://github.com/ARM-software/mango/tree/master/examples/simple_parallel.py&#34;&gt;simple_parallel&lt;/a&gt; for full working example.&lt;/p&gt; &#xA;&lt;h3&gt;Custom distributed scheduler&lt;/h3&gt; &#xA;&lt;p&gt;Users can define their own distribution strategies using &lt;code&gt;custom&lt;/code&gt; scheduler. To do so, users need to define an objective function that takes a list of parameters and returns the list of results:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango import scheduler&#xA;&#xA;@scheduler.custom(n_jobs=4)&#xA;def objective(params_batch):&#xA;    &#34;&#34;&#34; Template for custom distributed objective function&#xA;    Args:&#xA;        params_batch (list): Batch of parameter dictionaries to be evaluated in parallel&#xA;&#xA;    Returns:&#xA;        list: Values of objective function at given parameters&#xA;    &#34;&#34;&#34;&#xA;    # evaluate the objective on a distributed framework&#xA;    ...&#xA;    return results&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For example the following snippet uses &lt;a href=&#34;http://www.celeryproject.org/&#34;&gt;Celery&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import celery&#xA;from mango import Tuner, scheduler&#xA;&#xA;# connect to celery backend&#xA;app = celery.Celery(&#39;simple_celery&#39;, backend=&#39;rpc://&#39;)&#xA;&#xA;# remote celery task&#xA;@app.task&#xA;def remote_objective(x):&#xA;    return x * x&#xA;&#xA;@scheduler.custom(n_jobs=4)&#xA;def objective(params_batch):&#xA;    jobs = celery.group(remote_objective.s(params[&#39;x&#39;]) for params in params_batch)()&#xA;    return jobs.get()&#xA;&#xA;param_space = dict(x=range(-10, 10))&#xA;&#xA;tuner = Tuner(param_space, objective)&#xA;results = tuner.minimize()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A working example to tune hyperparameters of KNN using Celery is &lt;a href=&#34;https://github.com/ARM-software/mango/tree/master/examples/knn_celery.py&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;!--&#xA;&lt;a name=&#34;ObjectiveFunction&#34;&gt;&lt;/a&gt;&#xA;## 5. More on Objective Function&#xA;The serial objective function has the following structure.&#xA;&#xA;```python&#xA;def objective_function(params_list):&#xA;    evaluations = []&#xA;    for hyper_par in params_list:&#xA;        result =  evaluate_function_on_hyper_par&#xA;        evaluations.append(result)&#xA;    return evaluations&#xA;```&#xA;The objective function is called with the input list of hyper parameters. Each element of the list is the dictionary which is a sample drawn from the domain space of variables. Mango expects the objective function to return the list of&#xA;evaluations which has the same size as the args_list. Each value of the evaluations list is the function evaluated at hyperparameters&#xA;of params_list in the same order. A rich set of objective functions are shown in the [examples](https://github.com/ARM-software/mango/tree/master/examples). The size of the params_list is controlled by the batch_size configuration parameter of Mango. By default,&#xA;batch_size is 1. The configuration parameters of Mango are explained in the [Mango Configurations](#MangoConfigurations) section.&#xA;&#xA;The sample skeleton of the Celery based parallel objective function in Mango is as following.&#xA;&#xA;```python&#xA;def objective_celery(params_list):&#xA;    process_queue = []&#xA;    for par in params_list:&#xA;        process = train_clf.delay(par)&#xA;        process_queue.append((process, par))&#xA;    evals = []&#xA;    params = []&#xA;    for process, par in process_queue:&#xA;        result = process.get()&#xA;        evals.append(result)&#xA;        params.append(par)&#xA;    return params, evals&#xA;```&#xA;--&gt; &#xA;&lt;p&gt;&lt;a name=&#34;MangoConfigurations&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;6. Optional configurations&lt;/h2&gt; &#xA;&lt;p&gt;The default configuration parameters used by the Mango as below:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&#39;param_dict&#39;: ...,&#xA; &#39;userObjective&#39;: ...,&#xA; &#39;domain_size&#39;: 5000,&#xA; &#39;initial_random&#39;: 1,&#xA; &#39;num_iteration&#39;: 20,&#xA; &#39;batch_size&#39;: 1}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The configuration parameters are:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;domain_size&lt;/code&gt;: The size which is explored in each iteration by the gaussian process. Generally, a larger size is preferred if higher dimensional functions are optimized. More on this will be added with details about the internals of bayesian optimization.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;initial_random&lt;/code&gt;: The number of random samples tried. Note: Mango returns all the random samples together. Users can exploit this to parallelize the random runs without any constraint.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;num_iteration&lt;/code&gt;: The total number of iterations used by Mango to find the optimal value.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;batch_size&lt;/code&gt;: The size of args_list passed to the objective function for parallel evaluation. For larger batch sizes, Mango internally uses intelligent sampling to decide the optimal samples to evaluate.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;early_stopping&lt;/code&gt;: A callback to specify custom stopping criteria. The callback has the following signature:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def early_stopping(results):&#xA;   &#39;&#39;&#39;&#xA;       results is the same as dict returned by tuner&#xA;       keys available: params_tries, objective_values,&#xA;           best_objective, best_params&#xA;   &#39;&#39;&#39;&#xA;   ...&#xA;   return True/False&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Early stopping is one of Mango&#39;s important features that allow to early terminate the current parallel search based on the custom user-designed criteria, such as the total optimization time spent, current validation accuracy achieved, or improvements in the past few iterations. For usage see early stopping examples &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/EarlyStopping.ipynb&#34;&gt;notebook&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;code&gt;initial_custom&lt;/code&gt;: A list of initial evaluation points to warm up the optimizer instead of random sampling. For example, for a search space with two parameters &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt; the input could be: &lt;code&gt;[{&#39;x1&#39;: 10, &#39;x2&#39;: -5}, {&#39;x1&#39;: 0, &#39;x2&#39;: 10}]&lt;/code&gt;. This allows the user to customize the initial evaluation points and therefore guide the optimization process. If this option is given then &lt;code&gt;initial_random&lt;/code&gt; is ignored.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The default configuration parameters can be modified, as shown below. Only the parameters whose values need to adjusted can be passed as the dictionary.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;conf_dict = dict(num_iteration=40, domain_size=10000, initial_random=3)&#xA;&#xA;tuner = Tuner(param_dict, objective, conf_dict)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;AdditionalFeatures&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;7. Additional Features&lt;/h2&gt; &#xA;&lt;h3&gt;Handling runtime failed evaluation&lt;/h3&gt; &#xA;&lt;p&gt;At runtime, failed evaluations are widespread in production deployments. Mango abstractions enable users to make progress even in the presence of failures by only using the correct evaluations. The syntax can return the successful evaluation, and the user can flexibly keep track of failures, for example, using timeouts. Examples showing the usage of Mango in the presence of failures: &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/Failure_Handling.ipynb&#34;&gt;serial execution&lt;/a&gt; and &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/Failure_Handling_Parallel.ipynb&#34;&gt;parallel execution&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Neural Architecture Search&lt;/h3&gt; &#xA;&lt;p&gt;Mango can also do an efficient neural architecture search. An example on the MNIST dataset to search for optimal filter sizes, the number of filters, etc., is &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/examples/NAS_Mnist.ipynb&#34;&gt;available&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;More extensive examples are available in the &lt;a href=&#34;https://github.com/ARM-software/mango/tree/master/examples/THIN-Bayes&#34;&gt;THIN-Bayes&lt;/a&gt; folder doing &lt;em&gt;Neural Architecture Search&lt;/em&gt; for a class of neural networks and classical models for different regression and classification tasks.&lt;/p&gt; &#xA;&lt;!--&#xA;&lt;a name=&#34;Celery&#34;&gt;&lt;/a&gt;&#xA;## 7. Schedule Objective Function on Celery&#xA;User-defined objective function can be scheduled on local, cluster or cloud infrastructure. The objective function scheduler&#xA;is entirely independent of the Mango. This design was chosen to enable the scheduling of varied resource objective function according to developer needs. We have included examples using [Celery](http://www.celeryproject.org/). In the sample&#xA;examples, celery workers are used to evaluate the objective function in parallel. These examples assume celery is installed, and workers&#xA;are running. Default celery configurations can be modified in the [file](https://github.com/ARM-software/mango/blob/master/examples/classifiers/celery.py).&#xA;&#xA;- [KNN example using celery workers](https://github.com/ARM-software/mango/blob/master/examples/KNN_Celery.ipynb)&#xA;- [Prophet example using celery workers](https://github.com/ARM-software/mango/blob/master/examples/Prophet_Celery.ipynb)&#xA;&#xA;More examples will be included to show the scheduling of objective function using local threads/processes. By default examples schedule&#xA;the objective function on the local machine itself.&#xA;&#xA;&lt;a name =&#34;mangoAlgorithms&#34;&gt;&lt;/a&gt;&#xA;## 8. Algorithms&#xA;The optimization algorithms in Mango are based on widely used Bayesian optimization techniques, extended to sample a batch of configurations in parallel. Currently, Mango provides two parallel optimization algorithms that use the upper confidence bound as the acquisition function. The first algorithm uses hallucination combined with exponential rescaling of the surrogate function to select a batch. In the second algorithm, we create clusters of acquisition function in spatially distinct search spaces, and select the maximum value within each cluster to create the batch.&#xA;&#xA;&lt;a name=&#34;contactDetails&#34;&gt;&lt;/a&gt;&#xA;## More Details&#xA;Details about specifying parameter/variable domain space, user objective function, and internals of Mango will be added.&#xA;Please stay tuned.&#xA;--&gt; &#xA;&lt;p&gt;&lt;a name=&#34;CASHFeature&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;8. Combiner Classifier Selection and Optimization (CASH)&lt;/h2&gt; &#xA;&lt;p&gt;Mango now provides a novel functionality of combined classifier selection and optimization. It allows developers to directly specify a set of classifiers along with their different hyperparameter spaces. Mango internally finds the best classifier along with the optimal parameters with the least possible number of overall iterations. The examples are available &lt;a href=&#34;https://github.com/ARM-software/mango/tree/master/benchmarking/MetaTuner_Examples&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The important parts in the skeletion code are as below.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from mango import MetaTuner&#xA;&#xA;#define search spaces and objective functions as done for tuner.&#xA;&#xA;param_space_list = [param_space1, param_space2, param_space3, param_space4, ..]&#xA;objective_list = [objective_1, objective_2, objective_3, objective_4, ..]&#xA;&#xA;metatuner = MetaTuner(param_space_list, objective_list)&#xA;&#xA;results = metatuner.run()&#xA;&#xA;print(&#39;best_objective:&#39;,results[&#39;best_objective&#39;])&#xA;print(&#39;best_params:&#39;,results[&#39;best_params&#39;])&#xA;print(&#39;best_objective_fid:&#39;,results[&#39;best_objective_fid&#39;])&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Participate&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a name=&#34;CorePapers&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Core Papers to Cite Mango&lt;/h3&gt; &#xA;&lt;p&gt;More technical details are available in the &lt;a href=&#34;https://arxiv.org/pdf/2005.11394.pdf&#34;&gt;Mango paper-1 (ICASSP 2020)&lt;/a&gt; and &lt;a href=&#34;https://drive.google.com/file/d/1uzcTUfLM3JSc47RLQJin-YzybwNl6BZO/view&#34;&gt;Mango paper-2 (CogMI 2021)&lt;/a&gt; Please cite them as:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{sandha2020mango,&#xA;  title={Mango: A Python Library for Parallel Hyperparameter Tuning},&#xA;  author={Sandha, Sandeep Singh and Aggarwal, Mohit and Fedorov, Igor and Srivastava, Mani},&#xA;  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},&#xA;  pages={3987--3991},&#xA;  year={2020},&#xA;  organization={IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{sandha2021mango,&#xA;  title={Enabling Hyperparameter Tuning of Machine Learning Classifiers in Production},&#xA;  author={Sandha, Sandeep Singh and Aggarwal, Mohit and Saha, Swapnil Sayan and Srivastava, Mani},&#xA;  booktitle={CogMI 2021, IEEE International Conference on Cognitive Machine Intelligence},&#xA;  year={2021},&#xA;  organization={IEEE}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a name=&#34;ApplicationPapers&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Novel Applications built over Mango&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{saha2022auritus,&#xA;  title={Auritus: An open-source optimization toolkit for training and development of human movement models and filters using earables},&#xA;  author={Saha, Swapnil Sayan and Sandha, Sandeep Singh and Pei, Siyou and Jain, Vivek and Wang, Ziqi and Li, Yuchen and Sarker, Ankur and Srivastava, Mani},&#xA;  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},&#xA;  volume={6},&#xA;  number={2},&#xA;  pages={1--34},&#xA;  year={2022},&#xA;  publisher={ACM New York, NY, USA}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{saha2022tinyodom,&#xA;  title={Tinyodom: Hardware-aware efficient neural inertial navigation},&#xA;  author={Saha, Swapnil Sayan and Sandha, Sandeep Singh and Garcia, Luis Antonio and Srivastava, Mani},&#xA;  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},&#xA;  volume={6},&#xA;  number={2},&#xA;  pages={1--32},&#xA;  year={2022},&#xA;  publisher={ACM New York, NY, USA}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{saha2022thin,&#xA;  title={THIN-Bayes: Platform-Aware Machine Learning for Low-End IoT Devices},&#xA;  author={Saha, Swapnil Sayan and Sandha, Sandeep Singh and Aggarwal, Mohit and Srivastava, Mani},&#xA;  year={2022}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Slides&lt;/h3&gt; &#xA;&lt;p&gt;Slides explaining Mango abstractions and design choices are available. &lt;a href=&#34;https://github.com/ARM-software/mango/raw/master/documents/Mango_github_slides.pdf&#34;&gt;Mango Slides-1&lt;/a&gt;, &lt;a href=&#34;https://drive.google.com/file/d/1_sUOnbW-LkHMMcjq_WgzabN7IQ-wBRgn/view&#34;&gt;Mango Slides-2&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Contribute&lt;/h3&gt; &#xA;&lt;p&gt;Please take a look at &lt;a href=&#34;https://github.com/ARM-software/mango/issues&#34;&gt;open issues&lt;/a&gt; if you are looking for areas to contribute to.&lt;/p&gt; &#xA;&lt;h3&gt;Questions&lt;/h3&gt; &#xA;&lt;p&gt;For any questions feel free to reach out by creating an issue &lt;a href=&#34;https://github.com/ARM-software/mango/issues/new&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>LineaLabs/lineapy</title>
    <updated>2022-12-30T01:36:55Z</updated>
    <id>tag:github.com,2022-12-30:/LineaLabs/lineapy</id>
    <link href="https://github.com/LineaLabs/lineapy" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Move fast from data science prototype to pipeline. Capture, analyze, and transform messy notebooks into data pipelines with just two lines of code.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34; style=&#34;display:flex;flex-direction:column;&#34;&gt; &#xA; &lt;a href=&#34;https://lineapy.org/&#34;&gt; &lt;img src=&#34;https://user-images.githubusercontent.com/724072/165418570-7338c65b-0fd1-489c-b76a-f03f074f42ca.png&#34; alt=&#34;LineaPy&#34; width=&#34;500&#34;&gt; &lt;/a&gt; &#xA; &lt;h3&gt;Capture, analyze, and transform messy notebooks into data pipelines &lt;br&gt; with just two lines of code.&lt;/h3&gt; &#xA; &lt;p&gt; &lt;a href=&#34;https://twitter.com/lineapy_oss&#34;&gt; &lt;img alt=&#34;Follow LineaPy on Twitter!&#34; src=&#34;https://img.shields.io/twitter/follow/lineapy_oss?labelColor=00ACEE&amp;amp;logo=twitter&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/lineacommunity/shared_invite/zt-18kizfn3b-1Qu_HDT3ahGudnAwoFAw9Q&#34;&gt; &lt;img alt=&#34;Join the LineaPy Slack!&#34; src=&#34;https://img.shields.io/badge/slack-@lineapy--community-CF0E5B.svg?logo=slack&amp;amp;logoColor=white&amp;amp;labelColor=3F0E40&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA; &lt;p&gt; Ask questions or learn about our workshops on our &lt;a target=&#34;_blank&#34; href=&#34;https://join.slack.com/t/lineacommunity/shared_invite/zt-18kizfn3b-1Qu_HDT3ahGudnAwoFAw9Q&#34;&gt;Slack!&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34; style=&#34;display:flex;flex-direction:column;&#34;&gt; &#xA; &lt;h3&gt;üëá Try It Out! üëá&lt;/h3&gt; &#xA; &lt;div&gt; &#xA;  &lt;a href=&#34;https://bit.ly/3y5IiSq&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt; &lt;/a&gt; &#xA; &lt;/div&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://user-images.githubusercontent.com/13392380/169427654-487d8d4b-3eda-462a-a96c-51c151f39ab9.mp4&#34;&gt;https://user-images.githubusercontent.com/13392380/169427654-487d8d4b-3eda-462a-a96c-51c151f39ab9.mp4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://img.shields.io/badge/Python--versions-3.7%20%7C%203.8%20%7C%203.9-brightgreen&#34; alt=&#34;Python Versions&#34;&gt; &lt;a href=&#34;https://github.com/LineaLabs/lineapy/actions/workflows/python-app.yml&#34;&gt;&lt;img src=&#34;https://github.com/LineaLabs/lineapy/actions/workflows/python-app.yml/badge.svg?sanitize=true&#34; alt=&#34;Build&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://docs.lineapy.org/en/main/index.html&#34;&gt;&lt;img src=&#34;https://readthedocs.com/projects/lineapy-org-lineapy/badge/?version=latest&amp;amp;token=925cd1d5eaedb7cc60508c9cce377574da748a7d6c050bb2c3de2a360a9f4f20&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/LineaLabs/lineapy/raw/main/LICENSE.txt&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-Apache%202-brightgreen.svg?logo=apache&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/lineapy/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/lineapy.svg?logo=pypi&amp;amp;logoColor=white&#34; alt=&#34;PyPi&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#what-problems-can-lineapy-solve&#34;&gt;What Problems Can LineaPy Solve?&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#use-case-1-cleaning-messy-notebooks&#34;&gt;Use Case 1: Cleaning Messy Notebooks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#use-case-2-revisiting-previous-work&#34;&gt;Use Case 2: Revisiting Previous Work&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#use-case-3-building-pipelines&#34;&gt;Use Case 3: Building Pipelines&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#interfaces&#34;&gt;Interfaces&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#jupyter-and-ipython&#34;&gt;Jupyter and IPython&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#cli&#34;&gt;CLI&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#quick-start&#34;&gt;Quick Start&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#usage-reporting&#34;&gt;Usage Reporting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#what-next&#34;&gt;What Next?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;What Problems Can LineaPy Solve?&lt;/h2&gt; &#xA;&lt;h3&gt;Use Case 1: Cleaning Messy Notebooks&lt;/h3&gt; &#xA;&lt;p&gt;When working in a Jupyter notebook day after day, it&#39;s easy to write messy code ‚Äî You might execute cells out of order, execute the same cell repeatedly, and edit or delete cells until you&#39;ve acquired good results, especially when generating tables, models, and charts. This highly dynamic and interactive notebook use, however, can introduce some issues. Our colleagues may not be able to reproduce our results by rerunning our notebook, and worse still, we ourselves may forget the steps required to produce our previous results.&lt;/p&gt; &#xA;&lt;p&gt;One way to avoid this problem is to keep the notebook in sequential order by constantly re-executing the entire notebook during development. This approach, however, interrupts our natural workflows and stream of thoughts, decreasing our productivity. Therefore, it is much more common to clean up the notebook after development. This is a time-consuming process that is not immune from the reproducibility issues caused by deleted cells and out-of-order cell executions.&lt;/p&gt; &#xA;&lt;p&gt;To see how LineaPy can help with messy notebooks, check out &lt;a href=&#34;https://github.com/LineaLabs/lineapy/raw/v0.2.x/.colab/clean_up_a_messy_notebook/clean_up_a_messy_notebook.ipynb&#34;&gt;this&lt;/a&gt; demo or &lt;a href=&#34;https://bit.ly/3SuC4nm&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Use Case 2: Revisiting Previous Work&lt;/h3&gt; &#xA;&lt;p&gt;Data science is often a team effort where one person&#39;s work relies on results from another&#39;s. For example, a data scientist building a model may use features engineered by other colleagues. When using results generated by other people, we may encounter data quality issues including missing values, suspicious numbers, and unintelligible variable names. When we encounter these issues, we may need to check how these results came into being in the first place. Often, this means tracing back the code that was used to generate the result in question. In practice, this can be a challenging task because we may not know who produced the result. Even if we know who to ask, that person might not remember where the exact version of the code is stored, or worse, may have overwritten the code without version control. Additionally, the person may no longer be at the organization and may not have handed over the relevant knowledge. In any of these cases, it becomes extremely difficult to identify the root any issues, rendering the result unreliable and even unusable.&lt;/p&gt; &#xA;&lt;p&gt;To see how LineaPy can help here, check out &lt;a href=&#34;https://github.com/LineaLabs/lineapy/raw/v0.2.x/.colab/discover_and_trace_past_work/discover_and_trace_past_work.ipynb&#34;&gt;this&lt;/a&gt; demo or &lt;a href=&#34;https://bit.ly/3fsA9RL&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Use Case 3: Building Pipelines&lt;/h3&gt; &#xA;&lt;p&gt;As our notebooks become more mature, we may use them like pipelines. For example, our notebook might process the latest data to update a dashboard, or pre-process data and dump it into the file system for downstream model development. To keep our results up-to-date, we might be expected to re-execute these processes on a regular basis. Running notebooks manually is a brittle process that&#39;s prone to errors, so we may want to set up proper pipelines for production. If relevant engineering support is not available, we need to clean up and refactor our notebook code so that it can be used in orchestration systems or job schedulers, such as cron, Apache Airflow, or Prefect. Of course, this assumes that we already know how these tools work and how to use them ‚Äî If not, we need to spend time learning about them in the first place! All this operational work is time-consuming, and detracts from the time that we can spend on our core duties as a data scientist.&lt;/p&gt; &#xA;&lt;p&gt;To see how LineaPy can help here, check out &lt;a href=&#34;https://github.com/LineaLabs/lineapy/raw/v0.2.x/.colab/create_a_simple_pipeline/create_a_simple_pipeline.ipynb&#34;&gt;this&lt;/a&gt; demo or &lt;a href=&#34;https://bit.ly/3SJewuO&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;LineaPy is a Python package for capturing, analyzing, and automating data science workflows. At a high level, LineaPy traces the sequence of code execution to form a comprehensive understanding of the code and its context. This understanding allows LineaPy to provide a set of tools that help data scientists bring their work to production more quickly and easily, with just &lt;em&gt;two lines&lt;/em&gt; of code.&lt;/p&gt; &#xA;&lt;p&gt;Check this &lt;a href=&#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/#what-problems-can-lineapy-solve&#34;&gt;section&lt;/a&gt; for types of problems that LineaPy can help to solve.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;p&gt;LineaPy runs on &lt;code&gt;Python&amp;gt;=3.7&lt;/code&gt; and &lt;code&gt;IPython&amp;gt;=7.0.0&lt;/code&gt;. It does not come with a Jupyter installation, so you will need to &lt;a href=&#34;https://jupyter.org/install&#34;&gt;install one&lt;/a&gt; for interactive computing.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;To install LineaPy, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install lineapy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to run the latest version of LineaPy directly from the source, follow instructions &lt;a href=&#34;https://docs.lineapy.org/en/main/guides/contribute/setup.html#installation&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;LineaPy offers several extras to extend its core capabilities, such as support for PostgreSQL or Amazon S3. Learn more about these and other installation options &lt;a href=&#34;https://docs.lineapy.org/en/main/guides/installation.html#extras&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Interfaces&lt;/h3&gt; &#xA;&lt;h4&gt;Jupyter and IPython&lt;/h4&gt; &#xA;&lt;p&gt;To use LineaPy in an interactive computing environment such as Jupyter Notebook/Lab or IPython, load its extension by executing the following command at the top of your session:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%load_ext lineapy&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Please note:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;You must run this as the first command in a given session. Executing it in the middle of a session will lead to erroneous behaviors by LineaPy.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;This command loads the extension for the current session only. It does not carry over to different sessions, so you will need to repeat it for each new session.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Alternatively, you can launch the environment with the &lt;code&gt;lineapy&lt;/code&gt; command, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lineapy jupyter notebook&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lineapy jupyter lab&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;lineapy ipython&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will automatically load the LineaPy extension in the corresponding interactive shell application, and you will not need to manually load it for every new session.&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; If your Jupyter environment has multiple kernels, choose &lt;code&gt;Python 3 (ipykernel)&lt;/code&gt; which &lt;code&gt;lineapy&lt;/code&gt; defaults to.&lt;/p&gt; &#xA;&lt;h4&gt;CLI&lt;/h4&gt; &#xA;&lt;p&gt;You can also use LineaPy as a CLI command or runnable Python module. To see available options, run the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# LineaPy as a CLI command&#xA;lineapy python --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# LineaPy as a runnable Python module&#xA;python -m lineapy --help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Quick Start&lt;/h3&gt; &#xA;&lt;p&gt;Once LineaPy is installed and loaded, you are ready to start using the package. Let&#39;s look at a simple example using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Iris_flower_data_set&#34;&gt;Iris dataset&lt;/a&gt; to demonstrate how to use LineaPy to 1) store a variable&#39;s history, 2) get its cleaned-up code, and 3) build an executable pipeline for the variable.&lt;/p&gt; &#xA;&lt;p&gt;The following development code fits a linear regression model to the Iris dataset:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import lineapy&#xA;import pandas as pd&#xA;import matplotlib.pyplot as plt&#xA;from sklearn.linear_model import LinearRegression&#xA;&#xA;# Load data&#xA;url = &#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv&#34;&#xA;df = pd.read_csv(url)&#xA;&#xA;# Map each species to a color&#xA;color_map = {&#34;Setosa&#34;: &#34;green&#34;, &#34;Versicolor&#34;: &#34;blue&#34;, &#34;Virginica&#34;: &#34;red&#34;}&#xA;df[&#34;variety_color&#34;] = df[&#34;variety&#34;].map(color_map)&#xA;&#xA;# Plot petal vs. sepal width by species&#xA;df.plot.scatter(&#34;petal.width&#34;, &#34;sepal.width&#34;, c=&#34;variety_color&#34;)&#xA;plt.show()&#xA;&#xA;# Create dummy variables encoding species&#xA;df[&#34;d_versicolor&#34;] = df[&#34;variety&#34;].apply(lambda x: 1 if x == &#34;Versicolor&#34; else 0)&#xA;df[&#34;d_virginica&#34;] = df[&#34;variety&#34;].apply(lambda x: 1 if x == &#34;Virginica&#34; else 0)&#xA;&#xA;# Initiate the model&#xA;mod = LinearRegression()&#xA;&#xA;# Fit the model&#xA;mod.fit(&#xA;    X=df[[&#34;petal.width&#34;, &#34;d_versicolor&#34;, &#34;d_virginica&#34;]],&#xA;    y=df[&#34;sepal.width&#34;],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s say you&#39;re happy with your above code, and you&#39;ve decided to save the trained model. You can store the model as a LineaPy &lt;a href=&#34;https://docs.lineapy.org/en/main/concepts/artifact.html&#34;&gt;artifact&lt;/a&gt; with the following code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Save the model as an artifact&#xA;lineapy.save(mod, &#34;iris_model&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;A LineaPy artifact encapsulates both the value &lt;em&gt;and&lt;/em&gt; code, so you can easily retrieve the model&#39;s code, like so:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Retrieve the model artifact&#xA;artifact = lineapy.get(&#34;iris_model&#34;)&#xA;&#xA;# Check code for the model artifact&#xA;print(artifact.get_code())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The print statement will output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;import pandas as pd&#xA;from sklearn.linear_model import LinearRegression&#xA;&#xA;url = &#34;https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv&#34;&#xA;df = pd.read_csv(url)&#xA;color_map = {&#34;Setosa&#34;: &#34;green&#34;, &#34;Versicolor&#34;: &#34;blue&#34;, &#34;Virginica&#34;: &#34;red&#34;}&#xA;df[&#34;variety_color&#34;] = df[&#34;variety&#34;].map(color_map)&#xA;df[&#34;d_versicolor&#34;] = df[&#34;variety&#34;].apply(lambda x: 1 if x == &#34;Versicolor&#34; else 0)&#xA;df[&#34;d_virginica&#34;] = df[&#34;variety&#34;].apply(lambda x: 1 if x == &#34;Virginica&#34; else 0)&#xA;mod = LinearRegression()&#xA;mod.fit(&#xA;    X=df[[&#34;petal.width&#34;, &#34;d_versicolor&#34;, &#34;d_virginica&#34;]],&#xA;    y=df[&#34;sepal.width&#34;],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that these are the minimal essential steps to produce the model. That is, LineaPy has automatically cleaned up the original code by removing extraneous operations that do not affect the model (e.g., plotting).&lt;/p&gt; &#xA;&lt;p&gt;Let&#39;s say you&#39;re asked to retrain the model on a regular basis to account for any updates in the source data. You need to set up a pipeline to train the model ‚Äî LineaPy makes this as simple as a single function call:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lineapy.to_pipeline(&#xA;    artifacts=[&#34;iris_model&#34;],&#xA;    input_parameters=[&#34;url&#34;],  # Specify variable(s) to parametrize&#xA;    pipeline_name=&#34;iris_model_pipeline&#34;,&#xA;    output_dir=&#34;output/&#34;,&#xA;    framework=&#34;AIRFLOW&#34;,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This command generates several files that can be used to execute the pipeline from the UI or CLI. (Check this &lt;a href=&#34;https://docs.lineapy.org/en/main/tutorials/02_pipeline_building.html&#34;&gt;tutorial&lt;/a&gt; for more details.)&lt;/p&gt; &#xA;&lt;p&gt;In short, LineaPy automates time-consuming, manual steps in a data science workflow, helping us get our work to production more quickly and easily.&lt;/p&gt; &#xA;&lt;h2&gt;Usage Reporting&lt;/h2&gt; &#xA;&lt;p&gt;LineaPy collects anonymous usage data that helps our team to improve the product. Only LineaPy&#39;s API calls and CLI commands are being reported. We strip out as much potentially sensitive information as possible, and we will never collect user code, data, variable names, or stack traces.&lt;/p&gt; &#xA;&lt;p&gt;You can opt-out of usage tracking by setting environment variable:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export LINEAPY_DO_NOT_TRACK=true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;What Next?&lt;/h2&gt; &#xA;&lt;p&gt;To learn more about LineaPy, please check out the project &lt;a href=&#34;https://docs.lineapy.org/en/main/index.html&#34;&gt;documentation&lt;/a&gt; which contains many examples you can follow with. Some key resources include:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Resource&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.lineapy.org/en/main/index.html&#34;&gt;Docs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This is our knowledge hub ‚Äî when in doubt, start here!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.lineapy.org/en/main/concepts/artifact.html&#34;&gt;Concepts&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Learn about key concepts underlying LineaPy!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/LineaLabs/lineapy/tree/main/examples/tutorials&#34;&gt;Tutorials&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;These notebook tutorials will help you better understand core functionalities of LineaPy&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/LineaLabs/lineapy/tree/main/examples/use_cases&#34;&gt;Use Cases&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;These domain examples illustrate how LineaPy can help in real-world applications&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.lineapy.org/en/main/references/api_reference.html&#34;&gt;API Reference&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Need more technical details? This reference may help!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.lineapy.org/en/main/guides/contribute/index.html&#34;&gt;Contribute&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Want to contribute? These instructions will help you get set up!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;&lt;a href=&#34;https://join.slack.com/t/lineacommunity/shared_invite/zt-18kizfn3b-1Qu_HDT3ahGudnAwoFAw9Q&#34;&gt;Slack&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Have questions or issues unresolved? Join our community and ask away!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>