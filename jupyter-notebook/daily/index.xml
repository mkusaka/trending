<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-07-08T01:32:36Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hemansnation/AI-Engineer-Headquarters</title>
    <updated>2025-07-08T01:32:36Z</updated>
    <id>tag:github.com,2025-07-08:/hemansnation/AI-Engineer-Headquarters</id>
    <link href="https://github.com/hemansnation/AI-Engineer-Headquarters" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A collection of scientific methods, processes, algorithms, and systems to build stories &amp; models.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/hemansnation/AI-Engineer-Headquarters&#34;&gt;&lt;img src=&#34;https://firstcontributions.github.io/open-source-badges/badges/open-source-v1/open-source.svg?sanitize=true&#34; alt=&#34;Open Source Love&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1 align=&#34;center&#34;&gt;AI Engineer Headquarters&lt;/h1&gt; &#xA;&lt;p&gt; A drill of scientific methods, processes, algorithms, and systems to build stories &amp;amp; models. An in-depth learning resource for humans. &lt;/p&gt;&#xA;&lt;p&gt;This is a drill for people who aim to be in the top 1% of Data and AI experts.&lt;/p&gt; &#xA;&lt;p&gt;You can do the drill by watching video sessions or text content.&lt;/p&gt; &#xA;&lt;p&gt;I will recommend video sessions and use text content as go-to notes.&lt;/p&gt; &#xA;&lt;p&gt;You can be in one of the following categories:-&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;either you are working on a leadership position&lt;/li&gt; &#xA; &lt;li&gt;or you are working as a professional&lt;/li&gt; &#xA; &lt;li&gt;or you are a student&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;No matter what position you are working in currently, you need to put in the same amount of effort to be in the top 1%.&lt;/p&gt; &#xA;&lt;p&gt;Spoiler alert - There are NO Shortcuts in the tech field.&lt;/p&gt; &#xA;&lt;p&gt;This is for all humans who want to improve in the field and are courageous enough to take action.&lt;/p&gt; &#xA;&lt;p&gt;You will find all the topics explained here and whatever is needed to understand it completely.&lt;/p&gt; &#xA;&lt;p&gt;The drill is all action-oriented.&lt;/p&gt; &#xA;&lt;p&gt;To be the authority/best in the AI field, I created a routine that includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;4 hours of deep work sessions every day &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Deep work session rules: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;no phone/notifications&lt;/li&gt; &#xA;     &lt;li&gt;no talking to anyone&lt;/li&gt; &#xA;     &lt;li&gt;coffee/chai allowed&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;2 hours of shallow work sessions every day &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Shallow work session rules: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;phone allowed&lt;/li&gt; &#xA;     &lt;li&gt;talking allowed&lt;/li&gt; &#xA;     &lt;li&gt;include sharing your work online&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can customize the learning sessions according to your time availability.&lt;/p&gt; &#xA;&lt;p&gt;&lt;/p&gt; &#xA;&lt;h2&gt;the path&lt;/h2&gt; &#xA;&lt;ol start=&#34;0&#34;&gt; &#xA; &lt;li&gt;Prep&lt;/li&gt; &#xA; &lt;li&gt;Foundations of AI Engineering&lt;/li&gt; &#xA; &lt;li&gt;Mastering Large Language Models (LLMs)&lt;/li&gt; &#xA; &lt;li&gt;Retrieval-Augmented Generation (RAG)&lt;/li&gt; &#xA; &lt;li&gt;Fine-Tuning LLMs&lt;/li&gt; &#xA; &lt;li&gt;Reinforcement Learning and Ethical AI&lt;/li&gt; &#xA; &lt;li&gt;Agentic Workflows&lt;/li&gt; &#xA; &lt;li&gt;Career Acceleration&lt;/li&gt; &#xA; &lt;li&gt;Bonus&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>HandsOnLLM/Hands-On-Large-Language-Models</title>
    <updated>2025-07-08T01:32:36Z</updated>
    <id>tag:github.com,2025-07-08:/HandsOnLLM/Hands-On-Large-Language-Models</id>
    <link href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official code repo for the O&#39;Reilly Book - &#34;Hands-On Large Language Models&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Hands-On Large Language Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/jalammar/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Follow%20Jay-blue.svg?logo=linkedin&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.linkedin.com/in/mgrootendorst/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Follow%20Maarten-blue.svg?logo=linkedin&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.deeplearning.ai/short-courses/how-transformer-llms-work/?utm_campaign=handsonllm-launch&amp;amp;utm_medium=partner&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/DeepLearning.AI%20Course-NEW!-&amp;amp;labelColor=black&amp;amp;color=red.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAuMDAwMzY1MjgxIC0wLjAwMDE0MDE0MiAzMy4yOSAzMy4xNSI+Cgk8cGF0aCBkPSJNMTYuNjQzIDMzLjE0NWMtMy4yOTIgMC02LjUxLS45NzItOS4yNDYtMi43OTNhMTYuNTg4IDE2LjU4OCAwIDAxLTYuMTMtNy40MzhBMTYuNTA3IDE2LjUwNyAwIDAxLjMyIDEzLjM0YTE2LjU1IDE2LjU1IDAgMDE0LjU1NS04LjQ4NUExNi42NjUgMTYuNjY1IDAgMDExMy4zOTYuMzE4YTE2LjcxIDE2LjcxIDAgMDE5LjYxNi45NDQgMTYuNjI4IDE2LjYyOCAwIDAxNy40NyA2LjEwMyAxNi41MjIgMTYuNTIyIDAgMDEyLjgwNCA5LjIwN2MwIDQuMzk2LTEuNzUzIDguNjEtNC44NzQgMTEuNzE5YTE2LjY4IDE2LjY4IDAgMDEtMTEuNzY5IDQuODU0em0uMTI1LTYuNjI4YzYuOTA2IDAgMTIuNTE3LTUuNjk4IDEyLjUxNy0xMi43MyAwLTcuMDMtNS42MS0xMi43MjUtMTIuNTE3LTEyLjcyNS02LjkwNiAwLTEyLjUxNyA1LjY5OC0xMi41MTcgMTIuNzI1IDAgNy4wMjcgNS42MTEgMTIuNzMgMTIuNTE3IDEyLjczem0tLjEyNS0yLjkxOGMtNi4yODkgMC0xMS4zODYtNC45MjUtMTEuMzg2LTExLjAwMkM1LjI1NyA2LjUyIDEwLjM2IDEuNTkgMTYuNjQzIDEuNTljNi4yODQgMCAxMS4zODYgNC45MyAxMS4zODYgMTEuMDA3cy01LjA5NyAxMS4wMDItMTEuMzg2IDExLjAwMnptLS4yNDItNC41MDhjNC43NyAwIDguNjMzLTMuNjc5IDguNjMzLTguMjE4IDAtNC41MzgtMy44ODUtOC4yMjEtOC42MzMtOC4yMjEtNC43NDcgMC04LjYzMiAzLjY3OS04LjYzMiA4LjIyMSAwIDQuNTQzIDMuODg1IDguMjE4IDguNjMyIDguMjE4eiIgZmlsbD0iI0ZENEE2MSIvPgo8L3N2Zz4=&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Welcome! In this repository you will find the code for all examples throughout the book &lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;Hands-On Large Language Models&lt;/a&gt; written by &lt;a href=&#34;https://www.linkedin.com/in/jalammar/&#34;&gt;Jay Alammar&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/mgrootendorst/&#34;&gt;Maarten Grootendorst&lt;/a&gt; which we playfully dubbed: &lt;br&gt;&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;b&gt;&lt;i&gt;&#34;The Illustrated LLM Book&#34;&lt;/i&gt;&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt;Through the visually educational nature of this book and with &lt;strong&gt;almost 300 custom made figures&lt;/strong&gt;, learn the practical tools and concepts you need to use Large Language Models today!&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png&#34; width=&#34;50%&#34; height=&#34;50%&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;The book is available on:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961&#34;&gt;Amazon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.shroffpublishers.com/books/computer-science/large-language-models/9789355425522/&#34;&gt;Shroff Publishers (India)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/&#34;&gt;O&#39;Reilly&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Hands-Large-Language-Models-Alammar-ebook/dp/B0DGZ46G88/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;amp;qid=&amp;amp;sr=&#34;&gt;Kindle&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.barnesandnoble.com/w/hands-on-large-language-models-jay-alammar/1145185960&#34;&gt;Barnes and Noble&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/210408850-hands-on-large-language-models&#34;&gt;Goodreads&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;p&gt;We advise to run all examples through Google Colab for the easiest setup. Google Colab allows you to use a T4 GPU with 16GB of VRAM for free. All examples were mainly built and tested using Google Colab, so it should be the most stable platform. However, any other cloud provider should work.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Chapter&lt;/th&gt; &#xA;   &lt;th&gt;Notebook&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 1: Introduction to Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter01/Chapter%201%20-%20Introduction%20to%20Language%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 2: Tokens and Embeddings&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter02/Chapter%202%20-%20Tokens%20and%20Token%20Embeddings.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 3: Looking Inside Transformer LLMs&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter03/Chapter%203%20-%20Looking%20Inside%20LLMs.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 4: Text Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter04/Chapter%204%20-%20Text%20Classification.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 5: Text Clustering and Topic Modeling&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter05/Chapter%205%20-%20Text%20Clustering%20and%20Topic%20Modeling.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 6: Prompt Engineering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter06/Chapter%206%20-%20Prompt%20Engineering.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 7: Advanced Text Generation Techniques and Tools&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter07/Chapter%207%20-%20Advanced%20Text%20Generation%20Techniques%20and%20Tools.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 8: Semantic Search and Retrieval-Augmented Generation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter08/Chapter%208%20-%20Semantic%20Search.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 9: Multimodal Large Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter09/Chapter%209%20-%20Multimodal%20Large%20Language%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 10: Creating Text Embedding Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter10/Chapter%2010%20-%20Creating%20Text%20Embedding%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 11: Fine-tuning Representation Models for Classification&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter11/Chapter%2011%20-%20Fine-Tuning%20BERT.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Chapter 12: Fine-tuning Generation Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter12/Chapter%2012%20-%20Fine-tuning%20Generation%20Models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!TIP] You can check the &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/.setup/&#34;&gt;setup&lt;/a&gt; folder for a quick-start guide to install all packages locally and you can check the &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/.setup/conda/&#34;&gt;conda&lt;/a&gt; folder for a complete guide on how to setup your environment, including conda and PyTorch installation. Note that the depending on your OS, Python version, and dependencies your results might be slightly differ. However, they should this be similar to the examples in the book.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Reviews&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;Jay and Maarten have continued their tradition of providing beautifully illustrated and insightful descriptions of complex topics in their new book. Bolstered with working code, timelines, and references to key papers, their book is a valuable resource for anyone looking to understand the main techniques behind how Large Language Models are built.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Andrew Ng&lt;/strong&gt; - founder of &lt;a href=&#34;https://www.deeplearning.ai/&#34;&gt;DeepLearning.AI&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;This is an exceptional guide to the world of language models and their practical applications in industry. Its highly-visual coverage of generative, representational, and retrieval applications of language models empowers readers to quickly understand, use, and refine LLMs. Highly recommended!&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Nils Reimers&lt;/strong&gt; - Director of Machine Learning at Cohere | creator of &lt;a href=&#34;https://github.com/UKPLab/sentence-transformers&#34;&gt;sentence-transformers&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;I can’t think of another book that is more important to read right now. On every single page, I learned something that is critical to success in this era of language models.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Josh Starmer&lt;/strong&gt; - &lt;a href=&#34;https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw&#34;&gt;StatQuest&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;If you’re looking to get up to speed in everything regarding LLMs, look no further! In this wonderful book, Jay and Maarten will take you from zero to expert in the history and latest advances in large language models. With very intuitive explanations, great real-life examples, clear illustrations, and comprehensive code labs, this book lifts the curtain on the complexities of transformer models, tokenizers, semantic search, RAG, and many other cutting-edge technologies. A must read for anyone interested in the latest AI technology!&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Luis Serrano, PhD&lt;/strong&gt; - Founder and CEO of &lt;a href=&#34;https://www.youtube.com/@SerranoAcademy&#34;&gt;Serrano Academy&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&#34;&lt;em&gt;Hands-On Large Language Models brings clarity and practical examples to cut through the hype of AI. It provides a wealth of great diagrams and visual aids to supplement the clear explanations. The worked examples and code make concrete what other books leave abstract. The book starts with simple introductory beginnings, and steadily builds in scope. By the final chapters, you will be fine-tuning and building your own large language models with confidence.&lt;/em&gt;&#34;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Leland McInnes&lt;/strong&gt; - Researcher at the Tutte Institute for Mathematics and Computing | creator of &lt;a href=&#34;https://github.com/lmcinnes/umap&#34;&gt;UMAP&lt;/a&gt; and &lt;a href=&#34;https://github.com/scikit-learn-contrib/hdbscan&#34;&gt;HDBSCAN&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/bonus/&#34;&gt;Bonus content!&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;We attempted to put as much information into the book without it being overwhelming. However, even with a 400-page book there is still much to discover!&lt;/p&gt; &#xA;&lt;p&gt;We continue to create more guides that compliment the book and go more in-depth into new and &lt;a href=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/(bonus/)&#34;&gt;exciting topics&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state&#34;&gt;A Visual Guide to Mamba&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization&#34;&gt;A Visual Guide to Quantization&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://jalammar.github.io/illustrated-stable-diffusion/&#34;&gt;The Illustrated Stable Diffusion&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/mamba.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/quant.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/diffusion.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts&#34;&gt;A Visual Guide to Mixture of Experts&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms&#34;&gt;A Visual Guide to Reasoning LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1&#34;&gt;The Illustrated DeepSeek-R1&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/moe.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/reasoning.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/deepseek.png&#34; alt=&#34;&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please consider citing the book if you consider it useful for your research:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@book{hands-on-llms-book,&#xA;  author       = {Jay Alammar and Maarten Grootendorst},&#xA;  title        = {Hands-On Large Language Models},&#xA;  publisher    = {O&#39;Reilly},&#xA;  year         = {2024},&#xA;  isbn         = {978-1098150969},&#xA;  url          = {https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/},&#xA;  github       = {https://github.com/HandsOnLLM/Hands-On-Large-Language-Models}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>