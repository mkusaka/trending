<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-06-12T01:44:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Kulbear/deep-learning-coursera</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/Kulbear/deep-learning-coursera</id>
    <link href="https://github.com/Kulbear/deep-learning-coursera" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deep Learning Specialization by Andrew Ng on Coursera.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deep Learning Specialization on Coursera&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Master Deep Learning, and Break into AI&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Instructor: &lt;a href=&#34;http://www.andrewng.org/&#34;&gt;Andrew Ng&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;This repo contains all my work for this specialization. All the code base, quiz questions, screenshot, and images, are taken from, unless specified, &lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization on Coursera&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;What I want to say&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;VERBOSE CONTENT WARNING: YOU CAN JUMP TO THE NEXT SECTION IF YOU WANT&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;As a CS major student and a long-time self-taught learner, I have completed many CS related MOOCs on Coursera, Udacity, Udemy, and Edx. I do understand the hard time you spend on understanding new concepts and debugging your program. There are discussion forums on most MOOC platforms, however, even a question with detailed description may need some time to be answered. Here I released these solutions, which are &lt;strong&gt;only for your reference purpose&lt;/strong&gt;. It may help you to save some time. And I hope you don&#39;t copy any part of the code (the programming assignments are fairly easy if you read the instructions carefully), see the quiz solutions before you start your own adventure. This course is almost the simplest deep learning course I have ever taken, but the simplicity is based on the fabulous course content and structure. It&#39;s a treasure given by deeplearning.ai team.&lt;/p&gt; &#xA;&lt;p&gt;Currently, this repo has 3 major parts you may be interested in and I will give a list here.&lt;/p&gt; &#xA;&lt;h2&gt;Programming Assignments&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Logistic%20Regression%20with%20a%20Neural%20Network%20mindset.ipynb&#34;&gt;Week 2 - PA 1 - Logistic Regression with a Neural Network mindset&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Planar%20data%20classification%20with%20one%20hidden%20layer.ipynb&#34;&gt;Week 3 - PA 2 - Planar data classification with one hidden layer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step.ipynb&#34;&gt;Week 4 - PA 3 - Building your Deep Neural Network: Step by StepÂ¶&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20-%20Application.ipynb&#34;&gt;Week 4 - PA 4 - Deep Neural Network for Image Classification: Application&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Initialization.ipynb&#34;&gt;Week 1 - PA 1 - Initialization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Regularization.ipynb&#34;&gt;Week 1 - PA 2 - Regularization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Gradient%20Checking.ipynb&#34;&gt;Week 1 - PA 3 - Gradient Checking&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Optimization%20methods.ipynb&#34;&gt;Week 2 - PA 4 - Optimization Methods&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Tensorflow%20Tutorial.ipynb&#34;&gt;Week 3 - PA 5 - TensorFlow Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;There is no PA for this course. But this course comes with very interesting case study quizzes.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 4: Convolutional Neural Networks&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Step%20by%20Step%20-%20v1.ipynb&#34;&gt;Week 1 - PA 1 - Convolutional Model: step by step&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Application%20-%20v1.ipynb&#34;&gt;Week 1 - PA 2 - Convolutional Model: application&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Keras%20-%20Tutorial%20-%20Happy%20House%20v1.ipynb&#34;&gt;Week 2 - PA 1 - Keras - Tutorial - Happy House&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Convolutional%20Neural%20Networks/Residual%20Networks%20-%20v1.ipynb&#34;&gt;Week 2 - PA 2 - Residual Networks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 5: Sequence Models&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Sequence%20Models/Building%20a%20Recurrent%20Neural%20Network%20-%20Step%20by%20Step%20-%20v2.ipynb&#34;&gt;Week 1 - PA 1 - Building a Recurrent Neural Network - Step by Step&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb&#34;&gt;Week 1 - PA 2 - Character level language model - Dinosaurus land&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Quiz Solutions&lt;/h2&gt; &#xA;&lt;p&gt;There are concerns that some people may use the content here to quickly ace the course so I&#39;ll no longer update any quiz solution.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 1: Neural Networks and Deep Learning&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%201%20Quiz%20-%20Introduction%20to%20deep%20learning.md&#34;&gt;Week 1 Quiz - Introduction to deep learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%202%20Quiz%20-%20Neural%20Network%20Basics.md&#34;&gt;Week 2 Quiz - Neural Network Basics&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%203%20Quiz%20-%20%20Shallow%20Neural%20Networks.md&#34;&gt;Week 3 Quiz - Shallow Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Neural%20Networks%20and%20Deep%20Learning/Week%204%20Quiz%20-%20Key%20concepts%20on%20Deep%20Neural%20Networks.md&#34;&gt;Week 4 Quiz - Key concepts on Deep Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%201%20Quiz%20-%20Practical%20aspects%20of%20deep%20learning.md&#34;&gt;Week 1 Quiz - Practical aspects of deep learning&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%202%20Quiz%20-%20Optimization%20algorithms.md&#34;&gt;Week 2 Quiz - Optimization algorithms&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/Week%203%20Quiz%20-%20Hyperparameter%20tuning%2C%20Batch%20Normalization%2C%20Programming%20Frameworks.md&#34;&gt;Week 3 Quiz - Hyperparameter tuning, Batch Normalization, Programming Frameworks&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Course 3: Structuring Machine Learning Projects&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Structuring%20Machine%20Learning%20Projects/Week%201%20Quiz%20-%20Bird%20recognition%20in%20the%20city%20of%20Peacetopia%20(case%20study).md&#34;&gt;Week 1 Quiz - Bird recognition in the city of Peacetopia (case study)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/raw/master/Structuring%20Machine%20Learning%20Projects/Week%202%20Quiz%20-%20Autonomous%20driving%20(case%20study).md&#34;&gt;Week 2 Quiz - Autonomous driving (case study)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;del&gt;- Course 4: Convolutional Neural Networks&lt;/del&gt; &lt;del&gt;- Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;## Important Slide Notes&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;I screenshotted some important slide page and store them into GitHub issues. It seems not very helpful for everyone since I only keep those I think may be useful to me.&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/1&#34;&gt;Screenshots for Course 1: Neural Networks and Deep Learning&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/2&#34;&gt;Screenshots for Course 2: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/3&#34;&gt;Screenshots for Course 3: Structuring Machine Learning Projects&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- &lt;a href=&#34;https://github.com/Kulbear/deep-learning-coursera/issues/14&#34;&gt;Screenshots for Course 4: Convolutional Neural Networks&lt;/a&gt;&lt;/del&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;del&gt;- Screenshots for Course 5: Sequence Models&lt;/del&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Milestones&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2017-08-17&lt;/strong&gt;: Finished the first-released 3 courses, YAY! ğŸ˜ˆ&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>intel-analytics/BigDL</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/intel-analytics/BigDL</id>
    <link href="https://github.com/intel-analytics/BigDL" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Building Large-Scale AI Applications for Distributed Big Data&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/docs/readthedocs/image/bigdl_logo.jpg&#34; height=&#34;140px&#34;&gt;&lt;br&gt;&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Building Large-Scale AI Applications for Distributed Big Data&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;BigDL makes it easy for data scientists and data engineers to build end-to-end, distributed AI applications. The &lt;strong&gt;BigDL 2.0&lt;/strong&gt; release combines the &lt;a href=&#34;https://github.com/intel-analytics/BigDL/tree/branch-0.14&#34;&gt;original BigDL&lt;/a&gt; and &lt;a href=&#34;https://github.com/intel-analytics/analytics-zoo&#34;&gt;Analytics Zoo&lt;/a&gt; projects, providing the following features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-dllib&#34;&gt;DLlib&lt;/a&gt;: distributed deep learning library for Apache Spark &lt;em&gt;(i.e., the original BigDL framework with Keras-style API and Spark ML pipeline support)&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-orca&#34;&gt;Orca&lt;/a&gt;: seamlessly scale out TensorFlow and PyTorch pipelines for distributed Big Data&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-rayonspark&#34;&gt;RayOnSpark&lt;/a&gt;: run Ray programs directly on Big Data clusters&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#getting-started-with-chronos&#34;&gt;Chronos&lt;/a&gt;: scalable time series analysis using AutoML&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/intel-analytics/BigDL/main/#ppml-privacy-preserving-machine-learning&#34;&gt;PPML&lt;/a&gt;: privacy preserving big data analysis and machine learning (&lt;em&gt;experimental&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Nano/Overview/nano.html&#34;&gt;Nano&lt;/a&gt;: automatically accelerate TensorFlow and PyTorch pipelines by applying model CPU optimizations&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For more information, you may &lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;read the docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;You can use BigDL on &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/colab.html&#34;&gt;Google Colab&lt;/a&gt; without any installation. BigDL also includes a set of &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/notebooks.html&#34;&gt;notebooks&lt;/a&gt; that you can directly open and run in Colab.&lt;/p&gt; &#xA;&lt;p&gt;To install BigDL, we recommend using &lt;a href=&#34;https://docs.conda.io/projects/conda/en/latest/user-guide/install/&#34;&gt;conda&lt;/a&gt; environments.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create -n my_env &#xA;conda activate my_env&#xA;pip install bigdl &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To install latest nightly build, use &lt;code&gt;pip install --pre --upgrade bigdl&lt;/code&gt;; see &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/python.html&#34;&gt;Python&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/UserGuide/scala.html&#34;&gt;Scala&lt;/a&gt; user guide for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with DLlib&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;DLlib&lt;/strong&gt; is a distributed deep learning library for Apache Spark; with DLlib, users can write distributed deep learning applications as standard Spark programs (using either Scala or Python APIs).&lt;/p&gt; &#xA;&lt;p&gt;First, call &lt;code&gt;initNNContext&lt;/code&gt; at the beginning of the code:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;import com.intel.analytics.bigdl.dllib.NNContext&#xA;val sc = NNContext.initNNContext()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, define the BigDL model using Keras-style API:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val input = Input[Float](inputShape = Shape(10))  &#xA;val dense = Dense[Float](12).inputs(input)  &#xA;val output = Activation[Float](&#34;softmax&#34;).inputs(dense)  &#xA;val model = Model(input, output)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After that, use &lt;code&gt;NNEstimator&lt;/code&gt; to train/predict/evaluate the model using Spark Dataframes and ML pipelines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val trainingDF = spark.read.parquet(&#34;train_data&#34;)&#xA;val validationDF = spark.read.parquet(&#34;val_data&#34;)&#xA;val scaler = new MinMaxScaler().setInputCol(&#34;in&#34;).setOutputCol(&#34;value&#34;)&#xA;val estimator = NNEstimator(model, CrossEntropyCriterion())  &#xA;        .setBatchSize(size).setOptimMethod(new Adam()).setMaxEpoch(epoch)&#xA;val pipeline = new Pipeline().setStages(Array(scaler, estimator))&#xA;&#xA;val pipelineModel = pipeline.fit(trainingDF)  &#xA;val predictions = pipelineModel.transform(validationDF)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/DLlib/Overview/nnframes.html&#34;&gt;NNframes&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/DLlib/Overview/keras-api.html&#34;&gt;Keras API&lt;/a&gt; user guides for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with Orca&lt;/h2&gt; &#xA;&lt;p&gt;Most AI projects start with a Python notebook running on a single laptop; however, one usually needs to go through a mountain of pains to scale it to handle larger data set in a distributed fashion. The &lt;em&gt;&lt;strong&gt;Orca&lt;/strong&gt;&lt;/em&gt; library seamlessly scales out your single node TensorFlow or PyTorch notebook across large clusters (so as to process distributed Big Data).&lt;/p&gt; &#xA;&lt;p&gt;First, initialize &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html&#34;&gt;Orca Context&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context, OrcaContext&#xA;&#xA;# cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;sc = init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2) &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, perform &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/data-parallel-processing.html&#34;&gt;data-parallel processing in Orca&lt;/a&gt; (supporting standard Spark Dataframes, TensorFlow Dataset, PyTorch DataLoader, Pandas, Pillow, etc.):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from pyspark.sql.functions import array&#xA;&#xA;spark = OrcaContext.get_spark_session()&#xA;df = spark.read.parquet(file_path)&#xA;df = df.withColumn(&#39;user&#39;, array(&#39;user&#39;)) \  &#xA;       .withColumn(&#39;item&#39;, array(&#39;item&#39;))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, use &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/distributed-training-inference.html&#34;&gt;sklearn-style Estimator APIs in Orca&lt;/a&gt; to perform distributed &lt;em&gt;TensorFlow&lt;/em&gt;, &lt;em&gt;PyTorch&lt;/em&gt; or &lt;em&gt;Keras&lt;/em&gt; training and inference:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tensorflow import keras&#xA;from bigdl.orca.learn.tf.estimator import Estimator&#xA;&#xA;user = keras.layers.Input(shape=[1])  &#xA;item = keras.layers.Input(shape=[1])  &#xA;feat = keras.layers.concatenate([user, item], axis=1)  &#xA;predictions = keras.layers.Dense(2, activation=&#39;softmax&#39;)(feat)  &#xA;model = keras.models.Model(inputs=[user, item], outputs=predictions)  &#xA;model.compile(optimizer=&#39;rmsprop&#39;,  &#xA;              loss=&#39;sparse_categorical_crossentropy&#39;,  &#xA;              metrics=[&#39;accuracy&#39;])&#xA;&#xA;est = Estimator.from_keras(keras_model=model)  &#xA;est.fit(data=df,  &#xA;        batch_size=64,  &#xA;        epochs=4,  &#xA;        feature_cols=[&#39;user&#39;, &#39;item&#39;],  &#xA;        label_cols=[&#39;label&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/QuickStart/orca-tf-quickstart.html&#34;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/QuickStart/orca-pytorch-quickstart.html&#34;&gt;PyTorch&lt;/a&gt; quickstart, as well as the &lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;document website&lt;/a&gt;, for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with RayOnSpark&lt;/h2&gt; &#xA;&lt;p&gt;Ray is an open source distributed framework for emerging AI applications. &lt;em&gt;&lt;strong&gt;RayOnSpark&lt;/strong&gt;&lt;/em&gt; allows users to directly run Ray programs on existing Big Data clusters, and directly write Ray code inline with their Spark code (so as to process the in-memory Spark RDDs or DataFrames).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context&#xA;&#xA;# cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;sc = init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2, init_ray_on_spark=True) &#xA;&#xA;import ray&#xA;&#xA;@ray.remote&#xA;class Counter(object):&#xA;      def __init__(self):&#xA;          self.n = 0&#xA;&#xA;      def increment(self):&#xA;          self.n += 1&#xA;          return self.n&#xA;&#xA;counters = [Counter.remote() for i in range(5)]&#xA;print(ray.get([c.increment.remote() for c in counters]))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the RayOnSpark &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Ray/Overview/ray.html&#34;&gt;user guide&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Ray/QuickStart/ray-quickstart.html&#34;&gt;quickstart&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started with Chronos&lt;/h2&gt; &#xA;&lt;p&gt;Time series prediction takes observations from previous time steps as input and predicts the values at future time steps. The &lt;em&gt;&lt;strong&gt;Chronos&lt;/strong&gt;&lt;/em&gt; library makes it easy to build end-to-end time series analysis by applying AutoML to extremely large-scale time series prediction.&lt;/p&gt; &#xA;&lt;p&gt;To train a time series model with AutoML, first initialize &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Orca/Overview/orca-context.html&#34;&gt;Orca Context&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.orca import init_orca_context&#xA;&#xA;#cluster_mode can be &#34;local&#34;, &#34;k8s&#34; or &#34;yarn&#34;&#xA;init_orca_context(cluster_mode=&#34;yarn&#34;, cores=4, memory=&#34;10g&#34;, num_nodes=2, init_ray_on_spark=True)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, create &lt;em&gt;TSDataset&lt;/em&gt; for your data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.chronos.data import TSDataset&#xA;&#xA;tsdata_train, tsdata_valid, tsdata_test\&#xA;        = TSDataset.from_pandas(df, &#xA;                                dt_col=&#34;dt_col&#34;, &#xA;                                target_col=&#34;target_col&#34;, &#xA;                                with_split=True, &#xA;                                val_ratio=0.1, &#xA;                                test_ratio=0.1)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Next, create an &lt;em&gt;AutoTSEstimator&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from bigdl.chronos.autots import AutoTSEstimator&#xA;&#xA;autotsest = AutoTSEstimator(model=&#39;lstm&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Finally, call &lt;code&gt;fit&lt;/code&gt; on &lt;em&gt;AutoTSEstimator&lt;/em&gt;, which applies AutoML to find the best model and hyper-parameters; it returns a &lt;em&gt;TSPipeline&lt;/em&gt; which can be used for prediction or evaluation.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#train a pipeline with AutoML support&#xA;ts_pipeline = autotsest.fit(data=tsdata_train,&#xA;                            validation_data=tsdata_valid)&#xA;&#xA;#predict&#xA;ts_pipeline.predict(tsdata_test)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;See the Chronos &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Chronos/Overview/chronos.html&#34;&gt;user guide&lt;/a&gt; and &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Chronos/QuickStart/chronos-autotsest-quickstart.html&#34;&gt;example&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;PPML (Privacy Preserving Machine Learning)&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;BigDL PPML&lt;/strong&gt;&lt;/em&gt; provides a &lt;em&gt;Trusted Cluster Environment&lt;/em&gt; for protecting the end-to-end Big Data AI pipeline. It combines various low level hardware and software security technologies (e.g., Intel SGX, LibOS such as Graphene and Occlum, Federated Learning, etc.), and allows users to run unmodified Big Data analysis and ML/DL programs (such as Apache Spark, Apache Flink, Tensorflow, PyTorch, etc.) in a secure fashion on (private or public) cloud.&lt;/p&gt; &#xA;&lt;p&gt;See the &lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/PPML/Overview/ppml.html&#34;&gt;PPML user guide&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;More information&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/&#34;&gt;Document Website&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;mailto:bigdl-user-group+subscribe@googlegroups.com&#34;&gt;Mail List&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/bigdl-user-group&#34;&gt;User Group&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Application/powered-by.html&#34;&gt;Powered-By&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bigdl.readthedocs.io/en/latest/doc/Application/presentations.html&#34;&gt;Presentations&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citing BigDL&lt;/h2&gt; &#xA;&lt;p&gt;If you&#39;ve found BigDL useful for your project, you may cite the &lt;a href=&#34;https://arxiv.org/abs/1804.05839&#34;&gt;paper&lt;/a&gt; as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@inproceedings{SOCC2019_BIGDL,&#xA;  title={BigDL: A Distributed Deep Learning Framework for Big Data},&#xA;  author={Dai, Jason (Jinquan) and Wang, Yiheng and Qiu, Xin and Ding, Ding and Zhang, Yao and Wang, Yanzhang and Jia, Xianyan and Zhang, Li (Cherry) and Wan, Yan and Li, Zhichao and Wang, Jiao and Huang, Shengsheng and Wu, Zhongyuan and Wang, Yang and Yang, Yuhao and She, Bowen and Shi, Dongjie and Lu, Qi and Huang, Kai and Song, Guoqiong},&#xA;  booktitle={Proceedings of the ACM Symposium on Cloud Computing},&#xA;  publisher={Association for Computing Machinery},&#xA;  pages={50--60},&#xA;  year={2019},&#xA;  series={SoCC&#39;19},&#xA;  doi={10.1145/3357223.3362707},&#xA;  url={https://arxiv.org/pdf/1804.05839.pdf}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>Fafa-DL/Lhy_Machine_Learning</title>
    <updated>2022-06-12T01:44:11Z</updated>
    <id>tag:github.com,2022-06-12:/Fafa-DL/Lhy_Machine_Learning</id>
    <link href="https://github.com/Fafa-DL/Lhy_Machine_Learning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;æå®æ¯…2021æ˜¥å­£æœºå™¨å­¦ä¹ è¯¾ç¨‹è¯¾ä»¶åŠä½œä¸š&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;æå®æ¯…2021/2022æ˜¥å­£æœºå™¨å­¦ä¹ è¯¾ç¨‹è¯¾ä»¶åŠä½œä¸š&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Fafa-DL/readme-data/main/Bilibili.png&#34; alt=&#34;BILIBILI&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;é‡ç£…é¡»çŸ¥&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;ï¼ˆé‡ç£…é¡»çŸ¥ï¼Œç»Ÿä¸€è¯´æ˜ï¼‰ä¸ºæ–¹ä¾¿æ‰€æœ‰ç½‘è¯¾èµ„æ–™ä¸ä¼˜è´¨ç”µå­ä¹¦ç±çš„å®æ—¶æ›´æ–°ç»´æŠ¤ï¼Œåˆ›å»ºäº†ä¸€ä¸ªåœ¨çº¿å®æ—¶ç½‘ç›˜æ–‡ä»¶å¤¹ï¼Œæ”¾åœ¨å…¬ä¼—å·ã€å•¥éƒ½ä¼šä¸€ç‚¹çš„ç ”ç©¶ç”Ÿã€‘ï¼Œæœ¬èŠ‚è¯¾å¯¹åº”åºå·ã€05ã€‘ã€‚&#xA;&#xA;UPå°†2021&amp;amp;2022æ‰€æœ‰ä½œä¸šçš„æ•°æ®èµ„æ–™æ•´ç†æ‰“åŒ…å¥½äº†ï¼Œç”±äºæ–‡ä»¶å¤ªå¤§ï¼Œå·²åŒæ­¥æ”¾åœ¨ä¸Šè¿°æ‰€æåœ¨çº¿ç½‘ç›˜ã€‚&#xA;&#xA;åœ¨çº¿ç½‘ç›˜èƒ½æ»¡è¶³è¯¥è¯¾ç¨‹æ‰€éœ€èµ„æ–™çš„å…¨éƒ¨éœ€æ±‚ï¼Œé“¾æ¥æŒ‚æ‰ä¹Ÿä¼šåŠæ—¶æ›´æ–°ï¼Œç¥å¤§å®¶å­¦ä¹ é¡ºåˆ©ã€‚&#xA;&#xA;2022ä»…åœ¨2021åŸºç¡€ä¸Šè¿›è¡Œå°è¡¥å……ï¼Œ2021å†…å®¹å˜æˆäº†å‰ç½®çŸ¥è¯†ï¼ŒUPä¼šåœ¨è§†é¢‘æ ‡é¢˜æ‰“ä¸Š2022çš„æ ‡ç­¾ï¼›&#xA;&#xA;ppt/pdfæ”¯æŒç›´é“¾ä¸‹è½½ã€‚&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;æ›´æ–°æ—¥å¿—&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;æ—¥æœŸ&lt;/th&gt; &#xA;   &lt;th&gt;é¡¹ç›®&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/03/16&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW1ã€HW2ï¼ŒåŒæ­¥æ›´æ–°åŠ©æ•™èŒƒä¾‹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/03/26&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW3ã€HW4è¯¾ä»¶ã€ä»£ç ã€èŒƒä¾‹ï¼›releaseé¡µå‘å¸ƒHW1-HW4æ•°æ®&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/01&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°é€‰ä¿®å†…å®¹To Learn Moreï¼ŒåŸºæœ¬æ˜¯æè€å¸ˆä»Šå¹´ä¸æ‰“ç®—è®²è€Œä»¥å‰è®²è¿‡çš„çŸ¥è¯†ç‚¹(æ—§è§†é¢‘)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/09&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°GAN åŠ HW05&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/16&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Self-Supervised Learning åŠ HW06&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/04/30&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Explainable AI&amp;amp;Adversarial Attack åŠ HW07&amp;amp;HW08&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/06&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Domain Adaptation åŠ HW09&amp;amp;HW10&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/21&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°RL åŠ HW11&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/05/28&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Quantum ML&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/04&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Life-Long&amp;amp;Compression åŠ HW12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/11&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Meta Learning åŠ HW13&amp;amp;HW14&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/06/18&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW15ï¼Œéšç€æè€å¸ˆè¯¾ç¨‹ç»“è¯­è§†é¢‘ä¸Šä¼ ï¼Œ2021æœºå™¨å­¦ä¹ åŸºæœ¬ç»“æŸå•¦&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021/12/20&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Githubæ’ç‰ˆï¼Œåˆ é™¤repoä¸­çš„ppt/pdfç›´æ¥æä¾›ä¸‹è½½é“¾æ¥ï¼Œæ€»èµ„æ–™æ”¾å…¥&lt;a href=&#34;https://pan.baidu.com/s/13cxyIbvF0bEyytANLf58NQ&#34;&gt;ç™¾åº¦äº‘ç›˜-æå–ç ï¼šsv1i&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/17&lt;/td&gt; &#xA;   &lt;td&gt;2022æ˜¥å­£æœºå™¨å­¦ä¹ è¯¾ç¨‹ä»…åœ¨21åŸºç¡€ä¸Šè¿›è¡Œå°è¡¥å……ï¼ŒUPåŒæ­¥æ›´æ–°å®˜ç½‘è¡¥å……å†…å®¹&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/21&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 1:Introductionof Deep Learningè¡¥å……å†…å®¹ï¼ŒGithubæ’ç‰ˆå¤§æ›´æ–°&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/02/25&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 2:What to do if my network fails to trainè¡¥å……å†…å®¹ä¸HW2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/05&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 3:Images inputï¼ŒHW3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/13&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 4 Sequence as inputï¼ŒHW4&lt;br&gt;UPå°†2021&amp;amp;2022æ‰€æœ‰ä½œä¸šçš„æ•°æ®èµ„æ–™æ•´ç†æ‰“åŒ…å¥½æ”¾åœ¨å…¬ä¼—å·ã€å•¥éƒ½ä¼šä¸€ç‚¹çš„ç ”ç©¶ç”Ÿã€‘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/03/18&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 5 Sequence to sequenceï¼ŒHW5ï¼Œç›¸åº”Dataæ”¾åœ¨å…¬ä¼—å·ç»´æŠ¤çš„ç½‘ç›˜ä¸­&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/05&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 7ä»¥åŠHW6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/16&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/23&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/04/30&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°Lecture 9 &amp;amp; Lecture10ï¼ŒHW9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/06&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW10&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/13&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW11ï¼Œéƒ¨åˆ†Lecture10æ•™å­¦è§†é¢‘&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/24&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/05/30&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW13&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022/06/10&lt;/td&gt; &#xA;   &lt;td&gt;æ›´æ–°HW14ã€HW15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Bç«™ä¸»é¡µ&lt;/th&gt; &#xA;   &lt;th&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;å•¥éƒ½ä¼šä¸€ç‚¹çš„ç ”ç©¶ç”Ÿ&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æ™ºèƒ½æŠ€æœ¯æ¢è®¨ç¾¤1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=lY5KVICA&#34;&gt;78174903&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æ™ºèƒ½æŠ€æœ¯æ¢è®¨ç¾¤2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=ZCDCT3xV&#34;&gt;571218304&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;äººå·¥æ™ºèƒ½æŠ€æœ¯æ¢è®¨ç¾¤3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jq.qq.com/?_wv=1027&amp;amp;k=bakez5Yz&#34;&gt;584723646&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;åç§°&lt;/th&gt; &#xA;   &lt;th&gt;é¡¹ç›®&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021è¯¾ç¨‹ä¸»é¡µ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html&#34;&gt;æå®æ¯…2021æ˜¥å­£æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022è¯¾ç¨‹ä¸»é¡µ&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php&#34;&gt;æå®æ¯…2022æ˜¥å­£æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Bç«™è§†é¢‘åˆé›†&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN&#34;&gt;(å¼ºæ¨)æå®æ¯…2021æ˜¥æœºå™¨å­¦ä¹ è¯¾ç¨‹&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2021è§†é¢‘åŠèµ„æ–™ç›®å½•&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Fafa-DL/Lhy_Machine_Learning/tree/main/2021%20ML&#34;&gt;é“¾æ¥&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2022è§†é¢‘åŠèµ„æ–™ç›®å½•&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/Fafa-DL/Lhy_Machine_Learning/tree/main/2022%20ML&#34;&gt;é“¾æ¥&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;ç« èŠ‚&lt;/th&gt; &#xA;   &lt;th&gt;2021å‰ç½®çŸ¥è¯†&lt;/th&gt; &#xA;   &lt;th&gt;2022è¡¥å……&lt;/th&gt; &#xA;   &lt;th&gt;é€‰ä¿®&lt;/th&gt; &#xA;   &lt;th&gt;ä½œä¸š&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 1&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=3&#34;&gt;ï¼ˆä¸Šï¼‰æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=4&#34;&gt;ï¼ˆä¸‹ï¼‰æœºå™¨å­¦ä¹ åŸºæœ¬æ¦‚å¿µç®€ä»‹&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=1&#34;&gt;2022-æœºå™¨å­¦ä¹ ç›¸å…³è§„å®š&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=5&#34;&gt;2022-Colabæ•™å­¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=6&#34;&gt;2022-Pytorch Tutorial 1&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=7&#34;&gt;2022-Pytorch Tutorial 2&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/rule%20(v2).pdf&#34;&gt;Rules&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/introduction%20(v2).pdf&#34;&gt;Chinese class course intro&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Pytorch%20Tutorial%201.pdf&#34;&gt;Pytorch Tutorial 1&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Pytorch%20Tutorial%202.pdf&#34;&gt;Pytorch Tutorial 2&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Colab%20Tutorial%202022.pdf&#34;&gt;Colab Tutorial&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/EnvironmentSetup.pdf&#34;&gt;Environment Setup&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=13&#34;&gt;æ·±åº¦å­¦ä¹ ç®€ä»‹&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=14&#34;&gt;åå‘ä¼ æ’­&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=15&#34;&gt;é¢„æµ‹-å®å¯æ¢¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=16&#34;&gt;åˆ†ç±»-å®å¯æ¢¦&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=17&#34;&gt;é€»è¾‘å›å½’&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=11&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/HW01.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1FTcG6CE-HILnvFztEFKdauMlPKfQvm5Z#scrollTo=YdttVRkAfu2t&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/t/a3ebd5b5542f0f55e828d4f00de8e59a&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 2&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=19&#34;&gt;ï¼ˆä¸€ï¼‰å±€éƒ¨æœ€å°å€¼ (local minima) ä¸éç‚¹ (saddle point)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=20&#34;&gt;ï¼ˆäºŒï¼‰æ‰¹æ¬¡ (batch) ä¸åŠ¨é‡ (momentum)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=21&#34;&gt;ï¼ˆä¸‰ï¼‰è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ (Learning Rate)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=22&#34;&gt;ï¼ˆå››ï¼‰æŸå¤±å‡½æ•° (Loss) ä¹Ÿå¯èƒ½æœ‰å½±å“&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=23&#34;&gt;2022-å†æ¢å®å¯æ¢¦ã€æ•°ç å®è´åˆ†ç±»å™¨ â€” æµ…è°ˆæœºå™¨å­¦ä¹ åŸç†&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/theory%20(v7).pdf&#34;&gt;Theory&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=24&#34;&gt;Gradient Descent (Demo by AOE)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=26&#34;&gt; Beyond Adam (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=27&#34;&gt; Beyond Adam (part 2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=28&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw2_slides%202022.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1hmTFJ8hdcnqRz_0oJSXjTGhZLVU-bS1a?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw2&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 3&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=31&#34;&gt;å·ç§¯ç¥ç»ç½‘ç»œCNN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=32&#34;&gt;ä¸ºä»€ä¹ˆç”¨äº†éªŒè¯é›†è¿˜æ˜¯è¿‡æ‹Ÿåˆ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=33&#34;&gt;é±¼ä¸ç†ŠæŒå¯ä»¥å…¼å¾—çš„æœºå™¨å­¦ä¹ &lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/validation.pdf&#34;&gt;Validation&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/whydeep%20(v3).pdf&#34;&gt;Why Deep&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=34&#34;&gt;Spatial Transformer Layer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=35&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW3%20-%20Image%20Classification.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/15hMu9YiYjE_6HY99UXon2vKGk2KwugWu&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw3b&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 4&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=41&#34;&gt;è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-attention)ï¼ˆä¸Šï¼‰&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=42&#34;&gt;è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-attention)ï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=40&#34;&gt;RNN(part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=41&#34;&gt;RNN(part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=42&#34;&gt;GNN(part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=43&#34;&gt;GNN(part 2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=45&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW4.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1gC2Gojv9ov9MUQ1a1WDpVBD6FOcLZsog?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw4&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 5&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=48&#34;&gt;ç±»ç¥ç»ç½‘ç»œè®­ç»ƒä¸èµ·æ¥æ€ä¹ˆåŠï¼ˆäº”ï¼‰æ‰¹æ¬¡æ ‡å‡†åŒ–&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=49&#34;&gt;Transformerï¼ˆä¸Šï¼‰&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=50&#34;&gt;Transformerï¼ˆä¸‹ï¼‰&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=51&#34;&gt;å„å¼å„æ ·ç¥å¥‡çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ (Self-attention) å˜å‹&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/xformer%20(v8).pdf&#34;&gt;xformer&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=52&#34;&gt;NAT model&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=53&#34;&gt;Pointer network&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=54&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/HW05.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Tlyk2vCBQ8ZCuDQcCSEWTLzr1_xYF9CL#scrollTo=Le4RFWXxjmm0&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw5/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 6&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=58&#34;&gt;GANï¼ˆä¸€ï¼‰åŸºæœ¬æ¦‚å¿µä»‹ç»&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=59&#34;&gt;GANï¼ˆäºŒï¼‰ç†è®ºä»‹ç»ä¸WGAN&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=60&#34;&gt;GANï¼ˆä¸‰ï¼‰ç”Ÿæˆå™¨æ•ˆèƒ½è¯„ä¼°ä¸æ¡ä»¶å¼ç”Ÿæˆ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=61&#34;&gt;GANï¼ˆå››ï¼‰Cycle GAN&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=62&#34;&gt;Theory of GAN (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=63&#34;&gt;Theory of GAN (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=64&#34;&gt;Theory of GAN (part 3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=65&#34;&gt;Deep Generative Model (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=66&#34;&gt;Deep Generative Model (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=67&#34;&gt;FLOW-based Model&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=70&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW6.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/10lHBPFoNhTiiPe-yZ7SwAV1wwrkGc4En?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 7&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=71&#34;&gt;è‡ªç›‘ç£å­¦ä¹ ï¼ˆä¸€ï¼‰èŠéº»è¡—ä¸è¿›å‡»çš„å·¨äºº&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=72&#34;&gt;è‡ªç›‘ç£å­¦ä¹ ï¼ˆäºŒï¼‰BERTç®€ä»‹&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=73&#34;&gt;è‡ªç›‘ç£å­¦ä¹ ï¼ˆä¸‰ï¼‰BERTçš„å¥‡é—»è½¶äº‹&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=74&#34;&gt;è‡ªç›‘ç£å­¦ä¹ ï¼ˆå››ï¼‰GPTçš„é‡æœ›&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=75&#34;&gt;å¦‚ä½•æœ‰æ•ˆçš„ä½¿ç”¨è‡ªç£å¯¼å¼æ¨¡å‹&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=76&#34;&gt;è¯­éŸ³ä¸å½±åƒä¸Šçš„ç¥å¥‡è‡ªç£å¯¼å¼å­¦ä¹ æ¨¡å‹&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/PLM.pdf&#34;&gt;Recent Advance of Self-supervied learning for NLP&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/SSL_speech_image%20(v9).pdf&#34;&gt;SSL for Speech and Image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=77&#34;&gt;BERT (part 1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=78&#34;&gt;BERT (part 2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=80&#34;&gt;GPT-3&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=82&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw7_slides.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1QloQ42zYwX_ETAs2GIkeh8qFj0UjHXfH?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/c/ml2022spring-hw7&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 8&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=83&#34;&gt;è‡ªç¼–ç å™¨ (Auto-encoder) (ä¸Š) â€“ åŸºæœ¬æ¦‚å¿µ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=84&#34;&gt;è‡ªç¼–ç å™¨ (Auto-encoder) (ä¸‹) â€“ é¢†ç»“å˜å£°å™¨ä¸æ›´å¤šåº”ç”¨&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=85&#34;&gt;Anomaly Detection (1_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=86&#34;&gt;Anomaly Detection (2_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=87&#34;&gt;Anomaly Detection (3_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=88&#34;&gt;Anomaly Detection (4_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=89&#34;&gt;Anomaly Detection (5_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=90&#34;&gt;Anomaly Detection (6_7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=91&#34;&gt;Anomaly Detection (7_7)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=92&#34;&gt;PCA&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=93&#34;&gt;t-SNE&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=95&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20Homework%208%20Anomaly%20Detection.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/16J23Uqkclro8zvp5Y1EXFtEWOvMA9YXC#scrollTo=JoW1UrrxgI_U&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw8/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 9&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=96&#34;&gt;æœºå™¨å­¦ä¹ çš„å¯è§£é‡Šæ€§ (ä¸Š) â€“ ä¸ºä»€ä¹ˆç¥ç»ç½‘ç»œå¯ä»¥æ­£ç¡®åˆ†è¾¨å®å¯æ¢¦å’Œæ•°ç å®è´&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=77&#34;&gt;æœºå™¨å­¦ä¹ çš„å¯è§£é‡Šæ€§ (ä¸‹) â€“æœºå™¨å¿ƒä¸­çš„çŒ«é•¿ä»€ä¹ˆæ ·å­&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=98&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸Šçš„å¯¹æŠ—å¼æ”»å‡» Part1&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Attacks-in-NLP-Draft.pdf&#34;&gt;Adversarial Attack for NLP&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=100&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW9.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1DvQX9apokZHZNfZeG7brJS6XbsGpPFYU?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 10&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=101&#34;&gt;æ¥è‡ªäººç±»çš„æ¶æ„æ”»å‡» (Adversarial Attack) (ä¸Š) â€“ åŸºæœ¬æ¦‚å¿µ&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=102&#34;&gt;2021 - æ¥è‡ªäººç±»çš„æ¶æ„æ”»å‡» (Adversarial Attack) (ä¸‹) â€“ ç±»ç¥ç»ç½‘ç»œèƒ½å¦èº²è¿‡äººç±»æ·±ä¸è§åº•çš„æ¶æ„&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=103&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸Šçš„å¯¹æŠ—å¼æ”»å‡» Part2&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=104&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸Šçš„å¯¹æŠ—å¼æ”»å‡» Part3&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=105&#34;&gt;è‡ªç„¶è¯­è¨€å¤„ç†ä¸Šçš„æ¨¡ä»¿æ”»å‡» (Imitation Attack) ä»¥åŠåé—¨æ”»å‡» (Backdoor Attack)&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Attacks-in-NLP-Draft.pdf&#34;&gt;Adversarial Attack for NLP&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=106&#34;&gt;More about Adversarial Attack (1_2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=107&#34;&gt;More about Adversarial Attack (2_2)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=109&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW10%20Adversarial%20Attack.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1BcYS4bAInDCTo4Ilsc6w4o_SEoFTuHSO?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw10/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 11&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=110&#34;&gt; æ¦‚è¿°é¢†åŸŸè‡ªé€‚åº” (Domain Adaptation)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=111&#34;&gt;æ¶æè‡ªç£å¯¼å¼å­¦ä¹ æ¨¡å‹ BERTçš„ä¸‰ä¸ªæ•…äº‹&lt;/a&gt;&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/More%20self-supervised%20(v2).pdf&#34;&gt;More about self-supervised learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=113&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw11_slides%20(ML2022).pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1N2MceW-Z8olOSQpF-TGvqBq83tRdMOzu&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022-spring-hw11&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 12&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=114&#34;&gt;ï¼ˆä¸€ï¼‰å¢å¼ºå¼å­¦ä¹ å’Œæœºå™¨å­¦ä¹ ä¸€æ ·éƒ½æ˜¯ä¸‰ä¸ªæ­¥éª¤&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=115&#34;&gt;ï¼ˆäºŒï¼‰Policy Gradient ä¸ä¿®è¯¾å¿ƒæƒ…&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=116&#34;&gt;ï¼ˆä¸‰ï¼‰Actor-Critic&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=117&#34;&gt;ï¼ˆå››ï¼‰å›é¦ˆéå¸¸ç½•è§çš„æ™‚å€™æ€ä¹ˆåŠï¼Ÿæœºå™¨çš„æœ›æ¢…æ­¢æ¸´&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=118&#34;&gt;ï¼ˆäº”ï¼‰å¦‚ä½•ä»ç¤ºèŒƒä¸­å­¦ä¹ ï¼Ÿé€†å‘å¢å¼·å¼å­¦ä¹  (Inverse RL)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=120&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/hw12_RL_slides_english_version.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/11NS001dD653xCsxypBCohnvsI-CKs64o&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://ml.ee.ntu.edu.tw/hw12/&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 13&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=122&#34;&gt;ç¥ç»ç½‘ç»œå‹ç¼© (ä¸€) - ç±»ç¥ç»ç½‘ç»œå‰ªæ(Pruning) ä¸å¤§ä¹é€å‡è¯´(Lottery Ticket Hypothesis)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=123&#34;&gt;ç¥ç»ç½‘ç»œå‹ç¼© (äºŒ) - ä»å„ç§ä¸åŒçš„é¢å‘ä¾†å‹ç¼©ç¥ç»ç½‘ç»œ&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=125&#34;&gt;Proximal Policy Optimization (PPO)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=124&#34;&gt;Q-learning (Basic Idea)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=125&#34;&gt;Proximal Policy Optimization (Advanced Tips)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=127&#34;&gt;Proximal Policy Optimization (Continuous Action)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=128&#34;&gt;Geometry of Loss Surfaces (Conjecture)&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=130&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Machine%20Learning%20HW13.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1S7J12rzL4m5BjSk0QqYw2cnrcqP46VuV#scrollTo=k_UqVZtpSz5Z&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw13&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 14&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=131&#34;&gt;æœºå™¨ç»ˆèº«å­¦ä¹  (ä¸€) - ä¸ºä»€ä¹ˆä»Šæ—¥çš„äººå·¥æ™ºèƒ½æ— æ³•æˆä¸ºå¤©ç½‘ï¼Ÿç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=132&#34;&gt;æœºå™¨çµ‚èº«å­¦ä¹  (äºŒ) - ç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=134&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/Homework%2014%20%20Regularization-based%20%20Lifelong%20Learning.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/11XAhRjXoiQhGfs0LMw6qD2eqPVsPQUxn?usp=sharing&#34;&gt;Code&lt;/a&gt;&lt;br&gt;[Submission]&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lecture 15&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=135&#34;&gt;å…ƒå­¦ä¹  Meta Learning (ä¸€) - å…ƒå­¦ä¹ å’Œæœºå™¨å­¦ä¹ ä¸€æ ·ä¹Ÿæ˜¯ä¸‰å€‹æ­¥éª¤)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=136&#34;&gt;å…ƒå­¦ä¹  Meta Learning (äºŒ) - ä¸‡ç‰©çš†å¯ Meta&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Video:&lt;br&gt;[None]&lt;br&gt;&lt;br&gt;PDF:&lt;br&gt;[None]&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=137&#34;&gt;MAML (1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=138&#34;&gt;MAML (2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=139&#34;&gt;MAML (3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=140&#34;&gt;MAML (4)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=141&#34;&gt;MAML (5)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=142&#34;&gt;MAML (6)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=143&#34;&gt;MAML (7)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=144&#34;&gt;MAML (8)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=145&#34;&gt;MAML (9)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=146&#34;&gt;Gradient Descent as LSTM (1_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=147&#34;&gt;Gradient Descent as LSTM (2_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=148&#34;&gt;Gradient Descent as LSTM (3_3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=149&#34;&gt;Metric-based (1)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=150&#34;&gt;Metric-based (2)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=151&#34;&gt;Metric-based (3)&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=152&#34;&gt;Train+Test as RNN&lt;/a&gt;&lt;br&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Wv411h7kN?p=153&#34;&gt;Video&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/ml2022-course-data/ML2022%20HW15%20Meta%20Learning.pdf&#34;&gt;Slide&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1oKRpCYcU7P6qXHna05Kd9EkG6h1HtxdN?usp=sharingg&#34;&gt;Code&lt;/a&gt;&lt;br&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/ml2022spring-hw15&#34;&gt;Submission&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://space.bilibili.com/46880349&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Fafa-DL/readme-data/main/gzh.jpg&#34; alt=&#34;BILIBILI&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>