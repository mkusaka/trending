<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-25T01:32:57Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>PolymathicAI/the_well</title>
    <updated>2025-05-25T01:32:57Z</updated>
    <id>tag:github.com,2025-05-25:/PolymathicAI/the_well</id>
    <link href="https://github.com/PolymathicAI/the_well" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A 15TB Collection of Physics Simulation Datasets&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/PolymathicAI/the_well/master/docs/assets/images/the_well_color.svg?sanitize=true&#34; width=&#34;60%&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;br&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://github.com/PolymathicAI/the_well/actions/workflows/tests.yaml/badge.svg?sanitize=true&#34; alt=&#34;Test Workflow&#34;&gt; &lt;a href=&#34;https://pypi.org/project/the-well/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/the_well&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://polymathic-ai.org/the_well/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/docs-latest---?color=25005a&amp;amp;labelColor=grey&#34; alt=&#34;Docs&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/2412.00568&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2412.00568---?logo=arXiv&amp;amp;labelColor=b31b1b&amp;amp;color=grey&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://openreview.net/forum?id=00Sx577BT3&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/NeurIPS-2024---?logo=https%3A%2F%2Fneurips.cc%2Fstatic%2Fcore%2Fimg%2FNeurIPS-logo.svg&amp;amp;labelColor=68448B&amp;amp;color=b3b3b3&#34; alt=&#34;NeurIPS&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/collections/polymathic-ai/the-well-67e129f4ca23e0447395d74c&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/datasets-%20?logo=huggingface&amp;amp;logoColor=%23FFD21E&amp;amp;label=Hugging%20Face&amp;amp;labelColor=%236B7280&amp;amp;color=%23FFD21E&#34; alt=&#34;HuggingFace&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;h1&gt;The Well: 15TB of Physics Simulations&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to the Well, a large-scale collection of machine learning datasets containing numerical simulations of a wide variety of spatiotemporal physical systems. The Well draws from domain scientists and numerical software developers to provide 15TB of data across 16 datasets covering diverse domains such as biological systems, fluid dynamics, acoustic scattering, as well as magneto-hydrodynamic simulations of extra-galactic fluids or supernova explosions. These datasets can be used individually or as part of a broader benchmark suite for accelerating research in machine learning and computational sciences.&lt;/p&gt; &#xA;&lt;h2&gt;Tap into the Well&lt;/h2&gt; &#xA;&lt;p&gt;Once the Well package installed and the data downloaded you can use them in your training pipeline.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from the_well.data import WellDataset&#xA;from torch.utils.data import DataLoader&#xA;&#xA;trainset = WellDataset(&#xA;    well_base_path=&#34;path/to/base&#34;,&#xA;    well_dataset_name=&#34;name_of_the_dataset&#34;,&#xA;    well_split_name=&#34;train&#34;&#xA;)&#xA;train_loader = DataLoader(trainset)&#xA;&#xA;for batch in train_loader:&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For more information regarding the interface, please refer to the &lt;a href=&#34;https://github.com/PolymathicAI/the_well/tree/master/docs/api.md&#34;&gt;API&lt;/a&gt; and the &lt;a href=&#34;https://github.com/PolymathicAI/the_well/raw/master/docs/tutorials/dataset.ipynb&#34;&gt;tutorials&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;If you plan to use The Well datasets to train or evaluate deep learning models, we recommend to use a machine with enough computing resources. We also recommend creating a new Python (&amp;gt;=3.10) environment to install the Well. For instance, with &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34;&gt;venv&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m venv path/to/env&#xA;source path/to/env/activate/bin&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;From PyPI&lt;/h4&gt; &#xA;&lt;p&gt;The Well package can be installed directly from PyPI.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install the_well&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;From Source&lt;/h4&gt; &#xA;&lt;p&gt;It can also be installed from source. For this, clone the &lt;a href=&#34;https://github.com/PolymathicAI/the_well&#34;&gt;repository&lt;/a&gt; and install the package with its dependencies.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone https://github.com/PolymathicAI/the_well&#xA;cd the_well&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Depending on your acceleration hardware, you can specify &lt;code&gt;--extra-index-url&lt;/code&gt; to install the relevant PyTorch version. For example, use&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install . --extra-index-url https://download.pytorch.org/whl/cu121&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to install the dependencies built for CUDA 12.1.&lt;/p&gt; &#xA;&lt;h4&gt;Benchmark Dependencies&lt;/h4&gt; &#xA;&lt;p&gt;If you want to run the benchmarks, you should install additional dependencies.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install the_well[benchmark]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Downloading the Data&lt;/h3&gt; &#xA;&lt;p&gt;The Well datasets range between 6.9GB and 5.1TB of data each, for a total of 15TB for the full collection. Ensure that your system has enough free disk space to accomodate the datasets you wish to download.&lt;/p&gt; &#xA;&lt;p&gt;Once &lt;code&gt;the_well&lt;/code&gt; is installed, you can use the &lt;code&gt;the-well-download&lt;/code&gt; command to download any dataset of The Well.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;the-well-download --base-path path/to/base --dataset active_matter --split train&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If &lt;code&gt;--dataset&lt;/code&gt; and &lt;code&gt;--split&lt;/code&gt; are omitted, all datasets and splits will be downloaded. This could take a while!&lt;/p&gt; &#xA;&lt;h3&gt;Streaming from Hugging Face&lt;/h3&gt; &#xA;&lt;p&gt;Most of the Well datasets are also hosted on &lt;a href=&#34;https://huggingface.co/collections/polymathic-ai/the-well-67e129f4ca23e0447395d74c&#34;&gt;Hugging Face&lt;/a&gt;. Data can be streamed directly from the hub using the following code.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from the_well.data import WellDataset&#xA;from torch.utils.data import DataLoader&#xA;&#xA;# The following line may take a couple of minutes to instantiate the datamodule&#xA;trainset = WellDataset(&#xA;    well_base_path=&#34;hf://datasets/polymathic-ai/&#34;,  # access from HF hub&#xA;    well_dataset_name=&#34;active_matter&#34;,&#xA;    well_split_name=&#34;train&#34;,&#xA;)&#xA;train_loader = DataLoader(trainset)&#xA;&#xA;for batch in train_loader:&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For better performance in large training, we advise &lt;a href=&#34;https://raw.githubusercontent.com/PolymathicAI/the_well/master/#downloading-the-data&#34;&gt;downloading the data locally&lt;/a&gt; instead of streaming it over the network.&lt;/p&gt; &#xA;&lt;h2&gt;Benchmark&lt;/h2&gt; &#xA;&lt;h3&gt;Train Models on the Well&lt;/h3&gt; &#xA;&lt;p&gt;The repository allows benchmarking surrogate models on the different datasets that compose the Well. Some state-of-the-art models are already implemented in &lt;a href=&#34;https://github.com/PolymathicAI/the_well/tree/master/the_well/benchmark/models&#34;&gt;&lt;code&gt;models&lt;/code&gt;&lt;/a&gt;, while &lt;a href=&#34;https://github.com/PolymathicAI/the_well/tree/master/the_well/data&#34;&gt;dataset classes&lt;/a&gt; handle the raw data of the Well. The benchmark relies on &lt;a href=&#34;https://github.com/PolymathicAI/the_well/raw/master/the_well/benchmark/train.py&#34;&gt;a training script&lt;/a&gt; that uses &lt;a href=&#34;https://hydra.cc/&#34;&gt;hydra&lt;/a&gt; to instantiate various classes (e.g. dataset, model, optimizer) from &lt;a href=&#34;https://github.com/PolymathicAI/the_well/tree/master/the_well/benchmark/configs&#34;&gt;configuration files&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For instance, to run the training script of default FNO architecture on the active matter dataset, launch the following commands:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd the_well/benchmark&#xA;python train.py experiment=fno server=local data=active_matter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Each argument corresponds to a specific configuration file. In the command above &lt;code&gt;server=local&lt;/code&gt; indicates the training script to use &lt;a href=&#34;https://github.com/PolymathicAI/the_well/tree/master/the_well/benchmark/configs/server/local.yaml&#34;&gt;&lt;code&gt;local.yaml&lt;/code&gt;&lt;/a&gt;, which just declares the relative path to the data. The configuration can be overridden directly or edited with new YAML files. Please refer to &lt;a href=&#34;https://hydra.cc/&#34;&gt;hydra documentation&lt;/a&gt; for editing configuration.&lt;/p&gt; &#xA;&lt;p&gt;You can use this command within a sbatch script to launch the training with Slurm.&lt;/p&gt; &#xA;&lt;h3&gt;Load Benchmarked Model Checkpoints&lt;/h3&gt; &#xA;&lt;p&gt;The model benchmarked in the original paper of the Well have been designed as a a simple baseline. They should not be considered as state-of-the-art. We hope that the community will build upon these results to develop better architectures for PDE surrogate modeling.&lt;/p&gt; &#xA;&lt;p&gt;Most of the checkpoints of the models are available on &lt;a href=&#34;https://huggingface.co/collections/polymathic-ai/the-well-benchmark-models-67e69bd7cd8e60229b5cd43e&#34;&gt;Hugging Face&lt;/a&gt;. To load a specific checkpoint follow the example below of the FNO model trained on the &lt;code&gt;active_matter&lt;/code&gt; dataset.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from the_well.benchmark.models import FNO&#xA;&#xA;model = FNO.from_pretrained(&#34;polymathic-ai/FNO-active_matter&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;This project has been led by the &lt;a href=&#34;https://polymathic-ai.org/&#34;&gt;Polymathic AI&lt;/a&gt; organization, in collaboration with researchers from the Flatiron Institute, University of Colorado Boulder, University of Cambridge, New York University, Rutgers University, Cornell University, University of Tokyo, Los Alamos Natioinal Laboratory, University of California, Berkeley, Princeton University, CEA DAM, and University of Li√®ge.&lt;/p&gt; &#xA;&lt;p&gt;If you find this project useful for your research, please consider citing&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{ohana2024well,&#xA;  title={The well: a large-scale collection of diverse physics simulations for machine learning},&#xA;  author={Ohana, Ruben and McCabe, Michael and Meyer, Lucas and Morel, Rudy and Agocs, Fruzsina and Beneitez, Miguel and Berger, Marsha and Burkhart, Blakesly and Dalziel, Stuart and Fielding, Drummond and others},&#xA;  journal={Advances in Neural Information Processing Systems},&#xA;  volume={37},&#xA;  pages={44989--45037},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Contact&lt;/h2&gt; &#xA;&lt;p&gt;For questions regarding this project, please contact &lt;a href=&#34;https://rubenohana.github.io/&#34;&gt;Ruben Ohana&lt;/a&gt; and &lt;a href=&#34;https://mikemccabe210.github.io/&#34;&gt;Michael McCabe&lt;/a&gt; at {rohana,mmccabe}@flatironinstitute.org.&lt;/p&gt; &#xA;&lt;h2&gt;Bug Reports and Feature Requests&lt;/h2&gt; &#xA;&lt;p&gt;To report a bug (in the data or the code), request a feature or simply ask a question, you can &lt;a href=&#34;https://github.com/PolymathicAI/the_well/issues&#34;&gt;open an issue&lt;/a&gt; on the &lt;a href=&#34;https://github.com/PolymathicAI/the_well&#34;&gt;repository&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>