<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-12T01:40:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>LearnPythonWithRune/DataScienceWithPython</title>
    <updated>2023-06-12T01:40:11Z</updated>
    <id>tag:github.com,2023-06-12:/LearnPythonWithRune/DataScienceWithPython</id>
    <link href="https://github.com/LearnPythonWithRune/DataScienceWithPython" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Learn Data Science with focus on adding value with the most efficient tech stack.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DataScienceWithPython&lt;/h1&gt; &#xA;&lt;h2&gt;Get started with Data Science with Python&lt;/h2&gt; &#xA;&lt;p&gt;An engaging journey to become a &lt;a href=&#34;https://www.learnpythonwithrune.org/data-science-2/&#34;&gt;Data Scientist&lt;/a&gt; with Python&lt;/p&gt; &#xA;&lt;h2&gt;TL;DR&lt;/h2&gt; &#xA;&lt;p&gt;There are two options.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Download all the notebooks from this repository and run them in Jupyter Notebook. Chapter one in eBook will get you started with that.&lt;/li&gt; &#xA; &lt;li&gt;Follow along using Google colab&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Note: On each of those options, you&#39;ll find:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A starter folder, which contains all the notebooks, that are empty in order to follow along.&lt;/li&gt; &#xA; &lt;li&gt;A final folder, which contains all the notebooks with all the source code.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Option 1&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download all Jupyter Notebooks from repo (&lt;a href=&#34;https://github.com/LearnPythonWithRune/DataScienceWithPython/archive/refs/heads/main.zip&#34;&gt;zip-file-download&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;Unzip download (main.zip) an appropriate place.&lt;/li&gt; &#xA; &lt;li&gt;Launch Ananconda and start JuPyter Notebook (&lt;a href=&#34;https://www.anaconda.com/products/individual&#34;&gt;Install it from here if needed&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Open the first Notebook from download.&lt;/li&gt; &#xA; &lt;li&gt;Start watching the first video lesson (&lt;a href=&#34;https://www.youtube.com/watch?v=V-ACrS4egMQ&amp;amp;list=PLvMRWNpDTNwQ0wzQYY_lk2sedyzgHaZm3&#34;&gt;YouTube&lt;/a&gt;).&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Option 2&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;No installations needed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Go to &lt;a href=&#34;https://github.com/LearnPythonWithRune/DataScienceWithPython/tree/main/colab&#34;&gt;Colab Notebooks Folder&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Start watching the first video lesson (&lt;a href=&#34;https://www.youtube.com/watch?v=V-ACrS4egMQ&amp;amp;list=PLvMRWNpDTNwQ0wzQYY_lk2sedyzgHaZm3&#34;&gt;YouTube&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Note: On each notebook, click on &#34;Open in Colab&#34;, in order to open it on Google Colab&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Why do most fail with Data Science?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Most focus on getting good at all technical aspects: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Math&lt;/li&gt; &#xA;   &lt;li&gt;Stat&lt;/li&gt; &#xA;   &lt;li&gt;Python&lt;/li&gt; &#xA;   &lt;li&gt;R&lt;/li&gt; &#xA;   &lt;li&gt;Machine Learning&lt;/li&gt; &#xA;   &lt;li&gt;pandas&lt;/li&gt; &#xA;   &lt;li&gt;NumPy&lt;/li&gt; &#xA;   &lt;li&gt;PyTorch&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;...and the list could go on and we didn&#39;t dive into sub-categories (but you get the point)&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;DISCLAIMER!!!&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;This is the wrong (long) way to learn!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Master the Data Science Workflow&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/LearnPythonWithRune/DataScienceWithPython/main/jupyter/starter/img/ds-workflow.png&#34; alt=&#34;Data Science Workflow&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Understanding what matters &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;The full workflow&lt;/li&gt; &#xA;   &lt;li&gt;How to add value to customers&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Focus on how to add value &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;This can be done with limited technical knowledge&lt;/li&gt; &#xA;   &lt;li&gt;&lt;em&gt;...and we will cover all you need&lt;/em&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Later you can become an expert in whatever your interest are&lt;/li&gt; &#xA; &lt;li&gt;But you should first understand the &lt;em&gt;WHY!&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This course will cover all aspects of it with the focus to get you there as fast as possible!&lt;/p&gt; &#xA;&lt;h2&gt;What will we cover?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Data Science Workflow &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Acquire - Prepare - Analyze - Report - Actions&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Data Visualization&lt;/li&gt; &#xA; &lt;li&gt;pandas for Data Science&lt;/li&gt; &#xA; &lt;li&gt;Data Sources &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Web Scraping&lt;/li&gt; &#xA;   &lt;li&gt;Databases&lt;/li&gt; &#xA;   &lt;li&gt;CSV, Excel &amp;amp; parquet files&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Where to find data&lt;/li&gt; &#xA; &lt;li&gt;Join (combine) data&lt;/li&gt; &#xA; &lt;li&gt;Statistics you need to know&lt;/li&gt; &#xA; &lt;li&gt;Machine Learning Models &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Linear Regression&lt;/li&gt; &#xA;   &lt;li&gt;Classification&lt;/li&gt; &#xA;   &lt;li&gt;...also check out the &lt;a href=&#34;https://www.learnpythonwithrune.org/machine-learning/&#34;&gt;Machine Learning Course&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Cleaning Data&lt;/li&gt; &#xA; &lt;li&gt;Feature Scaling&lt;/li&gt; &#xA; &lt;li&gt;Feature Selection&lt;/li&gt; &#xA; &lt;li&gt;Model Selection&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;At the end of the course you are provided with a template covering all aspects of the Data Science Workflow&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Acquire - Prepare - Analyze - Report - Actions&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>explodinggradients/ragas</title>
    <updated>2023-06-12T01:40:11Z</updated>
    <id>tag:github.com,2023-06-12:/explodinggradients/ragas</id>
    <link href="https://github.com/explodinggradients/ragas" rel="alternate"></link>
    <summary type="html">&lt;p&gt;SOTA metrics for evaluating Retrieval Augmented Generation (RAG)&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img style=&#34;vertical-align:middle&#34; height=&#34;200&#34; src=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/docs/assets/logo.png&#34;&gt; &lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;i&gt;SOTA metrics for evaluating Retrieval Augmented Generation (RAG)&lt;/i&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/explodinggradients/ragas/releases&#34;&gt; &lt;img alt=&#34;GitHub release&#34; src=&#34;https://img.shields.io/github/release/explodinggradients/ragas.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://www.python.org/&#34;&gt; &lt;img alt=&#34;Build&#34; src=&#34;https://img.shields.io/badge/Made%20with-Python-1f425f.svg?color=purple&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/explodinggradients/ragas/raw/master/LICENSE&#34;&gt; &lt;img alt=&#34;License&#34; src=&#34;https://img.shields.io/github/license/explodinggradients/ragas.svg?color=green&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/drive/1HfutiEhHMJLXiWGT8pcipxT5L2TpYEdt?usp=sharing&#34;&gt; &lt;img alt=&#34;Open In Colab&#34; src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://github.com/explodinggradients/ragas/&#34;&gt; &lt;img alt=&#34;Downloads&#34; src=&#34;https://badges.frapsoft.com/os/v1/open-source.svg?v=103&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/#shield-installation&#34;&gt;Installation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/#fire-quickstart&#34;&gt;Quickstart&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/#luggage-metrics&#34;&gt;Metrics&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/#raising_hand_man-faq&#34;&gt;FAQ&lt;/a&gt; | &lt;a href=&#34;https://huggingface.co/explodinggradients&#34;&gt;Hugging Face&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p&gt;ragas is a framework that helps you evaluate your Retrieval Augmented Generation (RAG) pipelines. RAG denotes a class of LLM applications that use external data to augment the LLM‚Äôs context. There are existing tools and frameworks that help you build these pipelines but evaluating it and quantifying your pipeline performance can be hard.. This is were ragas (RAG Assessment) comes in&lt;/p&gt; &#xA;&lt;p&gt;ragas provides you with the tools based on the latest research for evaluating LLM generated text to give you insights about your RAG pipeline. ragas can be integrated with your CI/CD to provide continuous check to ensure performance.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üõ°&lt;/span&gt; Installation&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ragas&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if you want to install from source&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/explodinggradients/ragas &amp;amp;&amp;amp; cd ragas&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;span&gt;üî•&lt;/span&gt; Quickstart&lt;/h2&gt; &#xA;&lt;p&gt;This is a small example program you can run to see ragas in action!&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#xA;from ragas import evaluate&#xA;from datasets import Dataset&#xA;import os&#xA;&#xA;os.environ[&#34;OPENAI_API_KEY&#34;] = &#34;your-openai-key&#34;&#xA;&#xA;# prepare your huggingface dataset in the format&#xA;# Dataset({&#xA;#     features: [&#39;question&#39;,&#39;contexts&#39;,&#39;answer&#39;],&#xA;#     num_rows: 25&#xA;# })&#xA;&#xA;dataset: Dataset&#xA;&#xA;results = evaluate(dataset)&#xA;# {&#39;ragas_score&#39;: 0.860, &#39;context_relavency&#39;: 0.817, &#xA;# &#39;factuality&#39;: 0.892, &#39;answer_relevancy&#39;: 0.874}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want a more in-depth explanation of core components, check out our &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/examples/quickstart.ipynb&#34;&gt;quick-start notebook&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;üß≥&lt;/span&gt; Metrics&lt;/h2&gt; &#xA;&lt;p&gt;Ragas measures your pipeline&#39;s performance against two dimensions&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Factuality&lt;/strong&gt;: measures the factual consistency of the generated answer against the given context.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Relevancy&lt;/strong&gt;: measures how relevant retrieved contexts and the generated answer are to the question.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Through repeated experiments, we have found that the quality of a RAG pipeline is highly dependent on these two dimensions. The final &lt;code&gt;ragas_score&lt;/code&gt; is the harmonic mean of these two factors.&lt;/p&gt; &#xA;&lt;p&gt;To read more about our metrics, checkout &lt;a href=&#34;https://raw.githubusercontent.com/explodinggradients/ragas/main/docs/metrics.md&#34;&gt;docs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;span&gt;‚ùì&lt;/span&gt; How to use Ragas to improve your pipeline?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;&#34;Measurement is the first step that leads to control and eventually to improvement&#34; - James Harrington&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here we assume that you already have your RAG pipeline ready. When is comes to RAG pipelines, there are mainly two parts - Retriever and generator. A change in any of this should also impact your pipelines&#39;s quality.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;First, decide one parameter that you&#39;re interested in adjusting. for example the number of retrieved documents, K.&lt;/li&gt; &#xA; &lt;li&gt;Collect a set of sample prompts (min 20) to form your test set.&lt;/li&gt; &#xA; &lt;li&gt;Run your pipeline using the test set before and after the change. Each time record the prompts with context and generated output.&lt;/li&gt; &#xA; &lt;li&gt;Run ragas evaluation for each of them to generate evaluation scores.&lt;/li&gt; &#xA; &lt;li&gt;Compare the scores and you will know how much the change has affected your pipelines&#39;s performance.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;&lt;span&gt;üôã‚ôÇ&lt;/span&gt; FAQ&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Why harmonic mean? Harmonic mean penalizes extreme values. For example if your generated answer is fully factually consistent with the context (factuality = 1) but is not relevant to the question (relevancy = 0), simple average would give you a score of 0.5 but harmonic mean will give you 0.0&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
</feed>