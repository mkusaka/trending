<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-06T01:41:04Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Sentdex/TermGPT</title>
    <updated>2023-06-06T01:41:04Z</updated>
    <id>tag:github.com,2023-06-06:/Sentdex/TermGPT</id>
    <link href="https://github.com/Sentdex/TermGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Giving LLMs like GPT-4 the ability to plan and execute terminal commands&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TermGPT&lt;/h1&gt; &#xA;&lt;p&gt;Giving LLMs like GPT-4 the ability to plan and execute terminal commands&lt;/p&gt; &#xA;&lt;p&gt;Video explanation and usage examples: &lt;a href=&#34;https://youtu.be/O4EmRi0_CI4&#34;&gt;https://youtu.be/O4EmRi0_CI4&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The notebook also breaks down how the script works.&lt;/p&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;Run with &lt;code&gt;$ python3 TermGPT.py&lt;/code&gt; You will need to create a &lt;code&gt;.env&lt;/code&gt; file similar to &lt;a href=&#34;https://github.com/Sentdex/TermGPT/raw/main/.env.example&#34;&gt;https://github.com/Sentdex/TermGPT/blob/main/.env.example&lt;/a&gt;, or set &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; manually.&lt;/p&gt; &#xA;&lt;p&gt;From here, you make your programming/development request. The script will run and query GPT-4 for a series of terminal commands to run to achieve this objective. This is including, but not limited to: reading files, writing code, reading websites, running code, running terminal commands...etc.&lt;/p&gt; &#xA;&lt;p&gt;The proposed commands are stored to a list and then presented back to the user again in bold red text, prior to running. After reviewing these commands, you can opt to run them, or not.&lt;/p&gt; &#xA;&lt;h1&gt;Future work&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;I would like to primarily find an open source model that can yield similar performance to GPT-4 in this realm.&lt;/li&gt; &#xA; &lt;li&gt;Simplify and add more natural language. Most likely, starting &#34;prompts&#34; will need higher and lower level understanding. Rather than doing something like --r [FILENAME], I would like to have a higher level pass via the LLM to determine if any files should be read, allowing for a pure &#34;natural language&#34; approach, along with likely far more generalization.&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>haoosz/ViCo</title>
    <updated>2023-06-06T01:41:04Z</updated>
    <id>tag:github.com,2023-06-06:/haoosz/ViCo</id>
    <link href="https://github.com/haoosz/ViCo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official PyTorch codes for the paper: &#34;ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image Generation&#34;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ViCo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.00971&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/arXiv-2306.00971%20-b31b1b&#34; alt=&#34;arXiv&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/license/haoosz/ViCo?color=lightgray&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.00971&#34;&gt;&lt;strong&gt;ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image Generation&lt;/strong&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/haoosz/ViCo/main/img/teaser.png&#34; alt=&#34;teaser&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;‚è≥ To Do&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release inference code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Release pretrained models&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Release training code&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Hugging Face demo&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;‚öôÔ∏è Set-up&lt;/h2&gt; &#xA;&lt;p&gt;Create a conda environment &lt;code&gt;vico&lt;/code&gt; using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda env create -f environment.yaml&#xA;conda activate vico&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;‚è¨ Download&lt;/h2&gt; &#xA;&lt;p&gt;Download the &lt;a href=&#34;https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt&#34;&gt;pretrained stable diffusion v1-4&lt;/a&gt; under &lt;code&gt;models/ldm/stable-diffusion-v1&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide the pretrained checkpoints at 300. 350, and 400 steps of 8 objects. You can download the &lt;a href=&#34;https://drive.google.com/drive/folders/1m8TCsY-C1tIOflHtWnFzTbw2C6dq67mC?usp=sharing&#34;&gt;&lt;strong&gt;sample images&lt;/strong&gt;&lt;/a&gt; and their corresponding &lt;a href=&#34;https://drive.google.com/drive/folders/1I9BJpTLEGueK2hCaR2RKdQrlTrtF24lC?usp=drive_link&#34;&gt;&lt;strong&gt;pretrained checkpoints&lt;/strong&gt;&lt;/a&gt;. You can also download the data of any object:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Object&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Sample images&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Checkpoints&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;barn&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1bS3QYwzAOnOJcdqUNQ4VSGFnlBN87elT?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1EsLeRkPUg7WH-nMCept28pVaX0IPlCGu?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;batman&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1S_UFE9mAgaqWHNxrb2XudnuIyWafSwlv?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1elwu9CNtzx_hwK23SbJiSfLkpMtbA66d?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;clock&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1L4AqVO0o6dapAxjjfSUCVGwd9iB5hIv2?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1N0E-he1GLH_3c-H1E8204xYzOKU-RT_X?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;dog7&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/107YOi1qXHnGeDuAaxxe4AW9fj17hehxX?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1SujoFfOBeKbZI74mFrdCsDIov_5xprHb?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;monster toy&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/18nIAXQsG5KaGys2yNJtIuYso2cgZh-2f?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1EzDjyyya7_zOflOG5rPkxY--R5OxejYx?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;pink sunglasses&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/10it3Sd9U1wbkfksMWfFHXeAch6uanEDr?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1aHnAgM4dpWFsqiNeg3mIX68G6xjfuZ-X?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;teddybear&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1lT8mOSgeh0P8DlfIh34qC2cvk2QaqSBo?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1630qFd06T2Kz46pb-hs9OA99v3LD44IQ?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;wooden pot&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1eVDMNAfAEroqMV8AiFlBqRGNcElmWw70?usp=drive_link&#34;&gt;image&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1kXQuzfSsAJ895gHZJDiFF-5BHoX49gOx?usp=drive_link&#34;&gt;ckpt&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;üöÄ Inference&lt;/h2&gt; &#xA;&lt;p&gt;Before run the inference command, please set:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;REF_IMAGE_PATH&lt;/code&gt;: Path of &lt;strong&gt;the reference image&lt;/strong&gt;. It can be any image in the samples like &lt;code&gt;batman/1.jpg&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHECKPOINT_PATH&lt;/code&gt;: Path of &lt;strong&gt;the checkpoint weight&lt;/strong&gt;. Its subfolder should be similar to &lt;code&gt;checkpoints/*-399.pt&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OUTPUT_PATH&lt;/code&gt;: Path of &lt;strong&gt;the generated images&lt;/strong&gt;. For example, it can be like &lt;code&gt;outputs/batman&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;python scripts/vico_txt2img.py \&#xA;--ddim_eta 0.0  --n_samples 4  --n_iter 2  --scale 7.5  --ddim_steps 50  \&#xA;--ckpt_path models/ldm/stable-diffusion-v1/sd-v1-4.ckpt  \&#xA;--image_path REF_IMAGE_PATH \&#xA;--ft_path CHECKPOINT_PATH \&#xA;--load_step 399 \&#xA;--prompt &#34;a photo of * on the beach&#34; \&#xA;--outdir OUTPUT_PATH&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can specify &lt;code&gt;load_step&lt;/code&gt; (300,350,400) and personalize &lt;code&gt;prompt&lt;/code&gt; (a prefix &#34;a photo of&#34; usually makes better results).&lt;/p&gt; &#xA;&lt;h2&gt;üíª Training&lt;/h2&gt; &#xA;&lt;h3&gt;Coming soon!&lt;/h3&gt; &#xA;&lt;h2&gt;üìñ Citation&lt;/h2&gt; &#xA;&lt;p&gt;If you use this code in your research, please consider citing our paper:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@inproceedings{Hao2023ViCo,&#xA;  title={ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image Generation},&#xA;  author={Shaozhe Hao and Kai Han and Shihao Zhao and Kwan-Yee K. Wong},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>ProsusAI/finBERT</title>
    <updated>2023-06-06T01:41:04Z</updated>
    <id>tag:github.com,2023-06-06:/ProsusAI/finBERT</id>
    <link href="https://github.com/ProsusAI/finBERT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Financial Sentiment Analysis with BERT&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;FinBERT: Financial Sentiment Analysis with BERT&lt;/h1&gt; &#xA;&lt;p&gt;FinBERT sentiment analysis model is now available on Hugging Face model hub. You can get the model &lt;a href=&#34;https://huggingface.co/ProsusAI/finbert&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the &lt;a href=&#34;https://arxiv.org/pdf/1810.04805.pdf&#34;&gt;BERT&lt;/a&gt; language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. For the details, please see &lt;a href=&#34;https://arxiv.org/pdf/1908.10063.pdf&#34;&gt;FinBERT: Financial Sentiment Analysis with Pre-trained Language Models&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; FinBERT implementation relies on Hugging Face&#39;s &lt;code&gt;pytorch_pretrained_bert&lt;/code&gt; library and their implementation of BERT for sequence classification tasks. &lt;code&gt;pytorch_pretrained_bert&lt;/code&gt; is an earlier version of the &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;&lt;code&gt;transformers&lt;/code&gt;&lt;/a&gt; library. It is on the top of our priority to migrate the code for FinBERT to &lt;code&gt;transformers&lt;/code&gt; in the near future.&lt;/p&gt; &#xA;&lt;h2&gt;Installing&lt;/h2&gt; &#xA;&lt;p&gt;Install the dependencies by creating the Conda environment &lt;code&gt;finbert&lt;/code&gt; from the given &lt;code&gt;environment.yml&lt;/code&gt; file and activating it.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;conda activate finbert&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Models&lt;/h2&gt; &#xA;&lt;p&gt;FinBERT sentiment analysis model is now available on Hugging Face model hub. You can get the model &lt;a href=&#34;https://huggingface.co/ProsusAI/finbert&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Or, you can download the models from the links below:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/language-model/pytorch_model.bin&#34;&gt;Language model trained on TRC2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://prosus-public.s3-eu-west-1.amazonaws.com/finbert/finbert-sentiment/pytorch_model.bin&#34;&gt;Sentiment analysis model trained on Financial PhraseBank&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For both of these model, the workflow should be like this:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a directory for the model. For example: &lt;code&gt;models/sentiment/&amp;lt;model directory name&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA; &lt;li&gt;Download the model and put it into the directory you just created.&lt;/li&gt; &#xA; &lt;li&gt;Put a copy of &lt;code&gt;config.json&lt;/code&gt; in this same directory.&lt;/li&gt; &#xA; &lt;li&gt;Call the model with &lt;code&gt;.from_pretrained(&amp;lt;model directory name&amp;gt;)&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;p&gt;There are two datasets used for FinBERT. The language model further training is done on a subset of Reuters TRC2 dataset. This dataset is not public, but researchers can apply for access &lt;a href=&#34;https://trec.nist.gov/data/reuters/reuters.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;For the sentiment analysis, we used Financial PhraseBank from &lt;a href=&#34;https://www.researchgate.net/publication/251231107_Good_Debt_or_Bad_Debt_Detecting_Semantic_Orientations_in_Economic_Texts&#34;&gt;Malo et al. (2014)&lt;/a&gt;. The dataset can be downloaded from this &lt;a href=&#34;https://www.researchgate.net/profile/Pekka_Malo/publication/251231364_FinancialPhraseBank-v10/data/0c96051eee4fb1d56e000000/FinancialPhraseBank-v10.zip?origin=publication_list&#34;&gt;link&lt;/a&gt;. If you want to train the model on the same dataset, after downloading it, you should create three files under the &lt;code&gt;data/sentiment_data&lt;/code&gt; folder as &lt;code&gt;train.csv&lt;/code&gt;, &lt;code&gt;validation.csv&lt;/code&gt;, &lt;code&gt;test.csv&lt;/code&gt;. To create these files, do the following steps:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Download the Financial PhraseBank from the above link.&lt;/li&gt; &#xA; &lt;li&gt;Get the path of &lt;code&gt;Sentences_50Agree.txt&lt;/code&gt; file in the &lt;code&gt;FinancialPhraseBank-v1.0&lt;/code&gt; zip.&lt;/li&gt; &#xA; &lt;li&gt;Run the &lt;a href=&#34;https://raw.githubusercontent.com/ProsusAI/finBERT/master/scripts/datasets.py&#34;&gt;datasets script&lt;/a&gt;: &lt;code&gt;python scripts/datasets.py --data_path &amp;lt;path to Sentences_50Agree.txt&amp;gt;&lt;/code&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Training the model&lt;/h2&gt; &#xA;&lt;p&gt;Training is done in &lt;code&gt;finbert_training.ipynb&lt;/code&gt; notebook. The trained model will be saved to &lt;code&gt;models/classifier_model/finbert-sentiment&lt;/code&gt;. You can find the training parameters in the notebook as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;config = Config(   data_dir=cl_data_path,&#xA;                   bert_model=bertmodel,&#xA;                   num_train_epochs=4.0,&#xA;                   model_dir=cl_path,&#xA;                   max_seq_length = 64,&#xA;                   train_batch_size = 32,&#xA;                   learning_rate = 2e-5,&#xA;                   output_mode=&#39;classification&#39;,&#xA;                   warm_up_proportion=0.2,&#xA;                   local_rank=-1,&#xA;                   discriminate=True,&#xA;                   gradual_unfreeze=True )&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The last two parameters &lt;code&gt;discriminate&lt;/code&gt; and &lt;code&gt;gradual_unfreeze&lt;/code&gt; determine whether to apply the corresponding technique against catastrophic forgetting.&lt;/p&gt; &#xA;&lt;h2&gt;Getting predictions&lt;/h2&gt; &#xA;&lt;p&gt;We provide a script to quickly get sentiment predictions using FinBERT. Given a .txt file, &lt;code&gt;predict.py&lt;/code&gt; produces a .csv file including the sentences in the text, corresponding softmax probabilities for three labels, actual prediction and sentiment score (which is calculated with: probability of positive - probability of negative).&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example with the provided example text: &lt;code&gt;test.txt&lt;/code&gt;. From the command line, simply run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python predict.py --text_path test.txt --output_dir output/ --model_path models/classifier_model/finbert-sentiment&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Disclaimer&lt;/h2&gt; &#xA;&lt;p&gt;This is not an official Prosus product. It is the outcome of an intern research project in Prosus AI team.&lt;/p&gt; &#xA;&lt;h3&gt;About Prosus&lt;/h3&gt; &#xA;&lt;p&gt;Prosus is a global consumer internet group and one of the largest technology investors in the world. Operating and investing globally in markets with long-term growth potential, Prosus builds leading consumer internet companies that empower people and enrich communities. For more information, please visit &lt;a href=&#34;https://raw.githubusercontent.com/ProsusAI/finBERT/master/www.prosus.com&#34;&gt;www.prosus.com&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact information&lt;/h2&gt; &#xA;&lt;p&gt;Please contact Dogu Araci &lt;code&gt;dogu.araci[at]prosus[dot]com&lt;/code&gt; and Zulkuf Genc &lt;code&gt;zulkuf.genc[at]prosus[dot]com&lt;/code&gt; about any FinBERT related issues and questions.&lt;/p&gt;</summary>
  </entry>
</feed>