<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-03-21T01:39:33Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Beomi/KoAlpaca</title>
    <updated>2023-03-21T01:39:33Z</updated>
    <id>tag:github.com,2023-03-21:/Beomi/KoAlpaca</id>
    <link href="https://github.com/Beomi/KoAlpaca" rel="alternate"></link>
    <summary type="html">&lt;p&gt;KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko)&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/KoAlpaca.png&#34; alt=&#34;KoAlpaca icon&#34; style=&#34;width: 200px; height:200px; display: block; margin: auto; border-radius: 50%;&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko)&lt;/h1&gt; &#xA;&lt;p&gt;Stanford Alpaca ëª¨ë¸ì„ í•™ìŠµí•œ ë°©ì‹ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•œ, í•œêµ­ì–´ Alpaca ëª¨ë¸ì…ë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;h2&gt;ë°”ë¡œ ì¨ë³´ê¸°: Telegram Botìœ¼ë¡œ ë§Œë‚˜ë³´ì„¸ìš”!&lt;/h2&gt; &#xA;&lt;p&gt;ì•„ë˜ QRì½”ë“œë¥¼ ì°ê±°ë‚˜, í˜¹ì€ &lt;a href=&#34;https://t.me/KoAlpacaBot&#34;&gt;https://t.me/KoAlpacaBot&lt;/a&gt;ì—ì„œ ë§Œë‚˜ë³´ì„¸ìš”!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/koalpaca_telegram.jpg&#34; alt=&#34;KoAlpaca Telegram Bot QR Code&#34; style=&#34;width: 50%; max-width: 300px; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;p&gt;í•œêµ­ì–´ ëª¨ë¸ê³¼ ì˜í•œ ëª¨ë¸ ëª¨ë‘ ë³€ê²½í•´ê°€ë©° ì²´í—˜í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/telegram_example_1.png&#34; alt=&#34;KoAlpaca Telegram Bot QR Code&#34; style=&#34;width: 45%; max-width: 300px; display: inline-block; margin: auto;&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/telegram_example_2.png&#34; alt=&#34;KoAlpaca Telegram Bot QR Code&#34; style=&#34;width: 45%; max-width: 300px; display: inline-block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;ğŸ“£ ê° ëª¨ë¸ë³„ í•œ ëŒ€ì˜ GPUë¡œ ì„œë¹™ë˜ê³  ìˆì–´ì„œ, ìƒì„±ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì†ë„ë¥¼ ìœ„í•´ ìƒì„± ìµœëŒ€ í† í°ì€ ìš”ì²­ë‹¹ 128í† í°ìœ¼ë¡œ ì œí•œë˜ì–´ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;ì™„ì„±ëœ ëª¨ë¸: í•œêµ­ì–´ ëª¨ë¸(Polyglot-ko) &amp;amp; ì˜í•œ ëª¨ë¸(LLAMA)&lt;/h2&gt; &#xA;&lt;p&gt;KoAlpacaëŠ” ë°±ë³¸ ëª¨ë¸ë¡œ ë‘ ê°€ì§€ ëª¨ë¸ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Polyglot-ko 5.8B ê¸°ë°˜ -&amp;gt; &lt;a href=&#34;https://huggingface.co/beomi/KoAlpaca-Polyglot&#34;&gt;https://huggingface.co/beomi/KoAlpaca-Polyglot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Meta LLAMA 7B ê¸°ë°˜ -&amp;gt; &lt;a href=&#34;https://huggingface.co/beomi/KoAlpaca&#34;&gt;https://huggingface.co/beomi/KoAlpaca&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Metaì˜ LLAMA ëª¨ë¸ì€ í•œêµ­ì–´ ë°ì´í„°ì…‹ì„ ì¶©ë¶„íˆ í•™ìŠµí•˜ì§€ ì•Šì•„ì„œ, ì‹¤ì œ Inferenceë¥¼ ëŒë ¤ë³´ì•˜ì„ ë•Œ í•œêµ­ì–´ ì„±ëŠ¥ì´ ë‚®ê²Œ ë‚˜ì˜¤ëŠ” ì´ìŠˆê°€ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;ë³´ë‹¤ í•œêµ­ì–´ì— ë‚˜ì€ í€„ë¦¬í‹°ë¥¼ ì–»ì–´ë³´ê³ ì Polyglot-ko 5.8B ëª¨ë¸ì„ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©í•œ ë‘ ê°€ì§€ ëª¨ë¸ì„ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;h2&gt;LLAMA ëª¨ë¸ Inference ì˜ˆì‹œ ì½”ë“œ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/Inference%20Test.ipynb&#34;&gt;Inference Test.ipynb&lt;/a&gt; íŒŒì¼ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.&lt;/p&gt; &#xA;&lt;h2&gt;ë°ì´í„°ì…‹ ì œì‘ ë°©ë²•&lt;/h2&gt; &#xA;&lt;p&gt;ë°ì´í„°ì…‹ì€ ê¸°ë³¸ì ìœ¼ë¡œ &lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/en_alpaca_data.json&#34;&gt;Stanford Alpacaì—ì„œ ì œê³µí•œ 5ë§Œ2ì²œê°œ ë°ì´í„°ì…‹&lt;/a&gt;ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ë°ì´í„°ì…‹ ë²ˆì—­&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Alpaca ë°ì´í„°ì…‹ì€ ë‹¤ìŒê³¼ ê°™ì´ Instruct ë¶€ë¶„ê³¼ Input, ê·¸ë¦¬ê³  Output ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;...&#xA;{&#xA;    &#34;instruction&#34;: &#34;Describe a time when you had to make a difficult decision.&#34;,&#xA;    &#34;input&#34;: &#34;&#34;,&#xA;    &#34;output&#34;: &#34;I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client\u2019s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team\u2019s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client\u2019s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.&#34;&#xA;},&#xA;{&#xA;    &#34;instruction&#34;: &#34;Identify the odd one out.&#34;,&#xA;    &#34;input&#34;: &#34;Twitter, Instagram, Telegram&#34;,&#xA;    &#34;output&#34;: &#34;Telegram&#34;&#xA;},&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Outputì˜ ê²½ìš° OpenAIì˜ &lt;code&gt;text-davinci-003&lt;/code&gt; ëª¨ë¸ì˜ ìƒì„± ê²°ê³¼ì´ê¸° ë•Œë¬¸ì—, í•´ë‹¹ ë¶€ë¶„ì€ ë²ˆì—­í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;ë”°ë¼ì„œ Instructì™€ Input ì»¬ëŸ¼ì„ ë²ˆì—­í•˜ê³ , í•´ë‹¹ Inputë¶€ë¶„ì— ì—ëŸ¬ê°€ ìˆëŠ” ì¼ë¶€ë¥¼ ì œì™¸í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;ë²ˆì—­ì„ í•˜ê¸° ìœ„í•´ DeepL API ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , ë²ˆì—­ëœ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœê°€ ë©ë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;...&#xA;{&#xA;    &#34;instruction&#34;: &#34;í™€ìˆ˜ ì¤‘ í•˜ë‚˜ë¥¼ ë°íˆì„¸ìš”.&#34;,&#xA;    &#34;input&#34;: &#34;íŠ¸ìœ„í„°, ì¸ìŠ¤íƒ€ê·¸ë¨, í…”ë ˆê·¸ë¨&#34;&#xA;}&#xA;...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Output ë°ì´í„° ìƒì„±&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;ì´í›„ í•´ë‹¹ Instructì™€ Inputì€ ë‹¤ìŒê³¼ ê°™ì´ Batch Decoding ê¸°ë²•ì„ í†µí•´ì„œ OpenAI ChatGPT API(&lt;code&gt;gpt-3.5-turbo&lt;/code&gt;)ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;Alpaca ì—°êµ¬ì™€ ë™ì¼í•˜ê²Œ, í•œ Instruct/Input ì…‹ì— ëŒ€í•´ì„œ ë‹¨ì¼ ì‘ë‹µë§Œì„ ìƒì„±í•´ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;ê¸°ì¡´ ì—°êµ¬ì—ì„œëŠ” 20ê°œì˜ ë°ì´í„°ì…‹ì„ í•œë²ˆì— ìƒì„±í–ˆì§€ë§Œ, í•œêµ­ì–´ë¡œ ìƒì„±ì„ ì§„í–‰í•´ë³´ì•˜ì„ ë•Œ 10ê°œë¥¼ ë™ì‹œì— ìƒì„±í•  ë•Œ ì•ˆì •ì ìœ¼ë¡œ ìƒì„±ì´ ì§„í–‰ë˜ì–´ 10ê°œì”© ìƒì„±í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;ì•„ë˜ëŠ” ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©í•œ Promptì…ë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;PROMPT = &#34;&#34;&#34;\&#xA;ë‹¤ì–‘í•œ ì‘ì—…ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ì´ëŸ¬í•œ ì‘ì—… ì§€ì¹¨ì€ ChatGPT ëª¨ë¸ì— ì£¼ì–´ì§€ë©°, ChatGPT ëª¨ë¸ì´ ì§€ì¹¨ì„ ì™„ë£Œí•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.&#xA;&#xA;ìš”êµ¬ ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:&#xA;1. ë‹¤ì–‘ì„±ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ê° ì§€ì‹œì— ëŒ€í•´ ë™ì‚¬ë¥¼ ë°˜ë³µí•˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.&#xA;2. ì§€ì‹œì— ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ë„ ë‹¤ì–‘í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì§ˆë¬¸ê³¼ ëª…ë ¹í˜• ì§€ì‹œë¥¼ ê²°í•©í•´ì•¼ í•©ë‹ˆë‹¤.&#xA;3. ì§€ì‹œ ì‚¬í•­ì˜ ìœ í˜•ì´ ë‹¤ì–‘í•´ì•¼ í•©ë‹ˆë‹¤. ëª©ë¡ì—ëŠ” ê°œë°©í˜• ìƒì„±, ë¶„ë¥˜, í¸ì§‘ ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì‘ì—…ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.&#xA;2. GPT ì–¸ì–´ ëª¨ë¸ì€ ì§€ì‹œë¥¼ ì™„ë£Œí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì‹œê°ì  ë˜ëŠ” ì˜¤ë””ì˜¤ ì¶œë ¥ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•˜ì§€ ë§ˆì„¸ìš”. ë˜ ë‹¤ë¥¸ ì˜ˆë¡œ, ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì–´ë–¤ ì‘ì—…ë„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì˜¤í›„ 5ì‹œì— ê¹¨ìš°ê±°ë‚˜ ë¯¸ë¦¬ ì•Œë¦¼ì„ ì„¤ì •í•˜ë„ë¡ ìš”ì²­í•˜ì§€ ë§ˆì„¸ìš”.&#xA;3. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.&#xA;4. ë‹µë³€ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ëª…ë ¹ë¬¸ì´ë‚˜ ì§ˆë¬¸ë„ í—ˆìš©ë©ë‹ˆë‹¤.&#xA;5. ì§€ì‹œ ì‚¬í•­ì— ëŒ€í•œ ì ì ˆí•œ ì…ë ¥ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ í•„ë“œì—ëŠ” ì§€ì‹œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì˜ˆê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ë¥¼ í¬í•¨í•´ì•¼ í•˜ë©° ë‹¨ìˆœí•œ ìë¦¬ í‘œì‹œìë¥¼ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ì…ë ¥ì€ ì§€ì‹œ ì‚¬í•­ì„ ì–´ë µê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìƒë‹¹í•œ ë‚´ìš©ì„ ì œê³µí•´ì•¼ í•˜ì§€ë§Œ 100ë‹¨ì–´ë¥¼ ë„˜ì§€ ì•ŠëŠ” ê²ƒì´ ì´ìƒì ì…ë‹ˆë‹¤.&#xA;6. ì¼ë¶€ ì§€ì‹œì‚¬í•­ì€ ì¶”ê°€ ì…ë ¥ì´ ìˆê³ , ì¼ë¶€ ì§€ì‹œì—ëŠ” ì…ë ¥ í•„ë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ &#34;ì„¸ê³„ì—ì„œ ê°€ì¥ ë†’ì€ ë´‰ìš°ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€?&#34;ë¼ëŠ” ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ë¬»ëŠ” ì§€ì‹œì˜ ê²½ìš° êµ¬ì²´ì ì¸ ë§¥ë½ì„ ì œê³µí•  í•„ìš”ê°€ ì—†ì–´, ì…ë ¥ í•„ë“œê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&#xA;7. ì¶œë ¥ì€ ëª…ë ¹ì–´ì™€ ì…ë ¥ì— ëŒ€í•œ ì ì ˆí•œ ì‘ë‹µì´ì–´ì•¼ í•©ë‹ˆë‹¤.&#xA;&#xA;ì•„ë˜ì— 10ê°œì˜ ëª…ë ¹ì–´ì™€ ì…ë ¥(ì˜µì…˜)ì— ë”°ë¼ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”. &#xA;ì‘ë‹µì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ 10ê°€ì§€ë¥¼ 0ë²ˆ ë¶€í„° 9ë²ˆ ê¹Œì§€, ë²ˆí˜¸ì— ë”°ë¼ í•´ë‹¹ ë²ˆí˜¸ì˜ ëª…ë ¹ì–´ì™€ ì…ë ¥ì— ì•Œë§ê²Œ ì‘ì„±í•˜ì„¸ìš”.&#xA;&#xA;ê° ì‘ë‹µ ì‚¬ì´ëŠ” ### ìœ¼ë¡œ ë‚´ìš©ì„ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.&#xA;&#xA;ì‘ë‹µ0: ì²« ë²ˆì§¸ ì‘ë‹µë‚´ìš©###&#xA;ì‘ë‹µ1: ë‘ ë²ˆì§¸ ì‘ë‹µë‚´ìš©###&#xA;...&#xA;ì‘ë‹µ9: ë§ˆì§€ë§‰ ì‘ë‹µë‚´ìš©&#34;&#34;&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ì¶”ê°€ì ìœ¼ë¡œ, ì•„ë˜ì™€ ê°™ì´ ChatGPT APIì˜ system promptë¥¼ ì¶”ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&#34;content&#34;: &#34;ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. ì…ë ¥ì´ ì—†ìœ¼ë©´ ì…ë ¥ì„ ì œì™¸í•˜ê³ , ëª…ë ¹ì–´ì— ë”°ë¥¸ ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”. ì¶”ê°€ì  ì…ë ¥ì´ ìˆë‹¤ë©´ ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ëª…ë ¹ì–´ì™€ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ì…ë ¥ì— ë”°ë¼ ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.&#34;,&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;í•œêµ­ì–´ë¡œ ìƒì„±ì´ ì™„ë£Œëœ ë°ì´í„°ì…‹ì€ &lt;code&gt;ko_alpaca_data.json&lt;/code&gt;ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;h2&gt;ëª¨ë¸ í•™ìŠµ ë°©ë²•&lt;/h2&gt; &#xA;&lt;h3&gt;LLAMA 7B ëª¨ë¸ í•™ìŠµ&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/ko_alpaca_llama_train_02.jpeg&#34; alt=&#34;KoAlpaca LLAMA Train Loss Graph&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;ëª¨ë¸ í•™ìŠµì€ A100 80GB 4ëŒ€ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. í•™ìŠµì— ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ëŠ” &lt;code&gt;train.py&lt;/code&gt;ì— ì €ì¥ë˜ì–´ ìˆê³ , í•™ìŠµì— ì‚¬ìš©í•œ ìŠ¤í¬ë¦½íŠ¸ëŠ” &lt;code&gt;train.sh&lt;/code&gt;ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;h4&gt;ëª¨ë¸ í•™ìŠµì‹œ ìœ ì˜ì‚¬í•­&lt;/h4&gt; &#xA;&lt;p&gt;ì•„ë˜ì—ë„ ì í˜€ìˆì§€ë§Œ, í˜„ì¬(2023.03.18ê¸°ì¤€) LLAMA ëª¨ë¸ì€ Huggingface &lt;code&gt;main&lt;/code&gt; ë¸Œëœì¹˜ì—ë§Œ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, Layer ëª…ì¹­ì´ ì§€ì†ì ìœ¼ë¡œ ë°”ë€Œê³  ìˆì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ëŠ” &lt;code&gt;LlamaDecoderLayer&lt;/code&gt;ë¡œ ë˜ì–´ìˆìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# train.sh&#xA;--fsdp_transformer_layer_cls_to_wrap &#39;LlamaDecoderLayer&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Polyglot-ko 5.8B ëª¨ë¸ í•™ìŠµ&lt;/h3&gt; &#xA;&lt;p&gt;ëª¨ë¸ í•™ìŠµì€ A100 80GB 1ëŒ€ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt; &#xA;&lt;p&gt;*ë‚´ìš©ë³´ì¶© ì˜ˆì •&lt;/p&gt; &#xA;&lt;h2&gt;NSMC Benchmark Test&lt;/h2&gt; &#xA;&lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/Beomi/KoAlpaca/blob/master/nsmc_polyglot_and_koalpaca_by_few_shot.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt; &#xA;&lt;h3&gt;Benchmark Test ë°©ì‹&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;polyglot-ko 5.8b&lt;/code&gt;ì™€ &lt;code&gt;KoAlpaca-polyglot&lt;/code&gt;ê³¼ Benchmark ì„±ëŠ¥ ë¹„êµ&lt;/li&gt; &#xA; &lt;li&gt;Few-shot Learningìœ¼ë¡œ 2 ê°€ì§€ í”„ë¡¬í”„íŠ¸ ìœ í˜•ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì§„í–‰&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;1. Few-shot Learning êµ¬ì„±&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;few-shot êµ¬ì„±&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;code&gt;k=10&lt;/code&gt; ì„¤ì •&lt;/li&gt; &#xA;   &lt;li&gt;í…ìŠ¤íŠ¸ í† í° ê¸¸ì´ê°€ 25 ì´í•˜ì¸ ë¬¸ì¥ë§Œ êµ¬ì„±&lt;/li&gt; &#xA;   &lt;li&gt;ë°ì´í„° í† í° ê¸¸ì´ì˜ ì•½ 75 í¼ì„¼íƒ€ì¼ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í¬í•¨&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;NSMC ë°ì´í„° í† í° ê¸¸ì´ ë¶„í¬&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;Few shot ì¼€ì´ìŠ¤ í† í° í‰ê·  ê¸¸ì´:  20.229&#xA;Few shot ì¼€ì´ìŠ¤ í† í° ìµœëŒ€ ê¸¸ì´:  280&#xA;Few shot ì¼€ì´ìŠ¤ í† í° ê¸¸ì´ í‘œì¤€í¸ì°¨:  16.488&#xA;Few shot ì¼€ì´ìŠ¤ í† í° ê¸¸ì´ 80 í¼ì„¼íƒ€ì¼:  27.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;í”„ë¡¬í”„íŠ¸ ìœ í˜• 1: ë§¤ìš° ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±. ë¶„ì„ Taskì— ëŒ€í•œ ë‚´ìš©ì„ ëª…ì‹œì ìœ¼ë¡œ í•˜ì§€ ì•ŠìŒ&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def build_prompt_text(sent):&#xA;    return &#34;ë¬¸ì¥: &#34; + sent + &#39;\nê°ì •:&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;í”„ë¡¬í”„íŠ¸ ìœ í˜• 2: í”„ë¡¬í”„íŠ¸ ìœ í˜• 1ì— ë¹„í•´ Task ì˜ë„ ë‚´ìš©ì„ í¬í•¨. ë¶„ì„ Taskì— ëŒ€í•œ ë‚´ìš©ì„ ì˜ë¬¸í˜•ìœ¼ë¡œ í‘œí˜„&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def build_prompt_text(sent):&#xA;    return &#39;ë‹¤ìŒ ë¬¸ì¥ì€ ê¸ì •ì¼ê¹Œìš” ë¶€ì •ì¼ê¹Œìš”?\n&#39; + sent + &#39;\nì •ë‹µ:&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;3. Benchmark Test ê²°ê³¼&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;acc.&lt;/th&gt; &#xA;   &lt;th&gt;í”„ë¡¬í”„íŠ¸ ìœ í˜• 1&lt;/th&gt; &#xA;   &lt;th&gt;í”„ë¡¬í”„íŠ¸ ìœ í˜• 2&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;polyglot-ko&lt;/td&gt; &#xA;   &lt;td&gt;0.5752&lt;/td&gt; &#xA;   &lt;td&gt;0.7223&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;koalpaca-polyglot&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.6939&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;0.7683&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Stanford Alpaca: An Instruction-following LLaMA Model&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/release/python-390/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.9+-blue.svg?sanitize=true&#34; alt=&#34;Python 3.9+&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This is the repo for the Stanford Alpaca project, which aims to build and share an instruction-following LLaMA model. The repo contains:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://crfm.stanford.edu/alpaca/&#34;&gt;&lt;strong&gt;web demo&lt;/strong&gt;&lt;/a&gt; to interact with our Alpaca model&lt;/li&gt; &#xA; &lt;li&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/#data-release&#34;&gt;52K data&lt;/a&gt; used for fine-tuning the model&lt;/li&gt; &#xA; &lt;li&gt;The code for &lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/#data-generation-process&#34;&gt;generating the data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The code for &lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/#fine-tuning&#34;&gt;fine-tuning the model&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The current Alpaca model is fine-tuned from a 7B LLaMA model [1] on 52K instruction-following data generated by the techniques in the Self-Instruct [2] paper, with some modifications that we discuss in the next section. In a preliminary human evaluation, we found that the Alpaca 7B model behaves similarly to the &lt;code&gt;text-davinci-003&lt;/code&gt; model on the Self-Instruct instruction-following evaluation suite [2].&lt;/p&gt; &#xA;&lt;p&gt;Alpaca is still under development, and there are many limitations that have to be addressed. Importantly, we have not yet fine-tuned the Alpaca model to be safe and harmless. We thus encourage users to be cautious when interacting with Alpaca, and to report any concerning behavior to help improve the safety and ethical considerations of the model.&lt;/p&gt; &#xA;&lt;p&gt;Our initial release contains the data generation procedure, dataset, and training recipe. We intend to release the model weights if we are given permission to do so by the creators of LLaMA. For now, we have chosen to host a live demo to help readers better understand the capabilities and limits of Alpaca, as well as a way to help us better evaluate Alpaca&#39;s performance on a broader audience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please read our release &lt;a href=&#34;https://crfm.stanford.edu/2023/03/13/alpaca.html&#34;&gt;blog post&lt;/a&gt; for more details about the model, our discussion of the potential harm and limitations of Alpaca models, and our thought process for releasing a reproducible model.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;[1]: LLaMA: Open and Efficient Foundation Language Models. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample. &lt;a href=&#34;https://arxiv.org/abs/2302.13971v1&#34;&gt;https://arxiv.org/abs/2302.13971v1&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;[2]: Self-Instruct: Aligning Language Model with Self Generated Instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi. &lt;a href=&#34;https://arxiv.org/abs/2212.10560&#34;&gt;https://arxiv.org/abs/2212.10560&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Data Release&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/alpaca_data.json&#34;&gt;&lt;code&gt;alpaca_data.json&lt;/code&gt;&lt;/a&gt; contains 52K instruction-following data we used for fine-tuning the Alpaca model. This JSON file is a list of dictionaries, each dictionary contains the following fields:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;instruction&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, describes the task the model should perform. Each of the 52K instructions is unique.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;input&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, optional context or input for the task. For example, when the instruction is &#34;Summarize the following article&#34;, the input is the article. Around 40% of the examples have an input.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;output&lt;/code&gt;: &lt;code&gt;str&lt;/code&gt;, the answer to the instruction as generated by &lt;code&gt;text-davinci-003&lt;/code&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We used the following prompts for fine-tuning the Alpaca model:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;for examples with a non-empty input field:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.&#xA;&#xA;### Instruction:&#xA;{instruction}&#xA;&#xA;### Input:&#xA;{input}&#xA;&#xA;### Response:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;for examples with an empty input field:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;Below is an instruction that describes a task. Write a response that appropriately completes the request.&#xA;&#xA;### Instruction:&#xA;{instruction}&#xA;&#xA;### Response:&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;During inference (eg for the web demo), we use the user instruction with an empty input field (second option).&lt;/p&gt; &#xA;&lt;h2&gt;Data Generation Process&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt; &lt;strong&gt; Running the code &lt;/strong&gt; &lt;/summary&gt; &#xA; &lt;ol&gt; &#xA;  &lt;li&gt;Set environment variables &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; to your OpenAI API key.&lt;/li&gt; &#xA;  &lt;li&gt;Install the dependencies with &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;.&lt;/li&gt; &#xA;  &lt;li&gt;Run &lt;code&gt;python -m generate_instruction generate_instruction_following_data&lt;/code&gt; to generate the data.&lt;/li&gt; &#xA; &lt;/ol&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;We built on the data generation pipeline from &lt;a href=&#34;https://github.com/yizhongw/self-instruct&#34;&gt;self-instruct&lt;/a&gt; and made the following modifications:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;We used &lt;code&gt;text-davinci-003&lt;/code&gt; to generate the instruction data instead of &lt;code&gt;davinci&lt;/code&gt;.&lt;/li&gt; &#xA; &lt;li&gt;We wrote a new prompt (&lt;code&gt;prompt.txt&lt;/code&gt;) that explicitly gave the requirement of instruction generation to &lt;code&gt;text-davinci-003&lt;/code&gt;. Note: there is a slight error in the prompt we used, and future users should incorporate the edit in &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/pull/24&#34;&gt;https://github.com/tatsu-lab/stanford_alpaca/pull/24&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;We adopted much more aggressive batch decoding, i.e., generating 20 instructions at once, which significantly reduced the cost of data generation.&lt;/li&gt; &#xA; &lt;li&gt;We simplified the data generation pipeline by discarding the difference between classification and non-classification instructions.&lt;/li&gt; &#xA; &lt;li&gt;We only generated a single instance for each instruction, instead of 2 to 3 instances as in [1].&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This produced an instruction-following dataset with 52K examples obtained at a much lower cost (less than $500). In a preliminary study, we also find our 52K generated data to be much more diverse than the data released by &lt;a href=&#34;https://github.com/yizhongw/self-instruct/raw/main/data/seed_tasks.jsonl&#34;&gt;self-instruct&lt;/a&gt;. We plot the below figure (in the style of Figure 2 in the &lt;a href=&#34;https://arxiv.org/abs/2212.10560&#34;&gt;self-instruct paper&lt;/a&gt; to demonstrate the diversity of our data. The inner circle of the plot represents the root verb of the instructions, and the outer circle represents the direct objects.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/parse_analysis.png&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Beomi/KoAlpaca/main/assets/parse_analysis.png&#34; width=&#34;750&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Fine-tuning&lt;/h2&gt; &#xA;&lt;p&gt;We fine-tune our models using standard Hugging Face training code with the following hyperparameters:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Hyperparameter&lt;/th&gt; &#xA;   &lt;th&gt;Value&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Batch size&lt;/td&gt; &#xA;   &lt;td&gt;128&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Learning rate&lt;/td&gt; &#xA;   &lt;td&gt;2e-5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Epochs&lt;/td&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Max length&lt;/td&gt; &#xA;   &lt;td&gt;512&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Weight decay&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Given Hugging Face hasn&#39;t officially supported the LLaMA models, we fine-tuned LLaMA with Hugging Face&#39;s transformers library by installing it from a particular fork (i.e. this &lt;a href=&#34;https://github.com/huggingface/transformers/pull/21955&#34;&gt;PR&lt;/a&gt; to be merged). The hash of the specific commit we installed was &lt;code&gt;68d640f7c368bcaaaecfc678f11908ebbd3d6176&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To reproduce our fine-tuning runs for LLaMA, first install the requirements&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then, install the particular fork of Hugging Face&#39;s transformers library.&lt;/p&gt; &#xA;&lt;p&gt;Below is a command that fine-tunes LLaMA-7B with our dataset on a machine with 4 A100 80G GPUs in FSDP &lt;code&gt;full_shard&lt;/code&gt; mode. We were able to reproduce a model of similar quality as the one we hosted in our demo with the following command using &lt;strong&gt;Python 3.10&lt;/strong&gt;. Replace &lt;code&gt;&amp;lt;your_random_port&amp;gt;&lt;/code&gt; with a port of your own, &lt;code&gt;&amp;lt;your_path_to_hf_converted_llama_ckpt_and_tokenizer&amp;gt;&lt;/code&gt; with the path to your converted checkpoint and tokenizer (following instructions in the PR), and &lt;code&gt;&amp;lt;your_output_dir&amp;gt;&lt;/code&gt; with where you want to store your outputs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nproc_per_node=4 --master_port=&amp;lt;your_random_port&amp;gt; train.py \&#xA;    --model_name_or_path &amp;lt;your_path_to_hf_converted_llama_ckpt_and_tokenizer&amp;gt; \&#xA;    --data_path ./alpaca_data.json \&#xA;    --bf16 True \&#xA;    --output_dir &amp;lt;your_output_dir&amp;gt; \&#xA;    --num_train_epochs 3 \&#xA;    --per_device_train_batch_size 4 \&#xA;    --per_device_eval_batch_size 4 \&#xA;    --gradient_accumulation_steps 8 \&#xA;    --evaluation_strategy &#34;no&#34; \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 2000 \&#xA;    --save_total_limit 1 \&#xA;    --learning_rate 2e-5 \&#xA;    --weight_decay 0. \&#xA;    --warmup_ratio 0.03 \&#xA;    --lr_scheduler_type &#34;cosine&#34; \&#xA;    --logging_steps 1 \&#xA;    --fsdp &#34;full_shard auto_wrap&#34; \&#xA;    --fsdp_transformer_layer_cls_to_wrap &#39;LLaMADecoderLayer&#39; \&#xA;    --tf32 True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Warning&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;fsdp_transformer_layer_cls_to_wrap&lt;/code&gt; must be set to the name of the specific decoder layer. The LLaMA Hugging Face PR is not stable. Earlier commits used the name &lt;code&gt;LLaMADecoderLayer&lt;/code&gt; for their decoder layer (the commit hash our code is based on this). More recent commits use &lt;code&gt;LlamaDecoderLayer&lt;/code&gt; (notice the small case difference). Not setting &lt;code&gt;fsdp_transformer_layer_cls_to_wrap&lt;/code&gt; to the correct name will lead to drastic slowdowns in training.&lt;/p&gt; &#xA;&lt;h3&gt;Side notes&lt;/h3&gt; &#xA;&lt;p&gt;The same script also works for OPT fine-tuning. Here&#39;s an example for fine-tuning OPT-6.7B&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;torchrun --nproc_per_node=4 --master_port=&amp;lt;your_random_port&amp;gt; train.py \&#xA;    --model_name_or_path &#34;facebook/opt-6.7b&#34; \&#xA;    --data_path ./alpaca_data.json \&#xA;    --bf16 True \&#xA;    --output_dir &amp;lt;your_output_dir&amp;gt; \&#xA;    --num_train_epochs 3 \&#xA;    --per_device_train_batch_size 4 \&#xA;    --per_device_eval_batch_size 4 \&#xA;    --gradient_accumulation_steps 8 \&#xA;    --evaluation_strategy &#34;no&#34; \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 2000 \&#xA;    --save_total_limit 1 \&#xA;    --learning_rate 2e-5 \&#xA;    --weight_decay 0. \&#xA;    --warmup_ratio 0.03 \&#xA;    --lr_scheduler_type &#34;cosine&#34; \&#xA;    --logging_steps 1 \&#xA;    --fsdp &#34;full_shard auto_wrap&#34; \&#xA;    --fsdp_transformer_layer_cls_to_wrap &#39;OPTDecoderLayer&#39; \&#xA;    --tf32 True&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note the given training script is meant to be simple and easy to use, and is not particularly optimized. To run on more gpus, you may prefer to turn down &lt;code&gt;gradient_accumulation_steps&lt;/code&gt; to keep a global batch size of 128. Global batch size has not been tested for optimality.&lt;/p&gt; &#xA;&lt;h3&gt;Authors&lt;/h3&gt; &#xA;&lt;p&gt;All grad students below contributed equally and the order is determined by random draw.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.rohantaori.com/&#34;&gt;Rohan Taori&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ishaan.io/&#34;&gt;Ishaan Gulrajani&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tiiiger.github.io/&#34;&gt;Tianyi Zhang&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yanndubs.github.io/&#34;&gt;Yann Dubois&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lxuechen.com/&#34;&gt;Xuechen Li&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;All advised by &lt;a href=&#34;https://thashim.github.io/&#34;&gt;Tatsunori B. Hashimoto&lt;/a&gt;. Yann is also advised by &lt;a href=&#34;https://cs.stanford.edu/~pliang/&#34;&gt;Percy Liang&lt;/a&gt; and Xuechen is also advised by &lt;a href=&#34;https://guestrin.su.domains/&#34;&gt;Carlos Guestrin&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;Please cite the repo if you use the data or code in this repo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@misc{alpaca,&#xA;  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },&#xA;  title = {Stanford Alpaca: An Instruction-following LLaMA model},&#xA;  year = {2023},&#xA;  publisher = {GitHub},&#xA;  journal = {GitHub repository},&#xA;  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Naturally, you should also cite the original LLaMA paper [1] and the Self-Instruct paper [2].&lt;/p&gt; &#xA;&lt;h3&gt;Acknowledgements&lt;/h3&gt; &#xA;&lt;p&gt;We thank Yizhong Wang for his help in explaining the data generation pipeline in Self-Instruct and providing the code for the parse analysis plot. We thank Yifan Mai for helpful support, and members of the Stanford NLP Group as well as the Center for Research on Foundation Models (CRFM) for their helpful feedback.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>22-hours/cabrita</title>
    <updated>2023-03-21T01:39:33Z</updated>
    <id>tag:github.com,2023-03-21:/22-hours/cabrita</id>
    <link href="https://github.com/22-hours/cabrita" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Finetuning InstructLLaMA with portuguese data&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/22-hours/cabrita/main/assets/cabrita.png&#34; alt=&#34;Cabrita&#34; style=&#34;width: 20%; min-width: 300px; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Cabrita: A portuguese finetuned instruction LLaMA&lt;/h1&gt; &#xA;&lt;p&gt;This repository is intended to share all the steps and resources that we used to finetune our version of LLaMA.&lt;/p&gt; &#xA;&lt;p&gt;This model is designed for research use only, i.e., cannot be used for commercial purposes or entertainment.&lt;/p&gt; &#xA;&lt;h2&gt;References&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;If I have seen further it is by standing on the sholders [sic] of Giants. -- &lt;cite&gt;Isaac Newton&lt;/cite&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;We started this section with this citation because everything we did was only possible due to the strong community and works that other people and groups did. For our work, we rely mainly in the works developed by: &lt;a href=&#34;https://ai.facebook.com/blog/large-language-model-llama-meta-ai/&#34;&gt;LLaMA&lt;/a&gt;, &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;, &lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;Alpaca Lora&lt;/a&gt;, &lt;a href=&#34;https://openai.com/blog/chatgpt&#34;&gt;ChatGPT&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/&#34;&gt;Hugging Face&lt;/a&gt;. So, thank you all for the great work and open this to the world!&lt;/p&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;We translated the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/alpaca_data.json&#34;&gt;alpaca_data.json&lt;/a&gt; to portuguese using ChatGPT. Even this translation was not the best, the tradeoff between costs and results were. We paid around US$ 8.00 to translate the full dataset to portuguese. If you want to know more about how the dataset was built go to: &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Finetuning&lt;/h2&gt; &#xA;&lt;p&gt;To finetuned the LLaMA model we used the code available on &lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;Alpaca Lora&lt;/a&gt;, which provides code to finetune the LLaMA model using PEFT from Hugging Face. With this, we could run our finetuning step using 1 A100 at Colab on top of LLaMA-7B. We trained during 1 hour and we found the results pretty incredible with just that much time. The notebook we used is avaible &lt;a href=&#34;https://raw.githubusercontent.com/22-hours/cabrita/main/notebooks/train_lora.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Example outputs&lt;/h2&gt; &#xA;&lt;p&gt;Stanford Alpaca:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Instruction: Invente uma desculpa criativa pra dizer que nÃ£o preciso ir Ã  festa.&#xA;Response: Eu preciso se concentrar em trabalho importante para mim, por isso eu nÃ£o posso ir Ã  festa.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Cabrita:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;InstruÃ§Ã£o: Invente uma desculpa criativa pra dizer que nÃ£o preciso ir Ã  festa.&#xA;Resposta: &#34;Eu preciso ficar em casa para cuidar dos meus animais de estimaÃ§Ã£o.&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Stanford Alpaca:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Instruction: Como posso comeÃ§ar a carreira como cientista de dados? Escreva na forma de lista.&#xA;Response:&#xA;1. Comece por se especializar em um campo especÃ­fico, como big data, computaÃ§Ã£o, bioinformÃ¡tica ou estatÃ­stica.&#xA;2. Obtivere um diploma em um programa de graduaÃ§Ã£o relacionado a ciÃªncia de dados, como informÃ¡tica, matemÃ¡tica ou estatÃ­stica.&#xA;3. Aquisite experiÃªncia prÃ¡tica atravÃ©s de internships ou projetos em empresas ou instituiÃ§Ãµes.&#xA;4. Ameize sua resumo e currÃ­culo com resultados relevantes e experiÃªncia em trabalho relacionado.&#xA;5. Leia artigos, livros e atualizaÃ§Ãµes sobre ciÃªncia de dados.&#xA;6. Crie um portfÃ³lio com projetos e experimentos que tenha realizado.&#xA;7. Receba um certificado de qualificaÃ§Ã£o em alguma Ã¡rea de ciÃªncia de dados.&#xA;8. Tente obter contato com profissionais da Ã¡rea para conversar sobre oportunidades de emprego.&#xA;9. Acesse redes sociais, como LinkedIn, para encontrar empregos e conexÃµes.&#xA;10. Continui sua formaÃ§Ã£o atualizando-se com tecnologias e ferramentas de ciÃªncia de dados.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Cabrita:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;InstruÃ§Ã£o: Como posso comeÃ§ar a carreira como cientista de dados? Escreva na forma de lista.&#xA;Resposta: &#xA;1. Obtenha um mestrado em ciÃªncia de dados ou engenharia de dados.&#xA;2. Encontre um emprego como cientista de dados ou engenheiro de dados.&#xA;3. ConheÃ§a as principais ferramentas de anÃ¡lise de dados, como Python, R e SQL.&#xA;4. ConheÃ§a as principais tÃ©cnicas de anÃ¡lise de dados, como regressÃ£o linear, regressÃ£o logÃ­stica e anÃ¡lise de clustering.&#xA;5. ConheÃ§a as principais abordagens de anÃ¡lise de dados, como anÃ¡lise exploratÃ³ria, anÃ¡lise de associaÃ§Ã£o e anÃ¡lise de regressÃ£o.&#xA;6. ConheÃ§a as principais ferramentas de visualizaÃ§Ã£o de dados, como Tableau, QlikView e Power BI.&#xA;7. ConheÃ§a as principais abordagens de anÃ¡lise de dados, como anÃ¡lise de associaÃ§Ã£o, anÃ¡lise de regressÃ£o e anÃ¡lise exploratÃ³ria.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can test it using the eval notebook &lt;a href=&#34;https://raw.githubusercontent.com/22-hours/cabrita/main/notebooks/cabrita-lora.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Next steps&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Create a better portuguese dataset&lt;/li&gt; &#xA; &lt;li&gt;Evaluate the toxicity&lt;/li&gt; &#xA; &lt;li&gt;Finetune large models&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/piEsposito&#34;&gt;piEsposito&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pedrogengo&#34;&gt;pedrogengo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>lewangdev/gost-install.ipynb</title>
    <updated>2023-03-21T01:39:33Z</updated>
    <id>tag:github.com,2023-03-21:/lewangdev/gost-install.ipynb</id>
    <link href="https://github.com/lewangdev/gost-install.ipynb" rel="alternate"></link>
    <summary type="html">&lt;p&gt;é€šè¿‡ Jupyter Notebook å®‰è£… GOST&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;é€šè¿‡ Jupyter Notebook å®‰è£… GOST&lt;/h1&gt; &#xA;&lt;h2&gt;å®‰è£… Python ç¯å¢ƒ&lt;/h2&gt; &#xA;&lt;p&gt;å¦‚æœä¸ä¼šå®‰è£…ï¼Œè¯·é—® ChatGPT&lt;/p&gt; &#xA;&lt;h2&gt;å®‰è£… jupyterlab&lt;/h2&gt; &#xA;&lt;h3&gt;Windows ä¸Š&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m venv .venv&#xA;.\.venv\Scripts\activate&#xA;pip install jupyterlab&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;MacOS æˆ–è€… Linux ä¸Š&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python -m venv .venv&#xA;. .venv/bin/activate&#xA;pip install jupyterlab&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;è¿è¡Œ jupyterlab&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;jupyter-lab&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;æ“ä½œ&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;æµè§ˆå™¨æ‰“å¼€ &lt;a href=&#34;http://localhost:8888/lab/tree/gost_install.ipynb&#34;&gt;http://localhost:8888/lab/tree/gost_install.ipynb&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;æ ¹æ®æç¤ºä¸€æ­¥ä¸€æ­¥æ‰§è¡Œå³å¯&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>