<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-08-27T01:39:10Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Mikoto10032/DeepLearning</title>
    <updated>2022-08-27T01:39:10Z</updated>
    <id>tag:github.com,2022-08-27:/Mikoto10032/DeepLearning</id>
    <link href="https://github.com/Mikoto10032/DeepLearning" rel="alternate"></link>
    <summary type="html">&lt;p&gt;深度学习入门教程, 优秀文章, Deep Learning Tutorial&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepLearning Tutorial&lt;/h1&gt; &#xA;&lt;h2&gt;一. 入门资料&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64052743&#34;&gt;&lt;strong&gt;完备的 AI 学习路线，最详细的中英文资源整理&lt;/strong&gt;&lt;/a&gt; &lt;span&gt;⭐&lt;/span&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/apachecn/AiLearning&#34;&gt;AiLearning: 机器学习 - MachineLearning - ML、深度学习 - DeepLearning - DL、自然语言处理 NL&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/shunliz/Machine-Learning&#34;&gt;Machine-Learning&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;数学基础&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Mikoto10032/DeepLearning/master/notes/Images/MathematicalBasis.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%98%B5%E5%BE%AE%E7%A7%AF%E5%88%86&#34;&gt;矩阵微积分&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/0.basic&#34;&gt;机器学习的数学基础&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/fengdu78/Data-Science-Notes/tree/master/0.math/1.CS229&#34;&gt;CS229线性代数与概率论基础&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;机器学习基础&lt;/h3&gt; &#xA;&lt;h4&gt;快速入门&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.tensorinfinity.com/paper_18.html&#34;&gt;机器学习算法地图&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%5BML-Coursera%5D%5B2014%5D%5BAndrew%20Ng%5D/%5B2014%5D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0%E5%AE%8C%E6%95%B4%E7%89%88v5.1.pdf&#34;&gt;机器学习 吴恩达 Coursera个人笔记&lt;/a&gt; &amp;nbsp;&amp;amp;&amp;amp; &lt;a href=&#34;https://www.coursera.org/learn/machine-learning&#34;&gt;视频（含官方笔记）&lt;/a&gt; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kivy-cn.github.io/Stanford-CS-229-CN/#/&#34;&gt;CS229 课程讲义中文翻译&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%5BML-CS229%5D%5B2011%5D%5BAndrew%20NG%5D/%5B2011%5D%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E4%B8%AA%E4%BA%BA%E7%AC%94.pdf&#34;&gt;机器学习 吴恩达 cs229个人笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;http://cs229.stanford.edu/&#34;&gt;官网（笔记）&lt;/a&gt; &amp;nbsp;&amp;amp;&amp;amp; &lt;a href=&#34;http://open.163.com/newview/movie/free?pid=M6SGF6VB4&amp;amp;mid=M6SGHFBMC&#34;&gt;视频（中文字幕）&lt;/a&gt; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://themlbook.com/wiki/doku.php&#34;&gt;百页机器学习&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;深入理解&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/tree/master/books/%E6%9D%8E%E8%88%AA-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0&#34;&gt;《统计学习方法》李航&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/YongSun/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/&#34;&gt;《统计学习方法》各章节笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/c_1213397558586257408&#34;&gt;《统计学习方法》各章节笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/datawhalechina/statistical-learning-method-solutions-manual&#34;&gt;推荐答案：statistical-learning-method-solutions-manual&lt;/a&gt; &lt;a href=&#34;https://www.cnblogs.com/liaohuiqiang/category/1039314.html&#34;&gt;《统计学习方法》各章节笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/breeze_blows/article/details/85469944&#34;&gt;《统计学习方法》各章节代码实现与课后习题参考解答&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0PRML_Chinese_vision.pdf&#34;&gt;《模式识别与机器学习》 Christopher Bishop&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf&#34;&gt;《机器学习》 周志华&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/datawhalechina/pumpkin-book&#34;&gt;南瓜书：pumpkin-book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%20%E4%B8%AD%E6%96%87%E5%8F%8C%E9%A1%B5%E7%89%88.pdf&#34;&gt;《机器学习实战》 PelerHarrington&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488718&amp;amp;idx=1&amp;amp;sn=815a79d27d500f0fb8db1fe1fc6cfe48&amp;amp;chksm=83a2e54eb4d56c58a0989654f920d64ad2784ce52e4b2bc6883974257cf475c9983f05fb88c1&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000339&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=AwABAAoACwATAAQAI5ceAFaZHgDQmR4A3JkeAAAA&amp;amp;lang=zh_CN&amp;amp;pass_ticket=oEB1108Pes6HkdxEITmBjTb2Glju5%2BEGqHZKz50fMg0rgK4l9Fodlbe%2FDm96iX57&amp;amp;wx_header=1&#34;&gt;机器学习与深度学习书单&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;深度学习基础&lt;/h3&gt; &#xA;&lt;h4&gt;快速入门&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/dformoso/deeplearning-mindmap&#34;&gt;深度学习思维导图&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;http://www.tensorinfinity.com/paper_158.html&#34;&gt;深度学习算法地图&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B.pdf&#34;&gt;《斯坦福大学深度学习基础教程》 Andrew Ng（吴恩达）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.ai-start.com/dl2017/&#34;&gt;深度学习 吴恩达 个人笔记&lt;/a&gt; &amp;nbsp;&amp;amp;&amp;amp; &lt;a href=&#34;http://mooc.study.163.com/smartSpec/detail/1001319001.htm&#34;&gt;视频&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://deeplearning.mit.edu/&#34;&gt;MIT深度学习基础-2019视频课程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://speech.ee.ntu.edu.tw/~tlkagk/index.html&#34;&gt;台湾大学（NTU）李宏毅教授课程&lt;/a&gt; &amp;amp;&amp;amp; [&lt;a href=&#34;https://github.com/datawhalechina/leeml-notes&#34;&gt;leeml-notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/iamtrask/Grokking-Deep-Learning&#34;&gt;图解深度学习_Grokking-Deep-Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0neural%20networks%20and%20deep-learning-%E4%B8%AD%E6%96%87_ALL.pdf&#34;&gt;《神经网络与深度学习》 Michael Nielsen&lt;/a&gt; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cs.toronto.edu/~tijmen/csc321/&#34;&gt; CS321-Hinton&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs230/&#34;&gt; CS230: Deep Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://rail.eecs.berkeley.edu/deeprlcourse/resources/&#34;&gt; CS294-112&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;计算机视觉&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/21930884&#34;&gt;CS231 李飞飞 已授权个人翻译笔记&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;http://study.163.com/course/courseMain.htm?courseId=1003223001&#34;&gt;视频&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/WNkzfvYtEO5zJoe_-yAPow&#34;&gt;计算机视觉研究方向&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;自然语言处理&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs224n/index.html&#34;&gt;CS224n: Natural Language Processing with Deep Learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/FudanNLP/nlp-beginner&#34;&gt;NLP上手教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58874484&#34;&gt;NLP入门推荐书目（2019版）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;深度强化学习&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs234/index.html&#34;&gt;CS234: Reinforcement Learning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;深入理解&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.Yoshua%20Bengio%2BIan%20GoodFellow.pdf&#34;&gt;《深度学习》 Yoshua Bengio.Ian GoodFellow&lt;/a&gt;&lt;span&gt;⭐&lt;/span&gt; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.Jacob%20Eisenstein.pdf&#34;&gt;《自然语言处理》Jacob Eisenstein&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/Reinforcement%20Learning.Sutton.pdf&#34;&gt;《强化学习》&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;http://incompleteideas.net/book/RLbook2018trimmed.pdf&#34;&gt;第二版&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://handong1587.github.io/categories.html#deep_learning-ref&#34;&gt;hangdong的深度学习博客,论文推荐&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://course.fast.ai/&#34;&gt;Practical Deep Learning for Coders, v3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/Tensorflow%20%E5%AE%9E%E6%88%98Google%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.pdf&#34;&gt;《Tensorflow实战Google深度学习框架》 郑泽宇 顾思宇&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;一些书单&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/63784033&#34;&gt;2019年最新-深度学习、生成对抗、Pytorch优秀教材推荐&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;工程能力&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://pic4.zhimg.com/v2-009013278688f520c070b27910255cb1_r.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/20588261/answer/798928056&#34;&gt;如何系统地学习算法？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://leetcode.com/&#34;&gt;LeetCode&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/azl397985856/leetcode&#34;&gt;leetcode题解&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/huaxz1986/cplusplus-_Implementation_Of_Introduction_to_Algorithms&#34;&gt;《算法导论》中算法的C++实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mikoto10032/DeepLearning/master/#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E7%AF%87&#34;&gt;机器学习算法实战&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mikoto10032/DeepLearning/master/#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6&#34;&gt;深度学习框架&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/YMtnBAVDZepsMTO4h-VRtQ&#34;&gt;如何成为一名算法工程师&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMjcyNjE5MQ==&amp;amp;mid=2650488786&amp;amp;idx=1&amp;amp;sn=68b9536d0b0b3105ab8d79f8efcb0a4b&amp;amp;chksm=83a2e512b4d56c045c6ab0349108842e6a5b26e8f3e507ff5d19ee50e3bd63ef149a36d23eef&amp;amp;scene=0&amp;amp;xtrack=1&amp;amp;ascene=14&amp;amp;devicetype=android-28&amp;amp;version=27000437&amp;amp;nettype=WIFI&amp;amp;abtest_cookie=BAABAAoACwASABMABgAjlx4AVpkeANCZHgDcmR4A8ZkeAAOaHgAAAA%3D%3D&amp;amp;lang=zh_CN&amp;amp;pass_ticket=4yovfEr0v09yZCvvQ1NEy12qGIonnRpGi774X09Mh5EZD2oL%2BRz6FTtX9R5gALB1&amp;amp;wx_header=1&#34;&gt;从小白到入门算法，我的经验分享给你～&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/54161673&#34;&gt;我的研究生这三年&lt;/a&gt; &lt;span&gt;⭐&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/89392459&#34;&gt;编程面试的题目分类&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.huaxiaozhuan.com/&#34;&gt;《AI算法工程师手册》&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/76827460&#34;&gt;如何准备算法工程师面试，斩获一线互联网公司机器学习岗offer？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/HZ3Cd2jHuikyFN9ydvcMTw&#34;&gt;【完结】深度学习CV算法工程师从入门到初级面试有多远，大概是25篇文章的距离&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/CyC2018/CS-Notes&#34;&gt; 计算机相关技术面试必备&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://veal98.gitee.io/cs-wiki/#/&#34;&gt;CS-WiKi&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/wolverinn/Waking-Up&#34;&gt;计算机基础面试问题全面总结&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/keithnull/TeachYourselfCS-CN&#34;&gt;TeachYourselfCS-CN&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/imhuay/Algorithm_for_Interview-Chinese&#34;&gt;面试算法笔记-中文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DarLiner/Algorithm_Interview_Notes-Chinese&#34;&gt;算法工程师面试&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ShanghaiTechAIClub/DLInterview&#34;&gt;深度学习面试题目&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/scutan90/DeepLearning-500-questions&#34;&gt;深度学习500问&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/amusi/AI-Job-Notes#Strategy&#34;&gt;AI算法岗求职攻略&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Kaggle实战&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;常用算法： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Feature Engineering：continue variable &amp;amp;&amp;amp; categorical variable&lt;/li&gt; &#xA;     &lt;li&gt;Classic machine learning algorithm：LR, KNN, SVM, Random Forest, GBDT(XGBoost&amp;amp;&amp;amp;LightGBM), Factorization Machine, Field-aware Factorization Machine, Neural Network&lt;/li&gt; &#xA;     &lt;li&gt;Cross validation, model selection：grid search, random search, hyper-opt&lt;/li&gt; &#xA;     &lt;li&gt;Ensemble learning&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/EGiFG6u9BYr1aBdq0a0wIQ&#34;&gt;kaggle竞赛宝典第一章-竞赛框架篇！&lt;span&gt;⭐&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/apachecn/kaggle&#34;&gt;Kaggle 项目实战（教程） = 文档 + 代码 + 视频&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29086448&#34;&gt;Kaggle入门系列：（一）机器学习环境搭建&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/29417603&#34;&gt;Kaggle入门系列：（二）Kaggle简介&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/29086614&#34;&gt;Kaggle入门系列（三）Titanic初试身手&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61660061&#34;&gt;从 0 到 1 走进 Kaggle&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25742261&#34;&gt;Kaggle 入门指南&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61657532&#34;&gt;一个框架解决几乎所有机器学习问题&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/&#34;&gt;Approaching (Almost) Any Machine Learning Problem | Abhishek Thakur&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27424282&#34;&gt;分分钟带你杀入Kaggle Top 1%&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/48758045&#34;&gt;如何达到Kaggle竞赛top 2%？这里有一篇特征探索经验帖&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27486736&#34;&gt;如何在 Kaggle 首战中进入前 10%？&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://bbs.cvmart.net/topics/1717&#34;&gt;Kaggle 首战 Top 2%, APTOS 2019 复盘总结 + 机器学习竞赛通用流程归纳&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/344388290&#34;&gt;kaggle的riiid比赛里关于数据处理时间空间优化的笔记&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_33739541/article/details/87565983&#34;&gt;大数据&amp;amp;机器学习相关竞赛推荐&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;二. 神经网络模型概览&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_35082030/article/details/73368962&#34;&gt;1. 一文看懂25个神经网络模型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29141828&#34;&gt;2. DNN概述论文：详解前馈、卷积和循环神经网络技术&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://colah.github.io/&#34;&gt;3. colah&#39;s blog&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modelzoo.co/&#34;&gt;4. Model Zoom&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29141828&#34;&gt;5. DNN概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60245227&#34;&gt;GitHub上的机器学习/深度学习综述项目合集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/weslynn/AlphaTree-graphic-deep-neural-network&#34;&gt;AlphaTree-graphic-deep-neural-network&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;CNN&lt;/h3&gt; &#xA;&lt;h4&gt;发展史&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35388569&#34;&gt;94页论文综述卷积神经网络：从基础技术到研究前景&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像分类&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31006686&#34;&gt;从LeNet-5到DenseNet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/xuanyuyt/p/11329998.html&#34;&gt;深度学习笔记（十一）网络 Inception, Xception, MobileNet, ShuffeNet, ResNeXt, SqueezeNet, EfficientNet, MixConv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/68411179&#34;&gt;CNN网络结构的发展&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/weiaicunzai/awesome-image-classification&#34;&gt;Awesome - Image Classification：论文&amp;amp;&amp;amp;代码大全&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/rwightman/pytorch-image-models&#34;&gt;pytorch-image-models&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;目标检测&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32830206&#34;&gt;深度学习之目标检测的前世今生（Mask R-CNN）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29434605&#34;&gt;深度学习目标检测模型全面综述：Faster R-CNN、R-FCN和SSD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36184131&#34;&gt;从RCNN到SSD，这应该是最全的一份目标检测算法盘点&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40047760&#34;&gt;目标检测算法综述三部曲&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40047760&#34;&gt;基于深度学习的目标检测算法综述（一）&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40020809&#34;&gt;基于深度学习的目标检测算法综述（二）&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40102001&#34;&gt;基于深度学习的目标检测算法综述（三）&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;From RCNN to YOLOv3&lt;/a&gt;：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35724768&#34;&gt;上&lt;/a&gt;，&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35731743&#34;&gt;下&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/38709522&#34;&gt;后 R-CNN时代， Faster R-CNN、SSD、YOLO 各类变体统治下的目标检测综述：Faster R-CNN系列胜了吗？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60590369&#34;&gt;目标检测进化史&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59376548&#34;&gt;CVPR2019目标检测方法进展综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61080508&#34;&gt;一文看尽21篇目标检测最新论文（腾讯/Google/商汤/旷视/清华/浙大/CMU/华科/中科院等&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/82491218&#34;&gt;我这两年的目标检测&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Anchor-Free目标检测算法&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/40221183&#34;&gt;第一篇：arxiv2015_baidu_DenseBox&lt;/a&gt;， &lt;a href=&#34;https://www.zhihu.com/question/319605567/answer/647844997&#34;&gt;如何评价最新的anchor-free目标检测模型FoveaBox？&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/61644900&#34;&gt;FCOS: 最新的one-stage逐像素目标检测算法&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/62198865&#34;&gt;最新的Anchor-Free目标检测模型FCOS，现已开源！&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/62789701&#34;&gt;中科院牛津华为诺亚提出CenterNet，one-stage detector可达47AP，已开源！&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/VCBE123/AnchorFreeDetection&#34;&gt;AnchorFreeDetection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64563186&#34;&gt;Anchor free深度学习的目标检测方法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/63273342&#34;&gt;聊聊Anchor的&#34;前世今生&#34;（上）&lt;/a&gt;&amp;amp;&amp;amp;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/68291859&#34;&gt;聊聊Anchor的&#34;前世今生&#34;（下）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62975854&#34;&gt;目标检测算法综述之FPN优化篇&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/148738276&#34;&gt;一文看尽物体检测中的各种FPN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/amusi/awesome-object-detection&#34;&gt;awesome-object-detection：论文&amp;amp;&amp;amp;代码&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hoya012/deep_learning_object_detection&#34;&gt;deep_learning_object_detection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/kemaloksuz/ObjectDetectionImbalance&#34;&gt;ObjectDetectionImbalance&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像分割（语义分割、实例分割、全景分割）&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36801104&#34;&gt;图像语义分割(Semantic segmentation) Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_20084101/article/details/80432960&#34;&gt;干货 | 一文概览主要语义分割网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37618829&#34;&gt;语义分割 发展综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/76603228&#34;&gt;9102年了，语义分割的入坑指南和最新进展都是什么样的&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/110132002&#34;&gt;实例分割最新最全面综述：从Mask R-CNN到BlendMask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/133212654&#34;&gt;语义分割综述：深度学习背景下的语义分割的发展状况【推荐】&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/mrgloom/awesome-semantic-segmentation&#34;&gt;Awesome Semantic Segmentation：论文&amp;amp;&amp;amp;代码&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/110123136&#34;&gt;一篇看完就懂的最新语义分割综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/142451150&#34;&gt;基于深度学习的语义分割综述&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;轻量化卷积神经网络&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32746221&#34;&gt;纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;人脸相关&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35295839&#34;&gt;如何走近深度学习人脸识别？你需要这篇超长综述 | 附开源代码&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;人脸检测和识别算法综述&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36621308&#34;&gt;人脸检测算法综述 &lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32702868&#34;&gt;人脸检测背景介绍和发展现状&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36416906&#34;&gt;人脸识别算法演化史&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/shuzfan/article/details/50358809&#34;&gt;CascadeCNN&lt;/a&gt; &amp;nbsp;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_14845119/article/details/52680940&#34;&gt;MTCNN&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/ChanChiChoi/awesome-Face_Recognition&#34;&gt;awesome-Face_Recognition&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64191484&#34;&gt;异质人脸识别研究综述&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26431250&#34;&gt;老板来了：人脸识别+手机推送，老板来了你立刻知道。&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/33456076&#34;&gt;手把手教你用Python实现人脸识别&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.jianshu.com/p/e57205edc364&#34;&gt;人脸识别项目，网络模型，损失函数，数据集相关总结&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24816781&#34;&gt;基于深度学习的人脸识别技术综述&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/35295839&#34;&gt;如何走近深度学习人脸识别？你需要这篇超长综述&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/51324547&#34;&gt;人脸识别损失函数综述（附开源实现）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/64427565&#34;&gt;Face Recognition Loss on Mnist with Pytorch&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34404607&#34;&gt;人脸识别的LOSS（上）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34436551&#34;&gt;人脸识别的LOSS（下）&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;人脸关键点检测&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/88344339&#34;&gt;【每周CV论文推荐】 初学深度学习人脸关键点检测必读文章&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/CvdeV5xgUF0kStJQdRst0w&#34;&gt;从传统方法到深度学习，人脸关键点检测方法综述&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/42968117&#34;&gt;人脸关键点检测综述&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62824113&#34;&gt;人脸专集4 | 遮挡、光照等因素的人脸关键点检测&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/52525598&#34;&gt;【Face key point detection】人脸关键点检测实现&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35390012&#34;&gt;OpenCV实战：人脸关键点检测（FaceMark）&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/106774468&#34;&gt;CenterFace+TensorRT部署人脸和关键点检测400fps&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像超分辨率&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/57564211&#34;&gt;深度学习图像超分辨率综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31664818&#34;&gt;从SRCNN到EDSR，总结深度学习端到端超分辨率方法发展历程&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;行人重识别&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62843442&#34;&gt;【CVPR2019正式公布】行人重识别论文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62843442&#34;&gt;【CVPR2019正式公布】行人重识别论文&lt;/a&gt;，&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64004977&#34;&gt;2019 行人再识别年度进展回顾&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像着色&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MarkMoHR/Awesome-Image-Colorization&#34;&gt;Awesome-Image-Colorization&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;边检测&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers&#34;&gt;Awesome-Edge-Detection-Papers&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;OCR&amp;amp;&amp;amp;文本检测&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67319122&#34;&gt;2019CVPR文本检测综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65707543&#34;&gt;OCR文字处理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;amp;mid=2247485142&amp;amp;idx=1&amp;amp;sn=c0e01da30eb5e750be453eabe4be2bf4&amp;amp;chksm=fdb69b41cac11257ae22c7dac395e9651dab628fc35dd6d3c02d9566a8c7f5f2b56353d58a64&amp;amp;token=1065243837&amp;amp;lang=zh_CN#rd&#34;&gt;自然场景文本检测识别技术综述&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;点云&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65690433&#34;&gt;awesome-point-cloud-analysis&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;细粒度图像分类&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/73542103&#34;&gt;超全深度学习细粒度图像分析：项目、综述、教程一网打尽&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像检索&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;图像检索的十年&lt;a href=&#34;https://mp.weixin.qq.com/s/sM78DCOK3fuG2JrP2QaSZA&#34;&gt;上&lt;/a&gt;、&lt;a href=&#34;https://mp.weixin.qq.com/s/yzVMDEpwbXVS0y-CwWSBEA&#34;&gt;下&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;人群计数&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://chuansong.me/n/443237851736&#34;&gt;人群计数&lt;/a&gt;, &lt;a href=&#34;https://www.cnblogs.com/wmr95/p/8134692.html&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/u011285477/article/details/51954989&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/qingqingdeaini/article/details/79922549&#34;&gt;3&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;教程&lt;/h4&gt; &#xA;&lt;h5&gt;前馈神经网络&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59385110&#34;&gt;从基本原理到梯度下降，小白都能看懂的神经网络教程&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;激活函数&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30567264&#34;&gt;激活函数一览&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/XDU-Lakers/p/10557496.html&#34;&gt;深度学习中几种常见的激活函数理解与总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/67366051&#34;&gt;一个激活函数需要具有哪些必要的属性&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;反向传播算法&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014313009/article/details/51039334&#34;&gt;反向传播算法（过程及公式推导）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24801814&#34;&gt;通俗理解神经网络BP传播算法&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;优化问题&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25631496&#34;&gt;神经网络训练中的梯度消失与梯度爆炸&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/3f35e555d5ba&#34;&gt;梯度消失和梯度爆炸问题详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33006526&#34;&gt;详解深度学习中的梯度消失、爆炸原因及其解决方法&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/program_developer/article/details/80032376&#34;&gt;神经网络梯度消失和梯度爆炸及解决办法&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;卷积层&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215&#34;&gt;A Comprehensive Introduction to Different Types of Convolutions in Deep Learning&lt;/a&gt; &amp;amp;&amp;amp; 翻译：&lt;a href=&#34;https://www.leiphone.com/news/201902/D2Mkv61w9IPq9qGh.html&#34;&gt;上&lt;/a&gt;、&lt;a href=&#34;https://www.leiphone.com/news/201902/biIqSBpehsaXFwpN.html?uniqueCode=OTEsp9649VqJfUcO&#34;&gt;下&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/57575810&#34;&gt;卷积有多少种？一文读懂深度学习中的各种卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/cvtoEyes/p/8848815.html&#34;&gt;各种卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/yangperasd/p/7071657.html&#34;&gt;Convolution Network及其变种（反卷积、扩展卷积、因果卷积、图卷积）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59839551&#34;&gt;深度学习基础--卷积类型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28749411&#34;&gt;变形卷积核、可分离卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/chaolei3/article/details/79374563&#34;&gt;对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://buptldy.github.io/2016/10/29/2016-10-29-deconv/&#34;&gt;反卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/silence2015/article/details/79748729&#34;&gt;Dilated/Atrous conv 空洞卷积/多孔卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_37697191/article/details/89527315&#34;&gt;卷积层输出大小尺寸计算及 “SAME” 和 “VALID”&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/62760780&#34;&gt;卷积的三种模式full, same, valid以及padding的same, valid&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_43232545/article/details/103317773&#34;&gt;正常卷积与空洞卷积输出特征图与感受野大小的计算&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_xiao_feng/article/details/78003476&#34;&gt;【Tensorflow】tf.nn.depthwise_conv2d如何实现深度卷积?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_xiao_feng/article/details/78003730&#34;&gt;【Tensorflow】tf.nn.atrous_conv2d如何实现空洞卷积？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_xiao_feng/article/details/78002811&#34;&gt;【Tensorflow】tf.nn.separable_conv2d如何实现深度可分卷积?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_xiao_feng/article/details/71713358&#34;&gt;【TensorFlow】tf.nn.conv2d_transpose是怎样实现反卷积的？&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;池化层&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/112216409&#34;&gt;卷积神经网络中的各种池化操作&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;卷积神经网络&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/39022858&#34;&gt;卷积神经网络工作原理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28863709&#34;&gt;「七夕的礼物」: 一日搞懂卷积神经网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40050371&#34;&gt;一文读懂卷积神经网络中的1x1卷积核&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/xiaojiajia007/article/details/86008415&#34;&gt;如何理解神经网络中通过add和concate的方式融合特征？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/389912594/answer/1178054600&#34;&gt;神经网络中对需要concat的特征进行线性变换然后相加是否好于直接concat?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/65305385&#34;&gt;CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/hejunlin1992/p/12978988.html&#34;&gt;深度学习中卷积的参数量和计算量&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像分类网络详解&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/41736894&#34;&gt;经典CNN模型LeNet解读&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22659166&#34;&gt;机器学习进阶笔记之三 | 深入理解Alexnet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/41423739&#34;&gt;一文读懂VGG网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/52802896&#34;&gt;Inception V1,V2,V3,V4 模型总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/lanran2/article/details/79057994&#34;&gt;ResNet解析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35985680&#34;&gt;一文简述ResNet及其多种变体&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect&#34;&gt;CapsNet入门系列&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484099&amp;amp;idx=1&amp;amp;sn=97e209f1a9860c8d8c51e81d98fc8a0a&amp;amp;chksm=eb4ee600dc396f16624a33cdfc0ead905e62ae9447b49b20146020e6cbd7d71f089101512a40&amp;amp;scene=21#wechat_redirect&#34;&gt;CapsNet入门系列之一：胶囊网络背后的直觉&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484165&amp;amp;idx=1&amp;amp;sn=0ca679e3a5f499f8d8addb405fe3df83&amp;amp;chksm=eb4ee7c6dc396ed0a330fcac12690110bcaf9a8a10794dbc5e1a326c69ecbb140140f55fd6ba&amp;amp;scene=21#wechat_redirect&#34;&gt;CapsNet入门系列之二：胶囊如何工作&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&amp;amp;mid=2247484433&amp;amp;idx=1&amp;amp;sn=3afe4605bc2501eebbc41c6dd1af9572&amp;amp;chksm=eb4ee0d2dc3969c4619d6c1097d5c949c76c6c854e60d36eba4388da2c3855747818d062c90a&amp;amp;scene=21#wechat_redirect&#34;&gt;CapsNet入门系列之三：囊间动态路由算法&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/6CRSen8P6zKaMGtX8IRfqw&#34;&gt;CapsNet入门系列之四：胶囊网络架构&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/158591662&#34;&gt;深入剖析MobileNet和它的变种（例如：ShuffleNet）为什么会变快？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32304419&#34;&gt;CNN模型之ShuffleNet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40980942&#34;&gt;ShuffleNet V2和四个网络架构设计准则&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/78019001&#34;&gt;ResNeXt 深入解读与模型实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/63460684&#34;&gt;如何评价Momenta ImageNet 2017夺冠架构SENet?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/79419670&#34;&gt;CBAM：卷积块注意力模块&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/65529934&#34;&gt;CBAM: Convolutional Block Attention Module&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59690223&#34;&gt;SKNet——SENet孪生兄弟篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64988633&#34;&gt;GCNet：当Non-local遇见SENet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/xuanyuyt/p/11329998.html&#34;&gt;深度学习笔记（十一）网络 Inception, Xception, MobileNet, ShuffeNet, ResNeXt, SqueezeNet, EfficientNet, MixConv&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/320462422&#34;&gt;如何评价最新的Octave Convolution？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/136105870&#34;&gt;ResNeSt 之语义分割&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/133805433&#34;&gt;关于ResNeSt的点滴疑惑&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/143214871&#34;&gt;ResNeSt在刷榜之后被ECCV2020 strong reject&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;目标检测网络详解&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/70306015&#34;&gt;目标检测的性能评价指标&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/75348108&#34;&gt;NMS和计算mAP时的置信度阈值和IoU阈值 &lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/60834912&#34;&gt;白话mAP&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/37910324&#34;&gt;目标检测模型的评估指标mAP详解(附代码）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/iamoldpan/article/details/78799857&#34;&gt;深度学习中IU、IoU(Intersection over Union)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/&#34;&gt;Selective Search for Object Detection &lt;/a&gt;&lt;a href=&#34;https://blog.csdn.net/guoyunfei20/article/details/78723646&#34;&gt;（译文）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/106192020&#34;&gt;Region Proposal Network(RPN)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zijin0802034/article/details/77685438&#34;&gt;边框回归(Bounding Box Regression)详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/shuzfan/article/details/52711706&#34;&gt;NMS——非极大值抑制&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/128125301&#34;&gt;非极大值抑制NMS的python实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/151914931&#34;&gt;一文打尽目标检测NMS——精度提升篇&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/157900024&#34;&gt;一文打尽目标检测NMS——效率提升篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/104236411&#34;&gt;目标检测回归损失函数简介：SmoothL1/IoU/GIoU/DIoU/CIoU Loss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23006190&#34;&gt;将CNN引入目标检测的开山之作：R-CNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014696921/article/details/52824097&#34;&gt;R-CNN论文详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hjimce/article/details/50187029&#34;&gt;深度学习（十八）基于R-CNN的物体检测&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24780395&#34;&gt;Fast R-CNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hjimce/article/details/73382553&#34;&gt;深度学习（六十四）Faster R-CNN物体检测&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/59692298&#34;&gt;你真的学会RoI Pooling了吗?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36461718&#34;&gt;目标检测论文阅读：Feature Pyramid Networks for Object Detection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24954433&#34;&gt;SSD&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.codetd.com/article/2554465&#34;&gt;实例分割--Mask RCNN详解(ROI Align / Loss Function)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/37998710&#34;&gt;令人拍案称奇的Mask RCNN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32423092&#34;&gt;何恺明大神的「Focal Loss」，如何更好地理解？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/82148525&#34;&gt;FocalLoss 对样本不平衡的权重调节和减低损失值&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/qq_33278884/article/details/91572173&#34;&gt;focal_loss 多类别和二分类 Pytorch代码实现&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/qq_39012149/article/details/96184383&#34;&gt;多分类focal loss及其tensorflow实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/93658728&#34;&gt;堪比Focal Loss！解决目标检测中样本不平衡的无采样方法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/138824387&#34;&gt;目标检测正负样本区分策略和平衡策略总结(一)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/138828372&#34;&gt;目标检测正负样本区分策略和平衡策略总结(二)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/144659734&#34;&gt;目标检测正负样本区分策略和平衡策略总结(三）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.mamicode.com/info-detail-2314392.html&#34;&gt;YOLO&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/32525231&#34;&gt;目标检测|YOLO原理与实现&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/24916786&#34;&gt;图解YOLO&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/70387154&#34;&gt;【论文解读】Yolo三部曲解读——Yolov1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35325884?group_id=966229905398362112&#34;&gt;目标检测|YOLOv2原理与实现(附YOLOv3)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/25167153&#34;&gt;YOLO2&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/74540100&#34;&gt;【论文解读】Yolo三部曲解读——Yolov2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/49556105&#34;&gt;&amp;lt;机器爱学习&amp;gt;YOLO v3深入理解&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/76802514&#34;&gt;【论文解读】Yolo三部曲解读——Yolov3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/138510087&#34;&gt;YOLOv4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1808.01244&#34;&gt;目标检测之CornerNet&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/41825737&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/Hibercraft/article/details/81637451&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/41759548&#34;&gt;3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60612064&#34;&gt;目标检测小tricks--样本不均衡处理&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;图像分割网络详解&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/50996404&#34;&gt;超像素、语义分割、实例分割、全景分割 傻傻分不清 &lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/u013066730/article/details/103613154&#34;&gt;语义分割、实例分割和全景分割的区别&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_20084101/article/details/80455877&#34;&gt;语义分割卷积神经网络快速入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31428783&#34;&gt;图像语义分割入门+FCN/U-Net网络解析&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/Formlsl/article/details/80373200&#34;&gt;深入理解深度学习分割网络Ｕnet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/269914775&#34;&gt;Unet神经网络为什么会在医学图像分割表现好？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/38033032&#34;&gt;图像语义分割的工作原理和CNN架构变迁&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/77834369&#34;&gt;语义分割中的Attention和低秩重建&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/134253318&#34;&gt;打通多个视觉任务的全能Backbone:HRNet&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;注意力机制&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37601161&#34;&gt;深度学习中的注意力模型（2017版）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/bvl10101111/article/details/78470716&#34;&gt;Attention Model（mechanism） 的 套路&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/146130215&#34;&gt;计算机视觉中的注意力机制（推荐）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/106662375&#34;&gt;More About Attention（推荐）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32928645&#34;&gt;计算机视觉中的注意力机制&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31547842&#34;&gt;NLP中的Attention Mechanism&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/k8PdZAld2ANVoekuyQxI3w&#34;&gt;Transformer中的Attention&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bbs.cvmart.net/topics/2581&#34;&gt;综述：图像处理中的注意力机制&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h5&gt;特征融合&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/141685352&#34;&gt;盘点目标检测中的特征融合技巧（根据YOLO v4总结）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/147820687&#34;&gt;多尺度融合介绍&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Action&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/pytorch/vision/raw/master/torchvision/models/resnet.py&#34;&gt;PyTorch官方实现ResNet&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/akamaster/pytorch_resnet_cifar10&#34;&gt;pytorch_resnet_cifar10&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/268816646&#34;&gt;PyTorch 63.Coding for FLOPs, Params and Latency&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30753326&#34;&gt;先读懂CapsNet架构然后用TensorFlow实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37056927&#34;&gt;目标检测-20种模型的原味代码汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79306762&#34;&gt;TensorFlow Object Detection API 教程&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79306762&#34;&gt;TensorFlow 对象检测 API 教程1&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79307598&#34;&gt;TensorFlow 对象检测 API 教程2&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79307751&#34;&gt;TensorFlow 对象检测 API 教程3&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79307931&#34;&gt;TensorFlow 对象检测 API 教程 4&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_36148847/article/details/79307933&#34;&gt;TensorFlow 对象检测 API 教程5&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65327747&#34;&gt;在TensorFlow+Keras环境下使用RoI池化一步步实现注意力机制&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://discuss.gluon.ai/t/topic/7216&#34;&gt;mxnet如何查看参数数量&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/likelyzhao/CalFLOPS-Mxnet&#34;&gt;mxnet查看FLOPS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/milesial/Pytorch-UNet&#34;&gt;Pytorch-UNet&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/qubvel/segmentation_models.pytorch&#34;&gt;segmentation_models.pytorch&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GAN&lt;/h3&gt; &#xA;&lt;h4&gt;发展史&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26491601&#34;&gt;千奇百怪的GAN变体&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://kexue.fm/tag/GAN/&#34;&gt;苏剑林博客，讲解得淋漓尽致&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1807.04720.pdf&#34;&gt;The GAN Landscape：Losses, Architectures, Regularization, and Normalization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.leiphone.com/news/201701/Kq6FvnjgbKK8Lh8N.html&#34;&gt;深度学习新星：GAN的基本原理、应用和走向&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62746494&#34;&gt;GAN生成图像综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29882709&#34;&gt;2017年GAN 计算机视觉相关paper汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/72745900&#34;&gt;必读的10篇关于GAN的论文&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;教程&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27295635&#34;&gt;GAN原理学习笔记&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58812258&#34;&gt;GAN万字长文综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35783437?group_id=969598777652420608&#34;&gt;极端图像压缩的对抗生成网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=0CKeqXl5IY0&amp;amp;feature=youtu.be&#34;&gt;台湾大学李宏毅GAN教程&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/GAN-Basic%20Idea%20(2017.04.21).pdf&#34;&gt;Basic&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/GAN-Improving%20GAN%20(2017.05.05).pdf&#34;&gt;Improving&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34711316&#34;&gt;CycleGAN：图片风格，想换就换 | ICCV 2017论文解读&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25071913&#34;&gt;Wasserstein GAN&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/Invokar/article/details/88917214&#34;&gt;GAN：两者分布不重合JS散度为log2的数学证明&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/40105143&#34;&gt;用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Action&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24767059&#34;&gt;GAN学习指南：从原理入门到制作生成Demo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29837245&#34;&gt;机器之心GitHub项目：GAN完整理论推导与实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35030377&#34;&gt;在Keras上实现GAN：构建消除图片模糊的应用&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;RNN&lt;/h3&gt; &#xA;&lt;h4&gt;发展史&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32668465&#34;&gt;从90年代的SRNN开始，纵览循环神经网络27年的研究进展&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;教程&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/crownpku/Awesome-Chinese-NLP&#34;&gt;Awesome-Chinese-NLP&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/apachecn/nlp-pytorch-zh&#34;&gt;nlp-pytorch-zh&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28054589&#34;&gt;完全图解RNN、RNN变体、Seq2Seq、Attention机制&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/heyongluoyao8/article/details/48636251&#34;&gt;循环神经网络(RNN, Recurrent Neural Networks)介绍&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Dark_Scope/article/details/47056361&#34;&gt;RNN以及LSTM的介绍和公式梳理&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24018768&#34;&gt;（译）理解长短期记忆(LSTM) 神经网络&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35878575?group_id=970350175025385472&#34;&gt; 一文读懂LSTM和RNN&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27345523&#34;&gt;探索LSTM：基本概念到内部结构&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/matrix_space/article/details/53374040&#34;&gt; 翻译：深入理解LSTM系列&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/matrix_space/article/details/53374040&#34;&gt;深入理解 LSTM 网络 (一)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/matrix_space/article/details/53376870&#34;&gt;深入理解 LSTM 网络 (二)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32085405&#34;&gt;LSTM&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zybuluo.com/hanbingtao/note/541458&#34;&gt;深度学习其五 循环神经网络&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32582764&#34;&gt;用循环神经网络进行文件无损压缩：斯坦福大学提出DeepZip&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;&#34;&gt;吴恩达序列建模课程&lt;/a&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34309635&#34;&gt;Coursera吴恩达《序列模型》课程笔记（1）-- 循环神经网络（RNN）&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34975871&#34;&gt;Coursera吴恩达《序列模型》课程笔记（2）-- NLP &amp;amp; Word Embeddings&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35532553&#34;&gt;Coursera吴恩达《序列模型》课程笔记（3）-- Sequence models &amp;amp; Attention mechanism&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;word2vec&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;原理 &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26306795&#34;&gt;NLP 秒懂词向量Word2vec的本质&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35500923&#34;&gt;一篇通俗易懂的word2vec&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27830489&#34;&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56382372&#34;&gt;nlp中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zh.diveintodeeplearning.org/chapter_natural-language-processing/word2vec.html&#34;&gt;词嵌入（word2vec）&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/wangyangzhizhou/article/details/77073023&#34;&gt;谈谈谷歌word2vec的原理&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67117737&#34;&gt;Word2Vec中为什么使用负采样？&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;训练词向量 &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29200034&#34;&gt;练习-word2vec&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31886824&#34;&gt;word2vec方法的实现和应用&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/wzdjsgf/article/details/79541492&#34;&gt;自然语言处理入门 word2vec 使用tensorflow自己训练词向量&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28979653&#34;&gt;使用tensorflow实现word2vec中文词向量的训练&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/wangyangzhizhou/article/details/77530479?locationNum=1&amp;amp;fps=1&#34;&gt;如何用TensorFlow训练词向量&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/47812375&#34;&gt;聊聊 Transformer&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/144825330&#34;&gt;基于Transform的机器翻译系统&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35648927&#34;&gt;基于word2vec训练词向量(一)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35889385&#34;&gt;基于word2vec训练词向量(二)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35041012&#34;&gt;自然语言处理中的自注意力机制（Self-Attention Mechanism）&lt;/a&gt; &amp;nbsp; &amp;nbsp;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54491016&#34;&gt;自然语言处理中注意力机制综述&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27830489&#34;&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Action&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/graykode/nlp-tutorial&#34;&gt;推荐：nlp-tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lyeoni/nlp-tutorial&#34;&gt;nlp-tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/liuchonge/article/details/78405185?locationNum=8&amp;amp;fps=1&#34;&gt;tensorflow中RNNcell源码分析以及自定义RNNCell的方法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28196873&#34;&gt;TensorFlow中RNN实现的正确打开方式&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27906426&#34;&gt;TensorFlow RNN 代码&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67031035&#34;&gt;Tensorflow实现的深度NLP模型集锦&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33186759&#34;&gt;用tensorflow LSTM如何预测股票价格&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29797089&#34;&gt;TensorFlow的多层LSTM实践&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27087310&#34;&gt;《安娜卡列尼娜》文本生成——利用TensorFlow构建LSTM模型&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;GNN&lt;/h3&gt; &#xA;&lt;h4&gt;发展史&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/65539782&#34;&gt;Graph Neural Network（GNN）综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754422&amp;amp;idx=4&amp;amp;sn=0dc881487f362322a875b4ce06e645f7&amp;amp;chksm=871a8908b06d001ef7386ccc752827c20711877a4a23d6a8318978095dd241d118257c607b22&amp;amp;scene=21#wechat_redirect&#34;&gt;深度学习时代的图模型，清华发文综述图网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;amp;mid=2650754558&amp;amp;idx=2&amp;amp;sn=7d79191b9ed30679d5d40e22d9cabdf8&amp;amp;chksm=871a8980b06d00962e0dbe984e1d3469214db31cb402b4725a0dfe330249a830b45cb26932b5&amp;amp;scene=21#wechat_redirect&#34;&gt;清华大学图神经网络综述：模型与应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54241746&#34;&gt;图神经网络概述第三弹：来自IEEE Fellow的GNN综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/DeepGraphLearning/LiteratureDL4Graph&#34;&gt;GNN最全文献资料整理&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/nnzhan/Awesome-Graph-Neural-Networks&#34;&gt;Awesome-Graph-Neural-Networks&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;教程&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/54504471&#34;&gt;如何理解 Graph Convolutional Network（GCN）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54505069&#34;&gt;图卷积网络(GCN)新手村完全指南&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/71200936&#34;&gt;何时能懂你的心——图卷积神经网络（GCN）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/90470499&#34;&gt;图卷积网络GCN的理解与介绍&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/89503068&#34;&gt;一文读懂图卷积GCN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/101310106&#34;&gt;2020 年 GNN 开卷有益与再谈图卷积&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/120311352&#34;&gt;【GCN】万字长文带你入门 GCN&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/346942899/answer/848298494&#34;&gt;如何解决图神经网络（GNN）训练中过度平滑的问题？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/366088445&#34;&gt;全连接的图卷积网络(GCN)和self-attention这些机制有什么区别联系&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/147654689&#34;&gt;CNN与GCN的区别、联系及融合&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Action&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/57235377&#34;&gt;图卷积网络到底怎么做，这是一份极简的Numpy实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.dgl.ai/index.html&#34;&gt;DGL&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;三. 深度模型的优化与正则化&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://fa.bianp.net/teaching/2018/eecs227at/&#34;&gt;1. 优化算法纵览&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27449596&#34;&gt;2. 从梯度下降到Adam&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25703402&#34;&gt;3. 从梯度下降到拟牛顿法：盘点训练神经网络的五大学习算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800&#34;&gt;4. 正则化技术总结&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35429054?group_id=966442942538444800&#34;&gt;史上最全面的正则化技术总结与分析--part1&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35432128?group_id=966443101011738624&#34;&gt;史上最全面的正则化技术总结与分析--part2&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/38709373&#34;&gt;权重衰减（weight decay）与学习率衰减（learning rate decay）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/93624972&#34;&gt;pytorch必须掌握的的4种学习率衰减策略&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/chunyun0716/article/category/6188191/2&#34;&gt;5. 最优化算法系列（math）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25631496&#34;&gt;6. 神经网络训练中的梯度消失与梯度爆炸&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36050743&#34;&gt;7. 神经网络的优化及训练&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35888543&#34;&gt;8. 通俗讲解查全率和查准率&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34079183&#34;&gt;全面梳理：准确率,精确率,召回率,查准率,查全率,假阳性,真阳性,PRC,ROC,AUC,F1&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34473430&#34;&gt;机器学习之类别不平衡问题 (1) —— 各种评估指标&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34655990&#34;&gt;机器学习之类别不平衡问题 (2) —— ROC和PR曲线&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/84035782&#34;&gt;AUC详解与python实现&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/78628437&#34;&gt;微平均和宏平均&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/74980268&#34;&gt;机器学习中的性能度量&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/30643044&#34;&gt;精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30567264&#34;&gt;激活函数一览&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/XDU-Lakers/p/10557496.html&#34;&gt;深度学习中几种常见的激活函数理解与总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014595019/article/details/52562159&#34;&gt;深度学习笔记(三)：激活函数和损失函数&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30385380&#34;&gt;激活函数/损失函数汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zuolixiangfisher/article/details/88649110&#34;&gt;机器学习中常见的损失函数及其应用场景&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/61379965&#34;&gt;PyTorch的十八个损失函数&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/82199561&#34;&gt;深度度量学习中的损失函数&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014313009/article/details/51039334&#34;&gt;反向传播算法（过程及公式推导）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24801814&#34;&gt;通俗理解神经网络BP传播算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30922689&#34;&gt;10. Coursera吴恩达《优化深度神经网络》课程笔记（3）-- 超参数调试、Batch正则化和编程框架&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35423404&#34;&gt;11. 机器学习各种熵&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27305237&#34;&gt;12. 距离和相似性度量&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29974820&#34;&gt;13. 机器学习里的黑色艺术：normalization, standardization, regularization&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/pipisorry/article/details/52247379&#34;&gt;数据标准化/归一化normalization&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/20455227&#34;&gt;特征工程中的「归一化」有什么作用？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36101196&#34;&gt;14. LSTM系列的梯度问题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35027284&#34;&gt;15. 损失函数整理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/28124810&#34;&gt;16. 详解残差块为何有助于解决梯度弥散问题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34858971&#34;&gt;17. FAIR何恺明等人提出组归一化：替代批归一化，不受批量大小限制&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;18. Batch Normalization（BN）&lt;/a&gt;:&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26702482&#34;&gt;1 &lt;/a&gt;,&lt;a href=&#34;https://blog.csdn.net/hjimce/article/details/50866313&#34;&gt;2 &lt;/a&gt;,&lt;a href=&#34;https://bbs.cvmart.net/topics/576&#34;&gt;3 &lt;/a&gt;,&lt;a href=&#34;https://blog.csdn.net/edogawachia/article/details/80040456&#34;&gt;4 &lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/38176412&#34;&gt;5&lt;/a&gt;, &lt;a href=&#34;https://www.zhihu.com/question/38102762&#34;&gt;6&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/52132614&#34;&gt;7&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33173246&#34;&gt;19. 详解深度学习中的Normalization，不只是BN&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/69659844&#34;&gt;如何区分并记住常见的几种 Normalization 算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/philosophyatmath/article/details/70173128&#34;&gt;20. BFGS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33006526&#34;&gt;21. 详解深度学习中的梯度消失、爆炸原因及其解决方法&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/program_developer/article/details/80032376&#34;&gt;神经网络梯度消失和梯度爆炸及解决办法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1207.0580.pdf&#34;&gt;22. Dropout&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/stdcoutzyx/article/details/49022443&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/hjimce/article/details/50413257&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/shuzfan/article/details/50580915&#34;&gt;3&lt;/a&gt;，&lt;a href=&#34;https://blog.csdn.net/shuzfan/article/details/50580915&#34;&gt;系列解读Dropout&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/StreamRock/article/details/83590347&#34;&gt;23.谱归一化（Spectral Normalization）的理解&lt;/a&gt;，&lt;a href=&#34;https://blog.csdn.net/left_la/article/details/9159949&#34;&gt;常见向量范数和矩阵范数&lt;/a&gt;，&lt;a href=&#34;https://blog.csdn.net/StreamRock/article/details/83539937&#34;&gt;谱范数正则（Spectral Norm Regularization）的理解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35356992&#34;&gt;24.L1正则化与L2正则化&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/29360425&#34;&gt;深入理解L1、L2正则化&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/40814046&#34;&gt;L2正则=Weight Decay？并不是这样&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/63982470&#34;&gt;都9102年了，别再用Adam + L2 regularization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61944055&#34;&gt;25.为什么选用交叉熵而不是MSE&lt;/a&gt; &amp;amp;&amp;amp;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/63731947&#34;&gt;为什么使用交叉熵作为损失函数&lt;/a&gt; &amp;amp;&amp;amp;&lt;a href=&#34;http://sofasofa.io/forum_main_post.php?postid=1001792&#34;&gt;二元分类为什么不能用MSE做为损失函数？&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/319865092&#34;&gt;为什么平方损失函数不适用分类问题？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32154263&#34;&gt;浅谈神经网络中的梯度爆炸问题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/65626362&#34;&gt;为什么weight decay能够防止过拟合&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014313009/article/details/51043064&#34;&gt;交叉熵代价函数（作用及公式推导）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/67782576&#34;&gt;交叉熵损失的来源、说明、求导与pytorch实现&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/27223959&#34;&gt;Softmax函数与交叉熵&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/84764177&#34;&gt;极大似然估计与最小化交叉熵损失或者KL散度为什么等价&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://ruder.io/optimizing-gradient-descent/&#34;&gt;梯度下降优化算法纵览&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/qq_23269761/article/details/80901411&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://www.cnblogs.com/guoyaohua/p/8542554.html&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/qq_32172681/article/details/100979476&#34;&gt;几种优化算法的比较（BGD、SGD、Adam、RMSPROP）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25723112&#34;&gt;详解softmax函数以及相关求导过程&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/u014313009/article/details/51045303&#34;&gt;softmax的log似然代价函数（公式求导）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34044634&#34;&gt;【技术综述】一文道尽softmax loss及其变种&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/45014864&#34;&gt;从最优化的角度看待Softmax损失函数&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/45368976&#34;&gt;Softmax理解之二分类与多分类&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/49939159&#34;&gt;Softmax理解之Smooth程度控制&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/52108088&#34;&gt;Softmax理解之margin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;权重初始化&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62850258&#34;&gt;神经网络中的权重初始化一览：从基础到Kaiming&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/138064188&#34;&gt;深度学习中常见的权重初始化方法&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u012328159/article/details/80025785&#34;&gt;深度学习中神经网络的几种权重初始化方法&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/75879624&#34;&gt;谈谈神经网络权重为什么不能初始化为0&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/305340182&#34;&gt;神经网络中的偏置（bias）究竟有这么用？&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/66894061&#34;&gt;深度学习里面的偏置为什么不加正则？&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/26760839&#34;&gt;为什么说bagging是减少variance，而boosting是减少bias?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;四. 炼丹术士那些事&lt;/h2&gt; &#xA;&lt;h3&gt;调参经验&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/jiandanjinxin/article/details/77190687&#34;&gt;训练的神经网络不工作？一文带你跨过这37个坑&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/BVL10101111/article/details/76086344&#34;&gt;Deep Learning 之 训练过程中出现NaN问题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59918821&#34;&gt;神经网络训练trick&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/41631631&#34;&gt;你有哪些deep learning（rnn、cnn）调参的经验？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27725664&#34;&gt;GAN的一些小trick&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/han_xiaoyang/article/details/50521064&#34;&gt;深度学习与计算机视觉系列(8)_神经网络训练与注意点&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/liuweiyuxiang/article/details/80856991&#34;&gt;神经网络训练loss不下降原因集合&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/zongza/article/details/89185852&#34;&gt; loss不下降的解决方法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014038273/article/details/84108688&#34;&gt;深度学习：欠拟合问题的几种解决方案&lt;/a&gt; &amp;amp;&amp;amp;&lt;a href=&#34;https://blog.csdn.net/mzpmzk/article/details/79741682&#34;&gt;过拟合和欠拟合问题&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/whut_ldz/article/details/78882871&#34;&gt;机器学习：如何找到最优学习率&lt;/a&gt;及&lt;a href=&#34;https://github.com/L1aoXingyu/torchlib&#34;&gt;实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/338066667&#34;&gt;神经网络中 warmup 策略为什么有效&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;不平衡数据集处理方法&lt;/a&gt;: &lt;a href=&#34;https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/&#34;&gt;其一&lt;/a&gt;, &lt;a href=&#34;https://www.zhihu.com/question/285824343&#34;&gt;其二&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/songhk0209/article/details/71484469&#34;&gt;其三&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/ZhiningLiu1998/awesome-imbalanced-learning&#34;&gt;Awesome Imbalanced Learning&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/vandit15/Class-balanced-loss-pytorch&#34;&gt;Class-balanced-loss-pytorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/41841299&#34;&gt;同一个神经网络使用不同激活函数的表达能力是否一致&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/ly244855983/article/details/78938667#%E8%AE%A8%E8%AE%BA&#34;&gt;论文笔记之数据增广：mixup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/44331706&#34;&gt;避坑指南：数据科学家新手常犯的13个错误&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://bindog.github.io/blog/2018/02/10/model-explanation/&#34;&gt;凭什么相信CNN的结果?--可视化&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://bindog.github.io/blog/2018/02/10/model-explanation/&#34;&gt;凭什么相信你，我的CNN模型？（篇一：CAM和Grad-CAM)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/jacobgil/pytorch-grad-cam&#34;&gt;pytorch-grad-cam&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/insikk/Grad-CAM-tensorflow&#34;&gt;Grad-CAM-tensorflow&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/Ankush96/grad-cam.tensorflow&#34;&gt;grad-cam.tensorflow&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/js-fan/mxnet/tree/d2b802e2d2af3dae5b4ac941354602630d2ef1c7/example/cnn_visualization&#34;&gt;cnn_visualization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;http://bindog.github.io/blog/2018/02/11/model-explanation-2/&#34;&gt;凭什么相信你，我的CNN模型？（篇二：万金油LIME)&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/294ad9ae2e50&#34;&gt;论文笔记:Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_41185868/article/details/80323646&#34;&gt;CV：基于Keras利用训练好的hdf5模型进行目标检测实现输出模型中的表情或性别的gradcam(可视化)&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;大卷积核还是小卷积核?&lt;/a&gt; &lt;a href=&#34;https://www.jianshu.com/p/d75375dd7ebd&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://blog.csdn.net/kuangtun9713/article/details/79475457&#34;&gt;2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://baijiahao.baidu.com/s?id=1608193373391996908&#34;&gt;模型可解释性差？你考虑了各种不确定性了吗？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;炼丹笔记系列&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56882616&#34;&gt;炼丹笔记一：样本不平衡问题&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56022212&#34;&gt;炼丹笔记二：数据清洗&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56139575&#34;&gt;炼丹笔记三：数据增强&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56365469&#34;&gt;炼丹笔记四：小样本问题&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56443169&#34;&gt;炼丹笔记五：数据标注&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56745640&#34;&gt;炼丹笔记六 : 调参技巧&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/57738934&#34;&gt;炼丹笔记七：卷积神经网络模型设计&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;刷排行榜的小技巧&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.leiphone.com/news/201803/XBjvQriKTyTMPLcz.html&#34;&gt;Kaggle 六大比赛最全面解析（上）&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.leiphone.com/news/201803/chz1DNHqgVWNEm5t.html&#34;&gt;Kaggle 六大比赛最全面解析（下）&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;图像分类&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56139575&#34;&gt;炼丹笔记三：数据增强&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/41679153&#34;&gt;数据增强(Data Augmentation)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/38345420&#34;&gt;【技术综述】 深度学习中的数据增强（上）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/38437739&#34;&gt;【技术综述】深度学习中的数据增强（下）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/144921458&#34;&gt;深度学习数据增广技术一览&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/53324148&#34;&gt;《Bag of Tricks for Image Classification with CNN》&lt;/a&gt;&amp;amp;&amp;amp; &lt;a href=&#34;https://arxiv.org/pdf/1812.01187.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/66080948&#34;&gt;深度神经网络模型训练中的最新tricks总结【原理与代码汇总】&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/59918821&#34;&gt;神经网络训练trick&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Kaggle解决方案分享&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.itcodemonkey.com/article/4898.html&#34;&gt;从0上手Kaggle图像分类挑战：冠军解决方案详解&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.leiphone.com/news/201803/u40cjEZWArBfFaBm.html&#34;&gt;Kaggle 冰山图像分类大赛近日落幕，看冠军团队方案有何亮点&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/_S8EBBJ-u9g_fHp7I3ChMQ?&#34;&gt;【Kaggle冠军分享】图像识别和分类竞赛，数据增强及优化算法&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58496385&#34;&gt;识别座头鲸，Kaggle竞赛第一名解决方案解读&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60953933&#34;&gt;kaggle 首战拿金牌总结&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37522227&#34;&gt;16岁高中生夺冠Kaggle地标检索挑战赛！而且竟然是Kaggle老兵&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37663895&#34;&gt;6次Kaggle计算机视觉类比赛赛后感&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/63275166&#34;&gt;Kaggle首战斩获第三-卫星图像识别&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;目标检测&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ensemble&lt;/li&gt; &#xA; &lt;li&gt;deformable&lt;/li&gt; &#xA; &lt;li&gt;sync bn&lt;/li&gt; &#xA; &lt;li&gt;ms train/test&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56792817&#34;&gt;目标检测任务的优化策略tricks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60612064&#34;&gt;目标检测小tricks--样本不均衡处理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/137769687&#34;&gt;汇总|目标检测中的数据增强、backbone、head、neck、损失函数&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/39262769&#34;&gt;目标检测算法中的常见trick&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/141878389&#34;&gt;Bag of Freebies —— 提升目标检测模型性能的免费tricks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/102817180&#34;&gt;目标检测比赛中的tricks（已更新更多代码解析）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/50158f8daf0d&#34;&gt;Kaggle：肺癌自动诊断系统3D Deep Leaky Noisy-or Network 论文阅读&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://yq.aliyun.com/articles/89312&#34;&gt;干货|大神教你如何参加kaggle比赛——根据CT扫描图预测肺癌&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;五. 年度总结&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/53717510&#34;&gt;新年大礼包：机器之心2018高分教程合集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/104022144&#34;&gt;收藏、退出一气呵成，2019年机器之心干货教程都在这里了&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;六. 科研相关&lt;/h2&gt; &#xA;&lt;h3&gt;深度学习框架&lt;/h3&gt; &#xA;&lt;h4&gt;Python3.x(先修)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.python.org/3/tutorial/&#34;&gt;The Python Tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000&#34;&gt;廖雪峰Python教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.runoob.com/python3/python3-tutorial.html&#34;&gt;菜鸟教程&lt;/a&gt; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24162430&#34;&gt;给深度学习入门者的Python快速教程 - 基础篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jackfrued/Python-100-Days&#34;&gt;Python - 100天从新手到大师&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u010472607/article/details/78855816&#34;&gt;Python中读取,显示,保存图片的方法&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/weixin_37619439/article/details/86559239&#34;&gt;Python的图像打开保存显示的几种方式&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Numpy(先修)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.numpy.org/devdocs/user/quickstart.html&#34;&gt;Quickstart tutorial&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.jianshu.com/p/3e566f09a0cf&#34;&gt;Numpy快速入门(Numpy 1.14 官方文档中文翻译)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://www.numpy.org.cn/index.html&#34;&gt;Numpy中文文档&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24309547&#34;&gt;给深度学习入门者的Python快速教程 - numpy和Matplotlib篇&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Opencv-python&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html&#34;&gt;OpenCV-Python Tutorials&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/Undo-self-blog/p/8423851.html&#34;&gt;OpenCV官方教程中文版（For Python）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/feilong_csdn/article/category/8037591&#34;&gt;数字图像处理系列&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_40962368/article/category/7688903&#34;&gt;python+OpenCV图像处理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24425116&#34;&gt;给深度学习入门者的Python快速教程 - 番外篇之Python-OpenCV&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Pandas&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/d9774cf1fea5?utm_campaign=maleskine&amp;amp;utm_content=note&amp;amp;utm_medium=seo_notes&amp;amp;utm_source=recommendation&#34;&gt;Python 数据科学入门教程：Pandas&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Tensorflow&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/41667903&#34;&gt;如何高效地学习 TensorFlow 代码&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.tensorfly.cn/tfdoc/tutorials/overview.html&#34;&gt;中文教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.w3cschool.cn/tensorflow_python/&#34;&gt;TensorFlow官方文档&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs20si/syllabus.html&#34;&gt;CS20:Tensorflow for DeepLearning Research&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62981537&#34;&gt;吴恩达TensorFlow专项课程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35515805?group_id=967136289941897216&#34;&gt;【干货】史上最全的Tensorflow学习资源汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hzy46/Deep-Learning-21-Examples&#34;&gt;《21个项目玩转深度学习———基于TensorFlow的实践详解》&lt;/a&gt; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59507137&#34;&gt;最全Tensorflow2.0 入门教程持续更新&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/search?o=desc&amp;amp;q=tensorflow+tutorial&amp;amp;s=&amp;amp;type=Repositories&#34;&gt;Github优秀开源教程&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;MXNet&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://zh.gluon.ai/#&#34;&gt;Gluon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gluon-cv.mxnet.io/index.html#&#34;&gt;GluonCV&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://gluon-nlp.mxnet.io/&#34;&gt;GluonNLP&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;PyTorch&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ShusenTang/Dive-into-DL-PyTorch&#34;&gt;Pytorch版动手学深度学习&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch-cn.readthedocs.io/zh/latest/&#34;&gt;PyTorch中文文档&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pytorch.org/tutorials/index.html&#34;&gt;WELCOME TO PYTORCH TUTORIALS&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/64895011&#34;&gt;史上最全的PyTorch学习资源汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/INTERMT/Awesome-PyTorch-Chinese&#34;&gt;【干货】史上最全的PyTorch学习资源汇总&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mlelarge.github.io/dataflowr-web/cea_edf_inria.html&#34;&gt;Hands-on tour to deep learning with PyTorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/cfca9c4338e7&#34;&gt;pytorch学习(五)—图像的加载/读取方式&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/wsp_1138886114/article/details/83620869&#34;&gt;PyTorch—ImageFolder/自定义类 读取图片数据&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;深度学习常用命令&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Stephenfang51/command_for_deeplearning/raw/master/command%20for%20deeplearning.md&#34;&gt;command_for_deeplearning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/102176365&#34;&gt;Shell编程&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Python可视化&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/&#34;&gt;Top 50 matplotlib Visualizations – The Master Plots (with full python code)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zhw864680355/article/details/102500263&#34;&gt;Python之MatPlotLib使用教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/UfvEdzr-ZGmyT08yKDOchA&#34;&gt;十分钟上手matplotlib，开启你的python可视化&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/24309547&#34;&gt;给深度学习入门者的Python快速教程 - numpy和Matplotlib篇&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;标注工具&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;目标检测标注工具 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/tzutalin/labelImg&#34;&gt;labelImg&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;语义分割标注工具 &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/wkentaro/labelme&#34;&gt;labelme&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;数据集&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35449783&#34;&gt;1. 25个深度学习相关公开数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35423943&#34;&gt;2. 自然语言处理（NLP）数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pan.baidu.com/s/1o7QlUhO&#34;&gt;3.全唐诗(43030首)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~taesung_park/&#34;&gt;4. 伯克利大学公开数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36835964&#34;&gt;5. ACL 2018资源：100+ 预训练的中文词向量&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Embedding/Chinese-Word-Vectors&#34;&gt;6. 预训练中文词向量&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://academictorrents.com&#34;&gt;7. 公开数据集种子库&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/c20081052/article/details/79814082&#34;&gt;8. 计算机视觉，深度学习，数据挖掘数据集整理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/accepthjp/article/details/51831026&#34;&gt;9. 计算机视觉著名数据集CV Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/NNNNNNNNNNNNY/article/details/68485160&#34;&gt;10. 计算机视觉相关数据集和比赛&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/43846002&#34;&gt;11. 这是一份非常全面的开源数据集，你，真的不想要吗？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_40516558/article/details/81564464&#34;&gt;12. 人群密度估计现有主要数据集特点及其比较&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gwern.net/Danbooru2017&#34;&gt;13. DANBOORU2017: A LARGE-SCALE CROWDSOURCED AND TAGGED ANIME ILLUSTRATION DATASET&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://robustsystems.coe.neu.edu/sites/robustsystems.coe.neu.edu/files/systems/projectpages/reiddataset.html&#34;&gt;14. 行人重识别数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/56144877&#34;&gt;15. 自然语言处理常见数据集、论文最全整理分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/&#34;&gt;16. paper, code, sota&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/55627416&#34;&gt;17. 旷视RPC大型商品数据集发布！&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/60617001&#34;&gt;18. CVPR 2019「准满分」论文：英伟达推出首个跨摄像头汽车跟踪数据集(汽车Re-ID)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/59052013&#34;&gt;19.【OCR技术】大批量生成文字训练集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/msra-nlc/MSParS&#34;&gt;20. 语义分析数据集-MSRA&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ieee-dataport.org/&#34;&gt;IEEE DataPort&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.shujujishi.com/&#34;&gt;数据集市&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;医疗/医学图像数据集&lt;/a&gt;：&lt;a href=&#34;https://github.com/beamandrew/medical-data&#34;&gt;Medical Data for Machine Learning&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://grand-challenge.org/challenges/&#34;&gt;医疗领域图像挑战赛数据集&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/qq_31622015/article/details/90573874&#34;&gt;【医学影像系列：一】数据集合集 最新最全&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://github.com/sfikas/medical-imaging-datasets&#34;&gt;medical-imaging-datasets&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/50615907&#34;&gt;【数据集】一文道尽医学图像数据集与竞赛&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/102855802&#34;&gt;医学图像数据集汇总&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;记笔记工具&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67153848&#34;&gt;Markdown编辑器：Typora介绍&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/47897214&#34;&gt;Markdown语法介绍（常用）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/witnessai1/article/details/52551362&#34;&gt;Markdown 语法手册 （完整整理版）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014630987/article/details/70156489&#34;&gt;Markdown中Latex 数学公式基本语法&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;会议期刊列表&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/JackieTseng/conference_call_for_paper&#34;&gt;国际会议日期表&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/abhshkdz/ai-deadlines/&#34;&gt;ai-deadlines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://handong1587.github.io/deep_learning/2017/12/18/keep-up-with-new-trends.html&#34;&gt;Keep Up With New Trends&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/cserchen/article/details/40508181&#34;&gt;计算机会议排名等级&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.ccf.org.cn/Academic_Evaluation/By_category/&#34;&gt;中国计算机学会(CCF)推荐国际学术刊物和会议&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;论文写作工具&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jingyan.baidu.com/article/b2c186c83c9b40c46ff6ff4f.html&#34;&gt;Windows: Texlive+Texstudio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://jingyan.baidu.com/article/7c6fb4280b024180642c90e4.html&#34;&gt;Ubuntu: Texlive+Texmaker&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/quiet_girl/article/details/72847208&#34;&gt;Latex：基本用法、表格、公式、算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/garfielder007/article/details/51646604&#34;&gt;LaTeX 各种命令，符号&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;论文画图工具&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://msdn.itellyou.cn/&#34;&gt;Visio2016&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Mikoto10032/DeepLearning/master/#Python%E5%8F%AF%E8%A7%86%E5%8C%96&#34;&gt;Matplotlib&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;论文写作教程&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58752815&#34;&gt;刘知远_如何写一篇合格的NLP论文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://nlp.csai.tsinghua.edu.cn/~ly/talks/cwmt14_tut.pdf&#34;&gt;刘洋_如何写论文_V7&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://xpqiu.github.io/slides/20181019-PaperWriting.pdf&#34;&gt;如何端到端地写科研论文-邱锡鹏&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/33876355&#34;&gt;论文Introduction写作其一&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/52494933&#34;&gt;论文Introduction写作其二&lt;/a&gt;, &lt;a href=&#34;https://zhuanlan.zhihu.com/p/52494879&#34;&gt;论文Introduction写作其三&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/c_179195484&#34;&gt;毕业论文怎么写&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/104298923&#34;&gt;浅谈学术论文rebuttal&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/344008879&#34;&gt;学术论文投稿与返修（Rebuttal）分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/rationalscience-writing-lab&#34;&gt;研之成理写作实验室&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;智源论坛·论文写作专题报告会&lt;/a&gt;：&lt;a href=&#34;https://zhuanlan.zhihu.com/p/135989892&#34;&gt;《论文写作小白的成长之路》&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/136005095&#34;&gt;《谈如何写一篇合格的国际学术论文》&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/139571199&#34;&gt;《计算机视觉会议论文从投稿到接收》&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;ResearchGos&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22323250?refer=wjdml&#34;&gt;ResearchGo:研究生活第一帖——文献检索与管理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22402393?refer=wjdml&#34;&gt;ResearchGo:研究生活第二贴——文献阅读&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22622502?refer=wjdml&#34;&gt;ResearchGo:研究生活第三帖——阅读辅助&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23178836?refer=wjdml&#34;&gt;ResearchGo:研究生活第四帖——文献调研&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23356843?refer=wjdml&#34;&gt;ResearchGo:研究生活第五帖——文献综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/23872063?refer=wjdml&#34;&gt;ResearchGo:研究生活第六帖——如何讲论文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25191025&#34;&gt;ResearchGo:研究生活第七帖——专利检索与申请&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62100815&#34;&gt;ResearchGo:研究生活第八帖——写论文、做PPT、写文档必备工具集锦&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;毕业论文排版&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/52495345&#34;&gt;吐血推荐收藏的学位论文排版教程（完整版）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35951260&#34;&gt;论文怎么写——如何修改毕业论文格式&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;信号处理&lt;/h2&gt; &#xA;&lt;h3&gt;傅里叶变换&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/19763358&#34;&gt;傅里叶分析之掐死教程（完整版）更新于2014.06.06&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/34899574/answer/612923473&#34;&gt;如何简明的总结傅里叶变换？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/clover13/article/details/79469851&#34;&gt;从连续时间傅里叶级数到快速傅里叶变换&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/enjoy_pascal/article/details/81478582&#34;&gt;十分简明易懂的FFT（快速傅里叶变换）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hanxiaohu88/article/details/8245687&#34;&gt;傅里叶级数推导过程&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;小波变换&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/22450818&#34;&gt;形象易懂讲解算法I——小波变换&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/44215123&#34;&gt;小波变换完美通俗讲解系列之 （一）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/44217268&#34;&gt;小波变换完美通俗讲解系列之 （二）&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;实战&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/wanghui-garcia/p/12524515.html&#34;&gt;MWCNN中使用的haar小波变换 pytorch&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/baidu_27643275/article/details/84826773&#34;&gt;【小波变换】小波变换入门----haar小波&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hhaowang/article/details/82909332&#34;&gt;（3）小波变换原理及应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_30815237/article/details/89704855&#34;&gt;图像处理-小波变换&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;机器学习理论与实战&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/shunliz/Machine-Learning&#34;&gt;机器学习原理&lt;/a&gt;&lt;span&gt;⭐&lt;/span&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34534004&#34;&gt;ID3、C4.5、CART、随机森林、bagging、boosting、Adaboost、GBDT、xgboost算法总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/en-heng/p/5013995.html&#34;&gt;数据挖掘十大算法简要说明&lt;/a&gt;，&lt;a href=&#34;https://blog.csdn.net/qq_42379006/article/details/80741808&#34;&gt;机器学习十大经典算法入门&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/ljt1412451704/p/9678248.html&#34;&gt;【算法模型】轻松看懂机器学习十大常用算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;AdaBoost到GBDT系列&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25096501?refer=data-miner&#34;&gt;当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25257856?refer=data-miner&#34;&gt;当我们在谈论GBDT：Gradient Boosting 用于分类与回归&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25443980&#34;&gt;当我们在谈论GBDT：其他 Ensemble Learning 算法&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;机器学习理论篇之经典算法&lt;/h3&gt; &#xA;&lt;h4&gt;信息论&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35423404&#34;&gt;1. 机器学习中的各种熵&lt;/a&gt; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/32985487&#34;&gt;2. 从香农熵到手推KL散度：纵览机器学习中的信息论&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;多层感知机(MLP)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/baidu_33718858/article/details/84972537&#34;&gt;多层感知机（MLP）学习与总结博客&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/xholes/article/details/78461164&#34;&gt;多层感知机：Multi-Layer Perceptron&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/weixin_38206214/article/details/81137911&#34;&gt;神经网络基础-多层感知器(MLP)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;k近邻(KNN)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/sinat_30353259/article/details/80901746&#34;&gt;机器学习之KNN（k近邻）算法详解&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;k均值(K-means)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_32892383/article/details/80107795&#34;&gt;Kmeans聚类算法详解&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;朴素贝叶斯(Naive Bayesian)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_23947237/article/details/78265026&#34;&gt;一个例子搞清楚（先验分布/后验分布/似然估计）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_32690999/article/details/78737393&#34;&gt;朴素贝叶斯分类器（Naive Bayesian Classifier）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_17073497/article/details/81076250&#34;&gt;朴素贝叶斯分类器 详细解析&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;决策树(Decision Tree)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/lXaPZyNrgG9LBv-JHdGm9A&#34;&gt;最常见核心的决策树算法详细介绍，含ID3、C4.5、CART&lt;span&gt;⭐&lt;/span&gt;&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://mp.weixin.qq.com/s/Nl_-PdF0nHBq8yGp6AdI-Q&#34;&gt;最常用的决策树算法！Random Forest、Adaboost、GBDT 算法&lt;span&gt;⭐&lt;/span&gt;&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ&#34;&gt;终于有人把XGBoost 和 LightGBM 讲明白了，项目中最主流的集成算法！&lt;span&gt;⭐&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://blog.itblood.com/4082.html&#34;&gt;为什么xgboost要用泰勒展开，优势在哪里&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/c406495762/article/details/75663451&#34;&gt;Python3《机器学习实战》学习笔记（二）：决策树基础篇之让我们从相亲说起&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/c406495762/article/details/76262487&#34;&gt;Python3《机器学习实战》学习笔记（三）：决策树实战篇之为自己配个隐形眼镜&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://cuijiahua.com/blog/2017/12/ml_13_regtree_1.html&#34;&gt;机器学习实战教程（十三）：树回归基础篇之CART算法与树剪枝&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/gamer_gyt/article/details/51242815&#34;&gt;《机器学习实战》基于信息论的三种决策树算法(ID3,C4.5,CART)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31404571&#34;&gt;说说决策树剪枝算法&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/namelessml/article/details/52595066&#34;&gt;机器学习实战 第九章 树回归&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014688145/article/details/53212112&#34;&gt;决策树值ID3、C4.5实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u014688145/article/details/53326910&#34;&gt;决策树之CART实现&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;随机森林(Random Forest)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/login_sonata/article/details/73929426&#34;&gt;随机森林和GBDT的区别&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/sb19931201/article/details/52601058&#34;&gt;随机森林（Random Forest）入门与实战&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/justcxtoworld/p/3447231.html&#34;&gt;随机森林之特征选择&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;线性回归（Linear Regression）&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/lt793843439/article/details/91392646&#34;&gt;线性回归最小二乘法和最大似然估计&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/147297924&#34;&gt;【从入门到放弃】线性回归&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/z_feng12489/article/details/101388745&#34;&gt;线性回归(频率学派-最大似然估计)与岭回归(贝叶斯角度-最大后验估计)的概率解释&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/xierhacker/article/details/53316138&#34;&gt;机器学习笔记四：线性回归回顾与logistic回归&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;逻辑回归(Logistic Regression)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/100763009&#34;&gt;【机器学习面试总结】—— LR（逻辑回归）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62653034&#34;&gt;【机器学习面试题】逻辑回归篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/9d2686cd407e&#34;&gt;极大似然概率和最小损失函数，以及正则化简介&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/Cdd2xd/article/details/75635688&#34;&gt;GLM(广义线性模型) 与 LR(逻辑回归) 详解&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;支持向量机(SVM)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/93715996&#34;&gt;【机器学习面试总结】—— SVM&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61123737&#34;&gt;SVM系列-从基础到掌握&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%80%9A%E4%BF%97%E5%AF%BC%E8%AE%BA%EF%BC%88%E7%90%86%E8%A7%A3SVM%E7%9A%84%E4%B8%89%E5%B1%82%E5%A2%83%E7%95%8C%EF%BC%89LaTeX%E6%9C%80%E6%96%B0%E7%89%88_2015.1.9.pdf&#34;&gt;SVM通俗导论 July&lt;/a&gt;&amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;核函数 &lt;/a&gt;: &lt;a href=&#34;https://www.zhihu.com/question/24627666&#34;&gt;机器学习有很多关于核函数的说法，核函数的定义和作用是什么？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/35602879&#34;&gt;SVM中，高斯核为什么会把原始维度映射到无穷多维？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/leonis_v/article/details/50688766&#34;&gt;svm核函数的理解和选择&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/huang1024rui/article/details/51510611&#34;&gt;核函数和径向基核函数 (Radial Basis Function)--RBF&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/xiaowei_cqu/article/details/35993729&#34;&gt;SVM核函数&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;提升方法(Adaboost)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25096501&#34;&gt;当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;梯度提升决策树(GBDT)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35645973&#34;&gt;LightGBM大战XGBoost&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34698733&#34;&gt;概述XGBoost、Light GBM和CatBoost的同与不同&lt;/a&gt; &amp;nbsp; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.cnblogs.com/lvdongjie/p/11391245.html&#34;&gt;XGBoost、LightGBM、Catboost总结&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/34698733&#34;&gt;XGBoost、Light GBM和CatBoost的参数及性能比较&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36339161&#34;&gt;梯度提升决策树&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30339807&#34;&gt;GBDT原理及应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/31654000&#34;&gt;XGBOOST原理篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/sb19931201/article/details/52557382&#34;&gt;xgboost入门与实战（原理篇）&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://blog.csdn.net/sb19931201/article/details/52577592&#34;&gt;xgboost入门与实战（实战调参篇）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/41417638&#34;&gt;【干货合集】通俗理解kaggle比赛大杀器xgboost&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/bf02jgtrs00xktcx/article/details/82719765&#34;&gt;GBDT分类的原理及Python实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/shine19930820/article/details/71713680&#34;&gt;GBDT原理及利用GBDT构造新的特征-Python实现&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/47e73a985ba1&#34;&gt;Python+GBDT算法实战——预测实现100%准确率&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/m0_37870649/article/details/104561431&#34;&gt;xgboost之近似分位数算法（直方图算法）详解&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;EM(期望最大化)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/36331115&#34;&gt;人人都懂的EM算法 &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61768577&#34;&gt;EM算法入门文章&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;高斯混合模型(GMM)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/67107370&#34;&gt;高斯混合模型与EM算法的数学原理及应用实例&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30483076&#34;&gt;高斯混合模型（GMM）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;马尔科夫决策过程(MDP)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35124726&#34;&gt;马尔科夫决策过程之Markov Processes（马尔科夫过程）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35231424&#34;&gt;马尔科夫决策过程之Markov Reward Process（马尔科夫奖励过程）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35261164&#34;&gt;马尔科夫决策过程之Bellman Equation（贝尔曼方程）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35354956&#34;&gt;马尔科夫决策过程之Markov Decision Process(马尔科夫决策过程)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35373905&#34;&gt;马尔科夫决策过程之最优价值函数与最优策略&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;条件随机场(CRF, 判别式模型)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/104562658&#34;&gt;如何轻松愉快地理解条件随机场&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/35866596&#34;&gt;如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u013378306/article/details/55213029&#34;&gt;HMM ,MHMM,CRF 优缺点与区别&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;降维算法&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/62470700&#34;&gt;数据降维算法-从PCA到LargeVis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/43225794&#34;&gt;12种降维方法终极指南（含Python代码）&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;主成分分析(PCA)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/program_developer/article/details/80632779&#34;&gt;主成分分析（PCA）原理详解&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/hustqb/article/details/78394058&#34;&gt;图文并茂的PCA教程&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.360doc.com/content/13/1124/02/9482_331688889.shtml&#34;&gt;PCA数学原理&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;奇异值分解(SVD)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html&#34;&gt;强大的矩阵奇异值分解(SVD)及其应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/29846048&#34;&gt;奇异值分解（SVD）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zhongkejingwang/article/details/43053513&#34;&gt;奇异值分解(SVD)原理详解及推导&lt;/a&gt; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zhongkejingwang/article/details/43083603&#34;&gt;SVD在推荐系统中的应用详解以及算法推导&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;线性判别分析(LDA)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/42238953&#34;&gt;教科书上的LDA为什么长这个样子？&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;标签传播算法(Label Propagation Algorithm) &amp;nbsp; &amp;nbsp;&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/zouxy09/article/details/49105265&#34;&gt;标签传播算法（Label Propagation）及Python实现&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/books/Semi-Supervised%20Learning%20with%20Graphs.pdf&#34;&gt;参考资料&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;蒙塔卡罗树搜索(MCTS)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34950988&#34;&gt;蒙特卡洛树搜索入门指南&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;集成(Ensemble)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/41809927&#34;&gt;集成学习之bagging,stacking,boosting概念理解&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/follow&#34;&gt;Bagging和Boosting的总结&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_30189255/article/details/51532442&#34;&gt;集成学习法之bagging方法和boosting方法&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/Mr_tyting/article/details/72957853&#34;&gt;Bagging,Boosting,Stacking&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/65888174&#34;&gt;常用的模型集成方法介绍：bagging、boosting 、stacking&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;t分布随机邻居嵌入(TSNE)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/u012162613/article/details/45920827&#34;&gt;流形学习-高维数据的降维与可视化&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/flyingzhan/article/details/79521765&#34;&gt;tSNE&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/81400277&#34;&gt;使用t-SNE可视化图像embedding&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;谱聚类(Spectral Clustering)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/qq_24519677/article/details/82291867&#34;&gt;谱聚类（Spectral Clustering）算法介绍&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/xueyingxue001/article/details/51966980&#34;&gt;聚类5--谱和谱聚类&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;异常点检测&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/280696035/answer/417091151&#34;&gt;数据挖掘中常见的「异常检测」算法有哪些？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/30169110&#34;&gt;异常点检测算法综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/RYLlUJiYbWqGIhzflbRGEg&#34;&gt;异常检测的N种方法，其中有一个你一定想不到&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/158349346&#34;&gt;异常检测资源汇总：anomaly-detection-resources&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;机器学习实战篇&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/28641663&#34;&gt;机器学习中，有哪些特征选择的工程方法？&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/103070096&#34;&gt;机器学习（四）：数据预处理--特征工程概述&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/94994902&#34;&gt;特征工程完全手册 - 从预处理、构造、选择、降维、不平衡处理，到放弃&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://www.zhihu.com/question/20455227&#34;&gt;特征工程中的「归一化」有什么作用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&amp;amp;mid=2247484110&amp;amp;idx=1&amp;amp;sn=b016e270d7b7707e6ad41a81ca45fc28&amp;amp;chksm=c0791fd7f70e96c103a8a2aebee166ce14f5648b3b889dd85dd9786f48b6b8269f11e5e27e1c&amp;amp;scene=21#wechat_redirect&#34;&gt;15分钟带你入门sklearn与机器学习——分类算法篇&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/62034592&#34;&gt;如何为你的回归问题选择最合适的机器学习方法？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/105039597&#34;&gt;十分钟上手sklearn：安装，获取数据，数据预处理&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/105041301&#34;&gt;十分钟上手sklearn：特征提取，常用模型，交叉验证&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/lawlite19/MachineLearning_Python&#34;&gt;MachineLearning_Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/machinelearningmindset/machine-learning-course&#34;&gt;Machine Learning Course with Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Dod-o/Statistical-Learning-Method_Code&#34;&gt;Statistical-Learning-Method_Code&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/c406495762/column/info/16415&#34;&gt;Python3机器学习&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jianshu.com/p/9d2452fc93c2&#34;&gt;含大牛总结的分类模型一般需要调节的参数&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;机器学习、深度学习的一些研究方向&lt;/h2&gt; &#xA;&lt;h3&gt;多任务学习(Multi-Task Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27421983&#34;&gt;模型汇总-14 多任务学习-Multitask Learning概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://www.cnblogs.com/shuzirank/p/7141017.html&#34;&gt;(译)深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/138597214&#34;&gt;Multi-task Learning and Beyond: 过去，现在与未来&lt;/a&gt;；&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;零次学习(Zero Shot Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34656727&#34;&gt;零次学习（Zero-Shot Learning）入门&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;小样本学习(Few-Shot Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/xhw205/article/details/79491649&#34;&gt;few-shot learning是什么&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34656727&#34;&gt;零次学习（Zero-Shot Learning）入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/61215293&#34;&gt;小样本学习（Few-shot Learning）综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/few-shot-learning-in-cvpr19-6c6892fc8c5&#34;&gt;Few-Shot Learning in CVPR 2019&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_feng/article/details/78939864&#34;&gt;当小样本遇上机器学习 fewshot learning&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;多视觉学习(Multi-View Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/danliwoo/article/details/79278574&#34;&gt;Multi-view Learning 多视角学习入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/shine19930820/article/details/77426599&#34;&gt;多视角学习 (Multi-View Learning)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;嵌入(Embedding)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/53194407&#34;&gt;万物皆Embedding，从经典的word2vec到深度学习基本操作item2vec&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27830489&#34;&gt;YJango的Word Embedding--介绍&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;迁移学习(Transfer Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/linolzhang/article/details/73358219&#34;&gt;1. 迁移学习：经典算法解析&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/41979241&#34;&gt;2. 什么是迁移学习 (Transfer Learning)？这个领域历史发展前景如何？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Mikoto10032/DeepLearning/raw/master/notes/%E6%97%A5%E5%B8%B8%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/2018_4_12_%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.pdf&#34;&gt;3. 迁移学习个人笔记&lt;/a&gt; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/XJTU_NOC_Wei/article/details/77850221&#34;&gt;迁移学习总结(One Shot Learning, Zero Shot Learning)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;域自适应(Domain Adaptation)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27519182&#34;&gt;Domain Adaptation视频教程（附PPT）及经典论文分享&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27449079&#34;&gt;模型汇总15 领域适应性Domain Adaptation、One-shot/zero-shot Learning概述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/mao_xiao_feng/article/details/54426101&#34;&gt;【深度学习】论文导读：无监督域适应（Deep Transfer Network: Unsupervised Domain Adaptation）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37298073&#34;&gt;【论文阅读笔记】基于反向传播的无监督域自适应研究&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/21441807&#34;&gt;【Valse大会首发】领域自适应及其在人脸识别中的应用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/41126114&#34;&gt;CVPR 2018：基于域适应弱监督学习的目标检测&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;元学习(Meta Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35869158?group_id=970310501209645056&#34;&gt;OpenAI提出新型元学习方法EPG，调整损失函数实现新任务上的快速训练&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;强化学习(Reinforcement Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25498081&#34;&gt;强化学习（Reinforcement Learning）知识整理&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34918639&#34;&gt;强化学习从入门到放弃的资料&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25498081&#34;&gt;强化学习入门&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25498081&#34;&gt;强化学习入门 第一讲 MDP&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35882937&#34;&gt;强化学习——从Q-Learning到DQN到底发生了什么？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35688924&#34;&gt;从强化学习到深度强化学习（上）&lt;/a&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35965070&#34;&gt;从强化学习到深度强化学习（下）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/37048004&#34;&gt;一文带你理解Q-Learning的搜索策略&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;对比学习(Contrastive Learning)&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/asheeshcric/awesome-contrastive-self-supervised-learning&#34;&gt;论文列表&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/367290573&#34;&gt;对比学习（Contrastive Learning）:研究进展精要&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/346686467&#34;&gt;对比学习（Contrastive Learning）综述&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/357071960&#34;&gt;理解对比损失的性质以及温度系数的作用&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;推荐系统(Recommendation System)&lt;/h3&gt; &#xA;&lt;h4&gt;论文列表&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/58805184&#34;&gt;Embedding从入门到专家必读的十篇论文&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wzhe06/Reco-papers&#34;&gt;Reco-papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/wzhe06/Ad-papers&#34;&gt;Ad-papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/chocoluffy/deep-recommender-system&#34;&gt;deep-recommender-system&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/243243145&#34;&gt;CTR预估系列入门手册&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;教程&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/27502172&#34;&gt;推荐系统从入门到接着入门&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/133528693&#34;&gt;深度学习推荐系统笔记&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/34004488&#34;&gt;推荐系统干货总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54819505&#34;&gt;入门推荐系统，你不应该错过的知识清单&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/259985388&#34;&gt;从零开始了解推荐系统全貌&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/148207613&#34;&gt;推荐系统玩家 之 推荐系统入门——推荐系统的发展历程（上）&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/100019681&#34;&gt;推荐系统技术演进趋势：从召回到排序再到重排&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/115690499&#34;&gt;深入理解推荐系统：召回&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/138235048&#34;&gt;深入理解推荐系统：排序&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/423384620/answer/1687201890&#34;&gt;召回算法有哪些&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/138446984&#34;&gt;《深度学习推荐系统》总结系列一&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/140894123&#34;&gt;《深度学习推荐系统》总结系列二&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/81752025&#34;&gt;推荐系统--完整的架构设计和算法(协同过滤、隐语义)&lt;/a&gt; &amp;amp;&amp;amp; &lt;a href=&#34;https://zhuanlan.zhihu.com/p/123951784&#34;&gt;从0到1打造推荐系统-架构篇&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zhihu.com/question/19971859&#34;&gt;协同过滤和基于内容推荐有什么区别？&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/257895631&#34;&gt;CTR深度交叉特征入门总结&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://blog.csdn.net/wuzhongqiang/category_10128687.html&#34;&gt;推荐系统学习笔记&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;实战&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/zhongqiangwu960812/AI-RecommenderSystem&#34;&gt; AI-RecommenderSystem&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/datawhalechina/team-learning-rs&#34;&gt;team-learning-rs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Magic-Bubble/RecommendSystemPractice&#34;&gt;RecommendSystemPractice&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://surpriselib.com/&#34;&gt;Surprise&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>