<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-14T01:37:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>DataTalksClub/stock-markets-analytics-zoomcamp</title>
    <updated>2024-04-14T01:37:11Z</updated>
    <id>tag:github.com,2024-04-14:/DataTalksClub/stock-markets-analytics-zoomcamp</id>
    <link href="https://github.com/DataTalksClub/stock-markets-analytics-zoomcamp" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Course Materials for Analytics in Stock Markets Zoomcamp&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stock Market Analytics Zoomcamp&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSc5H6Jc-HJg9B7irveRASJCAS4BTnJcvM2QX2ykIGZ0UNgCPQ/viewform&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/875246/185755203-17945fd1-6b64-46f2-8377-1011dcb1a444.png&#34; height=&#34;50&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;b&gt;TODO List before the course starts: &lt;/b&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Subscribe to &lt;a href=&#34;https://pythoninvest.com/&#34;&gt;PythonInvest&lt;/a&gt; to receive analytics and future courses announcements.&lt;/li&gt; &#xA; &lt;li&gt;Register in &lt;a href=&#34;https://datatalks.club/slack.html&#34;&gt;DataTalks.Club&#39;s Slack&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Join the &lt;a href=&#34;https://datatalks-club.slack.com/archives/C06L1RTF10F&#34;&gt;&lt;code&gt;#course-stocks-analytics-zoomcamp&lt;/code&gt;&lt;/a&gt; channel&lt;/li&gt; &#xA; &lt;li&gt;Join the &lt;a href=&#34;https://t.me/stockanalyticszoomcamp&#34;&gt;course Telegram channel with announcements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The videos are published on &lt;a href=&#34;https://www.youtube.com/@pythoninvest2480&#34;&gt;PythonInvest&#39;s YouTube channel&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1ABQD6ns4vZHKu2dHGqqJ85LCOF7LzxqfvWBVXb_-M9E/edit?usp=sharing&#34;&gt;Frequently asked technical questions&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;b&gt;(Short) Syllabus (published on &lt;a href=&#34;https://pythoninvest.com/course&#34;&gt;PythonInvest&#39;s website&lt;/a&gt;) &lt;/b&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#Module-1-Introduction-and-Data-Sources&#34;&gt;Module 1: Introduction and Data Sources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#Module-2-Working-with-the-Data-(in-Pandas)&#34;&gt;Module 2: Working with the Data (in Pandas)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#Module-3-Analytical-Modeling&#34;&gt;Module 3: Analytical Modeling&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#Module-4-Trading-Strategy-and-Simulation&#34;&gt;Module 4: Trading Strategy and Simulation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#Module-5-Deployment-and-Automation&#34;&gt;Module 5: Deployment and Automation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/#project&#34;&gt;Project&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Taking the course&lt;/h2&gt; &#xA;&lt;h3&gt;2024 Cohort&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start&lt;/strong&gt;: 15 April 2024 (Monday) at 17:00 GMT&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Registration Form&lt;/strong&gt;: &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSc5H6Jc-HJg9B7irveRASJCAS4BTnJcvM2QX2ykIGZ0UNgCPQ/viewform&#34;&gt;LINK&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/cohorts/2024/&#34;&gt;Cohort folder&lt;/a&gt; with homeworks and deadlines&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Pre-Launch stream with course overview and Q&amp;amp;A (streamed on 25th March 2024)&lt;/strong&gt;:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oswTLnjkRUg&amp;amp;list=PLSWnIAnueyu8auG0v3VXfUkVJpLoeCJYF&amp;amp;index=1&#34;&gt;YouTube video&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/e/2PACX-1vSV8yZ6edMcJGvVuPWJxfict7pDI1YG8Ddbef7wRfnSEz_Q-59LUr60fcvYChF5dg-sSKzGkYQUPyif/pub?start=false&amp;amp;loop=false&amp;amp;delayms=3000&amp;amp;slide=id.g1d0e930b61f_0_81&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Supplementary pre-read for the project selection:&lt;/strong&gt;&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;Any recent financial news or analytics:&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Weekly news coverage on PythonInvest&#39;s Financial News Feed: &lt;a href=&#34;https://pythoninvest.com/&#34;&gt;https://pythoninvest.com/&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Analytical long-reads on PythonInvest&#39;s Blog: &lt;a href=&#34;https://pythoninvest.com/blog&#34;&gt;https://pythoninvest.com/blog&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Simply Wall St Market Insights: &lt;a href=&#34;https://simplywall.st/markets/insights&#34;&gt;https://simplywall.st/markets/insights&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Investing on CNBC: &lt;a href=&#34;https://www.cnbc.com/investing/&#34;&gt;https://www.cnbc.com/investing/&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Unhedged podcast and articles: &lt;a href=&#34;https://unhedged.ft.com/&#34;&gt;https://unhedged.ft.com/&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Yahoo Finance: &lt;a href=&#34;https://finance.yahoo.com/&#34;&gt;https://finance.yahoo.com/&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Books (note: these are affiliate links to Amazon):&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://amzn.to/3PJLADW&#34;&gt;Unknown Market Wizards (latest edition)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://amzn.to/3TYKruy&#34;&gt;The Man Who Solved the Market&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://amzn.to/3TYM5MN&#34;&gt;The Tao of Trading: How to Build Abundant Wealth in Any Market Condition&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Self-paced mode&lt;/h3&gt; &#xA;&lt;p&gt;All the materials of the course are freely available, so that you can take the course at your own pace&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow the suggested syllabus (see below) week by week&lt;/li&gt; &#xA; &lt;li&gt;You don&#39;t need to fill in the registration form. Just start watching the videos and join Slack&lt;/li&gt; &#xA; &lt;li&gt;Check &lt;a href=&#34;https://docs.google.com/document/d/1ABQD6ns4vZHKu2dHGqqJ85LCOF7LzxqfvWBVXb_-M9E/edit?usp=sharing&#34;&gt;FAQ&lt;/a&gt; if you have problems&lt;/li&gt; &#xA; &lt;li&gt;If you can&#39;t find a solution to your problem in FAQ, ask for help in Slack&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;(Detailed) Syllabus&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/01-data-sources/&#34;&gt;Module 1: Introduction and Data Sources&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Understanding Data-Driven Decisions and Initiating Data Extraction &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Explore the philosophy behind making decisions based on data.&lt;/li&gt; &#xA;   &lt;li&gt;Delve into the landscape of potential personal investments.&lt;/li&gt; &#xA;   &lt;li&gt;Address questions about where to focus attention and considerations of risk and reward.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Practical Setup: Colab and Initial Data Download &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Guide you through setting up Colab for practical data analysis.&lt;/li&gt; &#xA;   &lt;li&gt;Download your initial financial data using Finance APIs.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Essential Principles for API Selection &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Considerations for selecting the right API for your data needs.&lt;/li&gt; &#xA;   &lt;li&gt;When it becomes necessary to consider payment options in the API selection process.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/01-data-sources/&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/02-dataframe-analysis/&#34;&gt;Module 2: Working with the Data (in Pandas)&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The Core Libraries for Data Analysis in Python &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Explore the core libraries: Numpy, Pandas, and Matplotlib (including Seaborn and Plotly Express).&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Understanding Data Types and Manipulation &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Delve into various data types: numeric, string, and date categories.&lt;/li&gt; &#xA;   &lt;li&gt;Master the art of generating dummy variables for comprehensive analysis.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Enhancing Datasets with Feature Generation Techniques &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Derive additional features such as hour/day of the week, growth over different periods.&lt;/li&gt; &#xA;   &lt;li&gt;Incorporate technical indicators using the TaLib library.&lt;/li&gt; &#xA;   &lt;li&gt;Understand predictive elements, including future growth over a week, a month, or a year.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Effective Data Cleaning Strategies &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Learn strategies for cleaning and preparing data for analysis.&lt;/li&gt; &#xA;   &lt;li&gt;Acquire skills in joining multiple datasets for a holistic view.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Thorough Descriptive Analysis &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Conduct a comprehensive descriptive analysis of the dataset.&lt;/li&gt; &#xA;   &lt;li&gt;Explore correlations within the data to uncover meaningful insights.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/02-dataframe-analysis/&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/03-modeling/&#34;&gt;Module 3: Analytical Modeling&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Framing Hypotheses and Unraveling Time-Series Predictions&lt;/li&gt; &#xA; &lt;li&gt;Heuristics and hand rules for practical predictions.&lt;/li&gt; &#xA; &lt;li&gt;Predicting time-series data: trends, seasonality, and remainder decomposition.&lt;/li&gt; &#xA; &lt;li&gt;Regression techniques for understanding data relationships.&lt;/li&gt; &#xA; &lt;li&gt;Binary classification to determine growth direction.&lt;/li&gt; &#xA; &lt;li&gt;[Optional] Example of neural networks in analytical modelling.&lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/03-modeling/&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/04-trading-strategy-and-simulation/&#34;&gt;Module 4: Trading Strategy and Simulation&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Moving Beyond Prediction into the realm of Trading Strategy and Simulation:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[Optional] Explore screenshots of trading apps, guiding you on how to start—from downloading an app to placing a trade.&lt;/li&gt; &#xA; &lt;li&gt;Uncover key features of trading strategies, including considerations like trading fees, risk management, combining predictions, and timing of market entry.&lt;/li&gt; &#xA; &lt;li&gt;Delve into various strategy examples: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Single stock investment for a long-term approach.&lt;/li&gt; &#xA;   &lt;li&gt;Diversified portfolio optimisation for long investments in multiple stocks.&lt;/li&gt; &#xA;   &lt;li&gt;Market-neutral strategies, involving both long and short positions based on predictions.&lt;/li&gt; &#xA;   &lt;li&gt;Mean reversion strategy, driven by events.&lt;/li&gt; &#xA;   &lt;li&gt;Vertical stocks covering and pairs trading.&lt;/li&gt; &#xA;   &lt;li&gt;Exploration of &#34;Penny&#34; stocks and dividend strategies.&lt;/li&gt; &#xA;   &lt;li&gt;[Maybe - Advanced] Basic options strategy.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Simulate the financial results based on predictions and the chosen strategy.&lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/04-trading-strategy-and-simulation/&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/05-deployment-and-automation/&#34;&gt;Module 5: Deployment and Automation&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Streamlining Processes from Prediction to Action:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Transition from Colab notebooks to Python files for improved deployment and execution.&lt;/li&gt; &#xA; &lt;li&gt;Establish persistent storage mechanisms, including files and potentially a simple SQLite database with an introduction to SQL.&lt;/li&gt; &#xA; &lt;li&gt;Explore automation techniques such as scheduling cron jobs for a series of .py files and consider data workflow solutions like Apache Airflow.&lt;/li&gt; &#xA; &lt;li&gt;Learn to generate predictions and execute trades systematically.&lt;/li&gt; &#xA; &lt;li&gt;[Maybe - Advanced] Implement automated email notifications containing predictions, trade details, and updates on profit/loss for the designated period.&lt;/li&gt; &#xA; &lt;li&gt;Homework&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/05-deployment-and-automation/&#34;&gt;More details&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/project&#34;&gt;Project&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Putting everything we learned to practice&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Week 1 and 2: working on your project&lt;/li&gt; &#xA; &lt;li&gt;Week 3: reviewing your peers&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More details: will be shared in the coming weeks&lt;/p&gt; &#xA;&lt;h2&gt;Asking for help in Slack&lt;/h2&gt; &#xA;&lt;p&gt;The best way to get support is to use &lt;a href=&#34;https://datatalks.club/slack.html&#34;&gt;DataTalks.Club&#39;s Slack&lt;/a&gt;. Join the &lt;a href=&#34;https://datatalks-club.slack.com/archives/C06L1RTF10F&#34;&gt;&lt;code&gt;#course-stocks-analytics-zoomcamp&lt;/code&gt;&lt;/a&gt; channel.&lt;/p&gt; &#xA;&lt;p&gt;To make discussions in Slack more organized:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Follow &lt;a href=&#34;https://raw.githubusercontent.com/DataTalksClub/stock-markets-analytics-zoomcamp/main/asking-questions.md&#34;&gt;these recommendations&lt;/a&gt; when asking for help&lt;/li&gt; &#xA; &lt;li&gt;Read the &lt;a href=&#34;https://datatalks.club/slack/guidelines.html&#34;&gt;DataTalks.Club community guidelines&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>bat67/pytorch-tutorials-examples-and-books</title>
    <updated>2024-04-14T01:37:11Z</updated>
    <id>tag:github.com,2024-04-14:/bat67/pytorch-tutorials-examples-and-books</id>
    <link href="https://github.com/bat67/pytorch-tutorials-examples-and-books" rel="alternate"></link>
    <summary type="html">&lt;p&gt;PyTorch tutorials, examples and some books I found 【不定期更新】整理的PyTorch 最新版教程、例子和书籍&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PyTorch tutorials, examples and books&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/assets/pytorch-logo.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents / 目录:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#pytorch-tutorials-examples-and-books&#34;&gt;PyTorch tutorials, examples and books&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#table-of-contents--%E7%9B%AE%E5%BD%95&#34;&gt;Table of Contents / 目录:&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#pytorch-1x-tutorials-and-examples&#34;&gt;PyTorch 1.x tutorials and examples&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#books-and-slides-about-pytorch-%E4%B9%A6%E7%B1%8Dppt%E7%AD%89&#34;&gt;Books and slides about PyTorch 书籍、PPT等&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#%E4%BB%A5%E4%B8%8B%E6%98%AF%E4%B8%80%E4%BA%9B%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%95%99%E7%A8%8B&#34;&gt;以下是一些独立的教程&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#1-pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A060%E5%88%86%E9%92%9F%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E6%88%98&#34;&gt;1) PyTorch深度学习：60分钟入门与实战&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#2-learning-pytorch-with-examples-%E7%94%A8%E4%BE%8B%E5%AD%90%E5%AD%A6%E4%B9%A0pytorch&#34;&gt;2) Learning PyTorch with Examples 用例子学习PyTorch&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/#how-to-run-%E6%8E%A8%E8%8D%90%E7%9A%84%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F&#34;&gt;How to run? 推荐的运行方式&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;PyTorch 1.x tutorials and examples&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/0.PyTorch%E7%89%88%E6%9C%AC%E5%8F%98%E5%8C%96%E5%8F%8A%E8%BF%81%E7%A7%BB%E6%8C%87%E5%8D%97&#34;&gt;0.PyTorch 版本变化及迁移指南&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/1.PyTorch_for_Numpy_users%20%E7%BB%99Numpy%E7%94%A8%E6%88%B7%E7%9A%84PyTorch%E6%8C%87%E5%8D%97&#34;&gt;1.PyTorch_for_Numpy_Users 给Numpy用户的PyTorch指南&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/2.PyTorch%20_basics%20PyTorch%E5%9F%BA%E7%A1%80&#34;&gt;2.PyTorch_Basics PyTorch基础&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/3.Linear_regression%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92&#34;&gt;3.Linear_Regression 线性回归&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/4.Logistic_regression%20Logistic%E5%9B%9E%E5%BD%92&#34;&gt;4.Logistic_Regression Logistic 回归&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/5.Optimizer%20%E4%BC%98%E5%8C%96%E5%99%A8&#34;&gt;5.Optimizer 优化器&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/6.Neural_Network%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&#34;&gt;6.Neural_Network 神经网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/7.Convolutional_Neural_Network(CNN)%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&#34;&gt;7.Convolutional_Neural_Network(CNN) 卷积神经网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/8.Famous_CNN%20%E7%BB%8F%E5%85%B8%E7%9A%84CNN%E7%BD%91%E7%BB%9C&#34;&gt;8.Famous_CNN 经典的CNN网络&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/9.Using_Pretrained_Models%20%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B&#34;&gt;9.Using_Pretrained_models 使用预训练的模型&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/10.Dataset_and_Dataloader%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96&#34;&gt;10.Dataset_and_Dataloader 自定义数据读取&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/11.Custom_Dataset_Example%20%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86&#34;&gt;11.Custom_Dataset_example 定义自己的数据集&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/12.Visdom_Visualization%20visdom%E5%8F%AF%E8%A7%86%E5%8C%96&#34;&gt;12.Visdom_Visualization visdom可视化&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/13.Tensorboard_Visualization%20tensorboard%E5%8F%AF%E8%A7%86%E5%8C%96&#34;&gt;13.Tensorboard_Visualization tensorboard可视化&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/14.Semantic_Segmentation%20%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2&#34;&gt;14.Semantic_Segmentation 语义分割&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/15.Transfer_Learning%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&#34;&gt;15.Transfer_Learning 迁移学习&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/16.Neural_Style(StyleTransfer)%20%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB&#34;&gt;16.Neural_Style(StyleTransfer) 风格迁移&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/A.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%8EPyTorch&#34;&gt;A.计算机视觉与PyTorch&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PyTorch与计算机视觉简要总结 &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/raw/master/A.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%8EPyTorch/PyTorch%20and%20computer%20vision%20tasks%EF%BC%9Aa%20summary.md&#34;&gt;Markdown version&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/raw/master/A.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%8EPyTorch/PyTorch%20and%20computer%20vision%20tasks%EF%BC%9Aa%20summary.ipynb&#34;&gt;Notebook version&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/raw/master/B.PyTorch%E6%A6%82%E8%A7%88/PyTorch%E6%A6%82%E8%A7%88.md&#34;&gt;B.PyTorch概览&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/books-and-slides&#34;&gt;Books and slides about PyTorch 书籍、PPT等&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Note: some of these are old version; 下面的书籍部分还不是1.x版本。&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;该目录更新可能有延迟，全部资料请看&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/books-and-slides&#34;&gt;该文件夹&lt;/a&gt;内文件&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Automatic differentiation in PyTorch.pdf&lt;/li&gt; &#xA; &lt;li&gt;A&amp;nbsp;brief&amp;nbsp;summary&amp;nbsp;of&amp;nbsp;the&amp;nbsp;PTDC&amp;nbsp;’18&amp;nbsp;PyTorch&amp;nbsp;1.0&amp;nbsp;Preview and&amp;nbsp;Promise - Hacker Noon.pdf&lt;/li&gt; &#xA; &lt;li&gt;Deep Architectures.pdf&lt;/li&gt; &#xA; &lt;li&gt;Deep Architectures.pptx&lt;/li&gt; &#xA; &lt;li&gt;Deep Learning Toolkits II pytorch example.pdf&lt;/li&gt; &#xA; &lt;li&gt;Deep Learning with PyTorch - Vishnu Subramanian.pdf&lt;/li&gt; &#xA; &lt;li&gt;Deep-Learning-with-PyTorch.pdf&lt;/li&gt; &#xA; &lt;li&gt;Deep_Learning_with_PyTorch_Quick_Start_Guide.pdf&lt;/li&gt; &#xA; &lt;li&gt;First steps towards deep learning with pytorch.pdf&lt;/li&gt; &#xA; &lt;li&gt;Introduction to Tensorﬂow, PyTorch and Caffe.pdf&lt;/li&gt; &#xA; &lt;li&gt;pytorch 0.4 - tutorial - 有目录版.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch 0.4 中文文档 - 翻译.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch 1.0 Bringing research and production together Presentation.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch Recipes - A Problem-Solution Approach - Pradeepta Mishra.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch under the hood A guide to understand PyTorch internals.pdf&lt;/li&gt; &#xA; &lt;li&gt;pytorch-internals.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch_tutorial_0.0.4_余霆嵩.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch_tutorial_0.0.5_余霆嵩.pdf&lt;/li&gt; &#xA; &lt;li&gt;pytorch卷积、反卷积 - download from internet.pdf&lt;/li&gt; &#xA; &lt;li&gt;PyTorch深度学习实战 - 侯宜军.epub&lt;/li&gt; &#xA; &lt;li&gt;PyTorch深度学习实战 - 侯宜军.pdf&lt;/li&gt; &#xA; &lt;li&gt;深度学习之Pytorch - 廖星宇.pdf&lt;/li&gt; &#xA; &lt;li&gt;深度学习之PyTorch实战计算机视觉 - 唐进民.pdf&lt;/li&gt; &#xA; &lt;li&gt;深度学习入门之PyTorch - 廖星宇（有目录）.pdf&lt;/li&gt; &#xA; &lt;li&gt;深度学习框架PyTorch：入门与实践 - 陈云.pdf&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/Udacity-Deep-Learning-with-PyTorch&#34;&gt;Udacity: Deep Learning with PyTorch&lt;/a&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;展开查看&lt;/summary&gt; &#xA;   &lt;pre&gt;&#xA;* Part 1: Introduction to PyTorch and using tensors&#xA;* Part 2: Building fully-connected neural networks with PyTorch&#xA;* Part 3: How to train a fully-connected network with backpropagation on MNIST&#xA;* Part 4: Exercise - train a neural network on Fashion-MNIST&#xA;* Part 5: Using a trained network for making predictions and validating networks&#xA;* Part 6: How to save and load trained models&#xA;* Part 7: Load image data with torchvision, also data augmentation&#xA;* Part 8: Use transfer learning to train a state-of-the-art image classifier for dogs and cats&#xA;  &lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/books-and-slides/PyTorch-Zero-To-All%20Slides-newest%20from%20Google%20Drive&#34;&gt;PyTorch-Zero-To-All&lt;/a&gt;：Slides-newest from Google Drive &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;展开查看&lt;/summary&gt; &#xA;   &lt;pre&gt;&#xA;* Lecture 01_ Overview.pptx&#xA;* Lecture 02_ Linear Model.pptx&#xA;* Lecture 03_ Gradient Descent.pptx&#xA;* Lecture 04_ Back-propagation and PyTorch autograd.pptx&#xA;* Lecture 05_ Linear regression  in PyTorch way.pptx&#xA;* Lecture 06_ Logistic Regression.pptx&#xA;* Lecture 07_ Wide _ Deep.pptx&#xA;* Lecture 08_ DataLoader.pptx&#xA;* Lecture 09_ Softmax Classifier.pptx&#xA;* Lecture 10_ Basic CNN.pptx&#xA;* Lecture 11_ Advanced CNN.pptx&#xA;* Lecture 12_ RNN.pptx&#xA;* Lecture 13_ RNN II.pptx&#xA;* Lecture 14_ Seq2Seq.pptx&#xA;* Lecture 15_ NSML, Smartest ML Platform.pptx&#xA;  &lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-tutorials-examples-and-books/tree/master/books-and-slides/Deep-Learning-Course-Slides-and-Handout&#34;&gt;Deep Learning Course Slides and Handout - fleuret.org&lt;/a&gt; &#xA;  &lt;details&gt; &#xA;   &lt;summary&gt;展开查看&lt;/summary&gt; &#xA;   &lt;pre&gt;&#xA;* 1-1-from-anns-to-deep-learning.pdf&#xA;* 1-2-current-success.pdf&#xA;* 1-3-what-is-happening.pdf&#xA;* 1-4-tensors-and-linear-regression.pdf&#xA;* 1-5-high-dimension-tensors.pdf&#xA;* 1-6-tensor-internals.pdf&#xA;* 2-1-loss-and-risk.pdf&#xA;* 2-2-overfitting.pdf&#xA;* 2-3-bias-variance-dilemma.pdf&#xA;* 2-4-evaluation-protocols.pdf&#xA;* 2-5-basic-embeddings.pdf&#xA;* 3-1-perceptron.pdf&#xA;* 3-2-LDA.pdf&#xA;* 3-3-features.pdf&#xA;* 3-4-MLP.pdf&#xA;* 3-5-gradient-descent.pdf&#xA;* 3-6-backprop.pdf&#xA;* 4-1-DAG-networks.pdf&#xA;* 4-2-autograd.pdf&#xA;* 4-3-modules-and-batch-processing.pdf&#xA;* 4-4-convolutions.pdf&#xA;* 4-5-pooling.pdf&#xA;* 4-6-writing-a-module.pdf&#xA;* 5-1-cross-entropy-loss.pdf&#xA;* 5-2-SGD.pdf&#xA;* 5-3-optim.pdf&#xA;* 5-4-l2-l1-penalties.pdf&#xA;* 5-5-initialization.pdf&#xA;* 5-6-architecture-and-training.pdf&#xA;* 5-7-writing-an-autograd-function.pdf&#xA;* 6-1-benefits-of-depth.pdf&#xA;* 6-2-rectifiers.pdf&#xA;* 6-3-dropout.pdf&#xA;* 6-4-batch-normalization.pdf&#xA;* 6-5-residual-networks.pdf&#xA;* 6-6-using-GPUs.pdf&#xA;* 7-1-CV-tasks.pdf&#xA;* 7-2-image-classification.pdf&#xA;* 7-3-object-detection.pdf&#xA;* 7-4-segmentation.pdf&#xA;* 7-5-dataloader-and-surgery.pdf&#xA;* 8-1-looking-at-parameters.pdf&#xA;* 8-2-looking-at-activations.pdf&#xA;* 8-3-visualizing-in-input.pdf&#xA;* 8-4-optimizing-inputs.pdf&#xA;* 9-1-transposed-convolutions.pdf&#xA;* 9-2-autoencoders.pdf&#xA;* 9-3-denoising-and-variational-autoencoders.pdf&#xA;* 9-4-NVP.pdf&#xA;* 10-1-GAN.pdf&#xA;* 10-2-Wasserstein-GAN.pdf&#xA;* 10-3-conditional-GAN.pdf&#xA;* 10-4-persistence.pdf&#xA;* 11-1-RNN-basics.pdf&#xA;* 11-2-LSTM-and-GRU.pdf&#xA;* 11-3-word-embeddings-and-translation.pdf&#xA;  &lt;/pre&gt; &#xA;  &lt;/details&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;以下是一些独立的教程&lt;/h2&gt; &#xA;&lt;h3&gt;1) &lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn&#34;&gt;PyTorch深度学习：60分钟入门与实战&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;展开查看&lt;/summary&gt; &#xA; &lt;pre&gt;&#xA;&#xA;  &lt;ul&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;什么是PyTorch？（What is PyTorch?）&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#%E5%85%A5%E9%97%A8&#34;&gt;入门&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#%E5%BC%A0%E9%87%8F&#34;&gt;张量&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#%E8%BF%90%E7%AE%97&#34;&gt;运算&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#numpy%E6%A1%A5&#34;&gt;NumPy桥&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#%E5%B0%86torch%E7%9A%84tensor%E8%BD%AC%E5%8C%96%E4%B8%BAnumpy%E6%95%B0%E7%BB%84&#34;&gt;将torch的Tensor转化为NumPy数组&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#%E5%B0%86numpy%E6%95%B0%E7%BB%84%E8%BD%AC%E5%8C%96%E4%B8%BAtorch%E5%BC%A0%E9%87%8F&#34;&gt;将NumPy数组转化为Torch张量&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/What_is_PyTorch/%E4%BB%80%E4%B9%88%E6%98%AFPyTorch.md#cuda%E4%B8%8A%E7%9A%84%E5%BC%A0%E9%87%8F&#34;&gt;CUDA上的张量&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;Autograd：自动求导&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Autograd_Automatic_Differentiation/Autograd%EF%BC%9A%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.md#%E5%BC%A0%E9%87%8F&#34;&gt;张量&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Autograd_Automatic_Differentiation/Autograd%EF%BC%9A%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.md#%E6%A2%AF%E5%BA%A6&#34;&gt;梯度&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;神经网络（Neural Networks）&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Neural_Networks/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md#%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C&#34;&gt;定义网络&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Neural_Networks/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&#34;&gt;损失函数&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Neural_Networks/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD&#34;&gt;反向传播&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Neural_Networks/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md#%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D&#34;&gt;更新权重&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;训练分类器（Training a Classifier）&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#%E6%95%B0%E6%8D%AE%E5%91%A2&#34;&gt;数据呢？&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E5%99%A8&#34;&gt;训练一个图片分类器&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#1%E5%8A%A0%E8%BD%BD%E5%B9%B6%E6%A0%87%E5%87%86%E5%8C%96cifar10&#34;&gt;1.加载并标准化CIFAR10&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#2%E5%AE%9A%E4%B9%89%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&#34;&gt;2.定义卷积神经网络&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#3%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8&#34;&gt;3.定义损失函数和优化器&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#4%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C&#34;&gt;4.训练网络&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#5%E4%BD%BF%E7%94%A8%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C&#34;&gt;5.使用测试数据测试网络&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#%E5%9C%A8gpu%E4%B8%8A%E8%AE%AD%E7%BB%83&#34;&gt;在GPU上训练&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#%E5%9C%A8%E5%A4%9Agpu%E4%B8%8A%E8%AE%AD%E7%BB%83&#34;&gt;在多GPU上训练&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Training_a_Classifier/%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8.md#%E6%8E%A5%E4%B8%8B%E6%9D%A5%E8%A6%81%E5%81%9A%E4%BB%80%E4%B9%88&#34;&gt;接下来要做什么？&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;选读：数据并行处理（Optional: Data Parallelism）&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E5%AF%BC%E5%85%A5%E5%92%8C%E5%8F%82%E6%95%B0&#34;&gt;导入和参数&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E8%99%9A%E6%8B%9F%E6%95%B0%E6%8D%AE%E9%9B%86&#34;&gt;虚拟数据集&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E7%AE%80%E5%8D%95%E6%A8%A1%E5%9E%8B&#34;&gt;简单模型&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C&#34;&gt;创建一个模型和数据并行&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B&#34;&gt;运行模型&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E7%BB%93%E6%9E%9C&#34;&gt;结果&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#2%E4%B8%AAgpu&#34;&gt;2个GPU&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#3%E4%B8%AAgpu&#34;&gt;3个GPU&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#8%E4%B8%AAgpu&#34;&gt;8个GPU&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/Deep-Learning-with-PyTorch-A-60-Minute-Blitz-cn/raw/master/Optional_Data_Parallelism/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86.md#%E6%80%BB%E7%BB%93&#34;&gt;总结&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;  &lt;/ul&gt;&#xA;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h3&gt;2) &lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn&#34;&gt;Learning PyTorch with Examples 用例子学习PyTorch&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;展开查看&lt;/summary&gt; &#xA; &lt;pre&gt;&#xA;&#xA;  &lt;ul&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;张量(Tensors)&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/%E7%83%AD%E8%BA%AB%EF%BC%9A%E4%BD%BF%E7%94%A8NumPy&#34;&gt;热身：使用NumPy&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E5%BC%A0%E9%87%8F(Tensors)&#34;&gt;PyTorch：张量(Tensors)&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;自动求导(Autograd)&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC(Autograd)&#34;&gt;PyTorch：自动求导(Autograd)&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E5%87%BD%E6%95%B0&#34;&gt;PyTorch：定义自己的自动求导函数&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/TensorFlow%EF%BC%9A%E9%9D%99%E6%80%81%E5%9B%BE&#34;&gt;TensorFlow：静态图&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;nn&lt;/code&gt;模块(&lt;code&gt;nn&lt;/code&gt; module)&lt;/p&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E5%AE%9A%E5%88%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cnn%E6%A8%A1%E5%9D%97&#34;&gt;PyTorch：神经网络模块nn&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9D%97optim&#34;&gt;PyTorch：优化模块optim&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E5%AE%9A%E5%88%B6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Cnn%E6%A8%A1%E5%9D%97&#34;&gt;PyTorch：定制神经网络nn模块&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/bat67/pytorch-examples-cn/tree/master/PyTorch%EF%BC%9A%E6%8E%A7%E5%88%B6%E6%B5%81%E5%92%8C%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB&#34;&gt;PyTorch：控制流和参数共享&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt;&#xA;&#xA;  &lt;/ul&gt;&#xA;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;How to run? 推荐的运行方式&lt;/h2&gt; &#xA;&lt;p&gt;Some code in this repo is separated in blocks using &lt;code&gt;#%%&lt;/code&gt;. A block is as same as a cell in &lt;code&gt;Jupyter Notebook&lt;/code&gt;. So editors/IDEs supporting this functionality is recommanded.&lt;/p&gt; &#xA;&lt;p&gt;Such as:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bat67/pytorch-tutorials-examples-and-books/master/Functionality&#34;&gt;VSCode&lt;/a&gt; with &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=ms-python.python&#34;&gt;Microsoft Python extension&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/spyder/&#34;&gt;Spyder&lt;/a&gt; with &lt;a href=&#34;https://www.anaconda.com/&#34;&gt;Anaconda&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jetbrains.com/pycharm/&#34;&gt;PyCharm&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>OpenBMB/MiniCPM</title>
    <updated>2024-04-14T01:37:11Z</updated>
    <id>tag:github.com,2024-04-14:/OpenBMB/MiniCPM</id>
    <link href="https://github.com/OpenBMB/MiniCPM" rel="alternate"></link>
    <summary type="html">&lt;p&gt;MiniCPM-2B: An end-side LLM outperforms Llama2-13B.&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt; MiniCPM: 揭示端侧大语言模型的无限潜力 &lt;/h1&gt; &#xA;&lt;/div&gt; &#xA;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;b&gt;中文&lt;/b&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/README-en.md&#34;&gt;English&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34; target=&#34;_blank&#34;&gt;MiniCPM 技术博客&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34; target=&#34;_blank&#34;&gt;MiniCPM 论文&lt;/a&gt; | &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM-V/&#34; target=&#34;_blank&#34;&gt;MiniCPM-V 仓库&lt;/a&gt; | 加入我们的 &lt;a href=&#34;https://discord.gg/3cGQn9b3YM&#34; target=&#34;_blank&#34;&gt;discord&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/assets/wechat.jpg&#34; target=&#34;_blank&#34;&gt;微信群&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;MiniCPM 是面壁智能与清华大学自然语言处理实验室共同开源的系列端侧大模型，主体语言模型 MiniCPM-2B 仅有 24亿（2.4B）的非词嵌入参数量, 总计2.7B参数量。&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;经过 SFT 后，MiniCPM-2B 在公开综合性评测集上与 Mistral-7B 表现相近（中文、数学、代码能力更优），整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。&lt;/li&gt; &#xA; &lt;li&gt;经过 DPO 后，MiniCPM-2B 在当前最接近用户体感的评测集 MTBench 上也超越了 Llama2-70B-Chat、Vicuna-33B、Mistral-7B-Instruct-v0.1、Zephyr-7B-alpha 等众多代表性开源大模型。&lt;/li&gt; &#xA; &lt;li&gt;以 MiniCPM-2B 为基础构建端侧多模态大模型 MiniCPM-V 2.0，在多个测试基准中实现了 7B 以下模型的最佳性能，在 OpenCompass 榜单上超过了 Qwen-VL-Chat 9.6B、CogVLM-Chat 17.4B 和 Yi-VL 34B 等更大参数规模的模型。MiniCPM-V 2.0 还展现出领先的 OCR 能力，在场景文字识别能力上接近 Gemini Pro。&lt;/li&gt; &#xA; &lt;li&gt;经过 Int4 量化后，MiniCPM 可在手机上进行部署推理，流式输出速度略高于人类说话速度。MiniCPM-V 也直接跑通了多模态大模型在手机上的部署。&lt;/li&gt; &#xA; &lt;li&gt;一张1080/2080可高效参数微调，一张3090/4090可全参数微调，一台机器可持续训练 MiniCPM，二次开发成本较低。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;我们完全开源MiniCPM系列的模型参数供学术研究和有限商用。 具体而言，我们目前已公开以下模型，地址详见 &lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#1&#34;&gt;模型下载&lt;/a&gt; 部分&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;基于MiniCPM-2B的指令微调与人类偏好对齐版本&lt;strong&gt;MiniCPM-2B-SFT/DPO&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;基于MiniCPM-2B的多模态模型&lt;strong&gt;MiniCPM-V 2.0&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B-SFT/DPO的Int4量化版&lt;strong&gt;MiniCPM-2B-SFT/DPO-Int4&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B的128k长文本版本&lt;strong&gt;MiniCPM-2B-128k&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B的MoE版本&lt;strong&gt;MiniCPM-MoE-8x2B&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;更轻量级的MiniCPM-1B指令微调版本&lt;strong&gt;MiniCPM-1B-SFT&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;基于MLC-LLM、LLMFarm开发的MiniCPM手机端程序，&lt;strong&gt;文本及多模态模型均可在手机端进行推理&lt;/strong&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM-2B训练过程中的&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-history&#34;&gt;30个Checkpoints&lt;/a&gt;供模型机理研究。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;局限性：&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;受限于模型规模，模型可能出现&lt;strong&gt;幻觉性问题&lt;/strong&gt;。其中由于DPO模型生成的回复内容更长，更容易出现幻觉。我们也将持续进行MiniCPM模型的迭代改进。&lt;/li&gt; &#xA; &lt;li&gt;为了保证在学术研究用途上模型的通用性，我们&lt;strong&gt;未对模型进行任何身份认同训练&lt;/strong&gt;。同时由于我们用ShareGPT开源语料作为部分训练数据，模型可能会输出类似GPT系列模型的身份认同信息。&lt;/li&gt; &#xA; &lt;li&gt;受限于模型规模，模型的&lt;strong&gt;输出受到提示词（prompt）的影响较大&lt;/strong&gt;，可能多次尝试产生不一致的结果。&lt;/li&gt; &#xA; &lt;li&gt;受限于模型容量，模型的&lt;strong&gt;知识记忆较不准确&lt;/strong&gt;，后续我们将结合RAG方法来增强模型的知识记忆能力。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;目录&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#0&#34;&gt;更新日志&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#1&#34;&gt;模型下载&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#2&#34;&gt;快速上手&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#community&#34;&gt;开源社区&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#3&#34;&gt;评测结果&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#4&#34;&gt;手机部署&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#5&#34;&gt;Demo &amp;amp; API 部署&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#6&#34;&gt;二次开发&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#7&#34;&gt;开源协议&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#8&#34;&gt;工作引用&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#9&#34;&gt;典型示例&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;0&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;更新日志&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;2024/04/11 开源&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V-2.0&#34;&gt;MiniCPM-V-2.0&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;、&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;和&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B&lt;/a&gt;！点击&lt;a href=&#34;https://openbmb.vercel.app/?category=Chinese+Blog&#34;&gt;这里&lt;/a&gt;查看技术博客。&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;2024/03/16 MiniCPM-2B 的30余个中间检查点开放了！&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-history&#34;&gt;HuggingFace链接&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;2024/02/13 支持了llama.cpp&lt;/li&gt; &#xA; &lt;li&gt;2024/02/09 我们在README里加入了一个&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#community&#34;&gt;开源社区&lt;/a&gt;章节，用来收集开源社区对MiniCPM的支持案例。&lt;/li&gt; &#xA; &lt;li&gt;2024/02/08 我们更新了&lt;a href=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/#llamaformat&#34;&gt;llama-format的模型权重&lt;/a&gt;，方便大家更加快捷地使用我们的模型。&lt;/li&gt; &#xA; &lt;li&gt;2024/02/01 初始发布。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;1&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;模型下载&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;语言模型&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;HuggingFace&lt;/th&gt; &#xA;     &lt;th&gt;ModelScope&lt;/th&gt; &#xA;     &lt;th&gt;WiseModel&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/miniCPM-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/miniCPM-bf16&#34;&gt;MiniCPM-2B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16/summary&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16&#34;&gt;MiniCPM-2B-dpo-bf16&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-128k&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/openbmb/MiniCPM-2B-128k/summary&#34;&gt;MiniCPM-2B-128k&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-MoE-8x2B&#34;&gt;MiniCPM-MoE-8x2B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-1B-sft-bf16&#34;&gt;MiniCPM-1B-sft-bf16&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;p&gt;注: 更多模型版本见&lt;a href=&#34;https://huggingface.co/collections/openbmb/minicpm-2b-65d48bf958302b9fd25b698f&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;多模态模型&lt;/p&gt; &#xA;  &lt;table&gt; &#xA;   &lt;thead&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;th&gt;HuggingFace&lt;/th&gt; &#xA;     &lt;th&gt;ModelScope&lt;/th&gt; &#xA;     &lt;th&gt;WiseModel&lt;/th&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/thead&gt; &#xA;   &lt;tbody&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V-2.0&#34;&gt;MiniCPM-V 2.0&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-V-2.0/&#34;&gt;MiniCPM-V 2.0&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-V&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/MiniCPM-V/&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/MiniCPM-V&#34;&gt;MiniCPM-V&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;    &lt;tr&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://huggingface.co/openbmb/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://modelscope.cn/models/OpenBMB/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;     &lt;td&gt;&lt;a href=&#34;https://wisemodel.cn/models/OpenBMB/OmniLMM-12B&#34;&gt;OmniLMM-12B&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;/tr&gt; &#xA;   &lt;/tbody&gt; &#xA;  &lt;/table&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;2&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;快速上手&lt;/h2&gt; &#xA;&lt;h4&gt;在线体验&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1tJcfPyWGWA5HezO7GKLeyeIso0HyOc0l?usp=sharing&#34;&gt;Colab&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Huggingface 模型&lt;/h4&gt; &#xA;&lt;h5&gt;MiniCPM-2B&lt;/h5&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;安装&lt;code&gt;transformers&amp;gt;=4.36.0&lt;/code&gt;以及&lt;code&gt;accelerate&lt;/code&gt;后，运行以下代码&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoModelForCausalLM, AutoTokenizer&#xA;import torch&#xA;torch.manual_seed(0)&#xA;&#xA;path = &#39;openbmb/MiniCPM-2B-dpo-bf16&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;responds, history = model.chat(tokenizer, &#34;山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？&#34;, temperature=0.5, top_p=0.8, repetition_penalty=1.02)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;期望输出&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;山东省最高的山是泰山，海拔1545米。&#xA;&#xA;相对于黄山（海拔1864米），泰山海拔较低，相差约319米。&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p id=&#34;llamaformat&#34;&gt;&lt;/p&gt; &#xA;&lt;h5&gt;MiniCPM-2B （Llama Format）&lt;/h5&gt; &#xA;&lt;p&gt;我们将MiniCPM的模型权重转化成了Llama代码可以直接调用的&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16-llama-format&#34;&gt;格式&lt;/a&gt;，以便大家尝试:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import LlamaTokenizerFast, LlamaForCausalLM&#xA;model_path = &#34;openbmb/MiniCPM-2B-dpo-bf16-llama-format&#34;&#xA;tokenizer = LlamaTokenizerFast.from_pretrained(model_path)&#xA;model = LlamaForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;&#xA;prompt=&#34;Now you act like a terminal situated within a beginner&#39;s C++ practice repository folder, please provide the output for the command: `ls -l`&#34;&#xA;input_ids = tokenizer.encode(&#34;&amp;lt;用户&amp;gt;{}&amp;lt;AI&amp;gt;&#34;.format(prompt), return_tensors=&#39;pt&#39;, add_special_tokens=True).cuda()&#xA;responds = model.generate(input_ids, temperature=0.3, top_p=0.8, repetition_penalty=1.02, max_length=1024)&#xA;responds = tokenizer.decode(responds[0], skip_special_tokens=True)&#xA;print(responds)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h5&gt;MiniCPM-V&lt;/h5&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from PIL import Image&#xA;from transformers import AutoModel, AutoTokenizer&#xA;&#xA;model = AutoModel.from_pretrained(&#39;openbmb/MiniCPM-V&#39;, trust_remote_code=True)&#xA;tokenizer = AutoTokenizer.from_pretrained(&#39;openbmb/MiniCPM-V&#39;, trust_remote_code=True)&#xA;model.eval().cuda()&#xA;&#xA;image = Image.open(&#39;xx.jpg&#39;).convert(&#39;RGB&#39;)&#xA;question = &#39;What is in the image?&#39;&#xA;msgs = [{&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: question}]&#xA;&#xA;res, context, _ = model.chat(&#xA;    image=image,&#xA;    msgs=msgs,&#xA;    context=None,&#xA;    tokenizer=tokenizer,&#xA;    sampling=True,&#xA;    temperature=0.7&#xA;)&#xA;print(res)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;vLLM 推理&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;安装&lt;a href=&#34;https://github.com/vllm-project/vllm&#34;&gt;vLLM&lt;/a&gt;主分支版本: &lt;a href=&#34;https://docs.vllm.ai/en/latest/getting_started/installation.html#build-from-source&#34;&gt;从源码安装&lt;/a&gt;。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;测试样例&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python inference/inference_vllm.py --model_path &amp;lt;hf_repo_path&amp;gt; --prompt_path prompts/prompt_demo.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;期望输出&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;&amp;lt;用户&amp;gt;: Which city is the capital of China?&#xA;&amp;lt;AI&amp;gt;:&#xA; The capital city of China is Beijing. Beijing is a major political, cultural, and economic center in China, and it is known for its rich history, beautiful architecture, and vibrant nightlife. It is also home to many of China&#39;s most important cultural and historical sites, including the Forbidden City, the Great Wall of China, and the Temple of Heaven. Beijing is a popular destination for tourists from around the world, and it is an important hub for international business and trade.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;llama.cpp、Ollama、fastllm、mlx_lm推理&lt;/h4&gt; &#xA;&lt;p&gt;MiniCPM支持&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/&#34;&gt;llama.cpp&lt;/a&gt; 、&lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;ollama&lt;/a&gt;、&lt;a href=&#34;https://github.com/ztxz16/fastllm&#34;&gt;fastllm&lt;/a&gt;、&lt;a href=&#34;https://github.com/ml-explore/mlx-examples&#34;&gt;mlx_lm&lt;/a&gt;推理。感谢&lt;a href=&#34;https://github.com/runfuture&#34;&gt;@runfuture&lt;/a&gt;对llama.cpp和ollama的适配。&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#build&#34;&gt;安装llama.cpp&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;下载gguf形式的模型。&lt;a href=&#34;https://huggingface.co/runfuture/MiniCPM-2B-dpo-fp16-gguf&#34;&gt;下载链接-fp16格式&lt;/a&gt; &lt;a href=&#34;https://huggingface.co/runfuture/MiniCPM-2B-dpo-q4km-gguf&#34;&gt;下载链接-q4km格式&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;在命令行运行示例代码:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code&gt;./main -m ../../model_ckpts/download_from_hf/MiniCPM-2B-dpo-fp16-gguf.gguf --prompt &#34;&amp;lt;用户&amp;gt;写藏头诗，藏头是龙年大吉&amp;lt;AI&amp;gt;&#34; --temp 0.3 --top-p 0.8 --repeat-penalty 1.05&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;更多参数调整&lt;a href=&#34;https://github.com/ggerganov/llama.cpp/raw/master/examples/main/README.md&#34;&gt;详见&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ollama&lt;/strong&gt; 正在解决&lt;a href=&#34;https://github.com/ollama/ollama/issues/2383&#34;&gt;这个问题&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;fastllm&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ztxz16/fastllm&#34;&gt;编译安装fastllm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;模型推理&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;from transformers import AutoTokenizer, LlamaTokenizerFast, AutoModelForCausalLM&#xA;path = &#39;openbmb/MiniCPM-2B-dpo-fp16&#39;&#xA;tokenizer = AutoTokenizer.from_pretrained(path)&#xA;model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.float16, device_map=&#39;cuda&#39;, trust_remote_code=True)&#xA;from fastllm_pytools import llm&#xA;llm.set_device_map(&#34;cpu&#34;)&#xA;model = llm.from_hf(model, tokenizer, dtype = &#34;float16&#34;) # dtype支持 &#34;float16&#34;, &#34;int8&#34;, &#34;int4&#34;&#xA;print(model.response(&#34;&amp;lt;用户&amp;gt;山东省最高的山是哪座山, 它比黄山高还是矮？差距多少？&amp;lt;AI&amp;gt;&#34;, top_p=0.8, temperature=0.5, repeat_penalty=1.02))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;mlx_lm&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;安装mlx_lm库 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install mlx_lm&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA; &lt;li&gt;下载转换后的模型权重&lt;a href=&#34;https://huggingface.co/mlx-community/MiniCPM-2B-sft-bf16-llama-format-mlx&#34;&gt;MiniCPM-2B-sft-bf16-llama-format-mlx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;模型推理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python -m mlx_lm.generate --model mlx-community/MiniCPM-2B-sft-bf16-llama-format-mlx --prompt &#34;hello, tell me a joke.&#34; --trust-remote-code&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p id=&#34;community&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;开源社区&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/foldl/chatllm.cpp&#34;&gt;ChatLLM框架&lt;/a&gt;：&lt;a href=&#34;https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16/discussions/2#65c59c4f27b8c11e43fc8796&#34;&gt;在CPU上跑MiniCPM&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;3&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;评测结果&lt;/h2&gt; &#xA;&lt;h4&gt;评测设置&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;由于大模型评测难以统一，且大量评测也没有公开的prompt和测试代码，对于具体评测方式，我们只能尽量做到适合各类模型。&lt;/li&gt; &#xA; &lt;li&gt;整体而言，我们测试时采用统一的prompt输入，并按照各模型对应的模板进行输入调整。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;评测脚本及prompt已开源在我们的Github仓库中，也欢迎更多开发者来不断改进我们的评测方式。&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;文本评测部分，采用了我们的开源大模型能力评测框架&lt;a href=&#34;https://github.com/OpenBMB/UltraEval&#34;&gt;UltraEval&lt;/a&gt;。以下为开源模型复现流程： &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;安装UltraEval &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/OpenBMB/UltraEval.git&#xA;cd UltraEval&#xA;pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;li&gt;下载相关数据并解压处理 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget -O RawData.zip &#34;https://cloud.tsinghua.edu.cn/f/71b5232264ae4833a4d0/?dl=1&#34;&#xA;unzip RawData.zip&#xA;python data_process.py&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;     &lt;li&gt;执行评测脚本(提供了模板，可自定义) &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bash run_eval.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;部署模式&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;因为MiniCPM采用Mup的结构，与现有模型在具体计算上有细微差别，我们是基于vllm=0.2.2版本进行了我们模型的实现。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;对于非MiniCPM模型，我们采用了vllm=0.2.7的最新版本进行推理。&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;评测度量&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;对于QA任务（选择题任务），我们选用两种方式进行测试： &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;PPL：将选项作为题目生成的延续，并根据各个选项的PPL来进行答案选择；&lt;/li&gt; &#xA;   &lt;li&gt;第二种是直接生成答案选项。&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;对于不同模型，这两种方式得到的结果差异较大。MiniCPM两种模式上的结果较为接近，而Mistral-7B-v0.1等模型在PPL上表现较好，直接生成上效果较差。&lt;/li&gt; &#xA; &lt;li&gt;在具体评测时，我们以两种评测方式得分的最高者为最终结果，以此保证对比的公平性(以下表格中*号表示采用PPL)。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;文本模型评测&lt;/h4&gt; &#xA;&lt;p&gt;&lt;strong&gt;越级比较:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B&lt;/td&gt; &#xA;   &lt;td&gt;35.40&lt;/td&gt; &#xA;   &lt;td&gt;36.21&lt;/td&gt; &#xA;   &lt;td&gt;31.765&lt;/td&gt; &#xA;   &lt;td&gt;32.42&lt;/td&gt; &#xA;   &lt;td&gt;31.11&lt;/td&gt; &#xA;   &lt;td&gt;44.32&lt;/td&gt; &#xA;   &lt;td&gt;12.2&lt;/td&gt; &#xA;   &lt;td&gt;27.17&lt;/td&gt; &#xA;   &lt;td&gt;13.57&lt;/td&gt; &#xA;   &lt;td&gt;1.8&lt;/td&gt; &#xA;   &lt;td&gt;33.23&lt;/td&gt; &#xA;   &lt;td&gt;75.25&lt;/td&gt; &#xA;   &lt;td&gt;42.75&lt;/td&gt; &#xA;   &lt;td&gt;75.62*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-7B&lt;/td&gt; &#xA;   &lt;td&gt;49.46&lt;/td&gt; &#xA;   &lt;td&gt;47.19&lt;/td&gt; &#xA;   &lt;td&gt;59.655&lt;/td&gt; &#xA;   &lt;td&gt;58.96&lt;/td&gt; &#xA;   &lt;td&gt;60.35&lt;/td&gt; &#xA;   &lt;td&gt;57.65&lt;/td&gt; &#xA;   &lt;td&gt;17.07&lt;/td&gt; &#xA;   &lt;td&gt;42.15&lt;/td&gt; &#xA;   &lt;td&gt;41.24&lt;/td&gt; &#xA;   &lt;td&gt;5.34&lt;/td&gt; &#xA;   &lt;td&gt;37.75&lt;/td&gt; &#xA;   &lt;td&gt;83.42&lt;/td&gt; &#xA;   &lt;td&gt;64.76&lt;/td&gt; &#xA;   &lt;td&gt;75.32*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deepseek-7B&lt;/td&gt; &#xA;   &lt;td&gt;39.96&lt;/td&gt; &#xA;   &lt;td&gt;39.15&lt;/td&gt; &#xA;   &lt;td&gt;43.64&lt;/td&gt; &#xA;   &lt;td&gt;42.82&lt;/td&gt; &#xA;   &lt;td&gt;44.45&lt;/td&gt; &#xA;   &lt;td&gt;47.82&lt;/td&gt; &#xA;   &lt;td&gt;20.12&lt;/td&gt; &#xA;   &lt;td&gt;41.45&lt;/td&gt; &#xA;   &lt;td&gt;15.85&lt;/td&gt; &#xA;   &lt;td&gt;1.53&lt;/td&gt; &#xA;   &lt;td&gt;33.38&lt;/td&gt; &#xA;   &lt;td&gt;74.58*&lt;/td&gt; &#xA;   &lt;td&gt;42.15*&lt;/td&gt; &#xA;   &lt;td&gt;75.45*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B&lt;/td&gt; &#xA;   &lt;td&gt;48.97&lt;/td&gt; &#xA;   &lt;td&gt;49.96&lt;/td&gt; &#xA;   &lt;td&gt;44.54&lt;/td&gt; &#xA;   &lt;td&gt;46.12&lt;/td&gt; &#xA;   &lt;td&gt;42.96&lt;/td&gt; &#xA;   &lt;td&gt;62.69&lt;/td&gt; &#xA;   &lt;td&gt;27.44&lt;/td&gt; &#xA;   &lt;td&gt;45.2&lt;/td&gt; &#xA;   &lt;td&gt;33.13&lt;/td&gt; &#xA;   &lt;td&gt;5.0&lt;/td&gt; &#xA;   &lt;td&gt;41.06&lt;/td&gt; &#xA;   &lt;td&gt;83.92&lt;/td&gt; &#xA;   &lt;td&gt;70.73&lt;/td&gt; &#xA;   &lt;td&gt;80.43*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-13B&lt;/td&gt; &#xA;   &lt;td&gt;41.48&lt;/td&gt; &#xA;   &lt;td&gt;42.44&lt;/td&gt; &#xA;   &lt;td&gt;37.19&lt;/td&gt; &#xA;   &lt;td&gt;37.32&lt;/td&gt; &#xA;   &lt;td&gt;37.06&lt;/td&gt; &#xA;   &lt;td&gt;54.71&lt;/td&gt; &#xA;   &lt;td&gt;17.07&lt;/td&gt; &#xA;   &lt;td&gt;32.55&lt;/td&gt; &#xA;   &lt;td&gt;21.15&lt;/td&gt; &#xA;   &lt;td&gt;2.25&lt;/td&gt; &#xA;   &lt;td&gt;37.92&lt;/td&gt; &#xA;   &lt;td&gt;78.87*&lt;/td&gt; &#xA;   &lt;td&gt;58.19&lt;/td&gt; &#xA;   &lt;td&gt;79.23*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MPT-30B&lt;/td&gt; &#xA;   &lt;td&gt;38.17&lt;/td&gt; &#xA;   &lt;td&gt;39.82&lt;/td&gt; &#xA;   &lt;td&gt;30.72&lt;/td&gt; &#xA;   &lt;td&gt;29.34&lt;/td&gt; &#xA;   &lt;td&gt;32.09&lt;/td&gt; &#xA;   &lt;td&gt;46.56&lt;/td&gt; &#xA;   &lt;td&gt;21.95&lt;/td&gt; &#xA;   &lt;td&gt;35.36&lt;/td&gt; &#xA;   &lt;td&gt;10.31&lt;/td&gt; &#xA;   &lt;td&gt;1.56&lt;/td&gt; &#xA;   &lt;td&gt;38.22&lt;/td&gt; &#xA;   &lt;td&gt;78.66*&lt;/td&gt; &#xA;   &lt;td&gt;46.08*&lt;/td&gt; &#xA;   &lt;td&gt;79.72*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Falcon-40B&lt;/td&gt; &#xA;   &lt;td&gt;43.62&lt;/td&gt; &#xA;   &lt;td&gt;44.21&lt;/td&gt; &#xA;   &lt;td&gt;40.93&lt;/td&gt; &#xA;   &lt;td&gt;40.29&lt;/td&gt; &#xA;   &lt;td&gt;41.57&lt;/td&gt; &#xA;   &lt;td&gt;53.53&lt;/td&gt; &#xA;   &lt;td&gt;24.39&lt;/td&gt; &#xA;   &lt;td&gt;36.53&lt;/td&gt; &#xA;   &lt;td&gt;22.44&lt;/td&gt; &#xA;   &lt;td&gt;1.92&lt;/td&gt; &#xA;   &lt;td&gt;36.24&lt;/td&gt; &#xA;   &lt;td&gt;81.94*&lt;/td&gt; &#xA;   &lt;td&gt;57.68&lt;/td&gt; &#xA;   &lt;td&gt;83.26*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.1&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;同级比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;TinyLlama-1.1B&lt;/td&gt; &#xA;   &lt;td&gt;25.36&lt;/td&gt; &#xA;   &lt;td&gt;25.55&lt;/td&gt; &#xA;   &lt;td&gt;24.525&lt;/td&gt; &#xA;   &lt;td&gt;25.02&lt;/td&gt; &#xA;   &lt;td&gt;24.03&lt;/td&gt; &#xA;   &lt;td&gt;24.3&lt;/td&gt; &#xA;   &lt;td&gt;6.71&lt;/td&gt; &#xA;   &lt;td&gt;19.91&lt;/td&gt; &#xA;   &lt;td&gt;2.27&lt;/td&gt; &#xA;   &lt;td&gt;0.74&lt;/td&gt; &#xA;   &lt;td&gt;28.78&lt;/td&gt; &#xA;   &lt;td&gt;60.77*&lt;/td&gt; &#xA;   &lt;td&gt;28.15*&lt;/td&gt; &#xA;   &lt;td&gt;58.33*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-1.8B&lt;/td&gt; &#xA;   &lt;td&gt;34.72&lt;/td&gt; &#xA;   &lt;td&gt;31.87&lt;/td&gt; &#xA;   &lt;td&gt;47.57&lt;/td&gt; &#xA;   &lt;td&gt;49.81&lt;/td&gt; &#xA;   &lt;td&gt;45.32&lt;/td&gt; &#xA;   &lt;td&gt;43.37&lt;/td&gt; &#xA;   &lt;td&gt;7.93&lt;/td&gt; &#xA;   &lt;td&gt;17.80&lt;/td&gt; &#xA;   &lt;td&gt;19.26&lt;/td&gt; &#xA;   &lt;td&gt;2.42&lt;/td&gt; &#xA;   &lt;td&gt;29.07&lt;/td&gt; &#xA;   &lt;td&gt;63.97*&lt;/td&gt; &#xA;   &lt;td&gt;43.69&lt;/td&gt; &#xA;   &lt;td&gt;59.28*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Gemini Nano-3B&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;27.2(report)&lt;/td&gt; &#xA;   &lt;td&gt;22.8(report)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;42.4(report)&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;StableLM-Zephyr-3B&lt;/td&gt; &#xA;   &lt;td&gt;43.46&lt;/td&gt; &#xA;   &lt;td&gt;46.31&lt;/td&gt; &#xA;   &lt;td&gt;30.62&lt;/td&gt; &#xA;   &lt;td&gt;30.34&lt;/td&gt; &#xA;   &lt;td&gt;30.89&lt;/td&gt; &#xA;   &lt;td&gt;45.9&lt;/td&gt; &#xA;   &lt;td&gt;35.37&lt;/td&gt; &#xA;   &lt;td&gt;31.85&lt;/td&gt; &#xA;   &lt;td&gt;52.54&lt;/td&gt; &#xA;   &lt;td&gt;12.49&lt;/td&gt; &#xA;   &lt;td&gt;37.68&lt;/td&gt; &#xA;   &lt;td&gt;73.78&lt;/td&gt; &#xA;   &lt;td&gt;55.38&lt;/td&gt; &#xA;   &lt;td&gt;71.87*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Phi-2-2B&lt;/td&gt; &#xA;   &lt;td&gt;48.84&lt;/td&gt; &#xA;   &lt;td&gt;54.41&lt;/td&gt; &#xA;   &lt;td&gt;23.78&lt;/td&gt; &#xA;   &lt;td&gt;23.37&lt;/td&gt; &#xA;   &lt;td&gt;24.18&lt;/td&gt; &#xA;   &lt;td&gt;52.66&lt;/td&gt; &#xA;   &lt;td&gt;47.56&lt;/td&gt; &#xA;   &lt;td&gt;55.04&lt;/td&gt; &#xA;   &lt;td&gt;57.16&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;   &lt;td&gt;43.39&lt;/td&gt; &#xA;   &lt;td&gt;86.11&lt;/td&gt; &#xA;   &lt;td&gt;71.25&lt;/td&gt; &#xA;   &lt;td&gt;73.07*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.10&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;Chat模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;平均分&lt;/th&gt; &#xA;   &lt;th&gt;英文均分&lt;/th&gt; &#xA;   &lt;th&gt;中文均分&lt;/th&gt; &#xA;   &lt;th&gt;C-Eval&lt;/th&gt; &#xA;   &lt;th&gt;CMMLU&lt;/th&gt; &#xA;   &lt;th&gt;MMLU&lt;/th&gt; &#xA;   &lt;th&gt;HumanEval&lt;/th&gt; &#xA;   &lt;th&gt;MBPP&lt;/th&gt; &#xA;   &lt;th&gt;GSM8K&lt;/th&gt; &#xA;   &lt;th&gt;MATH&lt;/th&gt; &#xA;   &lt;th&gt;BBH&lt;/th&gt; &#xA;   &lt;th&gt;ARC-E&lt;/th&gt; &#xA;   &lt;th&gt;ARC-C&lt;/th&gt; &#xA;   &lt;th&gt;HellaSwag&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;ChatGLM2-6B&lt;/td&gt; &#xA;   &lt;td&gt;37.98&lt;/td&gt; &#xA;   &lt;td&gt;35.17&lt;/td&gt; &#xA;   &lt;td&gt;50.63&lt;/td&gt; &#xA;   &lt;td&gt;52.05&lt;/td&gt; &#xA;   &lt;td&gt;49.21&lt;/td&gt; &#xA;   &lt;td&gt;45.77&lt;/td&gt; &#xA;   &lt;td&gt;10.37&lt;/td&gt; &#xA;   &lt;td&gt;9.38&lt;/td&gt; &#xA;   &lt;td&gt;22.74&lt;/td&gt; &#xA;   &lt;td&gt;5.96&lt;/td&gt; &#xA;   &lt;td&gt;32.6&lt;/td&gt; &#xA;   &lt;td&gt;74.45&lt;/td&gt; &#xA;   &lt;td&gt;56.82&lt;/td&gt; &#xA;   &lt;td&gt;58.48*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;44.36&lt;/td&gt; &#xA;   &lt;td&gt;45.89&lt;/td&gt; &#xA;   &lt;td&gt;37.51&lt;/td&gt; &#xA;   &lt;td&gt;38.06&lt;/td&gt; &#xA;   &lt;td&gt;36.96&lt;/td&gt; &#xA;   &lt;td&gt;53.56&lt;/td&gt; &#xA;   &lt;td&gt;29.27&lt;/td&gt; &#xA;   &lt;td&gt;39.34&lt;/td&gt; &#xA;   &lt;td&gt;28.73&lt;/td&gt; &#xA;   &lt;td&gt;3.48&lt;/td&gt; &#xA;   &lt;td&gt;39.52&lt;/td&gt; &#xA;   &lt;td&gt;81.61&lt;/td&gt; &#xA;   &lt;td&gt;63.99&lt;/td&gt; &#xA;   &lt;td&gt;73.47*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;   &lt;td&gt;50.91&lt;/td&gt; &#xA;   &lt;td&gt;52.83&lt;/td&gt; &#xA;   &lt;td&gt;42.235&lt;/td&gt; &#xA;   &lt;td&gt;42.55&lt;/td&gt; &#xA;   &lt;td&gt;41.92&lt;/td&gt; &#xA;   &lt;td&gt;60.51&lt;/td&gt; &#xA;   &lt;td&gt;36.59&lt;/td&gt; &#xA;   &lt;td&gt;48.95&lt;/td&gt; &#xA;   &lt;td&gt;40.49&lt;/td&gt; &#xA;   &lt;td&gt;4.95&lt;/td&gt; &#xA;   &lt;td&gt;39.81&lt;/td&gt; &#xA;   &lt;td&gt;86.28&lt;/td&gt; &#xA;   &lt;td&gt;73.38&lt;/td&gt; &#xA;   &lt;td&gt;84.55*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Qwen-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;44.93&lt;/td&gt; &#xA;   &lt;td&gt;42.05&lt;/td&gt; &#xA;   &lt;td&gt;57.9&lt;/td&gt; &#xA;   &lt;td&gt;58.57&lt;/td&gt; &#xA;   &lt;td&gt;57.23&lt;/td&gt; &#xA;   &lt;td&gt;56.03&lt;/td&gt; &#xA;   &lt;td&gt;15.85&lt;/td&gt; &#xA;   &lt;td&gt;40.52&lt;/td&gt; &#xA;   &lt;td&gt;42.23&lt;/td&gt; &#xA;   &lt;td&gt;8.3&lt;/td&gt; &#xA;   &lt;td&gt;37.34&lt;/td&gt; &#xA;   &lt;td&gt;64.44*&lt;/td&gt; &#xA;   &lt;td&gt;39.25*&lt;/td&gt; &#xA;   &lt;td&gt;74.52*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yi-6B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;50.46&lt;/td&gt; &#xA;   &lt;td&gt;45.89&lt;/td&gt; &#xA;   &lt;td&gt;70.995&lt;/td&gt; &#xA;   &lt;td&gt;70.88&lt;/td&gt; &#xA;   &lt;td&gt;71.11&lt;/td&gt; &#xA;   &lt;td&gt;62.95&lt;/td&gt; &#xA;   &lt;td&gt;14.02&lt;/td&gt; &#xA;   &lt;td&gt;28.34&lt;/td&gt; &#xA;   &lt;td&gt;36.54&lt;/td&gt; &#xA;   &lt;td&gt;3.88&lt;/td&gt; &#xA;   &lt;td&gt;37.43&lt;/td&gt; &#xA;   &lt;td&gt;84.89&lt;/td&gt; &#xA;   &lt;td&gt;70.39&lt;/td&gt; &#xA;   &lt;td&gt;74.6*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Baichuan2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;44.68&lt;/td&gt; &#xA;   &lt;td&gt;42.74&lt;/td&gt; &#xA;   &lt;td&gt;53.39&lt;/td&gt; &#xA;   &lt;td&gt;53.28&lt;/td&gt; &#xA;   &lt;td&gt;53.5&lt;/td&gt; &#xA;   &lt;td&gt;53&lt;/td&gt; &#xA;   &lt;td&gt;21.34&lt;/td&gt; &#xA;   &lt;td&gt;32.32&lt;/td&gt; &#xA;   &lt;td&gt;25.25&lt;/td&gt; &#xA;   &lt;td&gt;6.32&lt;/td&gt; &#xA;   &lt;td&gt;37.46&lt;/td&gt; &#xA;   &lt;td&gt;79.63&lt;/td&gt; &#xA;   &lt;td&gt;60.15&lt;/td&gt; &#xA;   &lt;td&gt;69.23*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Deepseek-7B-chat&lt;/td&gt; &#xA;   &lt;td&gt;49.34&lt;/td&gt; &#xA;   &lt;td&gt;49.56&lt;/td&gt; &#xA;   &lt;td&gt;48.335&lt;/td&gt; &#xA;   &lt;td&gt;46.95&lt;/td&gt; &#xA;   &lt;td&gt;49.72&lt;/td&gt; &#xA;   &lt;td&gt;51.67&lt;/td&gt; &#xA;   &lt;td&gt;40.85&lt;/td&gt; &#xA;   &lt;td&gt;48.48&lt;/td&gt; &#xA;   &lt;td&gt;48.52&lt;/td&gt; &#xA;   &lt;td&gt;4.26&lt;/td&gt; &#xA;   &lt;td&gt;35.7&lt;/td&gt; &#xA;   &lt;td&gt;76.85&lt;/td&gt; &#xA;   &lt;td&gt;63.05&lt;/td&gt; &#xA;   &lt;td&gt;76.68*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Llama2-7B-Chat&lt;/td&gt; &#xA;   &lt;td&gt;38.16&lt;/td&gt; &#xA;   &lt;td&gt;39.17&lt;/td&gt; &#xA;   &lt;td&gt;33.59&lt;/td&gt; &#xA;   &lt;td&gt;34.54&lt;/td&gt; &#xA;   &lt;td&gt;32.64&lt;/td&gt; &#xA;   &lt;td&gt;47.64&lt;/td&gt; &#xA;   &lt;td&gt;14.02&lt;/td&gt; &#xA;   &lt;td&gt;27.4&lt;/td&gt; &#xA;   &lt;td&gt;21.15&lt;/td&gt; &#xA;   &lt;td&gt;2.08&lt;/td&gt; &#xA;   &lt;td&gt;35.54&lt;/td&gt; &#xA;   &lt;td&gt;74.28&lt;/td&gt; &#xA;   &lt;td&gt;54.78&lt;/td&gt; &#xA;   &lt;td&gt;75.65*&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2B&lt;/td&gt; &#xA;   &lt;td&gt;52.33&lt;/td&gt; &#xA;   &lt;td&gt;52.6&lt;/td&gt; &#xA;   &lt;td&gt;51.10&lt;/td&gt; &#xA;   &lt;td&gt;51.13&lt;/td&gt; &#xA;   &lt;td&gt;51.07&lt;/td&gt; &#xA;   &lt;td&gt;53.46&lt;/td&gt; &#xA;   &lt;td&gt;50.00&lt;/td&gt; &#xA;   &lt;td&gt;47.31&lt;/td&gt; &#xA;   &lt;td&gt;53.83&lt;/td&gt; &#xA;   &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;td&gt;36.87&lt;/td&gt; &#xA;   &lt;td&gt;85.44&lt;/td&gt; &#xA;   &lt;td&gt;68.00&lt;/td&gt; &#xA;   &lt;td&gt;68.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;strong&gt;DPO后模型比较：&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;模型&lt;/th&gt; &#xA;   &lt;th&gt;MT-bench&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-4-turbo&lt;/td&gt; &#xA;   &lt;td&gt;9.32&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;GPT-3.5-turbo&lt;/td&gt; &#xA;   &lt;td&gt;8.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-8*7b-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;8.30&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claude-2.1&lt;/td&gt; &#xA;   &lt;td&gt;8.18&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Zephyr-7B-beta&lt;/td&gt; &#xA;   &lt;td&gt;7.34&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;strong&gt;MiniCPM-2B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;strong&gt;7.25&lt;/strong&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Vicuna-33B&lt;/td&gt; &#xA;   &lt;td&gt;7.12&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Zephyr-7B-alpha&lt;/td&gt; &#xA;   &lt;td&gt;6.88&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LLaMA-2-70B-chat&lt;/td&gt; &#xA;   &lt;td&gt;6.86&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.1&lt;/td&gt; &#xA;   &lt;td&gt;6.84&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MPT-34B-instruct&lt;/td&gt; &#xA;   &lt;td&gt;6.39&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MiniCPM-2B-128k 模型评测&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Model&lt;/th&gt; &#xA;   &lt;th&gt;avg&lt;/th&gt; &#xA;   &lt;th&gt;avg w/o code&amp;amp;math&lt;/th&gt; &#xA;   &lt;th&gt;passkey&lt;/th&gt; &#xA;   &lt;th&gt;number_string&lt;/th&gt; &#xA;   &lt;th&gt;kv_retrieval&lt;/th&gt; &#xA;   &lt;th&gt;longbook_choice_eng&lt;/th&gt; &#xA;   &lt;th&gt;longbook_qa_chn&lt;/th&gt; &#xA;   &lt;th&gt;longbook_qa_eng&lt;/th&gt; &#xA;   &lt;th&gt;longbook_sum_eng&lt;/th&gt; &#xA;   &lt;th&gt;longdialogue_qa_eng&lt;/th&gt; &#xA;   &lt;th&gt;math_calc&lt;/th&gt; &#xA;   &lt;th&gt;math_find&lt;/th&gt; &#xA;   &lt;th&gt;code_debug&lt;/th&gt; &#xA;   &lt;th&gt;code_run&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;LWM-Text-128k&lt;/td&gt; &#xA;   &lt;td&gt;24.45&lt;/td&gt; &#xA;   &lt;td&gt;33.62&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;97.8&lt;/td&gt; &#xA;   &lt;td&gt;0.6&lt;/td&gt; &#xA;   &lt;td&gt;28.82&lt;/td&gt; &#xA;   &lt;td&gt;15.93&lt;/td&gt; &#xA;   &lt;td&gt;14.31&lt;/td&gt; &#xA;   &lt;td&gt;9.99&lt;/td&gt; &#xA;   &lt;td&gt;1.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;3.43&lt;/td&gt; &#xA;   &lt;td&gt;20.05&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yarn-Mistral-7b-128k&lt;/td&gt; &#xA;   &lt;td&gt;19.84&lt;/td&gt; &#xA;   &lt;td&gt;27.36&lt;/td&gt; &#xA;   &lt;td&gt;92.71&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;27.95&lt;/td&gt; &#xA;   &lt;td&gt;15.49&lt;/td&gt; &#xA;   &lt;td&gt;9.55&lt;/td&gt; &#xA;   &lt;td&gt;9.06&lt;/td&gt; &#xA;   &lt;td&gt;7.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;17.14&lt;/td&gt; &#xA;   &lt;td&gt;0.76&lt;/td&gt; &#xA;   &lt;td&gt;1.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Mistral-7B-Instruct-v0.2(ABF 1000w)&lt;/td&gt; &#xA;   &lt;td&gt;27.75&lt;/td&gt; &#xA;   &lt;td&gt;36.9&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;78.98&lt;/td&gt; &#xA;   &lt;td&gt;3.6&lt;/td&gt; &#xA;   &lt;td&gt;37.12&lt;/td&gt; &#xA;   &lt;td&gt;11.74&lt;/td&gt; &#xA;   &lt;td&gt;17.37&lt;/td&gt; &#xA;   &lt;td&gt;21.12&lt;/td&gt; &#xA;   &lt;td&gt;9.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;29.43&lt;/td&gt; &#xA;   &lt;td&gt;17.51&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Yi-6B-200k&lt;/td&gt; &#xA;   &lt;td&gt;22.15&lt;/td&gt; &#xA;   &lt;td&gt;32.54&lt;/td&gt; &#xA;   &lt;td&gt;100&lt;/td&gt; &#xA;   &lt;td&gt;94.92&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;36.68&lt;/td&gt; &#xA;   &lt;td&gt;15.07&lt;/td&gt; &#xA;   &lt;td&gt;9.2&lt;/td&gt; &#xA;   &lt;td&gt;0.92&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;4.29&lt;/td&gt; &#xA;   &lt;td&gt;0.51&lt;/td&gt; &#xA;   &lt;td&gt;0.75&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;chatglm3-6b-128k&lt;/td&gt; &#xA;   &lt;td&gt;25.58&lt;/td&gt; &#xA;   &lt;td&gt;36.57&lt;/td&gt; &#xA;   &lt;td&gt;89.93&lt;/td&gt; &#xA;   &lt;td&gt;99.66&lt;/td&gt; &#xA;   &lt;td&gt;5.2&lt;/td&gt; &#xA;   &lt;td&gt;46.29&lt;/td&gt; &#xA;   &lt;td&gt;10.7&lt;/td&gt; &#xA;   &lt;td&gt;8.38&lt;/td&gt; &#xA;   &lt;td&gt;25.91&lt;/td&gt; &#xA;   &lt;td&gt;6.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;5.33&lt;/td&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;MiniCPM-2.4B-128k&lt;/td&gt; &#xA;   &lt;td&gt;27.32&lt;/td&gt; &#xA;   &lt;td&gt;37.68&lt;/td&gt; &#xA;   &lt;td&gt;98.31&lt;/td&gt; &#xA;   &lt;td&gt;99.83&lt;/td&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;29.69&lt;/td&gt; &#xA;   &lt;td&gt;23.06&lt;/td&gt; &#xA;   &lt;td&gt;16.33&lt;/td&gt; &#xA;   &lt;td&gt;15.73&lt;/td&gt; &#xA;   &lt;td&gt;9.5&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;   &lt;td&gt;4.29&lt;/td&gt; &#xA;   &lt;td&gt;22.08&lt;/td&gt; &#xA;   &lt;td&gt;0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h4&gt;MiniCPM-MoE-8x2B模型评测&lt;/h4&gt; &#xA;&lt;div align=&#34;left&#34;&gt; &#xA; &lt;table style=&#34;margin: 0px auto;&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;    &lt;th nowrap&gt;BBH&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MMLU&lt;/th&gt; &#xA;    &lt;th nowrap&gt;CEval&lt;/th&gt; &#xA;    &lt;th nowrap&gt;CMMLU&lt;/th&gt; &#xA;    &lt;th nowrap&gt;HumanEval&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MBPP†&lt;/th&gt; &#xA;    &lt;th nowrap&gt;GSM8K&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MATH&lt;/th&gt; &#xA;   &lt;/tr&gt;&#xA;  &lt;/thead&gt; &#xA;  &lt;tbody align=&#34;center&#34;&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Llama2-34B*&lt;/td&gt; &#xA;    &lt;td&gt;44.1&lt;/td&gt; &#xA;    &lt;td&gt;62.6&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;22.6&lt;/td&gt; &#xA;    &lt;td&gt;33.0&lt;/td&gt; &#xA;    &lt;td&gt;42.2&lt;/td&gt; &#xA;    &lt;td&gt;6.24&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Mistral-7B-Instruct-v0.2&lt;/td&gt; &#xA;    &lt;td&gt;39.81&lt;/td&gt; &#xA;    &lt;td&gt;60.51&lt;/td&gt; &#xA;    &lt;td&gt;42.55&lt;/td&gt; &#xA;    &lt;td&gt;41.92&lt;/td&gt; &#xA;    &lt;td&gt;36.59&lt;/td&gt; &#xA;    &lt;td&gt;39.63&lt;/td&gt; &#xA;    &lt;td&gt;40.49&lt;/td&gt; &#xA;    &lt;td&gt;4.95&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Gemma-7B*&lt;/td&gt; &#xA;    &lt;td&gt;55.1&lt;/td&gt; &#xA;    &lt;td&gt;64.3&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;32.3&lt;/td&gt; &#xA;    &lt;td&gt;44.4&lt;/td&gt; &#xA;    &lt;td&gt;46.4&lt;/td&gt; &#xA;    &lt;td&gt;24.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Qwen1.5-7B*&lt;/td&gt; &#xA;    &lt;td&gt;40.2&lt;/td&gt; &#xA;    &lt;td&gt;61&lt;/td&gt; &#xA;    &lt;td&gt;74.1&lt;/td&gt; &#xA;    &lt;td&gt;73.1&lt;/td&gt; &#xA;    &lt;td&gt;36&lt;/td&gt; &#xA;    &lt;td&gt;37.4&lt;/td&gt; &#xA;    &lt;td&gt;62.5&lt;/td&gt; &#xA;    &lt;td&gt;20.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Deepseek-MoE(16B)*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;45.0&lt;/td&gt; &#xA;    &lt;td&gt;40.6&lt;/td&gt; &#xA;    &lt;td&gt;42.5&lt;/td&gt; &#xA;    &lt;td&gt;26.8&lt;/td&gt; &#xA;    &lt;td&gt;39.2&lt;/td&gt; &#xA;    &lt;td&gt;18.8&lt;/td&gt; &#xA;    &lt;td&gt;4.3&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-2.4B&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td&gt;36.87&lt;/td&gt; &#xA;    &lt;td&gt;53.46&lt;/td&gt; &#xA;    &lt;td&gt;51.13&lt;/td&gt; &#xA;    &lt;td&gt;51.07&lt;/td&gt; &#xA;    &lt;td&gt;50.00&lt;/td&gt; &#xA;    &lt;td&gt;35.93&lt;/td&gt; &#xA;    &lt;td&gt;53.83&lt;/td&gt; &#xA;    &lt;td&gt;10.24&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;b&gt;MiniCPM-MoE-8x2B&lt;/b&gt;&lt;/td&gt; &#xA;    &lt;td&gt;39.22&lt;/td&gt; &#xA;    &lt;td&gt;58.90&lt;/td&gt; &#xA;    &lt;td&gt;58.11&lt;/td&gt; &#xA;    &lt;td&gt;58.80&lt;/td&gt; &#xA;    &lt;td&gt;55.49&lt;/td&gt; &#xA;    &lt;td&gt;41.68&lt;/td&gt; &#xA;    &lt;td&gt;61.56&lt;/td&gt; &#xA;    &lt;td&gt;10.52&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;p id=&#34;4&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;注：* 表示结果取自技术报告。† 表示评测集为MBPP全集。&lt;/p&gt; &#xA;&lt;h4&gt;多模态模型评测&lt;/h4&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table style=&#34;margin: 0px auto;&#34;&gt; &#xA;  &lt;thead&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;th align=&#34;left&#34;&gt;Model&lt;/th&gt; &#xA;    &lt;th&gt;Size&lt;/th&gt; &#xA;    &lt;th&gt;TextVQA val&lt;/th&gt; &#xA;    &lt;th&gt;DocVQA test&lt;/th&gt; &#xA;    &lt;th&gt;OCRBench&lt;/th&gt; &#xA;    &lt;th&gt;OpenCompass&lt;/th&gt; &#xA;    &lt;th nowrap&gt;MME&lt;/th&gt; &#xA;    &lt;th&gt;MMB dev(en)&lt;/th&gt; &#xA;    &lt;th&gt;MMB dev(zh)&lt;/th&gt; &#xA;    &lt;th&gt;MMMU val&lt;/th&gt; &#xA;    &lt;th&gt;MathVista&lt;/th&gt; &#xA;    &lt;th&gt;LLaVA Bench&lt;/th&gt; &#xA;    &lt;th nowrap&gt;Object HalBench&lt;/th&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/thead&gt; &#xA;  &lt;tbody align=&#34;center&#34;&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Proprietary models&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Gemini Pro Vision&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;74.6&lt;/td&gt; &#xA;    &lt;td&gt;88.1&lt;/td&gt; &#xA;    &lt;td&gt;680&lt;/td&gt; &#xA;    &lt;td&gt;63.8&lt;/td&gt; &#xA;    &lt;td&gt;2148.9&lt;/td&gt; &#xA;    &lt;td&gt;75.2&lt;/td&gt; &#xA;    &lt;td&gt;74.0&lt;/td&gt; &#xA;    &lt;td&gt;48.9&lt;/td&gt; &#xA;    &lt;td&gt;45.8&lt;/td&gt; &#xA;    &lt;td&gt;79.9&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;GPT-4V&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;78.0&lt;/td&gt; &#xA;    &lt;td&gt;88.4&lt;/td&gt; &#xA;    &lt;td&gt;645&lt;/td&gt; &#xA;    &lt;td&gt;63.2&lt;/td&gt; &#xA;    &lt;td&gt;1771.5&lt;/td&gt; &#xA;    &lt;td&gt;75.1&lt;/td&gt; &#xA;    &lt;td&gt;75.0&lt;/td&gt; &#xA;    &lt;td&gt;53.8&lt;/td&gt; &#xA;    &lt;td&gt;47.8&lt;/td&gt; &#xA;    &lt;td&gt;93.1&lt;/td&gt; &#xA;    &lt;td&gt;86.4 / 92.7&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Open-source models 6B~34B&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Yi-VL-6B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;6.7B&lt;/td&gt; &#xA;    &lt;td&gt;45.5*&lt;/td&gt; &#xA;    &lt;td&gt;17.1*&lt;/td&gt; &#xA;    &lt;td&gt;290&lt;/td&gt; &#xA;    &lt;td&gt;49.3&lt;/td&gt; &#xA;    &lt;td&gt;1915.1 &lt;/td&gt; &#xA;    &lt;td&gt;68.6 &lt;/td&gt; &#xA;    &lt;td&gt;68.3 &lt;/td&gt; &#xA;    &lt;td&gt;40.3 &lt;/td&gt; &#xA;    &lt;td&gt;28.8 &lt;/td&gt; &#xA;    &lt;td&gt;51.9 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Qwen-VL-Chat&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;9.6B&lt;/td&gt; &#xA;    &lt;td&gt;61.5&lt;/td&gt; &#xA;    &lt;td&gt;62.6&lt;/td&gt; &#xA;    &lt;td&gt;488 &lt;/td&gt; &#xA;    &lt;td&gt;52.1 &lt;/td&gt; &#xA;    &lt;td&gt;1860.0 &lt;/td&gt; &#xA;    &lt;td&gt;60.6 &lt;/td&gt; &#xA;    &lt;td&gt;56.7 &lt;/td&gt; &#xA;    &lt;td&gt;37.0 &lt;/td&gt; &#xA;    &lt;td&gt;33.8 &lt;/td&gt; &#xA;    &lt;td&gt;67.7 &lt;/td&gt; &#xA;    &lt;td&gt;56.2 / 80.0&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Yi-VL-34B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;34B&lt;/td&gt; &#xA;    &lt;td&gt;43.4*&lt;/td&gt; &#xA;    &lt;td&gt;16.9*&lt;/td&gt; &#xA;    &lt;td&gt;290&lt;/td&gt; &#xA;    &lt;td&gt;52.6 &lt;/td&gt; &#xA;    &lt;td&gt;2050.2&lt;/td&gt; &#xA;    &lt;td&gt;71.1&lt;/td&gt; &#xA;    &lt;td&gt;71.4&lt;/td&gt; &#xA;    &lt;td&gt;45.1&lt;/td&gt; &#xA;    &lt;td&gt;30.7&lt;/td&gt; &#xA;    &lt;td&gt;62.3&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;DeepSeek-VL-7B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;7.3B&lt;/td&gt; &#xA;    &lt;td&gt;64.7*&lt;/td&gt; &#xA;    &lt;td&gt;47.0* &lt;/td&gt; &#xA;    &lt;td&gt;435&lt;/td&gt; &#xA;    &lt;td&gt;55.6 &lt;/td&gt; &#xA;    &lt;td&gt;1765.4 &lt;/td&gt; &#xA;    &lt;td&gt;74.1 &lt;/td&gt; &#xA;    &lt;td&gt;72.8 &lt;/td&gt; &#xA;    &lt;td&gt;38.3 &lt;/td&gt; &#xA;    &lt;td&gt;36.8&lt;/td&gt; &#xA;    &lt;td&gt;77.8 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;TextMonkey&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;9.7B&lt;/td&gt; &#xA;    &lt;td&gt;64.3&lt;/td&gt; &#xA;    &lt;td&gt;66.7 &lt;/td&gt; &#xA;    &lt;td&gt;558&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;CogVLM-Chat&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;17.4B&lt;/td&gt; &#xA;    &lt;td&gt;70.4&lt;/td&gt; &#xA;    &lt;td&gt;33.3*&lt;/td&gt; &#xA;    &lt;td&gt;590 &lt;/td&gt; &#xA;    &lt;td&gt;52.5 &lt;/td&gt; &#xA;    &lt;td&gt;1736.6 &lt;/td&gt; &#xA;    &lt;td&gt;63.7 &lt;/td&gt; &#xA;    &lt;td&gt;53.8 &lt;/td&gt; &#xA;    &lt;td&gt;37.3 &lt;/td&gt; &#xA;    &lt;td&gt;34.7 &lt;/td&gt; &#xA;    &lt;td&gt;73.9 &lt;/td&gt; &#xA;    &lt;td&gt;73.6 / 87.4 &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td colspan=&#34;12&#34; align=&#34;left&#34;&gt;&lt;strong&gt;Open-source models 1B~3B &lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;DeepSeek-VL-1.3B&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;1.7B&lt;/td&gt; &#xA;    &lt;td&gt;58.4*&lt;/td&gt; &#xA;    &lt;td&gt;37.9*&lt;/td&gt; &#xA;    &lt;td&gt;413&lt;/td&gt; &#xA;    &lt;td&gt;46.0 &lt;/td&gt; &#xA;    &lt;td&gt;1531.6 &lt;/td&gt; &#xA;    &lt;td&gt;64.0 &lt;/td&gt; &#xA;    &lt;td&gt;61.2 &lt;/td&gt; &#xA;    &lt;td&gt;33.8 &lt;/td&gt; &#xA;    &lt;td&gt;29.4 &lt;/td&gt; &#xA;    &lt;td&gt;51.1 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;MobileVLM V2&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;3.1B&lt;/td&gt; &#xA;    &lt;td&gt;57.5&lt;/td&gt; &#xA;    &lt;td&gt;19.4*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;1440.5(P) &lt;/td&gt; &#xA;    &lt;td&gt;63.2 &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;Mini-Gemini&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.2B&lt;/td&gt; &#xA;    &lt;td&gt;56.2&lt;/td&gt; &#xA;    &lt;td&gt;34.2*&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;1653.0 &lt;/td&gt; &#xA;    &lt;td&gt;59.8 &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;31.7 &lt;/td&gt; &#xA;    &lt;td&gt;-&lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;    &lt;td&gt;- &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;MiniCPM-V&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.8B &lt;/td&gt; &#xA;    &lt;td&gt;60.6&lt;/td&gt; &#xA;    &lt;td&gt;38.2 &lt;/td&gt; &#xA;    &lt;td&gt;366&lt;/td&gt; &#xA;    &lt;td&gt;47.6&lt;/td&gt; &#xA;    &lt;td&gt;1650.2 &lt;/td&gt; &#xA;    &lt;td&gt;67.9 &lt;/td&gt; &#xA;    &lt;td&gt;65.3 &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;38.3&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;28.9&lt;/td&gt; &#xA;    &lt;td&gt;51.3 &lt;/td&gt; &#xA;    &lt;td&gt;78.4 / 88.5 &lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td nowrap align=&#34;left&#34;&gt;&lt;strong&gt;MiniCPM-V 2.0&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;right&#34;&gt;2.8B &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;74.1&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;71.9&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;605&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;55.0&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;1808.6&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;69.6&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;68.1&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;38.2 &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;38.7&lt;/strong&gt;&lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;69.2&lt;/strong&gt; &lt;/td&gt; &#xA;    &lt;td&gt;&lt;strong&gt;85.5 / 92.2 &lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt; &#xA; &lt;/table&gt; &#xA;&lt;/div&gt; * 我们自己评测了正式开源的模型权重。 &#xA;&lt;p id=&#34;4&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;手机部署&lt;/h2&gt; &#xA;&lt;h4&gt;部署步骤&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;进行Int4量化后，MiniCPM只占2GB空间，具备在端侧手机进行模型部署的条件。&lt;/li&gt; &#xA; &lt;li&gt;对于不同的操作系统，我们进行了不同的适配。&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;注意：当前开源框架对手机支持还在完善，并非所有芯片与操作系统版本均能成功运行MLC-LLM或LLMFarm。&lt;/strong&gt;&lt;/li&gt; &#xA; &lt;li&gt;Android、HarmonyOS &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用开源框架MLC-LLM进行模型适配。&lt;/li&gt; &#xA;   &lt;li&gt;支持文本模型、多模态模型。&lt;/li&gt; &#xA;   &lt;li&gt;适用于MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4、MiniCPM-V。&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/mlc-MiniCPM&#34;&gt;编译安装MiniCPM指南&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;iOS &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用开源框架LLMFarm进行模型适配。&lt;/li&gt; &#xA;   &lt;li&gt;支持文本模型。&lt;/li&gt; &#xA;   &lt;li&gt;适用于MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4。&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/LLMFarm&#34;&gt;编译安装MiniCPM指南&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;部署性能&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;我们未针对手机推理模型进行深度优化和系统测试，仅验证MiniCPM使用手机芯片进行推理的可行性。&lt;strong&gt;我们也欢迎更多开发者进一步调优并更新下面的测试列表，不断提升端侧大模型在手机上的推理性能&lt;/strong&gt;。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;手机型号&lt;/th&gt; &#xA;   &lt;th&gt;操作系统&lt;/th&gt; &#xA;   &lt;th&gt;处理器&lt;/th&gt; &#xA;   &lt;th&gt;Memory（GB）&lt;/th&gt; &#xA;   &lt;th&gt;文本吞吐（token/s）&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;OPPO Find N3&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen2&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;6.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Samsung S23 Ultra&lt;/td&gt; &#xA;   &lt;td&gt;Android 14&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen2&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;6.4&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Meizu M182Q&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 888Plus&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi 12 Pro&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 8 Gen1&lt;/td&gt; &#xA;   &lt;td&gt;8+3&lt;/td&gt; &#xA;   &lt;td&gt;3.7&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi Redmi K40&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 870&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus LE 2100&lt;/td&gt; &#xA;   &lt;td&gt;Android 13&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 870&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 865&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1905&lt;/td&gt; &#xA;   &lt;td&gt;Android 10&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Oneplus HD1900&lt;/td&gt; &#xA;   &lt;td&gt;Android 11&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 855&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;3.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi MI 8&lt;/td&gt; &#xA;   &lt;td&gt;Android 9&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 845&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;2.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Huawei Nova 11SE&lt;/td&gt; &#xA;   &lt;td&gt;HarmonyOS 4.0.0&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 778&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;1.9&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi MIX 2&lt;/td&gt; &#xA;   &lt;td&gt;Android 9&lt;/td&gt; &#xA;   &lt;td&gt;snapdragon 835&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;1.3&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 15 Pro&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A17 pro&lt;/td&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;18.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 15&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A16&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;15.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 12 Pro&lt;/td&gt; &#xA;   &lt;td&gt;iOS 16.5.1&lt;/td&gt; &#xA;   &lt;td&gt;A14&lt;/td&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 12&lt;/td&gt; &#xA;   &lt;td&gt;iOS 17.2.1&lt;/td&gt; &#xA;   &lt;td&gt;A14&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;5.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;iPhone 11&lt;/td&gt; &#xA;   &lt;td&gt;iOS 16.6&lt;/td&gt; &#xA;   &lt;td&gt;A13&lt;/td&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;4.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Xiaomi Redmi K50&lt;/td&gt; &#xA;   &lt;td&gt;HyperOS 1.0.2&lt;/td&gt; &#xA;   &lt;td&gt;MediaTek Dimensity 8100&lt;/td&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;3.5&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;我们也使用MLC-LLM验证了在手机上部署MiniCPM-V系列模型的可行性，能够正常输入输出，但也存在图片处理时间较长的问题，需要进一步优化，兼容性问题也需要进一步解决。下面的动图是使用小米14 Pro运行MiniCPM-V 2.0的屏幕录像，没有进行任何编辑。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/OpenBMB/MiniCPM-V/raw/main/assets/gif_cases/station.gif&#34; width=&#34;36%/&#34;&gt; &lt;img src=&#34;https://github.com/OpenBMB/MiniCPM-V/raw/main/assets/gif_cases/english_menu.gif&#34; width=&#34;36%/&#34;&gt; &lt;/p&gt;&#xA;&lt;table align=&#34;center&#34;&gt;  &#xA;&lt;/table&gt; &#xA;&lt;p id=&#34;5&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Demo &amp;amp; API 部署&lt;/h2&gt; &#xA;&lt;h4&gt;基于Gradio的网页版Demo&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;使用如下命令启动基于Gradio的网页版demo：&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# generation powered by vllm&#xA;python demo/vllm_based_demo.py --model_path &amp;lt;vllmcpm_repo_path&amp;gt;&#xA;# generation powered by huggingface&#xA;python demo/hf_based_demo.py --model_path &amp;lt;hf_repo_path&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p id=&#34;6&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;二次开发&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;高效参数微调&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;一张1080/2080可实现高效参数微调&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/tree/main/finetune&#34;&gt;高效参数微调代码&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;全参数微调 or 持续训练&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;使用&lt;a href=&#34;https://github.com/OpenBMB/BMTrain&#34;&gt;BMTrain&lt;/a&gt;，借助重计算和ZeRO-3，一张3090/4090可实现全参数微调，一台机器可实现持续训练&lt;/li&gt; &#xA;   &lt;li&gt;相关代码也将陆续推出&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;mlx高效参数微调&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;环境准备 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install -r finetune/requirements_mlx.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;   &lt;li&gt;微调命令 &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# train&#xA;python mlx_finetune.py --model MiniCPM-2B-sft-bf16-llama-format-mlx  --data data/AdvertiseGen  --train  --seed 2024 --iters 500&#xA;# test&#xA;python mlx_finetune.py --model MiniCPM-2B-sft-bf16-llama-format-mlx  --data data/AdvertiseGen  --test --seed 2024&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;9&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;典型示例&lt;/h2&gt; &#xA;&lt;h4&gt;文本生成&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case1.png&#34; alt=&#34;内容创作-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case2.png&#34; alt=&#34;内容创作-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/creation.case3.png&#34; alt=&#34;内容创作-case3&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;代码生成&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code.case1.gif&#34; alt=&#34;代码生成-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/code.case2.gif&#34; alt=&#34;代码生成-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;数理逻辑&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/math.case1.png&#34; alt=&#34;数理逻辑-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/math.case2.png&#34; alt=&#34;数理逻辑-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;文本翻译&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/translation.case1.png&#34; alt=&#34;文本翻译-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/translation.case2.png&#34; alt=&#34;文本翻译-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;指令跟随&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/instruction_following.case1.png&#34; alt=&#34;指令跟随-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/instruction_following.case2.png&#34; alt=&#34;指令跟随-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;h4&gt;特殊字符&lt;/h4&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/special_char.case1.png&#34; alt=&#34;特殊字符-case1&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/OpenBMB/MiniCPM/main/assets/special_char.case2.png&#34; alt=&#34;特殊字符-case2&#34;&gt;&lt;/p&gt; &#xA;&lt;p id=&#34;7&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;开源协议&lt;/h2&gt; &#xA;&lt;h4&gt;模型协议&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;本仓库中代码依照 &lt;a href=&#34;https://github.com/OpenBMB/MiniCPM/raw/main/LICENSE&#34;&gt;Apache-2.0&lt;/a&gt; 协议开源&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重的使用则需要遵循 &lt;a href=&#34;https://github.com/OpenBMB/General-Model-License/raw/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md&#34;&gt;“通用模型许可协议-来源说明-宣传限制-商业授权”&lt;/a&gt;。&lt;/li&gt; &#xA; &lt;li&gt;MiniCPM 模型权重对学术研究完全开放。&lt;/li&gt; &#xA; &lt;li&gt;如需将模型用于商业用途，请联系&lt;a href=&#34;mailto:cpm@modelbest.cn&#34;&gt;cpm@modelbest.cn&lt;/a&gt;来获取书面授权，在登记后亦允许免费商业使用。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;声明&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;作为一个语言模型，MiniCPM 通过学习大量的文本来生成内容，但它无法理解、表达个人观点或价值判断，它所输出的任何内容都不代表模型开发者的观点和立场。&lt;/li&gt; &#xA; &lt;li&gt;因此用户在使用 MiniCPM 生成的内容时，应自行负责对其进行评估和验证。&lt;/li&gt; &#xA; &lt;li&gt;如果由于使用 MiniCPM 开源模型而导致的任何问题，包括但不限于数据安全问题、公共舆论风险，或模型被误导、滥用、传播或不当利用所带来的任何风险和问题，我们将不承担任何责任。&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p id=&#34;8&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;工作引用&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;如果觉得MiniCPM有助于您的工作，请引用我们的&lt;a href=&#34;https://arxiv.org/abs/2404.06395&#34;&gt;论文&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{hu2024minicpm,&#xA;  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},&#xA;  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},&#xA;  journal={arXiv preprint arXiv:2404.06395},&#xA;  year={2024}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>