<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-09-07T01:31:25Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>deep-learning-indaba/indaba-pracs-2023</title>
    <updated>2023-09-07T01:31:25Z</updated>
    <id>tag:github.com,2023-09-07:/deep-learning-indaba/indaba-pracs-2023</id>
    <link href="https://github.com/deep-learning-indaba/indaba-pracs-2023" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Notebooks for the Practicals at the Deep Learning Indaba 2023.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deep Learning Indaba Practicals 2023&lt;/h1&gt; &#xA;&lt;h2&gt;The Practicals&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;Topic ğŸ’¥&lt;/th&gt; &#xA;   &lt;th&gt;Description ğŸ“˜&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Dive into Machine Learning: Learning by Implementing &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/Intro_ML_English_Prac.ipynb&#34;&gt;English&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Intro_ML_English_Prac.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/introduction-to-ml-french/practicals/Intro_ML_French_Prac.ipynb&#34;&gt;French&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Intro_ML_French_Prac.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;This tutorial offers an immersive exploration of the world of machine learning. Our primary goal is to demystify complex concepts, presenting them in a simplified manner. We adopt an interactive approach, fostering a gradual and intuitive understanding that enables learners to construct their very first machine-learning model step by step.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/ML_for_Bio_Indaba_Practical_2023.ipynb&#34;&gt;Machine Learning for Biology: Learning the Language of Life&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/ML_for_Bio_Indaba_Practical_2023.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;In this tutorial we invite you to explore the language of proteins using machine learning. You don&#39;t require any previous bio experience, just some basic python, machine learning knowledge and a curious spirit! We will be working with cutting edge techniques in protein langauge modelling, such as using large language models to compute embeddings, how to visualise and explore these embeddings, and finally you will have a chance to train your own model!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;&#34;&gt;Responsible AI&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;As AI systems are increasingly used in high-stakes situations, there are important considerations on how to deploy the systems safely and responsibly. In this prac, we will discuss various principles for responsible AI. We will then concentrate on definitions of fairness. In the first half, we will do an activity to brainstorm definitions of fairness for specific use cases. In the second half, we will implement definitions of fairness per existing literature. We will then discuss and implement methods to improve the fairness outcomes of simple linear models.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/Introduction_to_Probabilistic_Thinking_and_Programming.ipynb&#34;&gt;Introduction to Probabilistic Thinking and Programming&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Introduction_to_Probabilistic_Thinking_and_Programming.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Thinking probabilistically and working with probability distributions can be very powerful tools for any machine learning practitioner. Unfortunately, they are tools that are often disregarded due to their perceived complexity. In this practical we hope to demistify these ideas by building intuition, provided practical tips, and introducing a very powerful framework for embracing the probabilistic approach â€“ probabilistic programming. Weâ€™ll both motivate why we need probabilistic programming and give an introduction for using it in practice. &lt;br&gt; &lt;br&gt; This prac is aimed at all knowledge levels! No matter what your prior experience with probabilistic thinking and/or programming, we are sure that you will be able to take away some useful knowledge from this practical. However, this means that depending on your level, some of the content will not be aimed at you. Donâ€™t worry, this will be clearly marked at all points. We reccomend that you try and stick to our suggestions in order to get the most out of this prac in the given time, but if curiosity gets the better of you thatâ€™s also great!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/Recommender_Systems.ipynb&#34;&gt;Recommender Systems or Why Your Phone Isn&#39;t Actually Spying on You (kinda)&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/Recommender_Systems.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Recommender Systems are probably one of the most ubiquitous type of machine learning model that we encounter in our online life. They influence what we see in our social media feeds, the products we buy, the music we listen to, the food we eat, and the movies we watch. Sometimes they&#39;re so good that people feel that their phone is spying on their conversations! In this prac, we hope to convince you that this isn&#39;t the case (mostly) as well as taking you through some of the techniques popularly used in industry that recommends the content you see online.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/RL_2023_prac.ipynb&#34;&gt;Frozen Lake: An Icy Adventure Using Reinforcement Learning!&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/RL_2023_prac.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;RL has seen tremendous success in a wide range of challenging domains such as learning to play complex games like &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;Atari&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/s41586-019-1724-z&#34;&gt;StarCraft II&lt;/a&gt; and &lt;a href=&#34;https://www.nature.com/articles/nature16961&#34;&gt;GO&lt;/a&gt;, and applications like &lt;a href=&#34;https://arxiv.org/abs/1808.00177&#34;&gt;robotics&lt;/a&gt;. Modern natural language processing (NLP) also uses RL to improve the quality of language models based on human feedback (see &lt;a href=&#34;https://huggingface.co/blog/rlhf&#34;&gt;RLHF&lt;/a&gt;). &lt;br&gt; &lt;br&gt; In this tutorial, we will show how RL can be used to help our agent cross a Frozen Lake, while avoiding perilous holes in the ice in order to get to a goal. You will use several different RL approaches, ranging from tabular Q-learning to more modern methods, such as &lt;a href=&#34;https://arxiv.org/abs/1312.5602&#34;&gt;DQN (Deep Q-Networks)&lt;/a&gt;. Along the way, you will be introduced to some of the most fundamental concepts and terminology in RL, while trying to build intuition into what RL is about.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Mathematical Tools for Machine Learning: Linear Algebra &lt;br&gt; &lt;br&gt; &lt;a href=&#34;&#34;&gt;English&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;&#34;&gt;French&lt;/a&gt; &lt;a href=&#34;&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Mathematics is the bedrock tool for all quantitative sciences and machine learning is no exception. Basic literacy in mathematics is essential for any machine learning scientist and fluency is often necessary for understanding or advancing the state of the art. In this practical we focus on linear algebra, providing separate tracks for those at the beginner and intermediate levels. This practical will equip you to understand the vast majority of the linear algebra used in machine learning code and papers, and provide you with the basic skills to do derivations and computations of your own. &lt;br&gt; &lt;br&gt; In the beginner track we give an introduction to the basics of vectors and matrices, as well as an introduction to inner products and norms. The beginner track concludes by applying the techniques weâ€™ve learned to derive the solution for ridge regression, a commonly used method for linear prediction with regularization. The intermediate track covers projections, orthonormal bases, the determinant, the trace, eigenvalues and eigenvectors. The intermediate track concludes by applying the techniques to principal component analysis, a very common method for dimensionality reduction. Whether youâ€™re taking the beginner or intermediate track (or both!), we hope you find this practical useful!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;&#34;&gt;LLMs for everyone&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/large_language_models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Welcome to &#34;LLMs for Everyone,&#34; a practical exploration into the captivating world of Language Models! This entire block of text was crafted only by ChatGPT, showcasing the remarkable capabilities of these type models. Throughout this practical, we will delve into the underlying fundamentals of transformers, the powerful technology that drives models like GPT, and learn how to fine-tune and train our very own Large Language Models. Let&#39;s embark on this exciting journey of understanding and creating LLMs, and discover how such impressive AI text generation is made possible!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/diffusion_models.ipynb&#34;&gt;Diffusion models: Building your own Stable Diffusion&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/diffusion_models.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Denoising Diffusion Models are a variant of generative modelling that serve as the backbone in recent advances in image synthesis - including Dall-E 2, Stable Diffusion, and Midjourney. These models utilise an iterative denoising process during generation to produce high-quality samples. In this practical, we will explore the fundamentals of diffusion models, the intuition behind them, and how they work in practice. By the end of the practical, we will have covered all the steps required to train one of these models from scratch!&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://github.com/deep-learning-indaba/indaba-pracs-2023/raw/main/practicals/geospatial_machine_learning.ipynb&#34;&gt;Let&#39;s map Africa! Introductory Tutorial to Geospatial Machine Learning&lt;/a&gt; &lt;br&gt; &lt;br&gt; &lt;a href=&#34;https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2023/blob/main/practicals/geospatial_machine_learning.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Climate change is a pressing issue affecting the entire planet, with the Global South bearing a disproportionate burden of its impacts despite contributing less to its causes compared to more developed nations in the Global North. Extreme climate events such as droughts, floods, storms, and heatwaves have led to food insecurity and poverty. On the other hand, satellite imagery and machine learning (ML) can help address climate related challenges in food and water security, biodiversity, energy, and public health. To this end, this practical is designed to provide an introductory tutorial on geospatial machine learning for agriculture, particularly to classify farm-level crop types in Kenya using Sentinel-2 satellite imagery. Starting with an introductory session on key concepts of geospatial ML, the tutorial delves into ML development, validation, and performance evaluation techniques. Moreover, we aim to kick-start a build-up of an African GeoAI community that strives and collaborates to solve related challenges in the continent.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;This repository contains the practical notebooks for the Deep Learning Indaba 2023, held at the University of Ghana, Accra, Ghana.&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;http://www.deeplearningindaba.com&#34;&gt;www.deeplearningindaba.com&lt;/a&gt; for more details.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>zhoujing204/python_course</title>
    <updated>2023-09-07T01:31:25Z</updated>
    <id>tag:github.com,2023-09-07:/zhoujing204/python_course</id>
    <link href="https://github.com/zhoujing204/python_course" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A python course for college students.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pythonè¯¾ç¨‹&lt;/h1&gt; &#xA;&lt;p&gt;æœ¬Pythonè¯¾ç¨‹æ˜¯ä¸ºæœ¬ç§‘ä¸‰å¹´çº§å¤§å­¦ç”Ÿå¼€è®¾çš„ã€‚æœ¬è¯¾ç¨‹ä¸ºé›¶åŸºç¡€è¯¾ç¨‹ï¼Œå­¦ä¹ æœ¬è¯¾ç¨‹ä¸éœ€è¦å…·å¤‡Pythonç¼–ç¨‹çŸ¥è¯†å’ŒåŸºç¡€ï¼Œä½†æ˜¯éœ€è¦å…·å¤‡ä¸€å®šè®¡ç®—æœºåŸºç¡€çš„çŸ¥è¯†ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;è¯¾ç¨‹ç›®æ ‡&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;æŒæ¡Pythonç¼–ç¨‹è¯­è¨€çš„åŸºæœ¬è¯­æ³•å’Œç‰¹æ€§ã€‚&lt;/li&gt; &#xA; &lt;li&gt;æŒæ¡é¢å‘å¯¹è±¡ç¼–ç¨‹ï¼ˆObject-Oriented Programming, OOPï¼‰çš„æ¦‚å¿µå’Œå®è·µï¼ŒæŒæ¡å‡½æ•°å¼ç¼–ç¨‹çš„æ¦‚å¿µå’Œå®è·µã€‚&lt;/li&gt; &#xA; &lt;li&gt;å­¦ä¹ ä½¿ç”¨Pythonè¿›è¡Œç¨‹åºè®¾è®¡å’Œå¼€å‘ï¼ŒåŒ…æ‹¬ç®—æ³•å’Œæ•°æ®ç»“æ„çš„åº”ç”¨ã€‚&lt;/li&gt; &#xA; &lt;li&gt;äº†è§£Pythonåœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨ï¼Œå¦‚ç§‘å­¦è®¡ç®—ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ã€Webåº”ç”¨å¼€å‘ç­‰ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åŸ¹å…»è‰¯å¥½çš„ç¼–ç¨‹ä¹ æƒ¯å’Œè§„èŒƒï¼ŒåŒ…æ‹¬ä»£ç å¯è¯»æ€§ã€æ¨¡å—åŒ–è®¾è®¡å’Œæ–‡æ¡£ç¼–å†™ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å­¦ä¼šä½¿ç”¨å¸¸è§çš„Pythonå¼€å‘å·¥å…·ã€é›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰å’Œç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚Gitï¼‰ã€‚&lt;/li&gt; &#xA; &lt;li&gt;å¼€å‘å®é™…é¡¹ç›®å’Œç»ƒä¹ å®è·µï¼Œä»¥å®è·µä¸­ä¸æ–­æå‡ç¼–ç¨‹æŠ€èƒ½å’Œæ€ç»´èƒ½åŠ›ã€‚&lt;/li&gt; &#xA; &lt;li&gt;åŸ¹å…»è‡ªä¸»å­¦ä¹ å’ŒæŒç»­å­¦ä¹ çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬é˜…è¯»å®˜æ–¹æ–‡æ¡£ã€å‚ä¸å¼€æºç¤¾åŒºå’Œæ¢ç´¢æ–°çš„Pythonåº“å’Œå·¥å…·ã€‚&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;è¯¾ç¨‹ç›®æ ‡æ—¨åœ¨å¸®åŠ©å­¦ç”Ÿå…¨é¢äº†è§£å’ŒæŒæ¡Pythonç¼–ç¨‹è¯­è¨€ï¼ŒåŸ¹å…»ä»–ä»¬åœ¨è½¯ä»¶å¼€å‘å’Œè®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„æŠ€èƒ½ï¼Œä¸ºæœªæ¥çš„å­¦ä¹ å’ŒèŒä¸šå‘å±•æ‰“ä¸‹åšå®åŸºç¡€ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;å‚è€ƒä¹¦ç±&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬è¯¾ç¨‹ä¸»è¦ä½¿ç”¨çš„æ•™æå’Œå‚è€ƒä¹¦ç±ä»¥åŠä¹¦ç±æºä»£ç å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;ã€ŠPythonç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µ ç¬¬2ç‰ˆã€‹&lt;a href=&#34;https://github.com/ehmatthes/pcc_2e&#34;&gt;æºä»£ç &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ã€Šæµç•…çš„Python ç¬¬2ç‰ˆã€‹&lt;a href=&#34;https://github.com/ehmatthes/pcc_2e&#34;&gt;æºä»£ç &lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;ã€ŠPythonæ•°æ®åˆ†æ ç¬¬3ç‰ˆã€‹&lt;a href=&#34;https://github.com/wesm/pydata-book&#34;&gt;æºä»£ç &lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;è¯¾ç¨‹å†…å®¹&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬è¯¾ç¨‹åœ¨è®²æˆè¿‡ç¨‹ä¸­å°†å®Œæ•´åœ°ä½¿ç”¨æ•™æ1è®²æˆPythonçš„åŸºæœ¬è¯­æ³•ä»¥åŠä¸‰ä¸ªå®è·µé¡¹ç›®çš„é‡è¦éƒ¨åˆ†ï¼Œåœ¨è®²æˆPythonä¸€äº›é«˜çº§è¯­æ³•å’Œè¯­è¨€ç‰¹æ€§æ—¶ï¼Œä¼šä½¿ç”¨å‚è€ƒä¹¦ç±2çš„éƒ¨åˆ†ç« èŠ‚ï¼Œåœ¨è®²æˆæ•°æ®åˆ†æç›¸å…³çŸ¥è¯†ä¾‹å¦‚Numpyå’ŒPandasæ—¶ä¼šä½¿ç”¨å‚è€ƒä¹¦ç±3çš„ç›¸å…³ç« èŠ‚ã€‚&lt;/p&gt; &#xA;&lt;p&gt;è¯¾ç¨‹ä¸»è¦æ•™å­¦å†…å®¹å¦‚ä¸‹ï¼š&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Pythonè¯¾ç¨‹ç®€ä»‹&lt;/li&gt; &#xA; &lt;li&gt;å˜é‡å’Œç®€å•æ•°æ®ç±»å‹&lt;/li&gt; &#xA; &lt;li&gt;åˆ—è¡¨, åˆ—è¡¨æ“ä½œ&lt;/li&gt; &#xA; &lt;li&gt;ifè¯­å¥,å­—å…¸, ç”¨æˆ·è¾“å…¥å’Œwhileå¾ªç¯&lt;/li&gt; &#xA; &lt;li&gt;Pythonæ•°æ®ç»“æ„&lt;/li&gt; &#xA; &lt;li&gt;å‡½æ•°&lt;/li&gt; &#xA; &lt;li&gt;å‡½æ•°é«˜çº§&lt;/li&gt; &#xA; &lt;li&gt;Pythoné¢å‘å¯¹è±¡ç¼–ç¨‹&lt;/li&gt; &#xA; &lt;li&gt;æ–‡ä»¶å’Œå¼‚å¸¸&lt;/li&gt; &#xA; &lt;li&gt;å•å…ƒæµ‹è¯•&lt;/li&gt; &#xA; &lt;li&gt;é¡¹ç›®ä¸€ï¼šå¤–æ˜Ÿäººå…¥ä¾µ&lt;/li&gt; &#xA; &lt;li&gt;é¡¹ç›®äºŒï¼šæ•°æ®å¯è§†åŒ–&lt;/li&gt; &#xA; &lt;li&gt;é¡¹ç›®ä¸‰ï¼šWebåº”ç”¨ç¨‹åº&lt;/li&gt; &#xA; &lt;li&gt;Pythonåœ¨æ•°æ®åˆ†æä»¥åŠäººå·¥æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;è¯¾ç¨‹å†…å®¹çš„å®‰æ’å¯ä»¥æ ¹æ®å­¦ç”Ÿå­¦ä¹ çš„å®é™…æƒ…å†µå’Œæ•™å­¦ç›®æ ‡è¿›è¡Œçµæ´»è°ƒæ•´ã€‚&lt;/p&gt; &#xA;&lt;h2&gt;è¯¾ç¨‹å®éªŒ&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬è¯¾ç¨‹å…±åŒ…æ‹¬7æ¬¡å®éªŒï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment1.md&#34;&gt;å®éªŒä¸€ Gitå’ŒMarkdownåŸºç¡€&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment2.md&#34;&gt;å®éªŒäºŒ Pythonå˜é‡ã€ç®€å•æ•°æ®ç±»å‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment3.md&#34;&gt;å®éªŒä¸‰ Pythonåˆ—è¡¨&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment4.md&#34;&gt;å®éªŒå›› Pythonå­—å…¸å’Œwhileå¾ªç¯&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment5.md&#34;&gt;å®éªŒäº” Pythonæ•°æ®ç»“æ„ä¸æ•°æ®æ¨¡å‹&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment6.md&#34;&gt;å®éªŒå…­ å‡½æ•°&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/zhoujing204/python_course/main/Experiments/experiment7.md&#34;&gt;å®éªŒä¸ƒ Pythoné¢å‘å¯¹è±¡ç¼–ç¨‹&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å®éªŒå†…å®¹åŒ…æ‹¬æ•™æã€ŠPythonä»å…¥é—¨åˆ°å®è·µã€‹çš„è¯¾åç»ƒä¹ ï¼Œå¦å¤–è¿˜åŒ…æ‹¬äº†&lt;a href=&#34;https://www.codewars.com&#34;&gt;Codewarsç½‘ç«™&lt;/a&gt;ä¸Šçš„KataæŒ‘æˆ˜ï¼ŒkataæŒ‘æˆ˜åŒ…æ‹¬ä»8kyu(æœ€å®¹æ˜“)åˆ°1kyuï¼ˆæœ€éš¾ï¼‰çš„8ä¸ªéš¾åº¦ç­‰çº§ï¼ŒåŒå­¦ä»¬å¯ä»¥è‡ªç”±é€‰æ‹©åˆé€‚è‡ªå·±çš„éš¾åº¦ç­‰çº§çš„ä»»åŠ¡æ¥å®Œæˆå®éªŒã€‚&lt;/p&gt; &#xA;&lt;h2&gt;è¯¾ç¨‹é¡¹ç›®&lt;/h2&gt; &#xA;&lt;p&gt;æœ¬è¯¾ç¨‹çš„æ•™æã€ŠPythonä»å…¥é—¨åˆ°å®è·µã€‹åŒ…æ‹¬äº†3ä¸ªé¡¹ç›®ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å¤–æ˜Ÿäººå…¥ä¾µ&lt;/li&gt; &#xA; &lt;li&gt;æ•°æ®å¯è§†åŒ–&lt;/li&gt; &#xA; &lt;li&gt;Webåº”ç”¨ç¨‹åº&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;åŒå­¦ä»¬ä¹Ÿå¯ä»¥è‡ªç”±é€‰æ‹©å…¶ä»–é¡¹ç›®æ¥å®Œæˆè¯¾ç¨‹é¡¹ç›®ï¼Œä¾‹å¦‚ï¼š&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;å…¶ä»–Webåº”ç”¨ç¨‹åºé¡¹ç›®&lt;/li&gt; &#xA; &lt;li&gt;å…¶ä»–æ¸¸æˆé¡¹ç›®&lt;/li&gt; &#xA; &lt;li&gt;Pythonçˆ¬è™«é¡¹ç›®&lt;/li&gt; &#xA; &lt;li&gt;Pythonæ•°æ®åˆ†æé¡¹ç›®&lt;/li&gt; &#xA; &lt;li&gt;Pythonäººå·¥æ™ºèƒ½é¡¹ç›®&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;å¦‚æœä½ ä¸çŸ¥é“åº”è¯¥å¦‚ä½•é€‰æ‹©åˆé€‚çš„é¡¹ç›®ä»¥åŠé¡¹ç›®æŒ‡å¯¼ï¼Œå¯ä»¥å‚è€ƒè¿™ä¸ªGithub Repo:&lt;a href=&#34;https://github.com/practical-tutorials/project-based-learning&#34;&gt;project-based-learning&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>baidu/puck</title>
    <updated>2023-09-07T01:31:25Z</updated>
    <id>tag:github.com,2023-09-07:/baidu/puck</id>
    <link href="https://github.com/baidu/puck" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Puck is a high-performance ANN search engine&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;This project is a library for approximate nearest neighbor(ANN) search named Puck. In Industrial deployment scenarios, limited memory, expensive computer resources and increasing database size are as important as the recall-vs-latency tradeof for all search applications. Along with the rapid development of retrieval business service, it has the big demand for the highly recall-vs-latency and precious but finite resource, the borning of Puck is precisely for meeting this kind of need.&lt;/p&gt; &#xA;&lt;p&gt;It contains two algorithms, Puck and Tinker. This project is written in C++ with wrappers for python3.&lt;br&gt; Puck is an efficient approache for large-scale dataset, which has the best performance of multiple 1B-datasets in &lt;a href=&#34;https://github.com/harsha-simhadri/big-ann-benchmarks/raw/main/neurips21/t1_t2/README.md#results-for-t1&#34;&gt;NeurIPS&#39;21 competition track&lt;/a&gt;. Since then, performance of Puck has increased by 70%. Puck includes a two-layered architectural design for inverted indices and a multi-level quantization on the dataset. If the memory is going to be a bottleneck, Puck could resolve your problems.&lt;br&gt; Tinker is an efficient approache for smaller dataset(like 10M, 100M), which has better performance than Nmslib in big-ann-benchmarks. The relationships among similarity points are well thought out, Tinker need more memory to save these. Thinker cost more memory then Puck, but has better performace than Puck. If you want a better searching performance and need not concerned about memory used, Tinker is a better choiese.&lt;/p&gt; &#xA;&lt;h2&gt;Introduction&lt;/h2&gt; &#xA;&lt;p&gt;This project supports cosine similarity, L2(Euclidean) and IP(Inner Product, conditioned). When two vectors are normalized, L2 distance is equal to 2 - 2 * cos. IP2COS is a transform method that convert IP distance to cos distance. The distance value in search result is always L2.&lt;/p&gt; &#xA;&lt;p&gt;Puck use a compressed vectors(after PQ) instead of the original vectors, the memory cost just over to 1/4 of the original vectors by default. With the increase of datasize, Puck&#39;s advantage is more obvious.&lt;br&gt; Tinker need save relationships of similarity points, the memory cost is more than the original vectors (less than Nmslib) by default. More performance details in benchmarks. Please see &lt;a href=&#34;https://raw.githubusercontent.com/baidu/puck/main/ann-benchmarks/README.md&#34;&gt;this readme&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Linux install&lt;/h2&gt; &#xA;&lt;h3&gt;1.The prerequisite is mkl, python and cmake.&lt;/h3&gt; &#xA;&lt;p&gt;&lt;strong&gt;MKL&lt;/strong&gt;: MKL must be installed to compile puck, download the MKL installation package corresponding to the operating system from the official website, and configure the corresponding installation path after the installation is complete. source the MKL component environment script, eg. source ${INSTALL_PATH}/mkl/latest/env/vars.sh. This will maintain many sets of environment variables, like MKLROOT.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html&#34;&gt;https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;python&lt;/strong&gt;: Version higher than 3.6.0.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;cmake&lt;/strong&gt;: Version higher than 3.21.&lt;/p&gt; &#xA;&lt;h3&gt;2.Clone this project.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/baidu/puck.git&#xA;cd puck&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3.Use cmake to build this project.&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cmake -DCMAKE_BUILD_TYPE=Release -DPYTHON_INCLUDE_DIR=$(python3 -c &#34;import sysconfig; print(sysconfig.get_path(&#39;include&#39;))&#34;)  \&#xA;    -DPYTHON_LIBRARY=$(python3 -c &#34;import sysconfig; print(sysconfig.get_config_var(&#39;LIBDIR&#39;))&#34;) \&#xA;    -DMKLROOT=${MKLROOT} \&#xA;    -DUSE_PYTHON=ON \&#xA;    -DBLA_VENDOR=Intel10_64lp_seq \&#xA;    -DBLA_STATIC=ON  \&#xA;    -B build .&#xA;&#xA;cd build &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Output files are saved in build/output subdirectory by default.&lt;/p&gt; &#xA;&lt;h2&gt;How to use&lt;/h2&gt; &#xA;&lt;p&gt;Output files include demos of train, build and search tools.&lt;br&gt; Train and build tools are in build/output/build_tools subdirectory.&lt;br&gt; Search demo tools are in build/output/bin subdirectory.&lt;/p&gt; &#xA;&lt;h3&gt;1.format vector dataset for train and build&lt;/h3&gt; &#xA;&lt;p&gt;The vectors are stored in raw little endian. Each vector takes 4+d*4 bytes for .fvecs format, where d is the dimensionality of the vector.&lt;/p&gt; &#xA;&lt;h3&gt;2.train &amp;amp; build&lt;/h3&gt; &#xA;&lt;p&gt;The default train configuration file is &#34;build/output/build_tools/conf/puck_train.conf&#34;. The length of each feature vector must be set in train configuration file (feature_dim).&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd output/build_tools&#xA;cp YOUR_FEATURE_FILE puck_index/all_data.feat.bin&#xA;sh script/puck_train_control.sh -t -b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;index files are saved in puck_index subdirectory by default.&lt;/p&gt; &#xA;&lt;h3&gt;3.search&lt;/h3&gt; &#xA;&lt;p&gt;During searching, the default value of index files path is &#39;./puck_index&#39;.&lt;br&gt; The format of query file, refer to &lt;a href=&#34;https://raw.githubusercontent.com/baidu/puck/main/tools/demo/init-feature-example&#34;&gt;demo&lt;/a&gt;&lt;br&gt; Search parameters can be modified using a configuration file, refer to &lt;a href=&#34;https://raw.githubusercontent.com/baidu/puck/main/demo/conf/puck.conf&#34;&gt;demo&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd output/&#xA;ln -s build_tools/puck_index .&#xA;./bin/search_client YOUR_QUERY_FEATURE_FILE RECALL_FILE_NAME --flagfile=conf/puck.conf&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;recall results are stored in file RECALL_FILE_NAME.&lt;/p&gt; &#xA;&lt;h2&gt;more details&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/baidu/puck/main/docs/README.md&#34;&gt;more details for puck&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;benchmark&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://raw.githubusercontent.com/baidu/puck/main/ann-benchmarks/README.md&#34;&gt;this readme&lt;/a&gt; for details.&lt;/p&gt; &#xA;&lt;p&gt;this ann-benchmark is forked from &lt;a href=&#34;https://github.com/harsha-simhadri/big-ann-benchmarks&#34;&gt;https://github.com/harsha-simhadri/big-ann-benchmarks&lt;/a&gt; of 2021.&lt;/p&gt; &#xA;&lt;p&gt;How to run this benchmark is the same with it. We add support of faiss(IVF,IVF-Flat,HNSW) , nmslibï¼ˆHNSWï¼‰,Puck and Tinker of T1 track. And We update algos.yaml of these method using recommended parameters of 4 datasets(bigann-10M, bigann-100M, deep-10M, deep-100M)&lt;/p&gt; &#xA;&lt;h2&gt;Discussion&lt;/h2&gt; &#xA;&lt;p&gt;Join our QQ group if you are interested in this project.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/baidu/puck/main/docs/PuckQQGroup.jpeg&#34; alt=&#34;QQ Group&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>