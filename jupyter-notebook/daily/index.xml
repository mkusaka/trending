<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-02-24T01:32:09Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vllm-project/aibrix</title>
    <updated>2025-02-24T01:32:09Z</updated>
    <id>tag:github.com,2025-02-24:/vllm-project/aibrix</id>
    <link href="https://github.com/vllm-project/aibrix" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Cost-efficient and pluggable Infrastructure components for GenAI inference&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AIBrix&lt;/h1&gt; &#xA;&lt;p&gt;Welcome to AIBrix, an open-source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimized for deploying, managing, and scaling large language model (LLM) inference, tailored specifically to enterprise needs.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; | &lt;a href=&#34;https://aibrix.readthedocs.io/latest/&#34;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://aibrix.github.io/&#34;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/vllm-project/aibrix/raw/main/docs/paper/AIBrix_White_Paper_0219_2025.pdf&#34;&gt;&lt;b&gt;White Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://x.com/vllm_project&#34;&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href=&#34;https://vllm-dev.slack.com/archives/C08EQ883CSV&#34;&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; &#xA;&lt;h2&gt;Key Features&lt;/h2&gt; &#xA;&lt;p&gt;The initial release includes the following key features:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;High-Density LoRA Management&lt;/strong&gt;: Streamlined support for lightweight, low-rank adaptations of models.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM Gateway and Routing&lt;/strong&gt;: Efficiently manage and direct traffic across multiple models and replicas.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;LLM App-Tailored Autoscaler&lt;/strong&gt;: Dynamically scale inference resources based on real-time demand.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Unified AI Runtime&lt;/strong&gt;: A versatile sidecar enabling metric standardization, model downloading, and management.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Distributed Inference&lt;/strong&gt;: Scalable architecture to handle large workloads across multiple nodes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Distributed KV Cache&lt;/strong&gt;: Enables high-capacity, cross-engine KV reuse.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Cost-efficient Heterogeneous Serving&lt;/strong&gt;: Enables mixed GPU inference to reduce costs with SLO guarantees.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;GPU Hardware Failure Detection&lt;/strong&gt;: Proactive detection of GPU hardware issues.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Architecture&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vllm-project/aibrix/main/docs/source/assets/images/aibrix-architecture-v1.jpeg&#34; alt=&#34;aibrix-architecture-v1&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Quick Start&lt;/h2&gt; &#xA;&lt;p&gt;To get started with AIBrix, clone this repository and follow the setup instructions in the documentation. Our comprehensive guide will help you configure and deploy your first LLM infrastructure seamlessly.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Local Testing&#xA;git clone https://github.com/vllm-project/aibrix.git&#xA;cd aibrix&#xA;&#xA;# Install nightly aibrix dependencies&#xA;kubectl create -k config/dependency&#xA;&#xA;# Install nightly aibrix components&#xA;kubectl create -k config/default&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install stable distribution&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# Install component dependencies&#xA;kubectl create -k &#34;github.com/vllm-project/aibrix/config/dependency?ref=v0.2.0&#34;&#xA;&#xA;# Install aibrix components&#xA;kubectl create -k &#34;github.com/vllm-project/aibrix/config/overlays/release?ref=v0.2.0&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;For detailed documentation on installation, configuration, and usage, please visit our &lt;a href=&#34;https://aibrix.readthedocs.io/latest/&#34;&gt;documentation page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;We welcome contributions from the community! Check out our &lt;a href=&#34;https://github.com/vllm-project/aibrix/CONTRIBUTING.md&#34;&gt;contributing guidelines&lt;/a&gt; to see how you can make a difference.&lt;/p&gt; &#xA;&lt;p&gt;Slack Channel: &lt;a href=&#34;https://vllm-dev.slack.com/archives/C08EQ883CSV&#34;&gt;https://vllm-dev.slack.com/archives/C08EQ883CSV&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;AIBrix is licensed under the &lt;a href=&#34;https://github.com/vllm-project/aibrix/LICENSE.md&#34;&gt;APACHE License&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Support&lt;/h2&gt; &#xA;&lt;p&gt;If you have any questions or encounter any issues, please submit an issue on our &lt;a href=&#34;https://github.com/vllm-project/aibrix/issues&#34;&gt;GitHub issues page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Thank you for choosing AIBrix for your GenAI infrastructure needs!&lt;/p&gt;</summary>
  </entry>
</feed>