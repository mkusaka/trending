<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-04-03T01:36:55Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>bofenghuang/vigogne</title>
    <updated>2023-04-03T01:36:55Z</updated>
    <id>tag:github.com,2023-04-03:/bofenghuang/vigogne</id>
    <link href="https://github.com/bofenghuang/vigogne" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Fine-tune French instruction-following models&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34; width=&#34;100%&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/assets/vigogne_logo.png&#34; alt=&#34;Vigogne&#34; style=&#34;width: 40%; min-width: 300px; display: block; margin: auto;&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Vigogne 🦙: French Instruction-following Models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/main/LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg?sanitize=true&#34; alt=&#34;Code License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/main/DATA_LICENSE&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg?sanitize=true&#34; alt=&#34;Data License&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;The vigogne (French name for vicuña) is a South American camelid native to the Andes Mountains. It is closely related to the llama, alpaca, and guanaco.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains code for reproducing the &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt; in French 🇫🇷 using &lt;a href=&#34;https://arxiv.org/abs/2106.09685&#34;&gt;low-rank adaptation (LoRA)&lt;/a&gt; provided by 🤗 Hugging Face&#39;s &lt;a href=&#34;https://github.com/huggingface/peft&#34;&gt;PEFT&lt;/a&gt; library. In addition to the LoRA technique, we also use &lt;a href=&#34;https://arxiv.org/abs/2208.07339&#34;&gt;LLM.int8()&lt;/a&gt; provided by &lt;a href=&#34;https://github.com/TimDettmers/bitsandbytes&#34;&gt;bitsandbytes&lt;/a&gt; to quantize pretrained language models (PLMs) to int8. Combining these two techniques allows us to fine-tune PLMs on a single consumer GPU such as RTX 4090.&lt;/p&gt; &#xA;&lt;p&gt;This project is based on &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;LLaMA&lt;/a&gt;, &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;, &lt;a href=&#34;https://github.com/tloen/alpaca-lora&#34;&gt;&lt;strong&gt;Alpaca-Lora&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://github.com/22-hours/cabrita&#34;&gt;Cabrita&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/docs/transformers/main_classes/trainer&#34;&gt;Hugging Face&lt;/a&gt;. In addition, we adapted the &lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/main/finetune.py&#34;&gt;training script&lt;/a&gt; to fine-tune on more models such as &lt;a href=&#34;https://huggingface.co/bigscience/bloom-7b1&#34;&gt;BLOOM&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/google/mt5-xxl&#34;&gt;mT5&lt;/a&gt;. We also share the &lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/main/data/vigogne_data_cleaned.json&#34;&gt;translated dataset&lt;/a&gt; and the trained &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-7b&#34;&gt;vigogne-lora-7b&lt;/a&gt; and &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-bloom-7b1&#34;&gt;vigogne-lora-bloom-7b1&lt;/a&gt; weights.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Usage and License Notices&lt;/strong&gt;: Same as &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca&lt;/a&gt;, Vigogne is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.&lt;/p&gt; &#xA;&lt;p&gt;💡 &lt;em&gt;The screencast below shows the current 🦙 Vigogne-LoRA-7B model running on Apple M1 Pro using 4GB of weights (no sped up).&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/assets/screencast.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#setup&#34;&gt;Setup&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#play-with--vigogne-models&#34;&gt;Play with 🦙 Vigogne models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#try-it-out-on-your-own-pc&#34;&gt;Try it out on your own PC&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#training&#34;&gt;Training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#example-outputs&#34;&gt;Example outputs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#bias-risks-and-limitations&#34;&gt;Bias, Risks, and Limitations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/bofenghuang/vigogne/main/#next-steps&#34;&gt;Next steps&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;Install dependencies&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Play with 🦙 Vigogne models&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;User Notice&lt;/strong&gt;: Facebook has not made the official LLaMA model weights open source, although various third-party download links are available online, such as &lt;code&gt;decapoda-research/llama-7b-hf&lt;/code&gt; in the HuggingFace model library. It should be noted that the use of these links may not comply with Facebook&#39;s policies. Due to the reasons mentioned above, the project cannot release the complete weights of fine-tuned models. However, only the LoRA weights can be provided, which can be considered as a &#34;patch&#34; for the original LLaMA model.&lt;/p&gt; &#xA;&lt;p&gt;The fine-tuned instruction-following vigogne models are available on 🤗 Hugging Face:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Fine-tuned LLaMA-7B model: &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-7b&#34;&gt;bofenghuang/vigogne-lora-7b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuned LLaMA-13B model: &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-13b&#34;&gt;bofenghuang/vigogne-lora-13b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuned LLaMA-30B model: &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-30b&#34;&gt;bofenghuang/vigogne-lora-30b&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuned BLOOM-7B1 model: &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-bloom-7b1&#34;&gt;bofenghuang/vigogne-lora-bloom-7b1&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Fine-tuned OPT-6.7B model: &lt;a href=&#34;https://huggingface.co/bofenghuang/vigogne-lora-opt-6.7b&#34;&gt;bofenghuang/vigogne-lora-opt-6.7b&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;You can infer these models by using the following Google Colab Notebook.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/bofenghuang/vigogne/blob/main/infer.ipynb&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can also run a Gradio demo using the following command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./demo.py \&#xA;    --base_model_name_or_path &amp;lt;name/or/path/to/hf/llama/7b/model&amp;gt; \&#xA;    --lora_model_name_or_path bofenghuang/vigogne-lora-7b&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Try it out on your own PC&lt;/h2&gt; &#xA;&lt;p&gt;The Vigogne models can now be easily deployed on PCs, thanks to the excellent tools created by the community. The following steps provide detailed instructions on how to combine Vigogne-LoRA weights with the original LLaMA model, quantize the resulting model to 4-bit, and finally deploy it on your own PC using &lt;a href=&#34;https://github.com/ggerganov/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note: the models will be quantized into 4-bit, so the performance might be worse than the non-quantized version. The responses are random due to the generation hyperparameters.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Please ensure that the following requirements are met prior to running:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;As the models are currently fully loaded into memory, you will need adequate disk space to save them and sufficient RAM to load them. You will need at least 13GB of RAM to quantize the 7B model. For more information, refer to this &lt;a href=&#34;https://github.com/ggerganov/llama.cpp#memorydisk-requirements&#34;&gt;link&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;It&#39;s best to use Python 3.9 or Python 3.10, as sentencepiece has not yet published a wheel for Python 3.11.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;1. Clone and build llama.cpp repo&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/ggerganov/llama.cpp&#xA;cd llama.cpp&#xA;make&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;2. Combine Vigogne-LoRA weights with the corresponding original LLaMA model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# combine&#xA;python ../scripts/export_state_dict_checkpoint.py \&#xA;    --base_model_name_or_path &amp;lt;name/or/path/to/hf/llama/7b/model&amp;gt; \&#xA;    --lora_model_name_or_path &#34;bofenghuang/vigogne-lora-7b&#34; \&#xA;    --output_dir ./models/7B&#xA;&#xA;# download the tokenizer.model file&#xA;wget -P ./models https://huggingface.co/bofenghuang/vigogne-lora-7b/resolve/main/tokenizer.model&#xA;&#xA;# check the files&#xA;tree models&#xA;# models&#xA;# ├── 7B&#xA;# │&amp;nbsp;&amp;nbsp; ├── consolidated.00.pth&#xA;# │&amp;nbsp;&amp;nbsp; └── params.json&#xA;# └── tokenizer.model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;3. Quantize the combined model&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# convert the 7B model to ggml FP16 format&#xA;python convert-pth-to-ggml.py ./models/7B/ 1&#xA;&#xA;# further quantize the model to 4-bit&#xA;python quantize.py 7B&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;4. Run the inference&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ./main -h for more information&#xA;./main -m ./models/7B/ggml-model-q4_0.bin --color -ins -c 2048 --temp 0.1 -n 256&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data&lt;/h2&gt; &#xA;&lt;p&gt;We translated the original &lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca/raw/main/alpaca_data.json&#34;&gt;alpaca_data.json&lt;/a&gt; to French using &lt;code&gt;gpt-3.5-turbo&lt;/code&gt; by the chat completion API.&lt;/p&gt; &#xA;&lt;p&gt;You can also translate it to other languages using the &lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/main/scripts/translate_data.py&#34;&gt;translation script&lt;/a&gt;. Don&#39;t forget to modify your &lt;a href=&#34;https://github.com/bofenghuang/vigogne/raw/e6ae25fc0569ca85c25529a6d06122b35426aa2d/scripts/translate_data.py#L47-L57&#34;&gt;translation prompt&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The translation may have compromised the accuracy of certain tasks, such as generating rhyming words or correcting grammar (discussed &lt;a href=&#34;https://github.com/tloen/alpaca-lora/pull/127&#34;&gt;here&lt;/a&gt;). We warmly welcome PRs to help clean up this dataset!&lt;/p&gt; &#xA;&lt;p&gt;The following command shows how to estimate the price for translating the full dataset.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./scripts/translate_data.py estimate_price \&#xA;    --input_json_file data/alpaca_data_cleaned.json \&#xA;    --ratio_output_input 1.0 \&#xA;    --model gpt-3.5-turbo-0301 \&#xA;    --price_per_thousand_tokens 0.002&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You can translate the dataset using the following command.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Specify your OpenAI API key&#xA;export OPENAI_API_KEY=xx&#xA;&#xA;./scripts/translate_data.py process_data \&#xA;    --input_json_file data/alpaca_data_cleaned.json \&#xA;    --output_json_file data/vigogne_data_cleaned.json \&#xA;    --model gpt-3.5-turbo \&#xA;    --max_parallel_requests 32&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training&lt;/h2&gt; &#xA;&lt;h3&gt;Fine-tuning LLaMA-7B model&lt;/h3&gt; &#xA;&lt;p&gt;The following command shows how to fine-tune LLaMA-7B model using a single GPU.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python finetune.py \&#xA;    --model_name_or_path &amp;lt;name/or/path/to/hf/llama/7b/model&amp;gt; \&#xA;    --train_file &#34;data/vigogne_data_cleaned.json&#34; \&#xA;    --output_dir &#34;outputs/llama-7b-ft-vigogne-lora&#34; \&#xA;    --run_name &#34;llama-7b-ft-vigogne-lora&#34; \&#xA;    --overwrite_output_dir \&#xA;    --model_max_length_percentile 95 \&#xA;    --preprocessing_num_workers 4 \&#xA;    --dataloader_num_workers 1 \&#xA;    --lora_r 8 \&#xA;    --lora_alpha 16 \&#xA;    --lora_dropout 0.05 \&#xA;    --target_modules &#34;q_proj&#34; &#34;v_proj&#34; \&#xA;    --per_device_train_batch_size 16 \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --gradient_accumulation_steps 8 \&#xA;    --num_train_epochs 3 \&#xA;    --learning_rate 3e-4 \&#xA;    --warmup_steps 100 \&#xA;    --logging_steps 25 \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 200 \&#xA;    --save_total_limit 3 \&#xA;    --report_to &#34;tensorboard&#34; &#34;wandb&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuning LLaMA-30B model&lt;/h3&gt; &#xA;&lt;p&gt;The following command shows how to fine-tune LLaMA-30B model using multi GPUs.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WORLD_SIZE=2 torchrun --nproc_per_node=2 --master_port=29001 finetune.py \&#xA;    --model_name_or_path &amp;lt;name/or/path/to/hf/llama/30b/model&amp;gt; \&#xA;    --train_file &#34;data/vigogne_data_cleaned.json&#34; \&#xA;    --output_dir &#34;outputs/llama-30b-ft-vigogne-lora&#34; \&#xA;    --run_name &#34;llama-30b-ft-vigogne-lora&#34; \&#xA;    --overwrite_output_dir \&#xA;    --model_max_length_percentile 95 \&#xA;    --preprocessing_num_workers 4 \&#xA;    --dataloader_num_workers 1 \&#xA;    --lora_r 8 \&#xA;    --lora_alpha 16 \&#xA;    --lora_dropout 0.05 \&#xA;    --target_modules &#34;q_proj&#34; &#34;v_proj&#34; \&#xA;    --per_device_train_batch_size 4 \&#xA;    --per_device_eval_batch_size 2 \&#xA;    --gradient_accumulation_steps 16 \&#xA;    --num_train_epochs 3 \&#xA;    --learning_rate 3e-4 \&#xA;    --warmup_steps 100 \&#xA;    --logging_steps 25 \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 200 \&#xA;    --save_total_limit 3 \&#xA;    --report_to &#34;tensorboard&#34; &#34;wandb&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuning BLOOM-7B1 model&lt;/h3&gt; &#xA;&lt;p&gt;The following command shows how to fine-tune &lt;a href=&#34;https://huggingface.co/bigscience/bloom-7b1&#34;&gt;bigscience/bloom-7b1&lt;/a&gt; model using a single GPU.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python finetune.py \&#xA;    --model_name_or_path &#34;bigscience/bloom-7b1&#34; \&#xA;    --train_file &#34;data/vigogne_data_cleaned.json&#34; \&#xA;    --output_dir &#34;outputs/bloom-7b1-ft-vigogne&#34; \&#xA;    --run_name &#34;bloom-7b1-ft-vigogne&#34; \&#xA;    --overwrite_output_dir \&#xA;    --model_max_length_percentile 95 \&#xA;    --preprocessing_num_workers 4 \&#xA;    --dataloader_num_workers 1 \&#xA;    --lora_r 16 \&#xA;    --lora_alpha 32 \&#xA;    --lora_dropout 0.05 \&#xA;    --target_modules &#34;query_key_value&#34; \&#xA;    --per_device_train_batch_size 16 \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --gradient_accumulation_steps 8 \&#xA;    --num_train_epochs 3 \&#xA;    --learning_rate 3e-4 \&#xA;    --warmup_steps 100 \&#xA;    --logging_steps 25 \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 200 \&#xA;    --save_total_limit 3 \&#xA;    --report_to &#34;tensorboard&#34; &#34;wandb&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Fine-tuning OPT-6.7B model&lt;/h3&gt; &#xA;&lt;p&gt;The following command shows how to fine-tune &lt;a href=&#34;https://huggingface.co/facebook/opt-6.7b&#34;&gt;facebook/opt-6.7b&lt;/a&gt; model using a single GPU.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python finetune.py \&#xA;    --model_name_or_path &#34;facebook/opt-6.7b&#34; \&#xA;    --train_file &#34;data/vigogne_data_cleaned.json&#34; \&#xA;    --output_dir &#34;outputs/opt-6b7-ft-vigogne&#34; \&#xA;    --run_name &#34;opt-6b7-ft-vigogne&#34; \&#xA;    --overwrite_output_dir \&#xA;    --model_max_length_percentile 95 \&#xA;    --preprocessing_num_workers 4 \&#xA;    --dataloader_num_workers 1 \&#xA;    --lora_r 16 \&#xA;    --lora_alpha 32 \&#xA;    --lora_dropout 0.05 \&#xA;    --target_modules &#34;q_proj&#34; &#34;v_proj&#34; \&#xA;    --per_device_train_batch_size 16 \&#xA;    --per_device_eval_batch_size 8 \&#xA;    --gradient_accumulation_steps 8 \&#xA;    --num_train_epochs 3 \&#xA;    --learning_rate 3e-4 \&#xA;    --warmup_steps 100 \&#xA;    --logging_steps 25 \&#xA;    --save_strategy &#34;steps&#34; \&#xA;    --save_steps 200 \&#xA;    --save_total_limit 3 \&#xA;    --report_to &#34;tensorboard&#34; &#34;wandb&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Example outputs&lt;/h2&gt; &#xA;&lt;p&gt;Répondez à la question suivante : Les pratiques artistiques transforment-elles le monde ?&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vigogne-LoRA-7B&lt;/strong&gt;: Les pratiques d&#39;art peuvent transformer le monde en créant des œuvres qui évoquent des sentiments, des idées et des émotions. Elles peuvent également être utilisées pour créer des Œuvres d&#39;Art Vivant qui sont des œuvre vivantes qui peuvent être utilisés pour créé des expériences et des conversations. Les praticiens d&#39;arts peuvent également utiliser leurs pratiques pour créerer des œufs d&#39;âme, des êtres vivants créés à partir de matériaux naturels, qui peuvent avoir un impact sur la façon dont les gens pensent et ressentent le monde.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Other models&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alpaca-LoRA&lt;/strong&gt;: Yes, artistic practices can transform the world. Art can be used to express ideas, explore new perspectives, and create dialogue. Art can also be used to inspire and motivate people to take action, and to create positive change in their communities.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;text-davinci-003&lt;/strong&gt;: Oui, les pratiques artistiques peuvent transformer le monde. Les artistes peuvent utiliser leur art pour exprimer leurs opinions et leurs idées, et ces idées peuvent avoir un impact sur la société et le monde. Les artistes peuvent également utiliser leur art pour sensibiliser le public à des sujets importants et pour encourager le changement. Les pratiques artistiques peuvent donc être un puissant outil pour transformer le monde.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Expliquez la différence entre DoS et phishing en français.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vigogne-LoRA-7B&lt;/strong&gt;: Le DoS (Denial of Service) est une attaque informatique qui consiste à bloquer ou à interrompre l&#39;accès à un service ou à un système informatique. Le phishing est une technique de fraude qui consisterait à obtenir des informations sensibles d&#39;un utilisateur en lui demandant de fournir des renseignements, tels que des mots de passe ou des numéros de carte de crédit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Other models&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alpaca-LoRA&lt;/strong&gt;: In French, the difference between a DDoS attack and phishing is that a DDoS attack is an attempt to overwhelm a system with a large amount of traffic, while phishing is an attempt to steal personal information by posing as a trusted source.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;text-davinci-003&lt;/strong&gt;:&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;p&gt;DoS (Denial of Service) est une attaque qui vise à rendre indisponible des services web ou réseau en saturant un serveur ou un réseau avec des requêtes. Elle peut aussi être utilisée pour perturber un réseau en envoyant des paquets mal formés ou en le surchargant.&lt;/p&gt; &#xA; &lt;p&gt;Phishing est une forme d&#39;escroquerie en ligne visant à voler des informations personnelles telles que des mots de passe et des numéros de carte de crédit en incitant les victimes à fournir leurs informations sur des faux sites Web ou des emails frauduleux.&lt;/p&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Résumez le texte suivant en une seule phrase.&lt;/p&gt; &#xA;&lt;p&gt;La science des données est l&#39;étude des données afin d&#39;en extraire des informations significatives pour les entreprises. Il s&#39;agit d&#39;une approche pluridisciplinaire qui combine des principes et des pratiques issus des domaines des mathématiques, des statistiques, de l&#39;intelligence artificielle et du génie informatique, en vue d&#39;analyser de grands volumes de données. Cette analyse aide les scientifiques des données à poser des questions et à y répondre, comme Que s&#39;est-il passé, Pourquoi cela s&#39;est-il passé, Que va-t-il se passer et Que peut-on faire avec des résultats.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vigogne-LoRA-7B&lt;/strong&gt;: Le scientifique des données utilise des données pour analyser et extraire de l’information pour aider les entrepreneurs à posent des questions, répondre à des questions existantes et prendre des décisions.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Other models&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alpaca-LoRA&lt;/strong&gt;: La science des données est l&#39;étude des données afin d&#39;en extraire des informations significatives pour les entreprises.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;strong&gt;text-davinci-003&lt;/strong&gt;: La science des données combine des principes et des pratiques issus des domaines des mathématiques, des statistiques, de l&#39;intelligence artificielle et du génie informatique pour analyser de grands volumes de données afin d&#39;en extraire des informations significatives pour les entreprises.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Écrivez une fonction qui prend une liste de chaînes de caractères et renvoie une liste sans doublons.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Vigogne-LoRA-7B&lt;/strong&gt;:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def remove_duplicates(lst):&#xA;    result = []&#xA;    for item in lst:&#xA;        if item not in result:&#xA;            result.append(item)&#xA;    return result&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;details&gt;&#xA; &lt;summary&gt;Other models&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;Alpaca-LoRA&lt;/strong&gt;:&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def remove_duplicates(list):&#xA;    seen = set()&#xA;    return [x for x in list if x not in seen]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;strong&gt;text-davinci-003&lt;/strong&gt;:&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA; &lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def remove_duplicates(liste):&#xA;  new_list = []&#xA;  for item in liste:&#xA;    if item not in new_list:&#xA;      new_list.append(item)&#xA;  return new_list&#xA;&#xA;liste = [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, &#34;a&#34;, &#34;d&#34;, &#34;e&#34;, &#34;f&#34;, &#34;c&#34;]&#xA;print(remove_duplicates(liste)) # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;Bias, Risks, and Limitations&lt;/h2&gt; &#xA;&lt;p&gt;Vigogne is still under development, and there are many limitations that have to be addressed. Please note that it is possible that the model generates harmful or biased content, incorrect information or generally unhelpful answers.&lt;/p&gt; &#xA;&lt;h2&gt;Next steps&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Collect more and cleaner French instruction-following data&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>Visualize-ML/Book1_Python-For-Beginners</title>
    <updated>2023-04-03T01:36:55Z</updated>
    <id>tag:github.com,2023-04-03:/Visualize-ML/Book1_Python-For-Beginners</id>
    <link href="https://github.com/Visualize-ML/Book1_Python-For-Beginners" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Book_1_《编程不难》 | 鸢尾花书：从加减乘除到机器学习；开始上传PDF草稿、Jupyter笔记。文件还会经过至少两轮修改，改动会很大，大家注意下载最新版本。请多提意见，谢谢&lt;/p&gt;&lt;hr&gt;</summary>
  </entry>
  <entry>
    <title>sophiamyang/tutorials-LangChain</title>
    <updated>2023-04-03T01:36:55Z</updated>
    <id>tag:github.com,2023-04-03:/sophiamyang/tutorials-LangChain</id>
    <link href="https://github.com/sophiamyang/tutorials-LangChain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;🤩 Is LangChain the easiest way to work with LLMs? It&#39;s an open-source tool and recently added ChatGPT Plugins. It provides so many capabilities that I find useful. Check out my video to learn more:&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kmbS6FDQh7c&#34;&gt;LangChain Overview video&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>