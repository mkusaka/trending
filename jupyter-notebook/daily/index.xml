<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-07-20T01:37:33Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>privacytrustlab/ml_privacy_meter</title>
    <updated>2023-07-20T01:37:33Z</updated>
    <id>tag:github.com,2023-07-20:/privacytrustlab/ml_privacy_meter</id>
    <link href="https://github.com/privacytrustlab/ml_privacy_meter" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Privacy Meter: An open-source library to audit data privacy in statistical and machine learning algorithms.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Privacy Meter&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/privacy-meter/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8-blue&#34; alt=&#34;PyPI - Python Version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/privacy-meter&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/privacy-meter&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/privacy-meter/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/openfl&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://join.slack.com/t/privacy-meter/shared_invite/zt-1oge6ovjq-SS4UZnBVB115Tx8Nn3TVhA&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/slack-@privacy_meter-blue.svg?logo=slack&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/license/privacytrustlab/ml_privacy_meter&#34; alt=&#34;License&#34;&gt; &lt;a href=&#34;https://arxiv.org/abs/2007.09339&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/cite-citation-brightgreen&#34; alt=&#34;Citation&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://colab.research.google.com/github/privacytrustlab/ml_privacy_meter/blob/master/docs/population_metric.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/contributors/privacytrustlab/ml_privacy_meter?color=dark-green&#34; alt=&#34;Contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/forks/privacytrustlab/ml_privacy_meter?style=social&#34; alt=&#34;Forks&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/stars/privacytrustlab/ml_privacy_meter?style=social&#34; alt=&#34;Stargazers&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/license/privacytrustlab/ml_privacy_meter&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;What is Privacy Meter?&lt;/h2&gt; &#xA;&lt;p&gt;Privacy Meter is an open-source library to audit data privacy in statistical and machine learning algorithms. The tool can help in the data protection impact assessment process by providing a quantitative analysis of the fundamental privacy risks of a (machine learning) model. It uses state-of-the-art inference techniques to audit a wide range of machine learning algorithms for classification, regression, computer vision, and natural language processing. Privacy Meter generates extensive reports about the aggregate and individual privacy risks for data records in the training set, at multiple levels of access to the model.&lt;/p&gt; &#xA;&lt;h2&gt;Why Privacy Meter?&lt;/h2&gt; &#xA;&lt;p&gt;Machine learning is playing a central role in automated decision-making in a wide range of organizations and service providers. The data, which is used to train the models, typically contain sensitive information about individuals. Although the data in most cases cannot be released, due to privacy concerns, the models are usually made public or deployed as a service for inference on new test data. For a safe and secure use of machine learning models, it is important to have a quantitative assessment of the privacy risks of these models, and to make sure that they do not reveal sensitive information about their training data. This is of great importance as there has been a surge in the use of machine learning in sensitive domains such as medical and finance applications.&lt;/p&gt; &#xA;&lt;p&gt;Data Protection regulations, such as GDPR and AI governance frameworks, require personal data to be protected when used in AI systems, and that the users have control over their data and awareness about how it is being used. For example, &lt;a href=&#34;https://gdpr-info.eu/art-35-gdpr/&#34;&gt;Article 35 of GDPR&lt;/a&gt; requires organizations to systematically analyze, identify and minimize the data protection risks of a project, especially when the project involves innovative technologies such as Artificial Intelligence, Machine Learning, and Deep Learning. Thus, proper mechanisms need to be in place to quantitatively evaluate and verify the privacy of individuals in every step of the data processing pipeline in AI systems.&lt;/p&gt; &#xA;&lt;p&gt;ML Privacy Meter is a Python library (&lt;code&gt;privacy_meter&lt;/code&gt;) that enables quantifying the privacy risks of machine learning models. The tool provides privacy risk scores which help in identifying data records among the training data that are at high risk of being leaked through the model parameters or predictions.&lt;/p&gt; &#xA;&lt;h2&gt;Overview&lt;/h2&gt; &#xA;&lt;p&gt;The core of the Privacy Meter consists of three parts: &lt;code&gt;Information Source&lt;/code&gt;, &lt;code&gt;Metric&lt;/code&gt; and &lt;code&gt;Metric Results&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/privacytrustlab/ml_privacy_meter/raw/master/source/_static/privacy_meter_architecture.png?raw=true&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt; &#xA;&lt;!-- Kindly refer to the tutorial on the population attack ([here](advanced/population_metric.ipynb)) to gain familiarity with the utilization of each component. --&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Privacy Meter supports Python &lt;code&gt;&amp;gt;=3.6&lt;/code&gt; and works with &lt;code&gt;tensorflow&amp;gt;=2.4.0&lt;/code&gt; and &lt;code&gt;torch&amp;gt;=1.10.0&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can install &lt;code&gt;privacy-meter&lt;/code&gt; using &lt;code&gt;pip&lt;/code&gt; for the latest stable version of the tool:&lt;/p&gt; &#xA;&lt;!-- ```bash&#xA;pip install git+https://github.com/privacytrustlab/ml_privacy_meter.git&#xA;``` --&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install privacy-meter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, one can install it via conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install privacy-meter&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;User manual&lt;/h2&gt; &#xA;&lt;p&gt;We offer two types of tutorials: basic usage (in the &lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/basic/&#34;&gt;basic&lt;/a&gt; folder) and advanced usage (in the &lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/&#34;&gt;advanced&lt;/a&gt; folder). The goal of the basic tutorials is to provide users with a seamless experience in working with various predefined privacy games, algorithms, and signals. These components represent state-of-the-art membership inference attacks and can be configured easily without requiring users to write code (See instructions &lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/basic/README.md&#34;&gt;here&lt;/a&gt;). On the other hand, the advanced usage is tailored for professional users who seek to conduct sophisticated auditing. It allows them to utilize both pre-existing and customized algorithms, signals, and models, empowering them to perform advanced auditing tasks at a higher level of complexity and customization. Specifically, we provide the following tutorials for advanced usage:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/population_metric.ipynb&#34;&gt;Understanding low-level APIs: Acquire a fundamental understanding of the Privacy Meter by executing a population attack on the CIFAR10 dataset.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/reference_metric.ipynb&#34;&gt;Understanding low-level APIs: Enhance your knowledge by conducting a reference attack on the CIFAR10 dataset.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/white_box_attack.ipynb&#34;&gt;Implementing a simple white-box attack using the Privacy Meter.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/openvino_models.ipynb&#34;&gt;Expanding the Privacy Meter to encompass OpenVINO models.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/tree/master/advanced/hf_causal_language_models.ipynb&#34;&gt;Integrating the Privacy Meter with HuggingFace models.&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Video (Talks)&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.sigsac.org/ccs/CCS2022/workshops/workshops.html#:~:text=Auditing%20Data%20Privacy%20in%20Machine%20Learning%3A%20A%20Comprehensive%20Introduction&#34;&gt;Auditing Data Privacy in Machine Learning: A Comprehensive Introduction&lt;/a&gt; at CCS 2022, by Reza Shokri.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/sqCd5A1UTrQ&#34;&gt;Auditing Data Privacy in Machine Learning&lt;/a&gt; at USENIX Enigma 2022, by Reza Shokri.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/DWqnKNZTz10&#34;&gt;Machine Learning Privacy Meter Tool&lt;/a&gt; at HotPETS 2020, by Sasi Kumar Murakonda.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;If you wish to add new ways of analyzing the privacy risk or add new model support, please follow our &lt;a href=&#34;https://raw.githubusercontent.com/privacytrustlab/ml_privacy_meter/master/CONTRIBUTING.md&#34;&gt;guidelines&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Contact / Feedback&lt;/h2&gt; &#xA;&lt;p&gt;Please feel free to join our &lt;a href=&#34;https://join.slack.com/t/privacy-meter/shared_invite/zt-1oge6ovjq-SS4UZnBVB115Tx8Nn3TVhA&#34;&gt;Slack Channel&lt;/a&gt; to provide your feedback and your thoughts on the project!&lt;/p&gt; &#xA;&lt;h2&gt;Citing Privacy Meter&lt;/h2&gt; &#xA;&lt;p&gt;To cite this repository, please include the following references (or you can download the &lt;a href=&#34;https://raw.githubusercontent.com/privacytrustlab/ml_privacy_meter/master/CITATION.bib&#34;&gt;bib file&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Reza Shokri. &lt;a href=&#34;https://arxiv.org/pdf/2111.09679.pdf&#34;&gt;Enhanced Membership Inference Attacks against Machine Learning Models&lt;/a&gt; in Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, 2022.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Sasi Kumar Murakonda, Reza Shokri. &lt;a href=&#34;https://arxiv.org/pdf/2007.09339.pdf&#34;&gt;MLPrivacy Meter: Aiding Regulatory Compliance by Quantifying the Privacy Risks of Machine Learning&lt;/a&gt; in Workshop on Hot Topics in Privacy Enhancing Technologies (HotPETs), 2020.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Milad Nasr, Reza Shokri, and Amir Houmansadr. &lt;a href=&#34;https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2019.pdf&#34;&gt;Comprehensive Privacy Analysis of Deep Learning: Stand-alone and Federated Learning under Passive and Active White-box Inference Attacks&lt;/a&gt; in IEEE Symposium on Security and Privacy, 2019.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. &lt;a href=&#34;https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2017.pdf&#34;&gt;Membership Inference Attacks against Machine Learning Models&lt;/a&gt; in IEEE Symposium on Security and Privacy, 2017.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Authors&lt;/h2&gt; &#xA;&lt;p&gt;The tool is designed and developed at NUS Data Privacy and Trustworthy Machine Learning Lab. We also welcome contributions from the community.&lt;/p&gt; &#xA;&lt;a href=&#34;https://github.com/privacytrustlab/ml_privacy_meter/graphs/contributors&#34;&gt; &lt;img src=&#34;https://stg.contrib.rocks/image?repo=privacytrustlab/ml_privacy_meter&#34;&gt; &lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>aws-samples/amazon-bedrock-workshop</title>
    <updated>2023-07-20T01:37:33Z</updated>
    <id>tag:github.com,2023-07-20:/aws-samples/amazon-bedrock-workshop</id>
    <link href="https://github.com/aws-samples/amazon-bedrock-workshop" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This is a workshop designed for Amazon Bedrock a foundational model service.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Amazon Bedrock Workshop&lt;/h1&gt; &#xA;&lt;h2&gt;Introduction to the Repository and Workshop&lt;/h2&gt; &#xA;&lt;p&gt;The goal of this workshop is to give you hands-on experience leveraging foundation models (FMs) through Amazon Bedrock. Amazon Bedrock is a fully managed service that provides access to FMs from third-party providers and Amazon; available via an API. With Bedrock, you can choose from a variety of models to find the one that’s best suited for your use case.&lt;/p&gt; &#xA;&lt;p&gt;Within this series of labs, you will be taken through some of the most common usage patterns we are seeing with our customers for Generative AI. We will explore techniques for generating text and images, creating value for organizations by improving productivity. This is achieved by leveraging foundation models to help in composing emails, summarizing text, answering questions, building chatbots, and creating images. You will gain hands-on experience using Bedrock APIs, SDKs, and open-source software for example LangChain and FAISS to implement these usage patterns.&lt;/p&gt; &#xA;&lt;p&gt;This workshop is intended for developers and solution builders.&lt;/p&gt; &#xA;&lt;p&gt;What’s included in this workshop:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Text Generation [Estimated time to complete - 30 mins]&lt;/li&gt; &#xA; &lt;li&gt;Text Summarization [Estimated time to complete - 30 mins]&lt;/li&gt; &#xA; &lt;li&gt;Questions Answering [Estimated time to complete - 45 mins]&lt;/li&gt; &#xA; &lt;li&gt;Chatbot [Estimated time to complete - 45 mins]&lt;/li&gt; &#xA; &lt;li&gt;Image Generation [Estimated time to complete - 30 mins]&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/10-overview.png&#34; alt=&#34;10-overview&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;Workshop Link: &lt;a href=&#34;https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/en-US&#34;&gt;https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/en-US/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Using these notebooks&lt;/h2&gt; &#xA;&lt;p&gt;Start by cloning the workshop repo&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/aws-samples/amazon-bedrock-workshop.git&#xA;cd amazon-bedrock-workshop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The bedrock SDK is not already a part of boto3. To download the additional python wheel run the following script&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;bash ./download-dependencies.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This script will create a &lt;code&gt;dependencies&lt;/code&gt; folder and download the relevant SDKs needed to use Amazon Bedrock. Which can then be installed as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ./dependencies/botocore-1.29.162-py3-none-any.whl --force-reinstall&#xA;pip install ./dependencies/boto3-1.26.162-py3-none-any.whl --force-reinstall&#xA;pip install ./dependencies/awscli-1.27.162-py3-none-any.whl --force-reinstall&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Following this a bedrock client can be created as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import boto3&#xA;bedrock = boto3.client(&#34;bedrock&#34;, region_name=&#34;us-east-1&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you need to use a specific role to access bedrock, you can do so using a session as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import boto3&#xA;session = boto3.session.Session(profile_name=&#39;bedrock&#39;)&#xA;boto3_bedrock = session.client(&#34;bedrock&#34;, region_name=&#34;us-east-1&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Content&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains notebook examples for the Bedrock Architecture Patterns workshop. The notebooks are organised by module as follows:&lt;/p&gt; &#xA;&lt;h2&gt;Intro&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/00_Intro/bedrock_boto3_setup.ipynb&#34;&gt;Simple Bedrock Usage&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows setting up the boto3 client and some basic usage of bedrock.&lt;/p&gt; &#xA;&lt;h3&gt;Generation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/01_Generation/00_generate_w_bedrock.ipynb&#34;&gt;Simple use case with boto3&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this notebook, you generate text using Amazon Bedrock. We demonstrate consuming the Amazon Titan model directly with boto3&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/01_Generation/01_zero_shot_generation.ipynb&#34;&gt;Simple use case with LangChain&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We then perform the same task but using the popular frame LangChain&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/01_Generation/02_contextual_generation.ipynb&#34;&gt;Generation with additional context&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We then take this further by enhancing the prompt with additional context in order to improve the response.&lt;/p&gt; &#xA;&lt;h3&gt;Summarization&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/02_Summarization/01.small-text-summarization-claude.ipynb&#34;&gt;Small text summarization&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;In this notebook, you use use Bedrock to perform a simple task of summarising a small piece of text.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/02_Summarization/02.long-text-summarization-titan.ipynb&#34;&gt;Long text summarization&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The above approach may not work as the content to be summarized gets larger and exceeds the max tokens of the model. In this notebook we show an approach of breaking the file up into smaller chunks, summarizing each chunk, and then summarizing the summaries.&lt;/p&gt; &#xA;&lt;h3&gt;Question Answering&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/03_QuestionAnswering/00_qa_w_bedrock_titan.ipynb&#34;&gt;Simple questions with context&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows a simple example answerting a question with given context by calling the model directly.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/03_QuestionAnswering/01_qa_w_rag_claude.ipynb&#34;&gt;Answering questions with Retrieval Augmented Generation&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We can improve the above process by implementing an architecure called Retreival Augmented Generation (RAG). RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context.&lt;/p&gt; &#xA;&lt;h3&gt;Chatbot&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/04_Chatbot/00_Chatbot_Claude.ipynb&#34;&gt;Chatbot using Claude&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows a chatbot using Claude&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/04_Chatbot/00_Chatbot_Titan.ipynb&#34;&gt;Chatbot using Titan&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook shows a chatbot using Titan&lt;/p&gt; &#xA;&lt;h3&gt;Text to Image&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aws-samples/amazon-bedrock-workshop/main/05_Image/Bedrock%20Stable%20Diffusion%20XL.ipynb&#34;&gt;Image Generation with Stable Diffusion&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This notebook demonstrates image generation with using the Stable Diffusion model&lt;/p&gt;</summary>
  </entry>
</feed>