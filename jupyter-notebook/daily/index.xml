<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-12-29T01:32:01Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>petercorke/RVC3-python</title>
    <updated>2025-12-29T01:32:01Z</updated>
    <id>tag:github.com,2025-12-29:/petercorke/RVC3-python</id>
    <link href="https://github.com/petercorke/RVC3-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Code examples for Robotics, Vision &amp; Control 3rd edition in Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Robotics, Vision &amp;amp; Control: 3rd edition in Python (2023)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/petercorke/robotics-toolbox-python&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/petercorke/robotics-toolbox-python/master/.github/svg/py_collection.min.svg?sanitize=true&#34; alt=&#34;A Python Robotics Package&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://qcr.github.io&#34;&gt;&lt;img src=&#34;https://github.com/qcr/qcr.github.io/raw/master/misc/badge.svg?sanitize=true&#34; alt=&#34;QUT Centre for Robotics Open Source&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34; alt=&#34;License: MIT&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://badge.fury.io/py/rvc3python&#34;&gt;&lt;img src=&#34;https://badge.fury.io/py/rvc3python.svg?sanitize=true&#34; alt=&#34;PyPI version&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/pypi/pyversions/rvc3python.svg?sanitize=true&#34; alt=&#34;PyPI - Python Version&#34;&gt; &lt;a href=&#34;https://pypistats.org/packages/rvc3python&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dw/rvc3python&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;table style=&#34;border:0px&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr style=&#34;border:0px&#34;&gt; &#xA;   &lt;td style=&#34;border:0px&#34;&gt; &lt;img src=&#34;https://github.com/petercorke/RVC3-python/raw/main/doc/frontcover.png&#34; alt=&#34;Front cover 978-3-031-06468-5_5208&#34; width=&#34;300&#34;&gt; &lt;/td&gt; &#xA;   &lt;td style=&#34;border:0px&#34;&gt; Welcome to the online hub for the book: &#xA;    &lt;ul type=&#34;none&#34;&gt; &#xA;     &lt;li&gt;&lt;b&gt;Robotics, Vision &amp;amp; Control&lt;/b&gt;: fundamental algorithms in Python (3rd edition) &lt;/li&gt;&#xA;     &lt;li&gt;Peter Corke, published by Springer-Nature 2023.&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;ISBN&lt;/b&gt; 978-3-031-06468-5 (hardcopy), 978-3-031-06469-2 (eBook)&lt;/li&gt; &#xA;     &lt;li&gt;&lt;b&gt;DOI&lt;/b&gt; &lt;a href=&#34;https://doi.org/10.1007/978-3-031-06469-2&#34;&gt;10.1007/978-3-031-06469-2&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;br&gt;&lt;br&gt; &lt;p&gt;Report an issue with the book or its supporting code &lt;a href=&#34;https://github.com/petercorke/RVC3-python/issues/new/choose&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Known errata for the book can be viewed &lt;a href=&#34;https://github.com/petercorke/RVC3-python/wiki/Errata&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;p&gt;This book uses many examples based on the following open-source Python packages&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/petercorke/robotics-toolbox-python&#34;&gt;&lt;img alt=&#34;Robotics Toolbox for Python&#34; src=&#34;https://github.com/petercorke/robotics-toolbox-python/raw/master/docs/figs/RobToolBox_RoundLogoB.png&#34; width=&#34;130&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/petercorke/machinevision-toolbox-python&#34;&gt;&lt;img alt=&#34;Machine Vision Toolbox for Python&#34; src=&#34;https://github.com/petercorke/machinevision-toolbox-python/raw/master/figs/VisionToolboxLogo_NoBackgnd@2x.png&#34; width=&#34;150&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/petercorke/spatialmath-python&#34;&gt;&lt;img alt=&#34;Spatial Maths Toolbox for Python&#34; src=&#34;https://github.com/petercorke/spatialmath-python/raw/master/docs/figs/CartesianSnakes_LogoW.png&#34; width=&#34;130&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/petercorke/bdsim&#34;&gt;&lt;img alt=&#34;Block diagram simulation for Python&#34; src=&#34;https://github.com/petercorke/bdsim/raw/master/figs/BDSimLogo_NoBackgnd@2x.png&#34; width=&#34;250&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Robotics Toolbox for Python&lt;/strong&gt;, &lt;strong&gt;Machine Vision Toolbox for Python&lt;/strong&gt;, &lt;strong&gt;Spatial Maths Toolbox for Python&lt;/strong&gt;, &lt;strong&gt;Block Diagram Simulation for Python&lt;/strong&gt;. These in turn have dependencies on other packages created by the author and third parties.&lt;/p&gt; &#xA;&lt;h2&gt;Installing the package&lt;/h2&gt; &#xA;&lt;p&gt;This package provides a simple one-step installation of &lt;em&gt;all&lt;/em&gt; the required Toolboxes&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install rvc3python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda install rvc3python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;There are a lot of dependencies and this might take a minute or so. You now have a very powerful computing environment for robotics and computer vision.&lt;/p&gt; &#xA;&lt;h3&gt;Python version&lt;/h3&gt; &#xA;&lt;p&gt;Given the rapid rate of language additions, particularly around type hinting, use at least Python 3.8. Python 3.7 goes end of life in June 2023.&lt;/p&gt; &#xA;&lt;p&gt;Not all package dependencies will work with the latest release of Python. In particular, check:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/torch/&#34;&gt;PyTorch&lt;/a&gt; used for segmentation examples in Chapter 12&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pypi.org/project/open3d&#34;&gt;Open3D&lt;/a&gt;, used for point cloud examples in Chapter 14.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Installing into a Conda environment&lt;/h3&gt; &#xA;&lt;p&gt;It&#39;s probably a good idea to create a virtual environment to keep this package and its dependencies separated from your other Python code and projects. If you&#39;ve never used virtual environments before this might be a good time to start, and it is really easy &lt;a href=&#34;https://conda.io/projects/conda/en/latest/user-guide/install/index.html&#34;&gt;using Conda&lt;/a&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n RVC3 python=3.10&#xA;conda activate RVC3&#xA;pip install rvc3python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing deep learning tools&lt;/h3&gt; &#xA;&lt;p&gt;Chapter 11 has some deep learning examples based on PyTorch. If you don&#39;t have PyTorch installed you can use the &lt;code&gt;pytorch&lt;/code&gt; install option&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install rvc3python[pytorch]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda install rvc3python&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Using the Toolboxes&lt;/h2&gt; &#xA;&lt;p&gt;The simplest way to get going is to use the command line tool&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ rvctool&#xA; ____       _           _   _             __     ___     _                ___      ____            _             _   _____ &#xA;|  _ \ ___ | |__   ___ | |_(_) ___ ___    \ \   / (_)___(_) ___  _ __    ( _ )    / ___|___  _ __ | |_ _ __ ___ | | |___ / &#xA;| |_) / _ \| &#39;_ \ / _ \| __| |/ __/ __|    \ \ / /| / __| |/ _ \| &#39;_ \   / _ \/\ | |   / _ \| &#39;_ \| __| &#39;__/ _ \| |   |_ \ &#xA;|  _ &amp;lt; (_) | |_) | (_) | |_| | (__\__ \_    \ V / | \__ \ | (_) | | | | | (_&amp;gt;  &amp;lt; | |__| (_) | | | | |_| | | (_) | |  ___) |&#xA;|_| \_\___/|_.__/ \___/ \__|_|\___|___( )    \_/  |_|___/_|\___/|_| |_|  \___/\/  \____\___/|_| |_|\__|_|  \___/|_| |____/ &#xA;                                      |/                                                                                   &#xA;                                                                                 &#xA;for Python (RTB==1.1.0, MVTB==0.9.5, SG==1.1.7, SMTB==1.1.7, NumPy==1.24.2, SciPy==1.10.1, Matplotlib==3.7.1)&#xA;&#xA;    import math&#xA;    import numpy as np&#xA;    from scipy import linalg, optimize&#xA;    import matplotlib.pyplot as plt&#xA;    from spatialmath import *&#xA;    from spatialmath.base import *&#xA;    from spatialmath.base import sym&#xA;    from spatialgeometry import *&#xA;    from roboticstoolbox import *&#xA;    from machinevisiontoolbox import *&#xA;    import machinevisiontoolbox.base as mvb&#xA;    &#xA;    # useful variables&#xA;    from math import pi&#xA;    puma = models.DH.Puma560()&#xA;    panda = models.DH.Panda()&#xA;&#xA;    func/object?       - show brief help&#xA;    help(func/object)  - show detailed help&#xA;    func/object??      - show source code&#xA;&#xA;Results of assignments will be displayed, use trailing ; to suppress&#xA;    &#xA;Python 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:24:27) [Clang 14.0.6 ]&#xA;Type &#39;copyright&#39;, &#39;credits&#39; or &#39;license&#39; for more information&#xA;IPython 8.11.0 -- An enhanced Interactive Python. Type &#39;?&#39; for help.&#xA;&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This provides an interactive Python (&lt;a href=&#34;https://ipython.readthedocs.io/en/stable&#34;&gt;IPython&lt;/a&gt;) session with all the Toolboxes and supporting packages imported, and ready to go. It&#39;s a highly capable, convenient, and &#34;MATLAB-like&#34; workbench environment for robotics and computer vision.&lt;/p&gt; &#xA;&lt;p&gt;For example to load an ETS model of a Panda robot, solve a forward kinematics and inverse kinematics problem, and an interactive graphical display is simply:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; panda = models.ETS.Panda()&#xA;ERobot: Panda (by Franka Emika), 7 joints (RRRRRRR)&#xA;┌─────┬───────┬───────┬────────┬─────────────────────────────────────────────┐&#xA;│link │ link  │ joint │ parent │             ETS: parent to link             │&#xA;├─────┼───────┼───────┼────────┼─────────────────────────────────────────────┤&#xA;│   0 │ link0 │     0 │ BASE   │ tz(0.333) ⊕ Rz(q0)                          │&#xA;│   1 │ link1 │     1 │ link0  │ Rx(-90°) ⊕ Rz(q1)                           │&#xA;│   2 │ link2 │     2 │ link1  │ Rx(90°) ⊕ tz(0.316) ⊕ Rz(q2)                │&#xA;│   3 │ link3 │     3 │ link2  │ tx(0.0825) ⊕ Rx(90°) ⊕ Rz(q3)               │&#xA;│   4 │ link4 │     4 │ link3  │ tx(-0.0825) ⊕ Rx(-90°) ⊕ tz(0.384) ⊕ Rz(q4) │&#xA;│   5 │ link5 │     5 │ link4  │ Rx(90°) ⊕ Rz(q5)                            │&#xA;│   6 │ link6 │     6 │ link5  │ tx(0.088) ⊕ Rx(90°) ⊕ tz(0.107) ⊕ Rz(q6)    │&#xA;│   7 │ @ee   │       │ link6  │ tz(0.103) ⊕ Rz(-45°)                        │&#xA;└─────┴───────┴───────┴────────┴─────────────────────────────────────────────┘&#xA;&#xA;┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐&#xA;│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │&#xA;├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤&#xA;│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │&#xA;│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │&#xA;└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘&#xA;&#xA;&amp;gt;&amp;gt;&amp;gt; panda.fkine(panda.qz)&#xA;   0.7071    0.7071    0         0.088     &#xA;   0.7071   -0.7071    0         0         &#xA;   0         0        -1         0.823     &#xA;   0         0         0         1      &#xA;&amp;gt;&amp;gt;&amp;gt; panda.ikine_LM(SE3.Trans(0.4, 0.5, 0.2) * SE3.Ry(pi/2))&#xA;IKSolution(q=array([  -1.849,   -2.576,   -2.914,     1.22,   -1.587,    2.056,   -1.013]), success=True, iterations=13, searches=1, residual=3.3549072615799585e-10, reason=&#39;Success&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt; panda.teach(panda.qz)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/petercorke/RVC3-python/raw/main/doc/panda_noodle.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Computer vision is just as easy. For example, we can import an image, blur it and display it alongside the original&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; mona = Image.Read(&#34;monalisa.png&#34;)&#xA;&amp;gt;&amp;gt;&amp;gt; Image.Hstack([mona, mona.smooth(sigma=5)]).disp()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/petercorke/machinevision-toolbox-python/raw/master/figs/mona%2Bsmooth.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;or load two images of the same scene, compute SIFT features and display putative matches&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; sf1 = Image.Read(&#34;eiffel-1.png&#34;, mono=True).SIFT()&#xA;&amp;gt;&amp;gt;&amp;gt; sf2 = Image.Read(&#34;eiffel-2.png&#34;, mono=True).SIFT()&#xA;&amp;gt;&amp;gt;&amp;gt; matches = sf1.match(sf2)&#xA;&amp;gt;&amp;gt;&amp;gt; matches.subset(100).plot(&#34;w&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/petercorke/machinevision-toolbox-python/raw/master/figs/matching.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;rvctool&lt;/code&gt; is a wrapper around &lt;a href=&#34;https://ipython.readthedocs.io/en/stable&#34;&gt;IPython&lt;/a&gt; where:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;robotics and vision functions and classes can be accessed without needing package prefixes&lt;/li&gt; &#xA; &lt;li&gt;results are displayed by default like MATLAB does, and like MATLAB you need to put a semicolon on the end of the line to prevent this&lt;/li&gt; &#xA; &lt;li&gt;the prompt is the standard Python REPL prompt &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; rather than the IPython prompt, this can be overridden by a command-line switch&lt;/li&gt; &#xA; &lt;li&gt;allows cutting and pasting in lines from the book, and prompt characters are ignored&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The Robotics, Vision &amp;amp; Control book uses &lt;code&gt;rvctool&lt;/code&gt; for all the included examples.&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;rvctool&lt;/code&gt; imports the all the above mentioned packages using &lt;code&gt;import *&lt;/code&gt; which is not considered best Python practice. It is very convenient for interactive experimentation, but in your own code you can handle the imports as you see fit.&lt;/p&gt; &#xA;&lt;h3&gt;Cutting and pasting&lt;/h3&gt; &#xA;&lt;p&gt;IPython is very forgiving when it comes to cutting and pasting in blocks of Python code. It will strip off the &lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; prompt character and ignore indentation. The normal python REPL is not so forgiving. IPython also maintains a command history and allows command editing.&lt;/p&gt; &#xA;&lt;h3&gt;Simple scripting&lt;/h3&gt; &#xA;&lt;p&gt;You can write very simple scripts, for example &lt;code&gt;test.py&lt;/code&gt; is&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;T = puma.fkine(puma.qn)&#xA;sol = puma.ikine_LM(T)&#xA;sol.q&#xA;puma.plot(sol.q);&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;then&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ rvctool test.py&#xA;   0         0         1         0.5963    &#xA;   0         1         0        -0.1501    &#xA;  -1         0         0         0.6575    &#xA;   0         0         0         1         &#xA;&#xA;IKSolution(q=array([7.235e-08,  -0.8335,  0.09396,    3.142,   0.8312,   -3.142]), success=True, iterations=15, searches=1, residual=1.406125546650288e-07, reason=&#39;Success&#39;)&#xA;array([7.235e-08,  -0.8335,  0.09396,    3.142,   0.8312,   -3.142])&#xA;PyPlot3D backend, t = 0.05, scene:&#xA;  robot: Text(0.0, 0.0, &#39;Puma 560&#39;)&#xA;&amp;gt;&amp;gt;&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;and you are dropped into an IPython session after the script has run.&lt;/p&gt; &#xA;&lt;h2&gt;Issues running on Apple Silicon&lt;/h2&gt; &#xA;&lt;p&gt;Check out the &lt;a href=&#34;https://github.com/petercorke/RVC3-python/wiki/Running-on-Apple-Silicon&#34;&gt;wiki page&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Using Jupyter and Colab&lt;/h2&gt; &#xA;&lt;p&gt;Graphics and animations are problematic in these environments, some things work well, some don&#39;t. As much as possible I&#39;ve tweaked the Jupyter notebooks to work as best they can in these environments.&lt;/p&gt; &#xA;&lt;p&gt;For local use the &lt;a href=&#34;https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter&#34;&gt;Jupyter plugin for Visual Studio Code&lt;/a&gt; is pretty decent. Colab suffers from old versions of major packages (though they are getting better at keeping up to date) and animations can suffer from slow update over the network.&lt;/p&gt; &#xA;&lt;h2&gt;Other command line tools&lt;/h2&gt; &#xA;&lt;p&gt;Additional command line tools available (from the Robotics Toolbox) include:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;eigdemo&lt;/code&gt;, animation showing linear transformation of a rotating unit vector which demonstrates eigenvalues and eigenvectors.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;tripleangledemo&lt;/code&gt;, Swift visualization that lets you experiment with various triple-angle sequences.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;twistdemo&lt;/code&gt;, Swift visualization that lets you experiment with 3D twists. The screw axis is the blue rod and you can position and orient it using the sliders, and adjust its pitch. Then apply a rotation about the screw using the bottom slider.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Block diagram models&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/petercorke/bdsim&#34;&gt;&lt;img src=&#34;https://github.com/petercorke/bdsim/raw/master/figs/BDSimLogo_NoBackgnd%402x.png&#34; alt=&#34;bdsim logo&#34; width=&#34;300&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Block diagram models are key to the pedagogy of the RVC3 book and 25 models are included. To simulate these models we use the Python package &lt;a href=&#34;https://github.com/petercorke/bdsim&#34;&gt;bdsim&lt;/a&gt; which can run models:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;written in Python using &lt;a href=&#34;https://github.com/petercorke/bdsim#getting-started&#34;&gt;bdsim&lt;/a&gt; blocks and wiring.&lt;/li&gt; &#xA; &lt;li&gt;created graphically using &lt;a href=&#34;https://github.com/petercorke/bdsim#bdedit-the-graphical-editing-tool&#34;&gt;bdedit&lt;/a&gt; and saved as a &lt;code&gt;.bd&lt;/code&gt; (JSON format) file.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The models are included in the &lt;code&gt;RVC3&lt;/code&gt; package when it is installed and &lt;code&gt;rvctool&lt;/code&gt; adds them to the module search path. This means you can invoke them from &lt;code&gt;rvctool&lt;/code&gt; by&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; %run -m vloop_test&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;If you want to directly access the folder containing the models, the command line tool&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;bdsim_path&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;will display the full path to where they have been installed in the Python package tree.&lt;/p&gt; &#xA;&lt;h1&gt;Additional book resources&lt;/h1&gt; &#xA;&lt;img src=&#34;https://github.com/petercorke/RVC3-python/raw/main/doc/frontcover.png&#34; alt=&#34;Front cover 978-3-031-06468-5_5208&#34; width=&#34;100&#34;&gt; &#xA;&lt;p&gt;This GitHub repo provides additional resources for readers including:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Jupyter notebooks containing all code lines from each chapter, see the &lt;a href=&#34;https://raw.githubusercontent.com/petercorke/RVC3-python/main/notebooks&#34;&gt;&lt;code&gt;notebooks&lt;/code&gt;&lt;/a&gt; folder&lt;/li&gt; &#xA; &lt;li&gt;The code to produce every Python/Matplotlib (2D) figure in the book, see the &lt;a href=&#34;https://raw.githubusercontent.com/petercorke/RVC3-python/main/figures&#34;&gt;&lt;code&gt;figures&lt;/code&gt;&lt;/a&gt; folder&lt;/li&gt; &#xA; &lt;li&gt;3D points clouds from chapter 14, and the code to create them, see the &lt;a href=&#34;https://raw.githubusercontent.com/petercorke/RVC3-python/pointclouds&#34;&gt;&lt;code&gt;pointclouds&lt;/code&gt;&lt;/a&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;3D figures from chapters 2-3, 7-9, and the code to create them, see the &lt;a href=&#34;https://raw.githubusercontent.com/petercorke/RVC3-python/3dfigures&#34;&gt;&lt;code&gt;3dfigures&lt;/code&gt;&lt;/a&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;All example scripts, see the &lt;a href=&#34;https://raw.githubusercontent.com/petercorke/RVC3-python/main/examples&#34;&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; folder.&lt;/li&gt; &#xA; &lt;li&gt;To run the visual odometry example in Sect. 14.8.3 you need to download two image sequence, each over 100MB, &lt;a href=&#34;https://github.com/petercorke/machinevision-toolbox-python/raw/master/mvtb-data/README.md#install-big-image-files&#34;&gt;see the instructions here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;To get that material you must clone the repo&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/petercorke/RVC3-python.git&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>