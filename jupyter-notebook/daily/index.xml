<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-07-26T01:30:42Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>Starlitnightly/omicverse</title>
    <updated>2024-07-26T01:30:42Z</updated>
    <id>tag:github.com,2024-07-26:/Starlitnightly/omicverse</id>
    <link href="https://github.com/Starlitnightly/omicverse" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A python library for multi omics included bulk, single cell and spatial RNA-seq analysis.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/README.assets/logo.png&#34; width=&#34;400&#34;&gt; &lt;/h1&gt;&#xA;&lt;br&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pypi.org/project/omicverse&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/omicverse&#34; alt=&#34;pypi-badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://omicverse.readthedocs.io/en/latest/?badge=latest&#34;&gt;&lt;img src=&#34;https://readthedocs.org/projects/omicverse/badge/?version=latest&#34; alt=&#34;Documentation Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/omicverse&#34;&gt;&lt;img src=&#34;https://static.pepy.tech/badge/omicverse&#34; alt=&#34;pypiDownloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://anaconda.org/conda-forge/omicverse&#34;&gt;&lt;img src=&#34;https://img.shields.io/conda/dn/conda-forge/omicverse?logo=Anaconda&#34; alt=&#34;condaDownloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://img.shields.io/apm/l/vim-mode&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-GNU-blue&#34; alt=&#34;License:GPL&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://scverse.org/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/scverse-ecosystem-blue.svg?labelColor=yellow&#34; alt=&#34;scverse&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/Starlitnightly/omicverse/&#34;&gt;&lt;img src=&#34;https://github.com/Starlitnightly/omicverse/workflows/py38%7Cpy39/badge.svg?sanitize=true&#34; alt=&#34;Pytest&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;code&gt;OmicVerse&lt;/code&gt;&lt;/strong&gt; is the fundamental package for multi omics included &lt;strong&gt;bulk ,single cell and spatial RNA-seq&lt;/strong&gt; analysis with Python. For more information, please read our paper: &lt;a href=&#34;https://www.nature.com/articles/s41467-024-50194-3&#34;&gt;OmicVerse: a framework for bridging and deepening insights across bulk and single-cell sequencing&lt;/a&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;/p&gt; &#xA; &lt;p&gt;&lt;strong&gt;Star Us&lt;/strong&gt;, You will receive all release notifications from GitHub without any delay ~ â­ï¸&lt;/p&gt; &#xA; &lt;p&gt;If you like &lt;strong&gt;OmicVerse&lt;/strong&gt; and want to support our mission, please consider making a &lt;a href=&#34;https://ifdian.net/a/starlitnightly&#34;&gt;ğŸ’—donation&lt;/a&gt; to support our efforts.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; &#xA; &lt;picture&gt; &#xA;  &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://api.star-history.com/svg?repos=Starlitnightly%2Fomicverse&amp;amp;theme=dark&amp;amp;type=Date&#34;&gt; &#xA;  &lt;img width=&#34;100%&#34; src=&#34;https://api.star-history.com/svg?repos=Starlitnightly%2Fomicverse&amp;amp;type=Date&#34;&gt; &#xA; &lt;/picture&gt; &#xA;&lt;/details&gt; &#xA;&lt;h2&gt;&lt;code&gt;1&lt;/code&gt; &lt;a href=&#34;https://starlitnightly.github.io/omicverse/&#34;&gt;Introduction&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The original name of the omicverse was &lt;a href=&#34;https://pypi.org/project/Pyomic/&#34;&gt;Pyomic&lt;/a&gt;, but we wanted to address a whole universe of transcriptomics, so we changed the name to &lt;strong&gt;&lt;code&gt;OmicVerse&lt;/code&gt;&lt;/strong&gt;, it aimed to solve all task in RNA-seq.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] &lt;strong&gt;BulkTrajBlend&lt;/strong&gt; algorithm in OmicVerse that combines Beta-Variational AutoEncoder for deconvolution and graph neural networks for overlapping community discovery to effectively interpolate and restore the continuity of &lt;strong&gt;&#34;omission&#34;&lt;/strong&gt; cells in the original scRNA-seq data.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/omicverse_guide/docs/img/omicverse.png#gh-light-mode-only&#34; alt=&#34;omicverse-light&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/omicverse_guide/docs/img/omicverse_dark.png#gh-dark-mode-only&#34; alt=&#34;omicverse-dark&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;&lt;code&gt;2&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Directory structure&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;.&#xA;â”œâ”€â”€ omicverse                  # Main Python package&#xA;â”œâ”€â”€ omicverse_guide            # Documentation files&#xA;â”œâ”€â”€ sample                     # Some test data&#xA;â”œâ”€â”€ LICENSE&#xA;â””â”€â”€ README.md&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;&lt;code&gt;3&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Getting Started &lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;OmicVerse can be installed via conda or pypi and you need to install &lt;code&gt;pytorch&lt;/code&gt; at first. Please refer to the &lt;a href=&#34;https://starlitnightly.github.io/omicverse/Installation_guild/&#34;&gt;installation tutorial&lt;/a&gt; for more detailed installation steps and adaptations for different platforms (&lt;code&gt;Windows&lt;/code&gt;, &lt;code&gt;Linux&lt;/code&gt; or &lt;code&gt;Mac OS&lt;/code&gt;).&lt;/p&gt; &#xA;&lt;p&gt;You can use &lt;code&gt;conda install omicverse -c conda-forge&lt;/code&gt; or &lt;code&gt;pip install -U omicverse&lt;/code&gt; for installation.&lt;/p&gt; &#xA;&lt;p&gt;Please checkout the documentations and tutorials at &lt;a href=&#34;https://starlitnightly.github.io/omicverse/&#34;&gt;omicverse page&lt;/a&gt; or &lt;a href=&#34;https://omicverse.readthedocs.io/en/latest/index.html&#34;&gt;omicverse.readthedocs.io&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;&lt;code&gt;4&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Data Framework and Reference&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The omicverse is implemented as an infrastructure based on the following four data structures.&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;td&gt; &lt;a href=&#34;https://github.com/pandas-dev/pandas&#34;&gt;pandas&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt; &lt;a href=&#34;https://github.com/scverse/anndata&#34;&gt;anndata&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt; &lt;a href=&#34;https://github.com/numpy/numpy&#34;&gt;numpy&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td&gt; &lt;a href=&#34;https://github.com/scverse/mudata&#34;&gt;mudata&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;The table contains the tools have been published&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;table&gt; &#xA;  &lt;tbody&gt;&#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Scanpy&lt;br&gt;&lt;a href=&#34;https://github.com/scverse/scanpy&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://link.springer.com/article/10.1186/s13059-017-1382-0&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;dynamicTreeCut&lt;br&gt;&lt;a href=&#34;https://github.com/kylessmith/dynamicTreeCut&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://academic.oup.com/bioinformatics/article/24/5/719/200751&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;scDrug&lt;br&gt;&lt;a href=&#34;https://github.com/ailabstw/scDrug&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S2001037022005505&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;MOFA&lt;br&gt;&lt;a href=&#34;https://github.com/bioFAM/mofapy2&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02015-1&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;COSG&lt;br&gt;&lt;a href=&#34;https://github.com/genecell/COSG&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://academic.oup.com/bib/advance-article-abstract/doi/10.1093/bib/bbab579/6511197?redirectedFrom=fulltext&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;CellphoneDB&lt;br&gt;&lt;a href=&#34;https://github.com/ventolab/CellphoneDB&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41586-018-0698-6&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;AUCell&lt;br&gt;&lt;a href=&#34;https://github.com/aertslab/AUCell&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://bioconductor.org/packages/AUCell&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Bulk2Space&lt;br&gt;&lt;a href=&#34;https://github.com/ZJUFanLab/bulk2space&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-022-34271-z&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;SCSA&lt;br&gt;&lt;a href=&#34;https://github.com/bioinfo-ibms-pumc/SCSA&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.3389/fgene.2020.00490&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;WGCNA&lt;br&gt;&lt;a href=&#34;http://www.genetics.ucla.edu/labs/horvath/CoexpressionNetwork/Rpackages/WGCNA&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-559&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;VIA&lt;br&gt;&lt;a href=&#34;https://github.com/ShobiStassen/VIA&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-021-25773-3&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;pyDEseq2&lt;br&gt;&lt;a href=&#34;https://github.com/owkin/PyDESeq2&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2022.12.14.520412v1&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;NOCD&lt;br&gt;&lt;a href=&#34;https://github.com/shchur/overlapping-community-detection&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/1909.12201&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;SIMBA&lt;br&gt;&lt;a href=&#34;https://github.com/pinellolab/simba&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-023-01899-8&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;GLUE&lt;br&gt;&lt;a href=&#34;https://github.com/gao-lab/GLUE&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41587-022-01284-4&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;MetaTiME&lt;br&gt;&lt;a href=&#34;https://github.com/yi-zhang/MetaTiME&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-023-38333-8&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;TOSICA&lt;br&gt;&lt;a href=&#34;https://github.com/JackieHanLab/TOSICA&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s41467-023-35923-4&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Harmony&lt;br&gt;&lt;a href=&#34;https://github.com/slowkow/harmonypy/&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-019-0619-0&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Scanorama&lt;br&gt;&lt;a href=&#34;https://github.com/brianhie/scanorama&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41587-019-0113-3&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Combat&lt;br&gt;&lt;a href=&#34;https://github.com/epigenelabs/pyComBat/&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1101/2020.03.17.995431&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;TAPE&lt;br&gt;&lt;a href=&#34;https://github.com/poseidonchan/TAPE&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s41467-022-34550-9&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;SEACells&lt;br&gt;&lt;a href=&#34;https://github.com/dpeerlab/SEACells&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41587-023-01716-9&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Palantir&lt;br&gt;&lt;a href=&#34;https://github.com/dpeerlab/Palantir&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s41587-019-0068-49&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;STAGATE&lt;br&gt;&lt;a href=&#34;https://github.com/QIFEIDKN/STAGATE_pyG&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-022-29439-6&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;scVI&lt;br&gt;&lt;a href=&#34;https://github.com/scverse/scvi-tools&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s41587-021-01206-w&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;MIRA&lt;br&gt;&lt;a href=&#34;https://github.com/cistrome/MIRA&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-022-01595-z&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;Tangram&lt;br&gt;&lt;a href=&#34;https://github.com/broadinstitute/Tangram/&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-021-01264-7&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;STAligner&lt;br&gt;&lt;a href=&#34;https://github.com/zhoux85/STAligner&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s43588-023-00528-w&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;CEFCON&lt;br&gt;&lt;a href=&#34;https://github.com/WPZgithub/CEFCON&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-023-44103-3&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;PyComplexHeatmap&lt;br&gt;&lt;a href=&#34;https://github.com/DingWB/PyComplexHeatmap&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1002/imt2.115&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;STT&lt;br&gt;&lt;a href=&#34;https://github.com/cliffzhou92/STT/&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-024-02266-x#Sec2&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;SLAT&lt;br&gt;&lt;a href=&#34;https://github.com/gao-lab/SLAT&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-023-43105-5&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;GPTCelltype&lt;br&gt;&lt;a href=&#34;https://github.com/Winnie09/GPTCelltype&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-024-02235-4&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;PROST&lt;br&gt;&lt;a href=&#34;https://github.com/Tang-Lab-super/PROST&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1038/s41467-024-44835-w&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;CytoTrace2&lt;br&gt;&lt;a href=&#34;https://github.com/digitalcytometry/cytotrace2&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://doi.org/10.1101/2024.03.19.585637&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;GraphST&lt;br&gt;&lt;a href=&#34;https://github.com/JinmiaoChenLab/GraphST&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-023-36796-3#citeas&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;   &lt;tr&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;COMPOSITE&lt;br&gt;&lt;a href=&#34;https://github.com/CHPGenetics/COMPOSITE/&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-024-49448-x#Abs1&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;    &lt;td align=&#34;center&#34;&gt;mellon&lt;br&gt;&lt;a href=&#34;https://github.com/settylab/mellon&#34;&gt;ğŸ“¦&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41592-024-02302-w&#34;&gt;ğŸ“–&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;/tr&gt; &#xA;  &lt;/tbody&gt;&#xA; &lt;/table&gt; &#xA;&lt;/div&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;&lt;strong&gt;Included Package not published or preprint&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[1] &lt;a href=&#34;https://github.com/andrecossa5/Cellula/&#34;&gt;Cellula&lt;/a&gt; is to provide a toolkit for the exploration of scRNA-seq. These tools perform common single-cell analysis tasks&lt;/li&gt; &#xA; &lt;li&gt;[2] &lt;a href=&#34;https://github.com/lilab-bcb/pegasus/&#34;&gt;pegasus&lt;/a&gt; is a tool for analyzing transcriptomes of millions of single cells. It is a command line tool, a python package and a base for Cloud-based analysis workflows.&lt;/li&gt; &#xA; &lt;li&gt;[3] &lt;a href=&#34;https://github.com/dylkot/cNMF&#34;&gt;cNMF&lt;/a&gt; is an analysis pipeline for inferring gene expression programs from single-cell RNA-Seq (scRNA-Seq) data.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;code&gt;5&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Contact&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Zehua Zeng (&lt;a href=&#34;mailto:starlitnightly@gmail.com&#34;&gt;starlitnightly@gmail.com&lt;/a&gt; or &lt;a href=&#34;mailto:zehuazeng@xs.ustb.edu.cn&#34;&gt;zehuazeng@xs.ustb.edu.cn&lt;/a&gt;)&lt;/li&gt; &#xA; &lt;li&gt;Lei Hu (&lt;a href=&#34;mailto:hulei@westlake.edu.cn&#34;&gt;hulei@westlake.edu.cn&lt;/a&gt;)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;&lt;code&gt;6&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Developer Guild and Contributing&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to contribute to omicverse, please refer to our &lt;a href=&#34;https://omicverse.readthedocs.io/en/latest/Developer_guild/&#34;&gt;developer documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;table align=&#34;center&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;th colspan=&#34;2&#34;&gt; &lt;br&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=Starlitnightly/omicverse&#34;&gt;&lt;br&gt;&lt;br&gt; &lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!IMPORTANT]&lt;br&gt; We would like to thank the following WeChat Official Accounts for promoting Omicverse.&lt;/p&gt; &#xA; &lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s/egAnRfr3etccU_RsN-zIlg&#34; target=&#34;_blank&#34; rel=&#34;noreferrer&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/README.assets/image-20230701163953794.png&#34; alt=&#34;linux&#34; width=&#34;50&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &lt;a href=&#34;https://zhuanlan.zhihu.com/c_1257815636945915904?page=3&#34; target=&#34;_blank&#34; rel=&#34;noreferrer&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/README.assets/WechatIMG688.png&#34; alt=&#34;linux&#34; width=&#34;50&#34; height=&#34;50&#34;&gt; &lt;/a&gt; &lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;&lt;code&gt;7&lt;/code&gt; &lt;a href=&#34;https://doi.org/10.1038/s41467-024-50194-3&#34;&gt;Citation&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you use &lt;code&gt;omicverse&lt;/code&gt; in your work, please cite the &lt;code&gt;omicverse&lt;/code&gt; publication as follows:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;OmicVerse: a framework for bridging and deepening insights across bulk and single-cell sequencing&lt;/strong&gt;&lt;/p&gt; &#xA; &lt;p&gt;Zeng, Z., Ma, Y., Hu, L. et al.&lt;/p&gt; &#xA; &lt;p&gt;&lt;em&gt;Nature Communication&lt;/em&gt; 2024 Jul 16. doi: &lt;a href=&#34;https://doi.org/10.1038/s41467-024-50194-3&#34;&gt;10.1038/s41467-024-50194-3&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;&lt;code&gt;8&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/#&#34;&gt;Other&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;If you would like to sponsor the development of our project, you can go to the afdian website (&lt;a href=&#34;https://afdian.net/a/starlitnightly&#34;&gt;https://afdian.net/a/starlitnightly&lt;/a&gt;) and sponsor us.&lt;/p&gt; &#xA;&lt;p&gt;Copyright Â© 2024 &lt;a href=&#34;https://112lab.asia/&#34;&gt;112 Lab&lt;/a&gt;. &lt;br&gt; This project is &lt;a href=&#34;https://raw.githubusercontent.com/Starlitnightly/omicverse/master/LICENSE&#34;&gt;GPL3.0&lt;/a&gt; licensed.&lt;/p&gt; &#xA;&lt;!-- LINK GROUP --&gt;</summary>
  </entry>
  <entry>
    <title>langchain-ai/langchain</title>
    <updated>2024-07-26T01:30:42Z</updated>
    <id>tag:github.com,2024-07-26:/langchain-ai/langchain</id>
    <link href="https://github.com/langchain-ai/langchain" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ğŸ¦œğŸ”— Build context-aware reasoning applications&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸ¦œï¸ğŸ”— LangChain&lt;/h1&gt; &#xA;&lt;p&gt;âš¡ Build context-aware reasoning applications âš¡&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/langchain-ai/langchain/releases&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/release/langchain-ai/langchain?style=flat-square&#34; alt=&#34;Release Notes&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/langchain-ai/langchain/actions/workflows/check_diffs.yml&#34;&gt;&lt;img src=&#34;https://github.com/langchain-ai/langchain/actions/workflows/check_diffs.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://opensource.org/licenses/MIT&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/l/langchain-core?style=flat-square&#34; alt=&#34;PyPI - License&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypistats.org/packages/langchain-core&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/dm/langchain-core?style=flat-square&#34; alt=&#34;PyPI - Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://star-history.com/#langchain-ai/langchain&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/langchain-ai/langchain?style=flat-square&#34; alt=&#34;GitHub star chart&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://libraries.io/github/langchain-ai/langchain&#34;&gt;&lt;img src=&#34;https://img.shields.io/librariesio/github/langchain-ai/langchain?style=flat-square&#34; alt=&#34;Dependency Status&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/langchain-ai/langchain/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-raw/langchain-ai/langchain?style=flat-square&#34; alt=&#34;Open Issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/langchain-ai/langchain&#34;&gt;&lt;img src=&#34;https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode&amp;amp;style=flat-square&#34; alt=&#34;Open in Dev Containers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://codespaces.new/langchain-ai/langchain&#34;&gt;&lt;img src=&#34;https://github.com/codespaces/badge.svg?sanitize=true&#34; alt=&#34;Open in GitHub Codespaces&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/langchainai&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/url/https/twitter.com/langchainai.svg?style=social&amp;amp;label=Follow%20%40LangChainAI&#34; alt=&#34;Twitter&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Looking for the JS/TS library? Check out &lt;a href=&#34;https://github.com/langchain-ai/langchainjs&#34;&gt;LangChain.js&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;To help you ship LangChain apps to production faster, check out &lt;a href=&#34;https://smith.langchain.com&#34;&gt;LangSmith&lt;/a&gt;. &lt;a href=&#34;https://smith.langchain.com&#34;&gt;LangSmith&lt;/a&gt; is a unified developer platform for building, testing, and monitoring LLM applications. Fill out &lt;a href=&#34;https://www.langchain.com/contact-sales&#34;&gt;this form&lt;/a&gt; to speak with our sales team.&lt;/p&gt; &#xA;&lt;h2&gt;Quick Install&lt;/h2&gt; &#xA;&lt;p&gt;With pip:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install langchain&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;With conda:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda install langchain -c conda-forge&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;ğŸ¤” What is LangChain?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;LangChain&lt;/strong&gt; is a framework for developing applications powered by large language models (LLMs).&lt;/p&gt; &#xA;&lt;p&gt;For these applications, LangChain simplifies the entire application lifecycle:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Open-source libraries&lt;/strong&gt;: Build your applications using LangChain&#39;s open-source &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts#langchain-expression-language-lcel&#34;&gt;building blocks&lt;/a&gt;, &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts&#34;&gt;components&lt;/a&gt;, and &lt;a href=&#34;https://python.langchain.com/v0.2/docs/integrations/platforms/&#34;&gt;third-party integrations&lt;/a&gt;. Use &lt;a href=&#34;https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/concepts/#langgraph&#34;&gt;LangGraph&lt;/a&gt; to build stateful agents with first-class streaming and human-in-the-loop support.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Productionization&lt;/strong&gt;: Inspect, monitor, and evaluate your apps with &lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;LangSmith&lt;/a&gt; so that you can constantly optimize and deploy with confidence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: Turn your LangGraph applications into production-ready APIs and Assistants with &lt;a href=&#34;https://langchain-ai.github.io/langgraph/cloud/&#34;&gt;LangGraph Cloud&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Open-source libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;langchain-core&lt;/code&gt;&lt;/strong&gt;: Base abstractions and LangChain Expression Language.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;langchain-community&lt;/code&gt;&lt;/strong&gt;: Third party integrations. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Some integrations have been further split into &lt;strong&gt;partner packages&lt;/strong&gt; that only rely on &lt;strong&gt;&lt;code&gt;langchain-core&lt;/code&gt;&lt;/strong&gt;. Examples include &lt;strong&gt;&lt;code&gt;langchain_openai&lt;/code&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;code&gt;langchain_anthropic&lt;/code&gt;&lt;/strong&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;code&gt;langchain&lt;/code&gt;&lt;/strong&gt;: Chains, agents, and retrieval strategies that make up an application&#39;s cognitive architecture.&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/&#34;&gt;&lt;code&gt;LangGraph&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;: A library for building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. Integrates smoothly with LangChain, but can be used without it.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Productionization:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;LangSmith&lt;/a&gt;&lt;/strong&gt;: A developer platform that lets you debug, test, evaluate, and monitor chains built on any LLM framework and seamlessly integrates with LangChain.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Deployment:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/cloud/&#34;&gt;LangGraph Cloud&lt;/a&gt;&lt;/strong&gt;: Turn your LangGraph applications into production-ready APIs and Assistants.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/svg/langchain_stack_062024.svg?sanitize=true&#34; alt=&#34;Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.&#34; title=&#34;LangChain Architecture Overview&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ§± What can you build with LangChain?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;â“ Question answering with RAG&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/tutorials/rag/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;End-to-end Example: &lt;a href=&#34;https://chat.langchain.com&#34;&gt;Chat LangChain&lt;/a&gt; and &lt;a href=&#34;https://github.com/langchain-ai/chat-langchain&#34;&gt;repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ§± Extracting structured output&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/tutorials/extraction/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;End-to-end Example: &lt;a href=&#34;https://github.com/langchain-ai/langchain-extract/&#34;&gt;SQL Llama2 Template&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ¤– Chatbots&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/tutorials/chatbot/&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;End-to-end Example: &lt;a href=&#34;https://weblangchain.vercel.app&#34;&gt;Web LangChain (web researcher chatbot)&lt;/a&gt; and &lt;a href=&#34;https://github.com/langchain-ai/weblangchain&#34;&gt;repo&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;And much more! Head to the &lt;a href=&#34;https://python.langchain.com/v0.2/docs/tutorials/&#34;&gt;Tutorials&lt;/a&gt; section of the docs for more.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸš€ How does LangChain help?&lt;/h2&gt; &#xA;&lt;p&gt;The main value props of the LangChain libraries are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;strong&gt;Components&lt;/strong&gt;: composable building blocks, tools and integrations for working with language models. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Off-the-shelf chains&lt;/strong&gt;: built-in assemblages of components for accomplishing higher-level tasks&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Off-the-shelf chains make it easy to get started. Components make it easy to customize existing chains and build new ones.&lt;/p&gt; &#xA;&lt;h2&gt;LangChain Expression Language (LCEL)&lt;/h2&gt; &#xA;&lt;p&gt;LCEL is the foundation of many of LangChain&#39;s components, and is a declarative way to compose chains. LCEL was designed from day 1 to support putting prototypes in production, with no code changes, from the simplest â€œprompt + LLMâ€ chain to the most complex chains.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel&#34;&gt;Overview&lt;/a&gt;&lt;/strong&gt;: LCEL and its benefits&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#runnable-interface&#34;&gt;Interface&lt;/a&gt;&lt;/strong&gt;: The standard Runnable interface for LCEL objects&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/how_to/#langchain-expression-language-lcel&#34;&gt;Primitives&lt;/a&gt;&lt;/strong&gt;: More on the primitives LCEL includes&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/how_to/lcel_cheatsheet/&#34;&gt;Cheatsheet&lt;/a&gt;&lt;/strong&gt;: Quick overview of the most common usage patterns&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Components&lt;/h2&gt; &#xA;&lt;p&gt;Components fall into the following &lt;strong&gt;modules&lt;/strong&gt;:&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ“ƒ Model I/O&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;This includes &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#prompt-templates&#34;&gt;prompt management&lt;/a&gt;, &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#example-selectors&#34;&gt;prompt optimization&lt;/a&gt;, a generic interface for &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#chat-models&#34;&gt;chat models&lt;/a&gt; and &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#llms&#34;&gt;LLMs&lt;/a&gt;, and common utilities for working with &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#output-parsers&#34;&gt;model outputs&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ“š Retrieval&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Retrieval Augmented Generation involves &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#document-loaders&#34;&gt;loading data&lt;/a&gt; from a variety of sources, &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#text-splitters&#34;&gt;preparing it&lt;/a&gt;, then &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#retrievers&#34;&gt;searching over (a.k.a. retrieving from)&lt;/a&gt; it for use in the generation step.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;ğŸ¤– Agents&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Agents allow an LLM autonomy over how a task is accomplished. Agents make decisions about which Actions to take, then take that Action, observe the result, and repeat until the task is complete. LangChain provides a &lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/#agents&#34;&gt;standard interface for agents&lt;/a&gt;, along with &lt;a href=&#34;https://github.com/langchain-ai/langgraph&#34;&gt;LangGraph&lt;/a&gt; for building custom agents.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸ“– Documentation&lt;/h2&gt; &#xA;&lt;p&gt;Please see &lt;a href=&#34;https://python.langchain.com&#34;&gt;here&lt;/a&gt; for full documentation, which includes:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/introduction/&#34;&gt;Introduction&lt;/a&gt;: Overview of the framework and the structure of the docs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/docs/use_cases/&#34;&gt;Tutorials&lt;/a&gt;: If you&#39;re looking to build something specific or are more of a hands-on learner, check out our tutorials. This is the best place to get started.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/how_to/&#34;&gt;How-to guides&lt;/a&gt;: Answers to â€œHow do Iâ€¦.?â€ type questions. These guides are goal-oriented and concrete; they&#39;re meant to help you complete a specific task.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/v0.2/docs/concepts/&#34;&gt;Conceptual guide&lt;/a&gt;: Conceptual explanations of the key parts of the framework.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://api.python.langchain.com&#34;&gt;API Reference&lt;/a&gt;: Thorough documentation of every class and method.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸŒ Ecosystem&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.smith.langchain.com/&#34;&gt;ğŸ¦œğŸ› ï¸ LangSmith&lt;/a&gt;: Trace and evaluate your language model applications and intelligent agents to help you move from prototype to production.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://langchain-ai.github.io/langgraph/&#34;&gt;ğŸ¦œğŸ•¸ï¸ LangGraph&lt;/a&gt;: Create stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://python.langchain.com/docs/langserve&#34;&gt;ğŸ¦œğŸ“ LangServe&lt;/a&gt;: Deploy LangChain runnables and chains as REST APIs.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ğŸ’ Contributing&lt;/h2&gt; &#xA;&lt;p&gt;As an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.&lt;/p&gt; &#xA;&lt;p&gt;For detailed information on how to contribute, see &lt;a href=&#34;https://python.langchain.com/v0.2/docs/contributing/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;ğŸŒŸ Contributors&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/langchain-ai/langchain/graphs/contributors&#34;&gt;&lt;img src=&#34;https://contrib.rocks/image?repo=langchain-ai/langchain&amp;amp;max=2000&#34; alt=&#34;langchain contributors&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>