<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-11-07T01:39:02Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>linyiLYi/pose-monitor</title>
    <updated>2022-11-07T01:39:02Z</updated>
    <id>tag:github.com,2022-11-07:/linyiLYi/pose-monitor</id>
    <link href="https://github.com/linyiLYi/pose-monitor" rel="alternate"></link>
    <summary type="html">&lt;p&gt;“让爷康康”是一款手机 AI 应用程序，可以监测不良坐姿并进行语音提示&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;PoseMon 让爷康康&lt;/h1&gt; &#xA;&lt;img align=&#34;right&#34; src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/screenshot_icon.jpg&#34; alt=&#34;Application Icon&#34; width=&#34;17%&#34;&gt; &#xA;&lt;p&gt;“让爷康康”是一款应用于安卓平台的手机应用，可以实时监测不良坐姿并给出语音提示。本项目主要基于 &lt;a href=&#34;https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/android&#34;&gt;Tensorflow Lite 官方示例 - 姿态估计&lt;/a&gt;实现，其中 AI 部分包含用于姿态估计的 &lt;a href=&#34;https://blog.tensorflow.org/2021/05/next-generation-pose-detection-with-movenet-and-tensorflowjs.html&#34;&gt;MoveNet&lt;/a&gt;，以及用于对姿态进行分类的&lt;a href=&#34;https://github.com/tensorflow/tensorflow/raw/master/tensorflow/lite/g3doc/tutorials/pose_classification.ipynb&#34;&gt;全连接网络&lt;/a&gt;。本应用不需要联网使用，所有 AI 特性均在手机本地运行，不需要将视频画面传输至外部服务器，仅需要摄像头权限用于获取姿态画面。视频介绍可以点击 &lt;a href=&#34;https://www.bilibili.com/video/BV1uD4y187zX/&#34;&gt;bilibili&lt;/a&gt; 或 &lt;a href=&#34;https://youtu.be/QWUfeczn-tQ&#34;&gt;YouTube&lt;/a&gt;。&lt;/p&gt; &#xA;&lt;h3&gt;文件结构&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;├───android&#xA;│   ├───app&#xA;│   │   └───src&#xA;│   └───gradle&#xA;├───doc_images&#xA;├───main&#xA;│   └───pose_data&#xA;│       └───train&#xA;│           ├───forwardhead&#xA;│           └───standard&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;项目的两个主要文件夹为 &lt;code&gt;android/&lt;/code&gt; 与 &lt;code&gt;main/&lt;/code&gt;。&lt;code&gt;android/&lt;/code&gt; 下包含了所有与移动 App 相关的代码，&lt;code&gt;main/&lt;/code&gt; 文件夹下则是分类网络的训练数据与记录了训练过程的 &lt;code&gt;pose_classification.ipynb&lt;/code&gt; 文件，训练数据存放在 &lt;code&gt;main/pose_data/train/&lt;/code&gt; 目录下，为精简项目体积，只上传了 &lt;code&gt;pose_classification.ipynb&lt;/code&gt; 用到的两张示例图片。如果需要训练分类模型，可以按 &lt;code&gt;pose_classification.ipynb&lt;/code&gt; 上面的指示填充 &lt;code&gt;main/pose_data/train/&lt;/code&gt; 与 &lt;code&gt;main/pose_data/test/&lt;/code&gt; 两个文件夹。&lt;code&gt;doc_images/&lt;/code&gt; 文件夹下是本文档所用到的示例图片，并不包括项目代码。&lt;/p&gt; &#xA;&lt;h2&gt;在 Android Studio 中编译程序并运行&lt;/h2&gt; &#xA;&lt;p&gt;本项目 Android 工程部分已编译为 apk 安装包，可直接在项目&lt;a href=&#34;https://github.com/linyiLYi/pose-monitor/releases/tag/release&#34;&gt;发布页面&lt;/a&gt;下载安装进行测试。如需进一步开发测试，可以在 Android Studio 中对安卓工程文件进行编译。&lt;/p&gt; &#xA;&lt;h3&gt;准备工作&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;安卓项目的编译需要 Android Studio，可以进入&lt;a href=&#34;https://developer.android.com/studio/install?hl=zh-cn&#34;&gt;官方网站&lt;/a&gt;按照说明进行下载安装。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;需要准备一部安卓手机。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;编译程序&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;通过 &lt;code&gt;git clone&lt;/code&gt; 克隆本项目，或者以压缩包形式下载项目文件并解压。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;打开 Android Studio，在初始的 &lt;code&gt;Welcome&lt;/code&gt; 界面选择 &lt;code&gt;Open an existing Android Studio project&lt;/code&gt;，打开项目中的安卓工程文件夹。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;安卓工程文件位于本项目的 &lt;code&gt;android/&lt;/code&gt; 文件夹下。在 Android Studio 的提示窗口中选择该文件夹。项目打开后软件可能会提示需要进行 Gradle 同步，同意并等待同步完成即可。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;将处于开发者模式的手机通过 USB 线连接到电脑，具体连接方法可以参考&lt;a href=&#34;https://developer.android.com/studio/run/device?hl=zh-cn&#34;&gt;官方教程&lt;/a&gt;。如果程序顶部工具栏右侧正确显示了你的手机型号，说明设备连接成功。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;如果是首次安装 Android Studio，可能还需要安装一系列开发工具。点击软件界面右上角的绿色三角按钮&lt;code&gt;Run &#39;app&#39;&lt;/code&gt;直接运行程序。如果有需要安装的工具，系统会进行提示，按照提示依次安装即可。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;模型介绍&lt;/h2&gt; &#xA;&lt;p&gt;本项目需要用到两个神经网络模型文件，均已包含在本项目中，不需要额外下载。第一个是 &lt;code&gt;int8&lt;/code&gt; 格式的 MoveNet Thunder 神经网络模型，可以点击&lt;a href=&#34;https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/int8/4&#34;&gt;官方模型文件链接&lt;/a&gt;进一步了解。&lt;a href=&#34;https://blog.tensorflow.org/2021/05/next-generation-pose-detection-with-movenet-and-tensorflowjs.html&#34;&gt;MoveNet&lt;/a&gt; 是谷歌推出的轻量级人体姿态估计模型，有 Thunder 和 Lightning 两个版本。其中 Thunder 版本运行速度较慢，但准确率更高，本项目使用的是 Thunder 版本。该版本又分为 &lt;code&gt;float16&lt;/code&gt;、&lt;code&gt;int8&lt;/code&gt; 两种数据格式。其中 &lt;code&gt;float16&lt;/code&gt; 模型只能在通用 GPU 上运行，而 &lt;code&gt;int8&lt;/code&gt; 模型既可以运行于通用 GPU 之上，也可以在高通骁龙处理器的 &lt;a href=&#34;https://developer.qualcomm.com/software/hexagon-dsp-sdk/dsp-processor&#34;&gt;Hexagon DSP 数字信号处理器&lt;/a&gt;上运行。运行在 Hexagon 处理器上时，AI 程序运行速度更快、也更省电，建议对 AI 模型进行移动部署时优先选择 Hexagon 处理器。目前谷歌也推出了自研的 Google Tensor 处理器，最新型号为 Tensor G2，如何调用 Tensor 处理器的 AI 加速单元尚不清楚，未来拿到设备实测确认后会更新文档。&lt;/p&gt; &#xA;&lt;h3&gt;训练自己的分类网络&lt;/h3&gt; &#xA;&lt;img align=&#34;right&#34; src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/labeled_movenet_result.png&#34; alt=&#34;17 Keypoints detected by MoveNet&#34; width=&#34;25%&#34;&gt; &#xA;&lt;p&gt;除了 MoveNet Thunder，本项目还使用了一个简单的全连接网络对 MoveNet 输出的姿态信息（人体 17 个关键点的坐标）进行分类，用来判断画面中的人处于“标准坐姿”、“翘二郎腿”、“脖子前倾驼背”中的哪一种状态。关于该分类网络的介绍以及训练过程实际演示，可以参考 Tensorflow Lite 的 &lt;a href=&#34;https://github.com/tensorflow/tensorflow/raw/master/tensorflow/lite/g3doc/tutorials/pose_classification.ipynb&#34;&gt;Jupyter Notebook 教程&lt;/a&gt;，或是本项目中修改并注释过的&lt;a href=&#34;https://github.com/linyiLYi/pose-monitor/raw/master/main/pose_classification.ipynb&#34;&gt;版本&lt;/a&gt;。本项目为了对“标准坐姿”、“翘二郎腿”、“脖子前倾驼背”三种姿态进行分类，为每种姿态采集了约 300 张照片作为训练集（共 876 张照片），为每种姿态采集了约 30 张作为测试集（共 74 张照片）。其中训练集与测试集为不同人物主体，以此来在训练过程中及时发现模型的过拟合问题。训练数据应存放于 &lt;code&gt;main/pose_data/train/&lt;/code&gt; 路径下的 &lt;code&gt;standard&lt;/code&gt;、&lt;code&gt;crossleg&lt;/code&gt;、&lt;code&gt;forwardhead&lt;/code&gt; 三个文件夹中，测试数据则位于 &lt;code&gt;main/pose_data/test/&lt;/code&gt; 路径下。本项目中用于训练分类网络的 &lt;a href=&#34;https://github.com/linyiLYi/pose-monitor/raw/master/main/pose_classification.ipynb&#34;&gt;Jupyter Notebook&lt;/a&gt; 会将原始数据自动转化为训练数据包，在此过程中生成每张照片的 MoveNet 检测结果，并将每张照片标记为三种姿态中的一种，最后将所有信息存储在 &lt;code&gt;main/pose_data/train_data.csv&lt;/code&gt;、&lt;code&gt;main/pose_data/test_data.csv&lt;/code&gt;，并生成记录标签信息的文本文件 &lt;code&gt;main/pose_data/pose_labels.txt&lt;/code&gt;。在 Notebook 中训练完毕后，在 &lt;code&gt;main/pose_data/&lt;/code&gt; 路径下会自动生成 &lt;code&gt;.tflite&lt;/code&gt; 权重文件，导入至 Android Studio 项目中，替换掉本项目中的 &lt;code&gt;android\app\src\main\assets\classifier.tflite&lt;/code&gt; 即可使用。&lt;/p&gt; &#xA;&lt;h2&gt;运行效果&lt;/h2&gt; &#xA;&lt;p&gt;将手机连接至电脑，Android Studio 可以对本项目进行编译并将 App 安装至手机。打开应用，授权使用相机后，App 便可以监测人体坐姿并根据实时检测结果给出语音提示。程序的显示界面主要分为上、中、下三部分，顶部显示 AI 对当前姿态的判断结果，中部为摄像头实时画面，底部为信息显示界面，其中“运算设备”一栏可以选择不同选项，使用 CPU、GPU 或 NNAPI（Hexagon AI 加速器）进行计算，其中 NNAPI 速度最快，也最省电。为了避免程序误报，App 加入了一系列判断逻辑以提高 Precision（精确率）。连续 30 帧出现不健康坐姿时，程序会进入警戒状态，此时如果接下来 30 帧画面同样均判定为不健康坐姿，程序才会发出语音提示。效果如图所示：&lt;/p&gt; &#xA;&lt;table width=&#34;100%&#34;&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td width=&#34;25%&#34; style=&#34;line-height:0;&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/screenshot_01.jpg&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; style=&#34;line-height:0;&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/screenshot_02.jpg&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; style=&#34;line-height:0;&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/screenshot_03.jpg&#34;&gt;&lt;/td&gt; &#xA;   &lt;td width=&#34;25%&#34; style=&#34;line-height:0;&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/linyiLYi/pose-monitor/master/doc_images/screenshot_04.jpg&#34;&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2&gt;鸣谢&lt;/h2&gt;&#xA;&lt;p&gt;本项目主要基于 &lt;a href=&#34;https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/android&#34;&gt;Tensorflow Lite Pose Estimation 示例项目&lt;/a&gt;，离不开 &lt;a href=&#34;https://www.tensorflow.org/?hl=zh-cn&#34;&gt;Tensorflow&lt;/a&gt;、&lt;a href=&#34;https://jupyter.org/&#34;&gt;Jupyter Notebook&lt;/a&gt; 等开源框架、开源开发工具。感谢各位程序工作者对开源社区的贡献！&lt;/p&gt;&#xA;&lt;ul&gt; &#xA; &lt;li&gt;[2022.11.06] 感谢 &lt;a href=&#34;https://github.com/zhengbangbo&#34;&gt;@zhengbangbo&lt;/a&gt; 加入对前置摄像头的支持。（注：前置摄像头只录上半身可能导致“跷二郎腿”姿势识别不稳定，但可以支持未来开发更多上半身姿势判断。）&lt;/li&gt; &#xA;&lt;/ul&gt;&#xA;&lt;table&gt;    &#xA;&lt;/table&gt;</summary>
  </entry>
</feed>