<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-18T01:34:12Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>meta-llama/llama-recipes</title>
    <updated>2024-04-18T01:34:12Z</updated>
    <id>tag:github.com,2024-04-18:/meta-llama/llama-recipes</id>
    <link href="https://github.com/meta-llama/llama-recipes" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Scripts for fine-tuning Llama2 with composable FSDP &amp; PEFT methods to cover single/multi-node GPUs. Supports default &amp; custom datasets for applications such as summarization &amp; question answering. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment.Demo apps to showcase Llama2 for WhatsApp &amp; Messenger&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Llama Recipes: Examples to get started using the Llama models from Meta&lt;/h1&gt; &#xA;&lt;p&gt;The &#39;llama-recipes&#39; repository is a companion to the &lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Llama 2 model&lt;/a&gt;. The goal of this repository is to provide a scalable library for fine-tuning Llama 2, along with some example scripts and notebooks to quickly get started with using the Llama 2 models in a variety of use-cases, including fine-tuning for domain adaptation and building LLM-based applications with Llama 2 and other tools in the LLM ecosystem. The examples here showcase how to run Llama 2 locally, in the cloud, and on-prem.&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;[!NOTE] The llama-recipes repository was recently refactored to promote a better developer experience of using the examples. Some files have been moved to new locations. The &lt;code&gt;src/&lt;/code&gt; folder has NOT been modified, so the functionality of this repo and package is not impacted.&lt;/p&gt; &#xA; &lt;p&gt;Make sure you update your local clone by running &lt;code&gt;git pull origin main&lt;/code&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#llama-recipes-examples-to-get-started-using-the-llama-models-from-meta&#34;&gt;Llama Recipes: Examples to get started using the Llama models from Meta&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#getting-started&#34;&gt;Getting Started&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#prerequisites&#34;&gt;Prerequisites&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#pytorch-nightlies&#34;&gt;PyTorch Nightlies&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#installing&#34;&gt;Installing&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-with-pip&#34;&gt;Install with pip&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-with-optional-dependencies&#34;&gt;Install with optional dependencies&lt;/a&gt;&lt;/li&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#install-from-source&#34;&gt;Install from source&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#getting-the-llama-models&#34;&gt;Getting the Llama models&lt;/a&gt; &#xA;      &lt;ul&gt; &#xA;       &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#model-conversion-to-hugging-face&#34;&gt;Model conversion to Hugging Face&lt;/a&gt;&lt;/li&gt; &#xA;      &lt;/ul&gt; &lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#repository-organization&#34;&gt;Repository Organization&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#recipes&#34;&gt;&lt;code&gt;recipes/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#src&#34;&gt;&lt;code&gt;src/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#contributing&#34;&gt;Contributing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;p&gt;These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.&lt;/p&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;h4&gt;PyTorch Nightlies&lt;/h4&gt; &#xA;&lt;p&gt;Some features (especially fine-tuning with FSDP + PEFT) currently require PyTorch nightlies to be installed. Please make sure to install the nightlies if you&#39;re using these features following &lt;a href=&#34;https://pytorch.org/get-started/locally/&#34;&gt;this guide&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Installing&lt;/h3&gt; &#xA;&lt;p&gt;Llama-recipes provides a pip distribution for easy install and usage in other projects. Alternatively, it can be installed from source.&lt;/p&gt; &#xA;&lt;h4&gt;Install with pip&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 llama-recipes&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Install with optional dependencies&lt;/h4&gt; &#xA;&lt;p&gt;Llama-recipes offers the installation of optional packages. There are three optional dependency groups. To run the unit tests we can install the required dependencies with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 llama-recipes[tests]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For the vLLM example we need additional requirements that can be installed with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 llama-recipes[vllm]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To use the sensitive topics safety checker install with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 llama-recipes[auditnlg]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Optional dependencies can also be combines with [option1,option2].&lt;/p&gt; &#xA;&lt;h4&gt;Install from source&lt;/h4&gt; &#xA;&lt;p&gt;To install from source e.g. for development use these commands. We&#39;re using hatchling as our build backend which requires an up-to-date pip as well as setuptools package.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:meta-llama/llama-recipes.git&#xA;cd llama-recipes&#xA;pip install -U pip setuptools&#xA;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For development and contributing to llama-recipes please install all optional dependencies:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:meta-llama/llama-recipes.git&#xA;cd llama-recipes&#xA;pip install -U pip setuptools&#xA;pip install --extra-index-url https://download.pytorch.org/whl/test/cu118 -e .[tests,auditnlg,vllm]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Getting the Llama models&lt;/h3&gt; &#xA;&lt;p&gt;You can find Llama 2 models on Hugging Face hub &lt;a href=&#34;https://huggingface.co/meta-llama&#34;&gt;here&lt;/a&gt;, &lt;strong&gt;where models with &lt;code&gt;hf&lt;/code&gt; in the name are already converted to Hugging Face checkpoints so no further conversion is needed&lt;/strong&gt;. The conversion step below is only for original model weights from Meta that are hosted on Hugging Face model hub as well.&lt;/p&gt; &#xA;&lt;h4&gt;Model conversion to Hugging Face&lt;/h4&gt; &#xA;&lt;p&gt;The recipes and notebooks in this folder are using the Llama 2 model definition provided by Hugging Face&#39;s transformers library.&lt;/p&gt; &#xA;&lt;p&gt;Given that the original checkpoint resides under models/7B you can install all requirements and convert the checkpoint with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;## Install Hugging Face Transformers from source&#xA;pip freeze | grep transformers ## verify it is version 4.31.0 or higher&#xA;&#xA;git clone git@github.com:huggingface/transformers.git&#xA;cd transformers&#xA;pip install protobuf&#xA;python src/transformers/models/llama/convert_llama_weights_to_hf.py \&#xA;   --input_dir /path/to/downloaded/llama/weights --model_size 7B --output_dir /output/path&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Repository Organization&lt;/h2&gt; &#xA;&lt;p&gt;Most of the code dealing with Llama usage is organized across 2 main folders: &lt;code&gt;recipes/&lt;/code&gt; and &lt;code&gt;src/&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;code&gt;recipes/&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Contains examples are organized in folders by topic:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Subfolder&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/quickstart&#34;&gt;quickstart&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;The &#34;Hello World&#34; of using Llama2, start here if you are new to using Llama2.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/finetuning&#34;&gt;finetuning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to finetune Llama2 on single-GPU and multi-GPU setups&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/inference&#34;&gt;inference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to deploy Llama2 for inference locally and using model servers&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/use_cases&#34;&gt;use_cases&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts showing common applications of Llama2&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/responsible_ai&#34;&gt;responsible_ai&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to use PurpleLlama for safeguarding model outputs&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/llama_api_providers&#34;&gt;llama_api_providers&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to run inference on Llama via hosted endpoints&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/benchmarks&#34;&gt;benchmarks&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to benchmark Llama 2 models inference on various backends&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/code_llama&#34;&gt;code_llama&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to run inference with the Code Llama models&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/recipes/evaluation&#34;&gt;evaluation&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Scripts to evaluate fine-tuned Llama2 models using &lt;code&gt;lm-evaluation-harness&lt;/code&gt; from &lt;code&gt;EleutherAI&lt;/code&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;code&gt;src/&lt;/code&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Contains modules which support the example recipes:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Subfolder&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/configs/&#34;&gt;configs&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains the configuration files for PEFT methods, FSDP, Datasets, Weights &amp;amp; Biases experiment tracking.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/datasets/&#34;&gt;datasets&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains individual scripts for each dataset to download and process. Note&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/inference/&#34;&gt;inference&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Includes modules for inference for the fine-tuned models.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/model_checkpointing/&#34;&gt;model_checkpointing&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains FSDP checkpoint handlers.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/policies/&#34;&gt;policies&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Contains FSDP scripts to provide different policies, such as mixed precision, transformer wrapping policy and activation checkpointing along with any precision optimizer (used for running FSDP with pure bf16 mode).&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/src/llama_recipes/utils/&#34;&gt;utils&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Utility files for:&lt;br&gt; - &lt;code&gt;train_utils.py&lt;/code&gt; provides training/eval loop and more train utils.&lt;br&gt; - &lt;code&gt;dataset_utils.py&lt;/code&gt; to get preprocessed datasets.&lt;br&gt; - &lt;code&gt;config_utils.py&lt;/code&gt; to override the configs received from CLI.&lt;br&gt; - &lt;code&gt;fsdp_utils.py&lt;/code&gt; provides FSDP wrapping policy for PEFT methods.&lt;br&gt; - &lt;code&gt;memory_utils.py&lt;/code&gt; context manager to track different memory stats in train loop.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contributing&lt;/h2&gt; &#xA;&lt;p&gt;Please read &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING.md&lt;/a&gt; for details on our code of conduct, and the process for submitting pull requests to us.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;See the License file &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/LICENSE&#34;&gt;here&lt;/a&gt; and Acceptable Use Policy &lt;a href=&#34;https://raw.githubusercontent.com/meta-llama/llama-recipes/main/USE_POLICY.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mszell/geospatialdatascience</title>
    <updated>2024-04-18T01:34:12Z</updated>
    <id>tag:github.com,2024-04-18:/mszell/geospatialdatascience</id>
    <link href="https://github.com/mszell/geospatialdatascience" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Course materials for: Geospatial Data Science&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Course materials for: Geospatial Data Science&lt;/h1&gt; &#xA;&lt;p&gt;These course materials cover the lectures for the course held for the first time in spring 2022 at IT University of Copenhagen. Public course page: &lt;a href=&#34;https://learnit.itu.dk/local/coursebase/view.php?ciid=940&#34;&gt;https://learnit.itu.dk/local/coursebase/view.php?ciid=940&lt;/a&gt;&lt;br&gt; Materials were slightly improved and reordered after the course.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: Basics in data science (including statistics, Python and pandas)&lt;br&gt; &lt;strong&gt;Ideal level/program&lt;/strong&gt;: 1st year Master in Data Science&lt;/p&gt; &#xA;&lt;h2&gt;Topics&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mszell/geospatialdatascience/main/docs/images/topics.png&#34; alt=&#34;alt text&#34; title=&#34;Topics&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;· 1. Geometric objects · 2. Geospatial data in Python · 3. Choropleth mapping · 4. Spatial weights · 5. Spatial autocorrelation · 6. Spatial clustering · 7. Point pattern analysis · 8. OpenStreetMap and OSMnx · 9. Spatial networks · 10. Bicycle networks · 11. Individual mobility · 12. Mobility patterns · 13. Aggregate mobility and urban scaling · 14. Sustainable mobility and geospatial epidemiology ·&lt;/p&gt; &#xA;&lt;h2&gt;Exercise materials and tutorials&lt;/h2&gt; &#xA;&lt;p&gt;See: &lt;a href=&#34;https://github.com/anerv/GDS2022_exercises&#34;&gt;https://github.com/anerv/GDS2022_exercises&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Schedule&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/mszell/geospatialdatascience/main/docs/images/courseschedule.png&#34; alt=&#34;alt text&#34; title=&#34;Course Schedule&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Sources&lt;/h2&gt; &#xA;&lt;p&gt;The course materials were adapted/inspired from a number of sources, &lt;em&gt;standing on the shoulders of giants&lt;/em&gt;, ordered by appearance in the course:&lt;/p&gt; &#xA;&lt;h3&gt;Main sources&lt;/h3&gt; &#xA;&lt;p&gt;Percentages are approximative.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[7%] Tenkanen, Heikinheimo, Aagesen: &lt;a href=&#34;https://autogis-site.readthedocs.io/en/latest/&#34;&gt;Automating GIS-processes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[40%] Arribas-Bel: &lt;a href=&#34;https://darribas.org/gds_course/content/home.html&#34;&gt;Geographic Data Science&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[7%] Boeing: &lt;a href=&#34;https://github.com/gboeing/osmnx-examples/tree/main/notebooks&#34;&gt;OSMnx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[1%] Tenkanen: &lt;a href=&#34;https://pyrosm.readthedocs.io/en/latest/index.html&#34;&gt;pyrosm&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2%] Gaboardo, Rey, Lumnitz: &lt;a href=&#34;https://pysal.org/spaghetti/&#34;&gt;spaghetti&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[2%] Pappalardo: &lt;a href=&#34;https://github.com/scikit-mobility/tutorials&#34;&gt;scikit-mobility&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[25%] Alessandretti, Szell: &lt;a href=&#34;https://arxiv.org/abs/2211.00355&#34;&gt;Urban Mobility&lt;/a&gt; (developed after the course)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Other major sources and further materials&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Rey, Arribas-Bel, Wolf: &lt;a href=&#34;https://geographicdata.science/book/intro.html&#34;&gt;Geographic Data Science with Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Prapas: &lt;a href=&#34;https://www.learndatasci.com/tutorials/geospatial-data-python-geopandas-shapely/&#34;&gt;Analyze Geospatial Data in Python: GeoPandas and Shapely&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Gimond: &lt;a href=&#34;https://mgimond.github.io/Spatial/index.html&#34;&gt;Intro to GIS and Spatial Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tan, Steinbach, Kumar: Introduction to Data Mining&lt;/li&gt; &#xA; &lt;li&gt;Timaite, Lovelace: &lt;a href=&#34;https://udsleeds.github.io/openinfra/articles/openinfra.html&#34;&gt;Getting started with open data on transport infrastructure&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Rodrigue: &lt;a href=&#34;https://transportgeography.org/&#34;&gt;The Geography of Transport Systems&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Barthelemy: &lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-030-94106-2&#34;&gt;Spatial Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Barbosa et al: &lt;a href=&#34;https://doi.org/10.1016/j.physrep.2018.01.001&#34;&gt;Human mobility: Models and applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mobility papers: &lt;a href=&#34;https://www.nature.com/articles/nature04292&#34;&gt;Brockmann et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/nature06958&#34;&gt;Gonzalez et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/srep00457&#34;&gt;Szell et al&lt;/a&gt;, &lt;a href=&#34;https://www.science.org/doi/abs/10.1126/science.1177170&#34;&gt;Song et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/ncomms9166&#34;&gt;Pappalardo et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/nphys1760&#34;&gt;Song et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/srep01376&#34;&gt;De Montjoye et al&lt;/a&gt;, &lt;a href=&#34;https://royalsocietypublishing.org/doi/abs/10.1098/rsif.2013.0246&#34;&gt;Schneider et al&lt;/a&gt;, &lt;a href=&#34;https://www.pnas.org/content/113/36/9977.short&#34;&gt;Sekara et al&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/nature10856&#34;&gt;Simini et al&lt;/a&gt;, &lt;a href=&#34;https://www.science.org/doi/10.1126/science.1245200&#34;&gt;Brockmann &amp;amp; Helbing&lt;/a&gt;, &lt;a href=&#34;https://www.nature.com/articles/s41598-022-10783-y&#34;&gt;Szell et al&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Kapp: &lt;a href=&#34;https://alexandrakapp.blog/2022/03/14/privacy-preserving-techniques-and-how-they-apply-to-mobility-data/&#34;&gt;Privacy-preserving techniques and how they apply to mobility data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Batty: &lt;a href=&#34;https://mitpress.mit.edu/books/new-science-cities&#34;&gt;The New Science of Cities&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Barthelemy: &lt;a href=&#34;https://www.cambridge.org/core/books/structure-and-dynamics-of-cities/50359353B081D0A38928961FE16FB2FD&#34;&gt;The Structure and Dynamics of Cities&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Tenkanen: &lt;a href=&#34;https://sustainability-gis.readthedocs.io/en/latest/index.html&#34;&gt;Spatial data science for sustainable development&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;OECD: &lt;a href=&#34;https://www.oecd.org/environment/transport-strategies-for-net-zero-systems-by-design-0a20f779-en.htm&#34;&gt;Transport Strategies for Net-Zero Systems by Design&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/GDSL-UL/Teaching_Links&#34;&gt;The GDSL Big List of Teaching Links&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;More sources are referenced within the slides and notebooks.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;All materials were used for educational, non-commercial reasons only. Feel free to use as you wish for the same purpose, at your own risk. For other re-use questions please consult the license of the respective source. Our main sources use the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;CC BY-SA 4.0 license&lt;/a&gt; so we use it too.&lt;/p&gt; &#xA;&lt;h2&gt;Credits&lt;/h2&gt; &#xA;&lt;p&gt;Lectures: &lt;a href=&#34;http://michael.szell.net/&#34;&gt;Michael Szell&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/anerv/GDS2022_exercises&#34;&gt;Exercises and tutorials&lt;/a&gt;: Ane Rahbek Vierø &amp;amp; Anastassia Vybornova&lt;/p&gt; &#xA;&lt;p&gt;Thanks to all our main sources for being so helpful and open with your materials! Special thanks to Adéla Sobotkova for helpful discussions and materials concerning syllabus, exam form, and project description, and to Vedran Sekara for slide materials.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>IBM/tsfm</title>
    <updated>2024-04-18T01:34:12Z</updated>
    <id>tag:github.com,2024-04-18:/IBM/tsfm</id>
    <link href="https://github.com/IBM/tsfm" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Foundation Models for Time Series&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tsfm&lt;/h1&gt; &#xA;&lt;p&gt;Public notebooks and utilities for working with Time Series Foundation Models (TSFM)&lt;/p&gt; &#xA;&lt;p&gt;The core TSFM time series models have been made available on Hugging Face -- details can be found &lt;a href=&#34;https://raw.githubusercontent.com/IBM/tsfm/main/wiki.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Python Version&lt;/h1&gt; &#xA;&lt;p&gt;The current Python versions supported are 3.9 and 3.10.&lt;/p&gt; &#xA;&lt;h2&gt;Initial Setup&lt;/h2&gt; &#xA;&lt;p&gt;First clone the repository:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git@github.com:IBM/tsfm.git&#xA;cd tsfm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Notebooks Installation&lt;/h2&gt; &#xA;&lt;p&gt;Several notebooks are provided in the &lt;code&gt;notebooks&lt;/code&gt; folder. They allow you to perform pre-training and finetuning on the models. To install use &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;.[notebooks]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Notebooks links&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Getting started with &lt;code&gt;PatchTSMixer&lt;/code&gt; &lt;a href=&#34;https://github.com/IBM/tsfm/raw/main/notebooks/hfdemo/patch_tsmixer_getting_started.ipynb&#34;&gt;[Try it out]&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transfer learning with &lt;code&gt;PatchTSMixer&lt;/code&gt; &lt;a href=&#34;https://github.com/IBM/tsfm/raw/main/notebooks/hfdemo/patch_tsmixer_transfer.ipynb&#34;&gt;[Try it out]&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Transfer learning with &lt;code&gt;PatchTST&lt;/code&gt; &lt;a href=&#34;https://github.com/IBM/tsfm/raw/main/notebooks/hfdemo/patch_tst_transfer.ipynb&#34;&gt;[Try it out]&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Getting started with &lt;code&gt;TinyTimeMixer (TTM)&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/IBM/tsfm/main/notebooks/hfdemo/ttm_getting_started.ipynb&#34;&gt;Try it out&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Demos Installation&lt;/h2&gt; &#xA;&lt;p&gt;The demo presented at NeurIPS 2023 is available in &lt;code&gt;tsfmhfdemos&lt;/code&gt;. This demo requires you to have pre-trained and finetuned models in place (we plan to release these at later date). To install the requirements use &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install &#34;.[demos]&#34;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Issues&lt;/h2&gt; &#xA;&lt;p&gt;If you encounter an issue with this project, you are welcome to submit a &lt;a href=&#34;https://github.com/IBM/TSFM/issues&#34;&gt;bug report&lt;/a&gt;. Before opening a new issue, please search for similar issues. It&#39;s possible that someone has already reported it.&lt;/p&gt; &#xA;&lt;h1&gt;Notice&lt;/h1&gt; &#xA;&lt;p&gt;The intention of this repository is to make it easier to use and demonstrate IBM Research TSFM components that have been made available in the &lt;a href=&#34;https://huggingface.co/docs/transformers/main/en/index&#34;&gt;Hugging Face transformers library&lt;/a&gt;. As we continute to develop these capabilities we will update the code here.&lt;/p&gt; &#xA;&lt;p&gt;IBM Public Repository Disclosure: All content in this repository including code has been provided by IBM under the associated open source software license and IBM is under no obligation to provide enhancements, updates, or support. IBM developers produced this code as an open source project (not as an IBM product), and IBM makes no assertions as to the level of quality nor security, and will not be maintaining this code going forward.&lt;/p&gt;</summary>
  </entry>
</feed>