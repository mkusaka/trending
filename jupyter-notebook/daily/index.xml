<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2025-05-30T01:32:57Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>google-ai-edge/ai-edge-torch</title>
    <updated>2025-05-30T01:32:57Z</updated>
    <id>tag:github.com,2025-05-30:/google-ai-edge/ai-edge-torch</id>
    <link href="https://github.com/google-ai-edge/ai-edge-torch" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Supporting PyTorch models with the Google AI Edge TFLite runtime.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Edge Torch&lt;/h1&gt; &#xA;&lt;p&gt;AI Edge Torch is a python library that supports converting PyTorch models into a .tflite format, which can then be run with TensorFlow Lite and MediaPipe. This enables applications for Android, iOS and IOT that can run models completely on-device. AI Edge Torch offers broad CPU coverage, with initial GPU and NPU support. AI Edge Torch seeks to closely integrate with PyTorch, building on top of torch.export() and providing good coverage of Core ATen operators.&lt;/p&gt; &#xA;&lt;p&gt;To get started converting PyTorch models to TF Lite, see additional details in the &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/#pytorch-converter&#34;&gt;PyTorch converter&lt;/a&gt; section. For the particular case of Large Language Models (LLMs) and transformer-based models, the &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/#generative-api&#34;&gt;Generative API&lt;/a&gt; supports model authoring and quantization to enable improved on device performance.&lt;/p&gt; &#xA;&lt;p&gt;Although part of the same PyPi package, the PyTorch converter is a Beta release, while the Generative API is an Alpha release. Please see the &lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/releases/&#34;&gt;release notes&lt;/a&gt; for additional information.&lt;/p&gt; &#xA;&lt;h2&gt;PyTorch Converter&lt;/h2&gt; &#xA;&lt;p&gt;Here are the steps needed to convert a PyTorch model to a TFLite flatbuffer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch&#xA;import torchvision&#xA;import ai_edge_torch&#xA;&#xA;# Use resnet18 with pre-trained weights.&#xA;resnet18 = torchvision.models.resnet18(torchvision.models.ResNet18_Weights.IMAGENET1K_V1)&#xA;sample_inputs = (torch.randn(1, 3, 224, 224),)&#xA;&#xA;# Convert and serialize PyTorch model to a tflite flatbuffer. Note that we&#xA;# are setting the model to evaluation mode prior to conversion.&#xA;edge_model = ai_edge_torch.convert(resnet18.eval(), sample_inputs)&#xA;edge_model.export(&#34;resnet18.tflite&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/docs/pytorch_converter/getting_started.ipynb&#34;&gt;getting started&lt;/a&gt; Jupyter notebook gives an initial walkthrough of the conversion process and can be tried out with Google Colab.&lt;/p&gt; &#xA;&lt;p&gt;Additional technical details of the PyTorch Converter are &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/docs/pytorch_converter/README.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Generative API&lt;/h2&gt; &#xA;&lt;p&gt;The AI Edge Torch Generative API is a Torch native library for authoring mobile-optimized PyTorch Transformer models, which can be converted to TFLite, allowing users to easily deploy Large Language Models (LLMs) on mobile devices. Users can convert the models using the AI Edge Torch PyTorch Converter, and run them via the TensorFlow Lite runtime. See &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/ai_edge_torch/generative/examples/cpp&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Mobile app developers can also use the Edge Generative API to integrate PyTorch LLMs directly with the MediaPipe LLM Inference API for easy integration within their application code. See &lt;a href=&#34;http://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference#ai_edge_model_conversion&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;More detailed documentation can be found &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/ai_edge_torch/generative&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The Generative API is currently CPU-only, with planned support for GPU and NPU. A further future direction is to collaborate with the PyTorch community to ensure that frequently used transformer abstractions can be directly supported without reauthoring.&lt;/p&gt; &#xA;&lt;h2&gt;Build Status&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Build Type&lt;/th&gt; &#xA;   &lt;th&gt;Status&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Generative API (Linux)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_generative_api.yml&#34;&gt;&lt;img src=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_generative_api.yml/badge.svg?branch=main&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Model Coverage (Linux)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_model_coverage.yml&#34;&gt;&lt;img src=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_model_coverage.yml/badge.svg?branch=main&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Unit tests (Linux)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_unittests.yml&#34;&gt;&lt;img src=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_unittests.yml/badge.svg?branch=main&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nightly Release&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_release.yml&#34;&gt;&lt;img src=&#34;https://github.com/google-ai-edge/ai-edge-torch/actions/workflows/nightly_release.yml/badge.svg?branch=main&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements and Dependencies&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python versions: &amp;gt;=3.10&lt;/li&gt; &#xA; &lt;li&gt;Operating system: Linux&lt;/li&gt; &#xA; &lt;li&gt;PyTorch: &lt;a href=&#34;https://pypi.org/project/torch/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/torch-%3E=2.4.0-blue&#34; alt=&#34;torch&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;TensorFlow: &lt;a href=&#34;https://pypi.org/project/tf-nightly/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/tf--nightly-latest-blue&#34; alt=&#34;tf-nightly&#34;&gt;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;!-- requirement badges are updated by ci/update_nightly_versions.py --&gt; &#xA;&lt;h3&gt;Python Virtual Env&lt;/h3&gt; &#xA;&lt;p&gt;Set up a Python virtualenv:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m venv --prompt ai-edge-torch venv&#xA;source venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The latest stable release can be installed with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ai-edge-torch&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternately, the nightly version can be installed with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install ai-edge-torch-nightly&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;The list of versioned releases can be seen &lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/releases&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;The full list of PyPi releases (including nightly builds) can be seen &lt;a href=&#34;https://pypi.org/project/ai-edge-torch/#history&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Contributing&lt;/h1&gt; &#xA;&lt;p&gt;See our &lt;a href=&#34;https://raw.githubusercontent.com/google-ai-edge/ai-edge-torch/main/CONTRIBUTING.md&#34;&gt;contribution documentation&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Getting Help&lt;/h1&gt; &#xA;&lt;p&gt;Please &lt;a href=&#34;https://github.com/google-ai-edge/ai-edge-torch/issues/new/choose&#34;&gt;create a GitHub issue&lt;/a&gt; with any questions.&lt;/p&gt;</summary>
  </entry>
</feed>