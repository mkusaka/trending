<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-04-06T01:31:10Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>camenduru/gaussian-splatting-colab</title>
    <updated>2024-04-06T01:31:10Z</updated>
    <id>tag:github.com,2024-04-06:/camenduru/gaussian-splatting-colab</id>
    <link href="https://github.com/camenduru/gaussian-splatting-colab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;üê£ Please follow me for new updates &lt;a href=&#34;https://twitter.com/camenduru&#34;&gt;https://twitter.com/camenduru&lt;/a&gt; &lt;br&gt; üî• Please join our discord server &lt;a href=&#34;https://discord.gg/k5BwmmvJJU&#34;&gt;https://discord.gg/k5BwmmvJJU&lt;/a&gt; &lt;br&gt; ü•≥ Please join my patreon community &lt;a href=&#34;https://patreon.com/camenduru&#34;&gt;https://patreon.com/camenduru&lt;/a&gt; &lt;br&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ü¶í Colab&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Colab&lt;/th&gt; &#xA;   &lt;th&gt;Info&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/gaussian-splatting-colab/blob/main/gaussian_splatting_colab.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;gaussian_splatting_colab&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1YniEH63VfZPuRGTddviUvNH48cDaLqtg&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;Clip Guided Gaussian Splatting Colab (thanks to &lt;a href=&#34;https://twitter.com/aman_gif&#34;&gt;@aman_gif&lt;/a&gt; ‚ù§)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/github/camenduru/gaussian-splatting-colab/blob/main/gaussian_splatting_viewer_colab.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;gaussian_splatting_viewer_colab (thanks to &lt;a href=&#34;https://twitter.com/antimatter15&#34;&gt;@antimatter15&lt;/a&gt; ‚ù§)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Viewer Tutorial&lt;/h2&gt; &#xA;&lt;p&gt;We can drag and drop our &lt;code&gt;point_cloud.ply&lt;/code&gt; ü•≥&lt;/p&gt; &#xA;&lt;h2&gt;Main Repo&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/graphdeco-inria/gaussian-splatting&#34;&gt;https://github.com/graphdeco-inria/gaussian-splatting&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Page&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/&#34;&gt;https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Paper&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.04079&#34;&gt;https://arxiv.org/abs/2308.04079&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Main Repo Viewer&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/antimatter15/splat&#34;&gt;https://github.com/antimatter15/splat&lt;/a&gt; thanks to @antimatter15 ‚ù§&lt;/p&gt; &#xA;&lt;h2&gt;Output&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/camenduru/gaussian-splatting-colab/assets/54370274/003ee472-6c1d-44e0-990a-6c795effe46f&#34;&gt;https://github.com/camenduru/gaussian-splatting-colab/assets/54370274/003ee472-6c1d-44e0-990a-6c795effe46f&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/camenduru/gaussian-splatting-colab/assets/54370274/e6d1674f-1ba5-4f46-aa30-be6e54dea45e&#34;&gt;https://github.com/camenduru/gaussian-splatting-colab/assets/54370274/e6d1674f-1ba5-4f46-aa30-be6e54dea45e&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>Tanu-N-Prabhu/Python</title>
    <updated>2024-04-06T01:31:10Z</updated>
    <id>tag:github.com,2024-04-06:/Tanu-N-Prabhu/Python</id>
    <link href="https://github.com/Tanu-N-Prabhu/Python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;This repository helps you understand python from the scratch.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34;&gt;Python Programming Hub&lt;/h1&gt; &#xA;&lt;h2 align=&#34;center&#34;&gt;One of the best places to learn Python and Data Science&lt;/h2&gt; &#xA;&lt;!-- Shield Badges --&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://discord.gg/qFryjbX&#34;&gt;&lt;img src=&#34;https://img.shields.io/discord/718138360538857794.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2&#34; alt=&#34;Discord&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/Tanu-N-Prabhu/Python?label=Fork&amp;amp;style=social&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/Tanu-N-Prabhu/Python?style=social&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/repo-size/Tanu-N-Prabhu/Python&#34; alt=&#34;GitHub repo size&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/Tanu-N-Prabhu/Python&#34; alt=&#34;GitHub contributors&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;a href=&#34;https://gitpod.io/#https://github.com/Tanu-N-Prabhu/Python&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Gitpod-ready--to--code-blue?logo=gitpod&#34; alt=&#34;Gitpod ready-to-code&#34;&gt;&lt;/a&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA;&lt;/table&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Img/logo.jpg&#34; alt=&#34;space-1.jpg&#34;&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Image Credits &lt;a href=&#34;https://www.wallpaperflare.com/programming-is-an-art-text-code-python-computer-python-programming-wallpaper-srfia&#34;&gt;Wallpaper Flare&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://hits.seeyoufarm.com&#34;&gt;&lt;img src=&#34;https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FTanu-N-Prabhu%2FPython&amp;amp;count_bg=%2379C83D&amp;amp;title_bg=%23555555&amp;amp;icon=&amp;amp;icon_color=%23E7E7E7&amp;amp;title=hits&amp;amp;edge_flat=false&#34; alt=&#34;Hits&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;justify&#34;&gt; This repository gives to enough knowledge about python programming, data science and also helps you to survive in this programming world !!! &lt;/h4&gt; &#xA;&lt;h1&gt;Installation tools&lt;/h1&gt; &#xA;&lt;h4&gt;Below are some tools that you can download before getting started with Python, now it‚Äôs a preference, so download whichever that fits the best for you.&lt;/h4&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Name of the tools&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.python.org/downloads/&#34;&gt;Python download&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://code.visualstudio.com/download&#34;&gt;Visual Studio Code&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://jupyter.org/install&#34;&gt;Jupyter Notebook&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://colab.research.google.com/notebooks/welcome.ipynb&#34;&gt;Google Colab&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;I use Google Colab for Python programming. It&#39;s one of the best interactive tools in the world. I like it because I can provide more documentation to the code and write some quality tutorials.&lt;/p&gt;&#xA; &lt;p&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h1&gt;Repository Contents&lt;/h1&gt; &#xA;&lt;h3&gt;This repository is divided into two parts such as Python Coding and Data Science for Beginners.&lt;/h3&gt; &#xA;&lt;h1&gt;Python Coding&lt;/h1&gt; &#xA;&lt;p&gt;Follow the steps down below to get started coding in Python!!!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Img/Python.PNG&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Pythonic Materials&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 1Ô∏è‚É£ ‚Æï Basic Concepts&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_Input%2C_Output_and_Import.ipynb&#34;&gt;Python Input, Output and Import functions&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_Variables.ipynb&#34;&gt;Python Variables&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Global%2C_Local_and_Nonlocal_variables_in_Python.ipynb&#34;&gt;Python Global, Local and Nonlocal Variables&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Strings&#34;&gt;Python Strings&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Lists&#34;&gt;Python Lists&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Tuples&#34;&gt;Python Tuples&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Dictionary%20&#34;&gt;Python Dictionary&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_Operators.ipynb&#34;&gt;Python Operators&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 2Ô∏è‚É£ ‚Æï Built-in Functions&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_Input%2C_Output_and_Import.ipynb&#34;&gt;Python Input, Output and Import built-in-functions&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Eval_built_in_function.ipynb&#34;&gt;Eval built-in-function&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Range_built_in_function.ipynb&#34;&gt;Range built-in-function&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_Lambda_Function.ipynb&#34;&gt;Python Lambda Function&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_enumerate()_built_in_function.ipynb&#34;&gt;Python Enumerate Function&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python_len()_built_in_function.ipynb&#34;&gt;Python len function&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 3Ô∏è‚É£ ‚Æï Libraries&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Numpy&#34;&gt;Numpy library&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Pandas&#34;&gt;Pandas library&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Learn_the_Python_Math_Module.ipynb&#34;&gt;Math Module&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/How_to_handle_JSON_in_Python%3F.ipynb&#34;&gt;JSON library&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 4Ô∏è‚É£ ‚Æï API&#39;s&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Google%20Translate%20API&#34;&gt;Google Translate API for Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Google_Trends_API.ipynb&#34;&gt;Google Trends API for Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Wikipedia_API_for_Python.ipynb&#34;&gt;Wikipedia API for Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/The_two_Google_Search_Python_Libraries_you_should_never_miss.ipynb&#34;&gt;Google Search API for Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 5Ô∏è‚É£ ‚Æï Additional Materials&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/How_to_get_started_coding_in_Python%3F.ipynb&#34;&gt;How to get started coding in Python?&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Is_Python_object_oriented%3F.ipynb&#34;&gt;Is Python Object Oriented?&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Speech_Recognition_using_Python.ipynb&#34;&gt;Speech Recognition using Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Learning_One_Hot_Encoding_in_Python_the_Easy_Way.ipynb&#34;&gt;One-Hot encoding in Python&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Reading_An_Image_In_Python_(Without_Using_Special_Libraries).ipynb&#34;&gt;Reading An Image In Python (Without Using Special Libraries)&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Rendering_Images_inside_a_Pandas_DataFrame.ipynb&#34;&gt;Rendering Images inside a Pandas DataFrame&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Using_the_Pandas_Data_Frame_as_a_Database_.ipynb&#34;&gt;Using the Pandas Data Frame as a Database&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Using_the_Pandas_DataFrame_in_Day_To_Day_Life.ipynb&#34;&gt;Using the Pandas DataFrame in Day-To-Day Life&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Presenting_Python_code_using_RISE.ipynb&#34;&gt;Presenting Python code using RISE&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Cheat_sheet_for_Google_Colab.ipynb&#34;&gt;Cheat Sheet for Google Colab&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Pick_up_Line_Generator.ipynb&#34;&gt;Pick-Up Line Generator using Python Dictionaries&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 6Ô∏è‚É£ ‚Æï Exercises&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/String_Concatenation_Exercise_Questions.ipynb&#34;&gt;String Concatenation Questions&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &#xA;   &lt;ul&gt; &#xA;    &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/String_Concatenation_Exercise_Answers.ipynb&#34;&gt;String Concatenation Answers&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA;   &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Built_In_Functions_Exercise_Questions.ipynb&#34;&gt;Built-In Functions Exercise Questions&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 7Ô∏è‚É£ ‚Æï Quiz&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Quiz/Python_Quiz_1.ipynb&#34;&gt;Quiz - 1&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Quiz/Python_Quiz_2.ipynb&#34;&gt;Quiz - 2&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Quiz/Python_Quiz_3.ipynb&#34;&gt;Quiz - 3&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Chapter 8Ô∏è‚É£ ‚Æï Interview Preparation&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Python%20Coding%20Interview%20Questions%20(Beginner%20to%20Advanced).md&#34;&gt;Python Coding Interview Questions (Beginner to Advanced)&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/35%20Python%20interview%20questions%20for%20experienced.md&#34;&gt;35 Python interview questions for experienced&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt; &lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Python_Interview_Questions_and_Answers_Strings.md&#34;&gt;Python Interview Questions - Strings&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt; &lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Python_Theoritical_Interview_Questions.md&#34;&gt;Python Theoretical Interview Questions&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt; &lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/15_Python_Interview_Questions_and_Answers.md&#34;&gt;15 Python Interview Questions and Answers&lt;/a&gt; &lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Children_with_candy.ipynb&#34;&gt;Assigning Candies to Children Problem with Solution&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Basic_calculator.ipynb&#34;&gt;Basic Calculator&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt; &lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Text_Justification.ipynb&#34;&gt;Text Justification&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Python%20Coding%20Interview%20Prep/Remove_Element.ipynb&#34;&gt;Removing an Element&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;p&gt;üëâ &lt;strong&gt;Expand&lt;/strong&gt; and &lt;strong&gt;Collapse&lt;/strong&gt; the above Chapters for more details&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Data Science&lt;/h1&gt; &#xA;&lt;p&gt;Follow the steps below to get started learning Data Science!!!&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/Tanu-N-Prabhu/Python/master/Img/Data.PNG&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Data Science Materials&lt;/h2&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Data Exploration&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/data_load.md&#34;&gt;Loading a File using Pandas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;details&gt; &#xA; &lt;summary&gt;Data Scraping from the Web&lt;/summary&gt; &#xA; &lt;ul&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Data%20Scraping%20from%20the%20Web/Scraping%20YouTube%20accounts%20with%20python.ipynb&#34;&gt;Scraping Two YouTube Accounts - PewDiePie vs T-Series&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/raw/master/Data%20Scraping%20from%20the%20Web/Web_Scraping_Rate_My_Professor_Website.ipynb&#34;&gt;Scraping Rate My Professor Website - My Graduate Professor&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;li&gt; &lt;p&gt;&lt;b&gt;&lt;a href=&#34;&#34;&gt;Scraping Pick Up Lines from the Knot&lt;/a&gt;&lt;/b&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;/ul&gt; &#xA;&lt;/details&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Tech is Easy&lt;/h1&gt; &#xA;&lt;p align=&#34;justify&#34;&gt;I Tanu Nanda Prabhu, always like simplifying complex things so that others can understand them more easily and better. Researching is my passion, I go through a ton of videos, articles, and tutorials and conclude starting a repository that purely contains tips and tricks for using Google Sheets. I update this repository every week with tons of information that will make your life simple. I am also seeking help from people who want to contribute to my repository. Feel free to Fork it and add updates, I will consider it.&lt;/p&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/TechIsEasy&#34;&gt;Tech Is Easy&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Nbviewer&lt;/h1&gt; &#xA;&lt;p&gt;&lt;b align=&#34;justify&#34;&gt;If the jupyter notebook doesn&#39;t load. Don&#39;t worry copy and paste the link to &lt;a href=&#34;https://nbviewer.jupyter.org&#34;&gt;nbviewer&lt;/a&gt;. Because most of my jupyter notebooks are not loading.&lt;/b&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Contributors&lt;/h1&gt; &#xA;&lt;h3&gt;Currently there are 10 contributors for this repository. Feel free to contribute!&lt;/h3&gt; &#xA;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=Tanu-N-Prabhu/Python&#34;&gt; &lt;/a&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Want to know, how I did this. Refer here for the &lt;a href=&#34;https://github.com/Tanu-N-Prabhu/myWebsite.io/raw/master/Docs/Displaying%20Contributors%20Image%20on%20README%20files%20with%20no%20Pain!.md&#34;&gt;docs&lt;/a&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Kaggle Datasets&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/tanuprabhu/datasets&#34;&gt;Kaggle Data Sets&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;HackerRank Exercises - Solved&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Tanu-N-Prabhu/Python/tree/master/Hacker_Rank_Exercises&#34;&gt;HackerRank Exercise Solved&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Reddit Communities&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/Python/&#34;&gt;Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/learnpython/&#34;&gt;Learn Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/pythontips/&#34;&gt;Python tips&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/pythoncoding?utm_medium=android_app&amp;amp;utm_source=share&#34;&gt;Python coding&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Submit your articles here&lt;/h1&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/data-science-from-scratch&#34;&gt;Data Science from Scratch&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;GPT Librarian &lt;img align=&#34;right&#34; width=&#34;50&#34; height=&#34;50&#34; src=&#34;https://github.com/Decron/Python/assets/1786607/5b4e7a09-a76f-40be-b87d-c6e007b7ff35&#34;&gt;&lt;/h1&gt; &#xA;&lt;p&gt;If you have access to ChatGPT premium, there is a GPT Librarian with access to all files here &lt;a href=&#34;https://chat.openai.com/g/g-2HlDYwyrW-python-from-scratch&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Contact for help&lt;/h1&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Contact&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;Info&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;Gmail&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;mailto:tanuprabhu96@gmail.com&#34;&gt;tanuprabhu96@gmail.com&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;Facebook&lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;Tanu N Prabhu&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;Instagram &lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;tanunprabhu&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;b&gt;Linkedin &lt;/b&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.linkedin.com/in/tanu-nanda-prabhu-a15a091b5/&#34;&gt;Tanu Nanda Prabhu&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Reviews&lt;/h1&gt; &#xA;&lt;p&gt;&lt;b&gt;Below given are some of the reviews about this Python GitHub Repository:&lt;/b&gt;&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;b&gt;‚Ä™Elin Uppstr√∂m&lt;/b&gt; - Senior Lecturer at Uppsala University, Sweden. &lt;br&gt; I found your excellent exercises at your GitHub wile preparing undergraduate course in data analysis. I want to use it in my course.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;b&gt;‚Ä™Cole Striler&lt;/b&gt; - Data Scientist, Founder of Datafied&lt;br&gt; I came across your GitHub and love your Jupyter Notebooks, especially the one on &#34;&lt;b&gt;Predicting PewDiePie&#39;s daily subscribers&lt;/b&gt;&#34;. I think you do a great job at explaining your work which is something others can learn.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;b&gt;Laurence Watson&lt;/b&gt; - Co-Founder &amp;amp; CEO, Treebeard&lt;br&gt; You have a lot of great Jupyter notebook content on GitHub.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;b&gt;Poonam Gupta&lt;/b&gt; - Math &amp;amp; AP Computer Science Instructor, Brunswick School &lt;br&gt; Thank you so much for posting such helpful posts on GitHub.Many, many thanks for all you do to spread the knowledge.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;strong&gt;Do you like the Repository, Please drop in your precious reviews by shooting an e-mail&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Feedback&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://form.jotform.com/92847563204259&#34;&gt;Any Feedback or Suggestions- Please Click Here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Version&lt;/h1&gt; &#xA;&lt;p&gt;&lt;b&gt; Version 14 - Last Updated on Jan 07, 2024 - 7:46 PM &lt;b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;&#xA;&lt;b&gt;&lt;b&gt; &lt;p&gt;&lt;a href=&#34;https://opensource.org/&#34;&gt;&lt;img src=&#34;https://badges.frapsoft.com/os/v1/open-source.svg?v=103&#34; alt=&#34;Open Source&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://tanu-n-prabhu.github.io/myWebsite.io/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Maintained%20by-Tanu%20Nanda%20Prabhu-red&#34; alt=&#34;Maintened by - Tanu Nanda Prabhu&#34;&gt;&lt;/a&gt; &lt;a href=&#34;http://commonmark.org&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/Made%20with-Markdown-1f425f.svg?sanitize=true&#34; alt=&#34;made-with-Markdown&#34;&gt;&lt;/a&gt;&lt;/p&gt; &lt;/b&gt;&lt;/b&gt;</summary>
  </entry>
  <entry>
    <title>arktrail/Dorothy-Ymir</title>
    <updated>2024-04-06T01:31:10Z</updated>
    <id>tag:github.com,2024-04-06:/arktrail/Dorothy-Ymir</id>
    <link href="https://github.com/arktrail/Dorothy-Ymir" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AI solution for Patent Classification&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Dorothy AI Patent Classifier&lt;/h1&gt; &#xA;&lt;p&gt;This github repository includes code for Dorothy AI Patent Classifier&lt;/p&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#data&#34;&gt;Data generation and preprocesss&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#data_loc&#34;&gt;Data location and summary&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#ml&#34;&gt;Machine learning model&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#fasttext&#34;&gt;FastText&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#tencent&#34;&gt;Tencent&#39;s NeuralClassifier&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#hftcnn&#34;&gt;HFT-CNN&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#eval&#34;&gt;Evaluation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#visual&#34;&gt;Visualization&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#webapp&#34;&gt;Web app&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/arktrail/Dorothy-Ymir/master/#other&#34;&gt;Other&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data generation and preprocess &lt;a id=&#34;data&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Step 1: We generate our dataset from all granted patents up to September 2019, the total number of patents in the dataset is 4,363,544. To regenerate this dataset, such command could be used&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch /pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_*.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or mannuly sbatch from&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_a.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;to&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/json_process_jobs/json_process_sin_h.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The extracted dataset is stored in the &lt;code&gt;/pylon5/sez3a3p/yyn1228/data/json_reparse&lt;/code&gt;, this path is defined in the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/database_reparse.py&#34;&gt;database_reparse.py&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Step 2: We parse the cpc field into labels we need (section, classs, subclass, etc.), convert the text into a list of tokens, and split the data into train, valid, and test datasets by the ratio of 8:1:1. This step also removes all punctuations and convert all uppercase letters into lower case. This can be done by running the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/text_preprocess.py&#34;&gt;data_preprocess/text_preprocess.py&lt;/a&gt;, for example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python3 -u data_preprocess/text_preprocess.py \&#xA;/pylon5/sez3a3p/yyn1228/data/json_reparse \&#xA;/pylon5/sez3a3p/yyn1228/data/all_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Step 3: We further preprocess the data into a format that can be used by the machine learning libraries. This can be done by running the file &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/data_preprocess/create_training_data.py&#34;&gt;data_preprocess/create_training_data.py&lt;/a&gt;. Note that the file takes 6 arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;input directory&lt;/li&gt; &#xA; &lt;li&gt;output directory&lt;/li&gt; &#xA; &lt;li&gt;text field: &#39;title&#39;, &#39;abstraction&#39;, &#39;claims&#39;, &#39;brief_summary&#39; (&#39;description&#39; is too large to include)&lt;/li&gt; &#xA; &lt;li&gt;level name: &#39;section&#39;, &#39;class&#39;, &#39;subclass&#39;, &#39;main_group&#39;, &#39;subgroup&#39;&lt;/li&gt; &#xA; &lt;li&gt;whether to remove stop words: True means remove stop words&lt;/li&gt; &#xA; &lt;li&gt;whether to follow fasttext format: True means FastText format, False means Tecent format&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;For example:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python3 -u data_preprocess/create_training_data.py \&#xA;/pylon5/sez3a3p/yyn1228/data/all_data \&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_group \&#xA;brief_summary main_group false true&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Data location and summary &lt;a id=&#34;data_loc&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Processed data after Step 1, which includes 91 files and most of which have 50,000 patents.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/json_reparse&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 2, which includes three files: train.json, valid.json, and test.json.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_data&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Smaller datasets for valid and test: created by shuffling valid.json and test.json above and taking the first 60,000 records. These data have the following fields:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;all_labels: all true labels at the lowest subgroup level&lt;/li&gt; &#xA; &lt;li&gt;title, abstraction, claims, brief_summary, description: text split into list of tokens for various cpc text fields&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_data_small&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 3 for brief summary and subclass level, in Tecent&#39;s format. Note that these data do not have stop words.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_summary_nonstop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Processed data after Step 3 for brief summary and all levels, in FastText&#39;s format. Note that these data include stop words.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_section&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_class&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext (this is subclass)&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_group&#xA;/pylon5/sez3a3p/yyn1228/data/all_summary_fasttext_subgroup&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Smaller datasets initially used for testing purposes. Note that these data were generated by legacy code and may not be easily reproduced.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/pylon5/sez3a3p/yyn1228/data/summary_only&#xA;/pylon5/sez3a3p/yyn1228/data/summary_only_fasttext&#xA;/pylon5/sez3a3p/yyn1228/data/summary_only_nonstop&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Machine learning model &lt;a id=&#34;ml&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This section introduces how we use various libraries to train machine learning models. All the models are trained using the brief summary text field.&lt;/p&gt; &#xA;&lt;h3&gt;FastText &lt;a id=&#34;fasttext&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/facebookresearch/fastText/tree/master/python&#34;&gt;Facebook&#39;s FastText library&lt;/a&gt; to train the well-known FastText model. This method first converts words into word embeddings and then average word embeddings to create the document embedding. Note that this does not consider the order of the words. To keep some information regarding the order, it includes 2-grams into the vocabulary. Because this model is relatively simple and Facebook uses a lot of tricks to speed up the training, the training can be done by using CPUs instead of GPUs in a couple of hours. To account for the hierarchical information, we borrow the idea from HFT-CNN: we first train the section level and pass the word embeddings into the next word as pretrained word embeddings.&lt;/p&gt; &#xA;&lt;p&gt;To train FastText on PSC, first run the training job to train the data on the section level&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch model/FastText/summary_all_section/train_fasttext.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Then save the word embeddings by running&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ sbatch model/FastText/summary_all_section/bin_to_vec.job&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And then do the same thing for the class, subclass, group, and subgroup levels. To change the hyperparameters, just edit the train.py file in the corresponding folder.&lt;/p&gt; &#xA;&lt;h3&gt;Tencent&#39;s NeuralClassifier &lt;a id=&#34;tencent&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/Tencent/NeuralNLP-NeuralClassifier&#34;&gt;Tencent&#39;s NeuralClassifier library&lt;/a&gt; to train the classic CNN/RNN/RCNN text classification models. This model accounts for the hierarchical structure by adding a loss that is calculated based on the label tree, which forces closer leaves in the tree to have closer losses. Note that the library supports many models but we also tried the classic CNN/RNN/RCNN models. We edit some code to allow for using existing vocabulary.&lt;/p&gt; &#xA;&lt;p&gt;A detailed README on how to train the model using NeuralClassifier is saved here: &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/model/NeuralClassifier/README.md&#34;&gt;README.md&lt;/a&gt;. All models are saved in the &#34;/pylon5/sez3a3p/yyn1228/Dorothy-Ymir/model/NeuralClassifier/output/xxx/checkpoint_dir_cpc&#34; folders on PSC.&lt;/p&gt; &#xA;&lt;p&gt;Because there are many hyperparameters to tune, we include a summary of all the models we trained with their corresponding hyperparameters: &lt;img src=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/tencent.png&#34; alt=&#34;tencent models&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;HFT-CNN &lt;a id=&#34;hftcnn&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;p&gt;We also use &lt;a href=&#34;https://github.com/ShimShim46/HFT-CNN&#34;&gt;the HFT-CNN library&lt;/a&gt; to train another model. The idea is to train a CNN model on each level, which pass word embeddings and parameters in early layers to the CNN model on the next level. We add some code to support multi-GPU training. Follow the &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/model/HFT-CNN/README.md&#34;&gt;README.md&lt;/a&gt; here to train the model. Subclass level model is saved in the &#34;/pylon5/sez3a3p/yyn1228/Dorothy-Ymir/model/HFT-CNN/CNN/CNN/PARAMS/&#34; folders on PSC.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluation &lt;a id=&#34;eval&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;The detailed evaluation is saved in &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/prob_evaluate.ipynb&#34;&gt;notebooks/prob_evaluate.ipynb&lt;/a&gt;. It also includes methods to ensemble different models. See below a summary of the model results below. The best recall at n ‚âà 5 is 91.6%. &lt;img src=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/eval.png&#34; alt=&#34;evaluation&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;To see how the model works on other text fields, we also evaluate the model using title, abstract, and claims, although the model is trained using brief summary. Note that we have not used description to evaluate the model because it would explode the storage, but it is worth trying to evaluate the model using the first 1,000 tokens of the description. Also note that these evaluations only use the FastText model.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Text Field&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 5&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 5&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Title&lt;/td&gt; &#xA;   &lt;td&gt;0.107&lt;/td&gt; &#xA;   &lt;td&gt;0.568&lt;/td&gt; &#xA;   &lt;td&gt;0.098&lt;/td&gt; &#xA;   &lt;td&gt;0.603&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Abstract&lt;/td&gt; &#xA;   &lt;td&gt;0.675&lt;/td&gt; &#xA;   &lt;td&gt;0.401&lt;/td&gt; &#xA;   &lt;td&gt;0.190&lt;/td&gt; &#xA;   &lt;td&gt;0.709&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Claims&lt;/td&gt; &#xA;   &lt;td&gt;0.699&lt;/td&gt; &#xA;   &lt;td&gt;0.379&lt;/td&gt; &#xA;   &lt;td&gt;0.247&lt;/td&gt; &#xA;   &lt;td&gt;0.710&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Title + Abstract + Claims&lt;/td&gt; &#xA;   &lt;td&gt;0.749&lt;/td&gt; &#xA;   &lt;td&gt;0.403&lt;/td&gt; &#xA;   &lt;td&gt;0.251&lt;/td&gt; &#xA;   &lt;td&gt;0.755&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Brief Summary&lt;/td&gt; &#xA;   &lt;td&gt;0.851&lt;/td&gt; &#xA;   &lt;td&gt;0.453&lt;/td&gt; &#xA;   &lt;td&gt;0.216&lt;/td&gt; &#xA;   &lt;td&gt;0.856&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;We also train FastText models at all the 5 levels. Note that it is only plausible to use the FastText model to train for group and subgroup because there are too many labels. At the subclass level, there are 666 labels and it takes hours to train a non-FastText model; at the subgroup level, there are 200,000 labels, which means if we still use the same model, it would take weeks to finish the training. For group and subgroup, we use the &#34;hierarchical softmax loss&#34; in the FastText model, which is a trick developed by Facebook and significantly shortens training time but lowers the performance a little bit.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Precision @ 5&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 5&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Section&lt;/td&gt; &#xA;   &lt;td&gt;0.921&lt;/td&gt; &#xA;   &lt;td&gt;0.623&lt;/td&gt; &#xA;   &lt;td&gt;0.271&lt;/td&gt; &#xA;   &lt;td&gt;0.992&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Class&lt;/td&gt; &#xA;   &lt;td&gt;0.886&lt;/td&gt; &#xA;   &lt;td&gt;0.535&lt;/td&gt; &#xA;   &lt;td&gt;0.257&lt;/td&gt; &#xA;   &lt;td&gt;0.929&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Subclass&lt;/td&gt; &#xA;   &lt;td&gt;0.851&lt;/td&gt; &#xA;   &lt;td&gt;0.453&lt;/td&gt; &#xA;   &lt;td&gt;0.216&lt;/td&gt; &#xA;   &lt;td&gt;0.856&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For the group:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 10&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 100&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Group&lt;/td&gt; &#xA;   &lt;td&gt;0.220&lt;/td&gt; &#xA;   &lt;td&gt;0.661&lt;/td&gt; &#xA;   &lt;td&gt;0.912&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;For subgroup:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Level&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 10&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 100&lt;/th&gt; &#xA;   &lt;th&gt;Recall @ 1000&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Subgroup&lt;/td&gt; &#xA;   &lt;td&gt;0.054&lt;/td&gt; &#xA;   &lt;td&gt;0.208&lt;/td&gt; &#xA;   &lt;td&gt;0.468&lt;/td&gt; &#xA;   &lt;td&gt;0.750&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Visualization &lt;a id=&#34;visual&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;This notebook at &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/visualization.ipynb&#34;&gt;notebooks/visualization.ipynb&lt;/a&gt; includes visualizations of patent embeddings and word embeddings. The patent embedding figure is the one used in the presentation. The word embedding figure does not show very clear clusters, because the word lists and categories we choose are too general. The notebook includes all the code to generate the word embeddings and the word lists can be changed easily. If more representative word lists and categories are found, change the word lists and rerun the word embedding part in the notebook to get the word embedding visualization.&lt;/p&gt; &#xA;&lt;h2&gt;Web app &lt;a id=&#34;webapp&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;p&gt;Inorder to obtain an intuitive feeling of the result, we built an web app that could predict the corresponding CPC code given by any text in real time, and generate an tree plot. One thing to note is that the WebApp is under the &lt;code&gt;visualization&lt;/code&gt; branch, and the model impl is under &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; &#xA;&lt;p&gt;The backend for our Web app is Django, the frontend is built by React and the project is deployed on the AWS. The user could easily type in any text the describe one tech utility, and the predicted cpc codes will be render in the form of tree in secondes.&lt;/p&gt; &#xA;&lt;p&gt;For the backend, we load the model and make the prediction in &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/models.py&#34;&gt;&lt;code&gt;models.py &lt;/code&gt;&lt;/a&gt; at the very first time of the prediction, so for the following predictions, we can get rid of loading the giant model file too much times. But the prediction also need to be structed and parsed into the format that could be used for frontend, and this part of work is done by &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/treebuilder.py&#34;&gt;&lt;code&gt;treebuilders.py&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/visualization/visualization/visualization-demo/backend/demo/views.py&#34;&gt;&lt;code&gt;views.py&lt;/code&gt;&lt;/a&gt;. Also, in the backend, we need to rank the predcitions according to their confidence scores made by our model for the frontend render work, so the total data we return back to front is :&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;res = {&#39;tree&#39;: tree, &#39;ordered_labels&#39;: ordered_labels}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;where &lt;code&gt;tree&lt;/code&gt; is the parsed predictions in tree structure format, and &lt;code&gt;ordered_labels&lt;/code&gt; is the prediction labels ranked by their confidence scores.&lt;/p&gt; &#xA;&lt;p&gt;In the front end, we use these two data to render a tree chart, and we also provide an adjust bar that could change the tree leafnode numbers for analyse.&lt;/p&gt; &#xA;&lt;p&gt;The implementation is well documented, so it is easy for further integration.&lt;/p&gt; &#xA;&lt;h2&gt;Other &lt;a id=&#34;other&#34;&gt;&lt;/a&gt;&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/CPC_Preliminary_Data_Analysis.ipynb&#34;&gt;notebooks/CPC_Preliminary_Data_Analysis.ipynb&lt;/a&gt;: this notebook includes some preliminary data analysis of the CPC MCF data (e.g. average number of labels, duplicate issues, number of labels at each level, etc.)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/CPC_Text_Data.ipynb&#34;&gt;notebooks/CPC_Text_Data.ipynb&lt;/a&gt;: this notebook has some preliminary data analysis of the CPC text data (e.g. average number of tokens of each text field)&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/yyn19951228/Dorothy-Ymir/raw/master/notebooks/evaluate.ipynb&#34;&gt;notebooks/evaluate.ipynb&lt;/a&gt;: this notebook has some old evaluation methods (e.g. macro and micro F1, precision and recall at different percentiles, etc.)&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
</feed>