<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-10-24T01:31:19Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>yiqunchen/GenePT</title>
    <updated>2023-10-24T01:31:19Z</updated>
    <id>tag:github.com,2023-10-24:/yiqunchen/GenePT</id>
    <link href="https://github.com/yiqunchen/GenePT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GenePT &lt;img src=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/figs/genept_sticker.png&#34; align=&#34;right&#34; width=&#34;150px&#34;&gt;&lt;/h1&gt; &#xA;&lt;h3&gt;What is GenePT?&lt;/h3&gt; &#xA;&lt;p&gt;&lt;code&gt;GenePT&lt;/code&gt; is a single-cell foundation model that leverages ChatGPT embeddings to tackle gene-level and cell-level biology tasks. This project is motivated by the significant recent progress in using large-scale (e.g., tens of millions of cells) gene expression data to develop foundation models for single-cell biology. These models implicitly learn gene and cellular functions from the gene expression profiles, which requires extensive data curation and resource-intensive training. By contrast, GenePT offers a complementary approach by using NCBI text descriptions of individual genes with GPT-3.5 to generate gene embeddings. From there, GenePT generates single-cell embeddings in two ways: (i) by averaging the gene embeddings, weighted by each gene’s expression level; or (ii) by creating a sentence embedding for each cell, using gene names ordered by the expression level.&lt;/p&gt; &#xA;&lt;p&gt;Without the need for dataset curation and additional pretraining, GenePT is efficient and easy to use. On many downstream tasks used to evaluate recent single-cell foundation models --- e.g., classifying gene properties and cell types --- GenePT achieves comparable, and often better, performance than existing single-cell foundation models. GenePT demonstrates that large language model embedding of literature is a simple and effective path for biological foundation models.&lt;/p&gt; &#xA;&lt;h3&gt;How do I use GenePT?&lt;/h3&gt; &#xA;&lt;p&gt;The analysis scripts used to generate GenePT data and to reproduce the analysis in the paper can be found in the repo (with details for each script in the &lt;strong&gt;Breakdown of analysis files&lt;/strong&gt; section below).&lt;/p&gt; &#xA;&lt;p&gt;We also provide the following list of readily-available datasets that might be useful for a broader range of applications:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Extracted summary texts scraped from the NCBI page for each gene.&lt;/li&gt; &#xA; &lt;li&gt;Pre-computed GPT-3.5 embeddings (&lt;code&gt;text-embedding-ada-002&lt;/code&gt;) for each gene. These data are deposited at &lt;a href=&#34;https://doi.org/10.5281/zenodo.10030426&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.10030426.svg?sanitize=true&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Tutorials and Use&lt;/h3&gt; &#xA;&lt;p&gt;We provide example notebooks to run the following analyses:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Gene-level prediction tasks&lt;/li&gt; &#xA; &lt;li&gt;Gene-gene interaction analysis analysis&lt;/li&gt; &#xA; &lt;li&gt;Cell-level biological data annotation&lt;/li&gt; &#xA; &lt;li&gt;Batch effect removal (Cardiomyocyte dataset; Aorta dataset)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Please file an &lt;a href=&#34;https://github.com/yiqunchen/GenePT/issues&#34;&gt;issue&lt;/a&gt; if you have a request for a tutorial that is not currently included.&lt;/p&gt; &#xA;&lt;h3&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt;If you use &lt;code&gt;GenePT&lt;/code&gt; for your analysis, please cite our manuscript:&lt;/p&gt; &#xA;&lt;p&gt;Chen YT, Zou J. (2023+) GenePT: A Simple But Hard-to-Beat Foundation Model for Genes and Cells Built From ChatGPT. bioRxiv preprint: &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.10.16.562533v1&#34;&gt;https://www.biorxiv.org/content/10.1101/2023.10.16.562533v1&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Breakdown of analysis files:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/request_ncbi_text_for_genes.ipynb&#34;&gt;request_ncbi_text_for_genes.ipynb&lt;/a&gt; provides example code to download NCBI gene summary page.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/gene_embeddings_examples.ipynb&#34;&gt;gene_embeddings_examples.ipynb&lt;/a&gt; provides example code to embed the extracted descriptions in 1 using GPT-3.5 embeddings. Note that this requires a valid registration of the OpenAI API (see instructions and pricing details at &lt;a href=&#34;https://openai.com/blog/openai-api&#34;&gt;https://openai.com/blog/openai-api&lt;/a&gt;).&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/gene_level_task_table_1.ipynb&#34;&gt;gene_level_task_table_1.ipynb&lt;/a&gt; reproduces the gene level tasks for GenePT embeddings in Table 1 of the paper.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/gene_level_task_figure_2.ipynb&#34;&gt;gene_level_task_figure_2.ipynb&lt;/a&gt; provides the necessary data and output for the gene level tasks described in Figure 2 of our paper.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/aorta_data_analysis.ipynb&#34;&gt;aorta_data_analysis.ipynb&lt;/a&gt; provides example code to create your foundation-model cell embeddings in &amp;lt;20 lines of code and demonstrates the batch effect removal + biology preservation (Figure 4 results of the paper).&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;Datasets used in GenePT&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;For the gene-level tasks, we make use of the following datasets: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Geneformer provides the datasets for gene-level tasks reported in Table 1 (&lt;a href=&#34;https://huggingface.co/datasets/ctheodoris/Genecorpus-30M/tree/main/example_input_files/gene_classification&#34;&gt;https://huggingface.co/datasets/ctheodoris/Genecorpus-30M/tree/main/example_input_files/gene_classification&lt;/a&gt;)&lt;/li&gt; &#xA;   &lt;li&gt;Gene-gene interaction network datasets were collected as part of the Gene2vec paper, available at &lt;a href=&#34;https://github.com/jingcheng-du/Gene2vec/tree/master/predictionData&#34;&gt;https://github.com/jingcheng-du/Gene2vec/tree/master/predictionData&lt;/a&gt;.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;For the cell-level tasks, we make use of the following datasets: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;hPancreas, Myeloid, and Multiple Sclerosis (processed and distributed by Cui et al. (2023+)) &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Multiple Sclerosis (M.S.) dataset: &lt;a href=&#34;https://drive.google.com/drive/folders/1Qd42YNabzyr2pWt9xoY4cVMTAxsNBt4v?usp=sharing&#34;&gt;link&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;Myeloid (Mye.) dataset: &lt;a href=&#34;https://drive.google.com/drive/folders/1VbpApQufZq8efFGakW3y8QDDpY9MBoDS?usp=drive_link&#34;&gt;link&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;hPancreas dataset: &lt;a href=&#34;https://drive.google.com/drive/folders/1s9XjcSiPC-FYV3VeHrEa7SeZetrthQVV?usp=drive_link&#34;&gt;link&lt;/a&gt;.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Cardiomyocyte dataset: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Original data can be downloaded &lt;a href=&#34;https://singlecell.broadinstitute.org/single_cell/study/SCP1303/single-nuclei-profiling-of-human-dilated-and-hypertrophic-cardiomyopathy&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;We created a random 10% subset of the original dataset for our cell-level analysis, available at &lt;a href=&#34;https://drive.google.com/drive/folders/1LgFvJqWNq9BqHbuxB2tYf62kXs9KqL4t?usp=share_link&#34;&gt;this google drive folder&lt;/a&gt;.&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Aorta dataset: &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Original data has been deposited &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE155468&#34;&gt;here&lt;/a&gt;, and we used the additional cell type annotation provided by the authors on &lt;a href=&#34;https://github.com/LI-Yan-Ming/Circulation.-2020-142-1374-1388/raw/main/meta_addsubcluster_cellcycle.csv&#34;&gt;GitHub&lt;/a&gt;.&lt;/li&gt; &#xA;     &lt;li&gt;We created a 20% random subset of the original dataset (&lt;a href=&#34;https://drive.google.com/drive/folders/1LgFvJqWNq9BqHbuxB2tYf62kXs9KqL4t?usp=share_link&#34;&gt;link&lt;/a&gt;).&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;The initial list of genes are curated from &lt;a href=&#34;https://drive.google.com/drive/folders/1oWh_-ZRdhtoGQ2Fw24HP41FgLoomVo-y&#34;&gt;vocab.json&lt;/a&gt; (provided by scGPT authors) and &lt;a href=&#34;https://huggingface.co/ctheodoris/Geneformer/blob/main/geneformer/token_dictionary.pkl&#34;&gt;token_dictionary.pkl&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yiqunchen/GenePT/main/figs/Presentation3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;References:&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Chaffin, M. et al. Single-nucleus profiling of human dilated and hypertrophic cardiomyopathy. Nature 608, 174–180 (2022).&lt;/li&gt; &#xA; &lt;li&gt;Chen YT, Zou J. (2023+) GenePT: A Simple But Hard-to-Beat Foundation Model for Genes and Cells Built From ChatGPT. bioRxiv preprint: &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2023.10.16.562533v1&#34;&gt;https://www.biorxiv.org/content/10.1101/2023.10.16.562533v1&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Cui, H., et al. (2023). scGPT: Towards building a foundation model for single-cell multi-omics using generative AI. bioRxiv, 2023-04.&lt;/li&gt; &#xA; &lt;li&gt;Li, Y. et al. Single-cell transcriptome analysis reveals dynamic cell populations and differential gene expression patterns in control and aneurysmal human aortic tissue. Circulation 142, 1374–1388 (2020).&lt;/li&gt; &#xA;&lt;/ol&gt;</summary>
  </entry>
  <entry>
    <title>nlmatics/llmsherpa</title>
    <updated>2023-10-24T01:31:19Z</updated>
    <id>tag:github.com,2023-10-24:/nlmatics/llmsherpa</id>
    <link href="https://github.com/nlmatics/llmsherpa" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Developer APIs to Accelerate LLM Projects&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LLM Sherpa&lt;/h1&gt; &#xA;&lt;p&gt;LLM Sherpa provides strategic APIs to accelerate large language model (LLM) use cases.&lt;/p&gt; &#xA;&lt;h2&gt;LayoutPDFReader&lt;/h2&gt; &#xA;&lt;p&gt;Most PDF to text parsers do not provide layout information. Often times, even the sentences are split with arbritrary CR/LFs making it very difficult to find paragraph boundaries. This poses various challenges in chunking and adding long running contextual information such as section header to the passages while indexing/vectorizing PDFs for LLM applications such as retrieval augmented generation (RAG).&lt;/p&gt; &#xA;&lt;p&gt;LayoutPDFReader solves this problem by parsing PDFs along with hierarchical layout information such as:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Sections and subsections along with their levels.&lt;/li&gt; &#xA; &lt;li&gt;Paragraphs - combines lines.&lt;/li&gt; &#xA; &lt;li&gt;Links between sections and paragraphs.&lt;/li&gt; &#xA; &lt;li&gt;Tables along with the section the tables are found in.&lt;/li&gt; &#xA; &lt;li&gt;Lists and nested lists.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;With LayoutPDFReader, developers can find optimal chunks of text to vectorize, and a solution for limited context window sizes of LLMs.&lt;/p&gt; &#xA;&lt;h3&gt;Important Notes&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;LLMSherpa uses a free and open api server. The server does not store your PDFs except for temporary storage during parsing.&lt;/li&gt; &#xA; &lt;li&gt;The LayoutPDFReader is tested on a wide variety of PDFs. That being said, it is still challenging to get every PDF parsed correctly.&lt;/li&gt; &#xA; &lt;li&gt;OCR is currently not supported. Only PDFs with a text layer are supported.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;em&gt;For private hosting options, OCR support and help with specific issues with your PDFs contact &lt;a href=&#34;mailto:contact@nlmatics.com&#34;&gt;contact@nlmatics.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;You can experiment with the library directly in Google Colab &lt;a href=&#34;https://colab.research.google.com/drive/1hx5Y2TxWriAuFXcwcjsu3huKyn39Q2id?usp=sharing&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s a &lt;a href=&#34;https://open.substack.com/pub/ambikasukla/p/efficient-rag-with-document-layout?r=ft8uc&amp;amp;utm_campaign=post&amp;amp;utm_medium=web&#34;&gt;writeup&lt;/a&gt; explaining the problem and our approach.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;a another &lt;a href=&#34;https://medium.com/@kirankurup/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125&#34;&gt;blog&lt;/a&gt; explaining the solution.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llmsherpa&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Read a PDF file&lt;/h3&gt; &#xA;&lt;p&gt;The first step in using the LayoutPDFReader is to provide a url or file path to it and get back a document object.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llmsherpa.readers import LayoutPDFReader&#xA;&#xA;llmsherpa_api_url = &#34;https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all&#34;&#xA;pdf_url = &#34;https://arxiv.org/pdf/1910.13461.pdf&#34; # also allowed is a file path e.g. /home/downloads/xyz.pdf&#xA;pdf_reader = LayoutPDFReader(llmsherpa_api_url)&#xA;doc = pdf_reader.read_pdf(pdf_url)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Install LlamaIndex&lt;/h3&gt; &#xA;&lt;p&gt;In the following examples, we will use &lt;a href=&#34;https://www.llamaindex.ai/&#34;&gt;LlamaIndex&lt;/a&gt; for simplicity. Install the library if you haven&#39;t already.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install llama-index&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Setup OpenAI&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;openai.api_key = #&amp;lt;Insert API Key&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Summarize a Section using prompts&lt;/h3&gt; &#xA;&lt;p&gt;LayoutPDFReader offers powerful ways to pick sections and subsections from a large document and use LLMs to extract insights from a section.&lt;/p&gt; &#xA;&lt;p&gt;The following code looks for the Fine-tuning section of the document:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import display, HTML&#xA;selected_section = None&#xA;# find a section in the document by title&#xA;for section in doc.sections():&#xA;    if section.title == &#39;3 Fine-tuning BART&#39;:&#xA;        selected_section = section&#xA;        break&#xA;# use include_children=True and recurse=True to fully expand the section. &#xA;# include_children only returns at one sublevel of children whereas recurse goes through all the descendants&#xA;HTML(section.to_html(include_children=True, recurse=True))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Running the above code yields the following HTML output:&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;h3&gt;3 Fine-tuning BART&lt;/h3&gt;&#xA; &lt;p&gt;The representations produced by BART can be used in several ways for downstream applications.&lt;/p&gt;&#xA; &lt;h4&gt;3.1 Sequence Classiﬁcation Tasks&lt;/h4&gt;&#xA; &lt;p&gt;For sequence classiﬁcation tasks, the same input is fed into the encoder and decoder, and the ﬁnal hidden state of the ﬁnal decoder token is fed into new multi-class linear classiﬁer.\nThis approach is related to the CLS token in BERT; however we add the additional token to the end so that representation for the token in the decoder can attend to decoder states from the complete input (Figure 3a).&lt;/p&gt;&#xA; &lt;h4&gt;3.2 Token Classiﬁcation Tasks&lt;/h4&gt;&#xA; &lt;p&gt;For token classiﬁcation tasks, such as answer endpoint classiﬁcation for SQuAD, we feed the complete document into the encoder and decoder, and use the top hidden state of the decoder as a representation for each word.\nThis representation is used to classify the token.&lt;/p&gt;&#xA; &lt;h4&gt;3.3 Sequence Generation Tasks&lt;/h4&gt;&#xA; &lt;p&gt;Because BART has an autoregressive decoder, it can be directly ﬁne tuned for sequence generation tasks such as abstractive question answering and summarization.\nIn both of these tasks, information is copied from the input but manipulated, which is closely related to the denoising pre-training objective.\nHere, the encoder input is the input sequence, and the decoder generates outputs autoregressively.&lt;/p&gt;&#xA; &lt;h4&gt;3.4 Machine Translation&lt;/h4&gt;&#xA; &lt;p&gt;We also explore using BART to improve machine translation decoders for translating into English.\nPrevious work Edunov et al.\n(2019) has shown that models can be improved by incorporating pre-trained encoders, but gains from using pre-trained language models in decoders have been limited.\nWe show that it is possible to use the entire BART model (both encoder and decoder) as a single pretrained decoder for machine translation, by adding a new set of encoder parameters that are learned from bitext (see Figure 3b).&lt;/p&gt;&#xA; &lt;p&gt;More precisely, we replace BART’s encoder embedding layer with a new randomly initialized encoder.\nThe model is trained end-to-end, which trains the new encoder to map foreign words into an input that BART can de-noise to English.\nThe new encoder can use a separate vocabulary from the original BART model.&lt;/p&gt;&#xA; &lt;p&gt;We train the source encoder in two steps, in both cases backpropagating the cross-entropy loss from the output of the BART model.\nIn the ﬁrst step, we freeze most of BART parameters and only update the randomly initialized source encoder, the BART positional embeddings, and the self-attention input projection matrix of BART’s encoder ﬁrst layer.\nIn the second step, we train all model parameters for a small number of iterations.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;Now, let&#39;s create a custom summary of this text using a prompt:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index.llms import OpenAI&#xA;context = selected_section.to_html(include_children=True, recurse=True)&#xA;question = &#34;list all the tasks discussed and one line about each task&#34;&#xA;resp = OpenAI().complete(f&#34;read this text and answer question: {question}:\n{context}&#34;)&#xA;print(resp.text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above code results in following output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Tasks discussed in the text:&#xA;&#xA;1. Sequence Classification Tasks: The same input is fed into the encoder and decoder, and the final hidden state of the final decoder token is used for multi-class linear classification.&#xA;2. Token Classification Tasks: The complete document is fed into the encoder and decoder, and the top hidden state of the decoder is used as a representation for each word for token classification.&#xA;3. Sequence Generation Tasks: BART can be fine-tuned for tasks like abstractive question answering and summarization, where the encoder input is the input sequence and the decoder generates outputs autoregressively.&#xA;4. Machine Translation: BART can be used to improve machine translation decoders by incorporating pre-trained encoders and using the entire BART model as a single pretrained decoder. The new encoder parameters are learned from bitext.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Analyze a Table using prompts&lt;/h3&gt; &#xA;&lt;p&gt;With LayoutPDFReader, you can iterate through all the tables in a document and use the power of LLMs to analyze a Table Let&#39;s look at the 6th table in this document. If you are using a notebook, you can display the table as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import display, HTML&#xA;HTML(doc.tables()[5].to_html())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The output table structure looks like this:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;SQuAD 1.1 EM/F1&lt;/th&gt; &#xA;   &lt;th&gt;SQuAD 2.0 EM/F1&lt;/th&gt; &#xA;   &lt;th&gt;MNLI m/mm&lt;/th&gt; &#xA;   &lt;th&gt;SST Acc&lt;/th&gt; &#xA;   &lt;th&gt;QQP Acc&lt;/th&gt; &#xA;   &lt;th&gt;QNLI Acc&lt;/th&gt; &#xA;   &lt;th&gt;STS-B Acc&lt;/th&gt; &#xA;   &lt;th&gt;RTE Acc&lt;/th&gt; &#xA;   &lt;th&gt;MRPC Acc&lt;/th&gt; &#xA;   &lt;th&gt;CoLA Mcc&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BERT&lt;/td&gt; &#xA;   &lt;td&gt;84.1/90.9&lt;/td&gt; &#xA;   &lt;td&gt;79.0/81.8&lt;/td&gt; &#xA;   &lt;td&gt;86.6/-&lt;/td&gt; &#xA;   &lt;td&gt;93.2&lt;/td&gt; &#xA;   &lt;td&gt;91.3&lt;/td&gt; &#xA;   &lt;td&gt;92.3&lt;/td&gt; &#xA;   &lt;td&gt;90.0&lt;/td&gt; &#xA;   &lt;td&gt;70.4&lt;/td&gt; &#xA;   &lt;td&gt;88.0&lt;/td&gt; &#xA;   &lt;td&gt;60.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;UniLM&lt;/td&gt; &#xA;   &lt;td&gt;-/-&lt;/td&gt; &#xA;   &lt;td&gt;80.5/83.4&lt;/td&gt; &#xA;   &lt;td&gt;87.0/85.9&lt;/td&gt; &#xA;   &lt;td&gt;94.5&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;92.7&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;70.9&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;61.1&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;XLNet&lt;/td&gt; &#xA;   &lt;td&gt;89.0/94.5&lt;/td&gt; &#xA;   &lt;td&gt;86.1/88.8&lt;/td&gt; &#xA;   &lt;td&gt;89.8/-&lt;/td&gt; &#xA;   &lt;td&gt;95.6&lt;/td&gt; &#xA;   &lt;td&gt;91.8&lt;/td&gt; &#xA;   &lt;td&gt;93.9&lt;/td&gt; &#xA;   &lt;td&gt;91.8&lt;/td&gt; &#xA;   &lt;td&gt;83.8&lt;/td&gt; &#xA;   &lt;td&gt;89.2&lt;/td&gt; &#xA;   &lt;td&gt;63.6&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;RoBERTa&lt;/td&gt; &#xA;   &lt;td&gt;88.9/94.6&lt;/td&gt; &#xA;   &lt;td&gt;86.5/89.4&lt;/td&gt; &#xA;   &lt;td&gt;90.2/90.2&lt;/td&gt; &#xA;   &lt;td&gt;96.4&lt;/td&gt; &#xA;   &lt;td&gt;92.2&lt;/td&gt; &#xA;   &lt;td&gt;94.7&lt;/td&gt; &#xA;   &lt;td&gt;92.4&lt;/td&gt; &#xA;   &lt;td&gt;86.6&lt;/td&gt; &#xA;   &lt;td&gt;90.9&lt;/td&gt; &#xA;   &lt;td&gt;68.0&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BART&lt;/td&gt; &#xA;   &lt;td&gt;88.8/94.6&lt;/td&gt; &#xA;   &lt;td&gt;86.1/89.2&lt;/td&gt; &#xA;   &lt;td&gt;89.9/90.1&lt;/td&gt; &#xA;   &lt;td&gt;96.6&lt;/td&gt; &#xA;   &lt;td&gt;92.5&lt;/td&gt; &#xA;   &lt;td&gt;94.9&lt;/td&gt; &#xA;   &lt;td&gt;91.2&lt;/td&gt; &#xA;   &lt;td&gt;87.0&lt;/td&gt; &#xA;   &lt;td&gt;90.4&lt;/td&gt; &#xA;   &lt;td&gt;62.8&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Now let&#39;s ask a question to analyze this table:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index.llms import OpenAI&#xA;context = doc.tables()[5].to_html()&#xA;resp = OpenAI().complete(f&#34;read this table and answer question: which model has the best performance on squad 2.0:\n{context}&#34;)&#xA;print(resp.text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The above question will result in the following output:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;The model with the best performance on SQuAD 2.0 is RoBERTa, with an EM/F1 score of 86.5/89.4.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;That&#39;s it! LayoutPDFReader also supports tables with nested headers and header rows.&lt;/p&gt; &#xA;&lt;p&gt;Here&#39;s an example with nested headers:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;from IPython.core.display import display, HTML&#xA;HTML(doc.tables()[6].to_html())&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;CNN/DailyMail&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;XSum&lt;/th&gt; &#xA;   &lt;th&gt;&lt;/th&gt; &#xA;   &lt;th&gt;-&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;R1&lt;/td&gt; &#xA;   &lt;td&gt;R2&lt;/td&gt; &#xA;   &lt;td&gt;RL&lt;/td&gt; &#xA;   &lt;td&gt;R1&lt;/td&gt; &#xA;   &lt;td&gt;R2&lt;/td&gt; &#xA;   &lt;td&gt;RL&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;   &lt;td&gt;---&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Lead-3&lt;/td&gt; &#xA;   &lt;td&gt;40.42&lt;/td&gt; &#xA;   &lt;td&gt;17.62&lt;/td&gt; &#xA;   &lt;td&gt;36.67&lt;/td&gt; &#xA;   &lt;td&gt;16.30&lt;/td&gt; &#xA;   &lt;td&gt;1.60&lt;/td&gt; &#xA;   &lt;td&gt;11.95&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PTGEN (See et al., 2017)&lt;/td&gt; &#xA;   &lt;td&gt;36.44&lt;/td&gt; &#xA;   &lt;td&gt;15.66&lt;/td&gt; &#xA;   &lt;td&gt;33.42&lt;/td&gt; &#xA;   &lt;td&gt;29.70&lt;/td&gt; &#xA;   &lt;td&gt;9.21&lt;/td&gt; &#xA;   &lt;td&gt;23.24&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;PTGEN+COV (See et al., 2017)&lt;/td&gt; &#xA;   &lt;td&gt;39.53&lt;/td&gt; &#xA;   &lt;td&gt;17.28&lt;/td&gt; &#xA;   &lt;td&gt;36.38&lt;/td&gt; &#xA;   &lt;td&gt;28.10&lt;/td&gt; &#xA;   &lt;td&gt;8.02&lt;/td&gt; &#xA;   &lt;td&gt;21.72&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;UniLM&lt;/td&gt; &#xA;   &lt;td&gt;43.33&lt;/td&gt; &#xA;   &lt;td&gt;20.21&lt;/td&gt; &#xA;   &lt;td&gt;40.51&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;   &lt;td&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BERTSUMABS (Liu &amp;amp; Lapata, 2019)&lt;/td&gt; &#xA;   &lt;td&gt;41.72&lt;/td&gt; &#xA;   &lt;td&gt;19.39&lt;/td&gt; &#xA;   &lt;td&gt;38.76&lt;/td&gt; &#xA;   &lt;td&gt;38.76&lt;/td&gt; &#xA;   &lt;td&gt;16.33&lt;/td&gt; &#xA;   &lt;td&gt;31.15&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BERTSUMEXTABS (Liu &amp;amp; Lapata, 2019)&lt;/td&gt; &#xA;   &lt;td&gt;42.13&lt;/td&gt; &#xA;   &lt;td&gt;19.60&lt;/td&gt; &#xA;   &lt;td&gt;39.18&lt;/td&gt; &#xA;   &lt;td&gt;38.81&lt;/td&gt; &#xA;   &lt;td&gt;16.50&lt;/td&gt; &#xA;   &lt;td&gt;31.27&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;BART&lt;/td&gt; &#xA;   &lt;td&gt;44.16&lt;/td&gt; &#xA;   &lt;td&gt;21.28&lt;/td&gt; &#xA;   &lt;td&gt;40.90&lt;/td&gt; &#xA;   &lt;td&gt;45.14&lt;/td&gt; &#xA;   &lt;td&gt;22.27&lt;/td&gt; &#xA;   &lt;td&gt;37.25&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;p&gt;Now let&#39;s ask an interesting question:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index.llms import OpenAI&#xA;context = doc.tables()[6].to_html()&#xA;question = &#34;tell me about R1 of bart for different datasets&#34;&#xA;resp = OpenAI().complete(f&#34;read this table and answer question: {question}:\n{context}&#34;)&#xA;print(resp.text)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And we get the following answer:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;R1 of BART for different datasets:&#xA;&#xA;- For the CNN/DailyMail dataset, the R1 score of BART is 44.16.&#xA;- For the XSum dataset, the R1 score of BART is 45.14.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Vector search and Retrieval Augmented Generation with Smart Chunking&lt;/h3&gt; &#xA;&lt;p&gt;LayoutPDFReader does smart chunking keeping the integrity of related text together:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;All list items are together including the paragraph that precedes the list.&lt;/li&gt; &#xA; &lt;li&gt;Items in a table are chuncked together&lt;/li&gt; &#xA; &lt;li&gt;Contextual information from section headers and nested section headers is included&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following code creates a LlamaIndex query engine from LayoutPDFReader document chunks&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index.readers.schema.base import Document&#xA;from llama_index import VectorStoreIndex&#xA;&#xA;index = VectorStoreIndex([])&#xA;for chunk in doc.chunks():&#xA;    index.insert(Document(text=chunk.to_context_text(), extra_info={}))&#xA;query_engine = index.as_query_engine()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s run one query:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;response = query_engine.query(&#34;list all the tasks that work with bart&#34;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We get the following response:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;BART works well for text generation, comprehension tasks, abstractive dialogue, question answering, and summarization tasks.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Let&#39;s try another query that needs answer from a table:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;response = query_engine.query(&#34;what is the bart performance score on squad&#34;)&#xA;print(response)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Here&#39;s the response we get:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;The BART performance score on SQuAD is 88.8 for EM and 94.6 for F1.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Get the Raw JSON&lt;/h3&gt; &#xA;&lt;p&gt;To get the complete json returned by llmsherpa service and process it differently, simply get the json attribute&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;doc.json&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>sugarforever/LangChain-Advanced</title>
    <updated>2023-10-24T01:31:19Z</updated>
    <id>tag:github.com,2023-10-24:/sugarforever/LangChain-Advanced</id>
    <link href="https://github.com/sugarforever/LangChain-Advanced" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LangChain-Advanced&lt;/h1&gt;</summary>
  </entry>
</feed>