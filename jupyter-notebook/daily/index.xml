<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-29T01:31:28Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>center-for-humans-and-machines/transformer-heads</title>
    <updated>2024-03-29T01:31:28Z</updated>
    <id>tag:github.com,2024-03-29:/center-for-humans-and-machines/transformer-heads</id>
    <link href="https://github.com/center-for-humans-and-machines/transformer-heads" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Toolkit for attaching, training, saving and loading of new heads for transformer models&lt;/p&gt;&lt;hr&gt;&lt;h4 align=&#34;center&#34;&gt; &lt;p&gt; &lt;a href=&#34;https://transformer-heads.readthedocs.io/en/latest/&#34;&gt;Documentation&lt;/a&gt; | &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/docs/source/getting_started.md&#34;&gt;Getting Started&lt;/a&gt; | &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/comments/1bnd621/new_library_transformerheads_for_attaching_heads/&#34;&gt;Reddit Post with more info&lt;/a&gt; &lt;/p&gt; &lt;/h4&gt; &#xA;&lt;h1&gt;Transformer Heads&lt;/h1&gt; &#xA;&lt;p&gt;This library aims to be an allround toolkit for attaching, training, saving and loading of new heads for transformer models.&lt;br&gt; A new head could be:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;A &lt;a href=&#34;https://arxiv.org/pdf/1610.01644.pdf&#34;&gt;linear probe&lt;/a&gt; used to get an understanding of the information processing in a transformer architecture&lt;/li&gt; &#xA; &lt;li&gt;A head to be finetuned jointly with the weights of a pretrained transformer model to perform a completely different kind of task. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;E.g. a transformer pretrained to do causal language modelling could get a sequence classification head attached and be finetuned to do sentiment classification.&lt;/li&gt; &#xA;   &lt;li&gt;Or one could attach a regression head to turn a large language model into a value function for a reinforcement learning problem.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;On top of that, attaching multiple heads at once can make multi-task learning easy, making it possible to train very general models.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;Install from pypi: &lt;code&gt;pip install transformer-heads&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Or, clone this repo and from the root of this repository: &lt;code&gt;pip install -e .&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Create head configurations&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;head_config = HeadConfig(&#xA;    name=f&#34;imdb_head_3&#34;,&#xA;    layer_hook=-3,  # Attach at the output of the third-to-last transformer-block&#xA;    in_size=hidden_size,&#xA;    output_activation=&#34;linear&#34;,&#xA;    pred_for_sequence=True,&#xA;    loss_fct=&#34;cross_entropy&#34;,&#xA;    num_outputs=2,&#xA;    target=&#34;label&#34; # The name of the ground-truth column in the dataset&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Create a model with your head from a pretrained transformer model&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = load_headed(&#xA;    LlamaForCausalLM,&#xA;    &#34;meta-llama/Llama-2-7b-hf&#34;,&#xA;    head_configs=[heads_config],&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Train you model using (for example) the simple to use huggingface &lt;em&gt;Trainer&lt;/em&gt; interface:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;trainer = Trainer(&#xA;    model,&#xA;    args=args,&#xA;    train_dataset=imdb_dataset[&#34;train&#34;],&#xA;    data_collator=collator,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For a more in-depth introduction and a fully working example, check the &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/linear_probe.ipynb&#34;&gt;linear probe notebook&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Joint training of multiple linear probes&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/_images/multi_linear_probe.svg?sanitize=true&#34; alt=&#34;_images/multi_linear_probe.svg&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Notebooks&lt;/h2&gt; &#xA;&lt;p&gt;This repository contains multiple jupyter notebooks for a tutorial/illustration of how do do certain things with this library. Here is an overview of which notebook you should check out depending on the use you are interested in.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Linear Probes (understanding the inner workings of transformers) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Basic example with one probe for causal LM: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/linear_probe.ipynb&#34;&gt;notebooks/gpt2/linear_probe.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Train many probes for causal LM at once: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/multi_linear_probe.ipynb&#34;&gt;notebooks/gpt2/multi_linear_probe.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Train many probes for text classification at once: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/text_classification_linear_probe.ipynb&#34;&gt;notebooks/gpt2/text_classification_linear_probe.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Finetuning on a new type of task (with a new head) &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;QLoRA: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/text_classification_qlora.ipynb&#34;&gt;notebooks/gpt2/text_classification_qlora.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Full finetuning: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/text_classification_full_finetune.ipynb&#34;&gt;notebooks/gpt2/text_classification_full_finetune.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Joint multi-task learning &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Many heads doing completely different tasks + QLoRA, all trained at the same time: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/joint_multitask_learning.ipynb&#34;&gt;notebooks/gpt2/joint_multitask_learning.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Regression with pretrained transformers &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Check the regression heads of this notebook: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/joint_multitask_learning.ipynb&#34;&gt;notebooks/gpt2/joint_multitask_learning.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Saving and loading &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Notebook: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/notebooks/gpt2/saving_and_loading.ipynb&#34;&gt;notebooks/gpt2/saving_and_loading.ipynb&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;Tests: &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/transformer_heads/tests/test_load_model.py&#34;&gt;transformer_heads/tests/test_load_model.py&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Joint multi-task training with different types of heads and QLoRA.&lt;/h2&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/_images/example_architecture.svg?sanitize=true&#34; alt=&#34;_images/example_architecture.svg&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;More custom loss functions and models&lt;/h2&gt; &#xA;&lt;p&gt;At the state of writing, only a subset of loss functions / models are supported out of the box. At the time of writing, the supported models are &lt;code&gt;Mistral-7b&lt;/code&gt;, &lt;code&gt;LLaMA 2&lt;/code&gt; (all model sizes) and &lt;code&gt;gpt2&lt;/code&gt;. Check &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/transformer_heads/constants.py&#34;&gt;transformer_heads/constants.py&lt;/a&gt; for more up to date info.&lt;/p&gt; &#xA;&lt;p&gt;However, it is not so hard to add/use different loss functions/models. You&#39;ll just need to add their respective information to &lt;code&gt;loss_fct_map&lt;/code&gt; and &lt;code&gt;model_type_map&lt;/code&gt;. Just import from &lt;code&gt;transformer_heads.constants&lt;/code&gt;. To add a loss function, add a mapping from string to torch class. To add a model add a mapping from model type to a 2 tuple out of attribute name of the base model in the Model Class and Base model class. That may sound confusing, but what that means is just the following:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformer_heads.constants import model_type_map, loss_fct_map&#xA;import torch.nn as nn&#xA;from transformers import MistralModel&#xA;&#xA;loss_fct_map[&#34;bce&#34;] = nn.BCELoss()&#xA;model_type_map[&#34;mistral&#34;] = (&#34;model&#34;,MistralModel)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Can my transformer architecture be supported?&lt;/h2&gt; &#xA;&lt;p&gt;One of the basic assumtions of my library is that there is a transformer class such as the LlamaForCausalLM class of huggingface that has an &lt;a href=&#34;https://github.com/huggingface/transformers/raw/7eb3ba82241c927053689270a0751f4ff5d33c54/src/transformers/models/llama/modeling_llama.py#L1116&#34;&gt;attribute pointing to a base model that outputs raw hidden state&lt;/a&gt;. If your transformers model is built up in a similar way, adding support may be as easy as adding an entry to the &lt;a href=&#34;https://github.com/center-for-humans-and-machines/transformer-heads/raw/8ea0805ab95ca01dff7ea73ed9c844df946c17cb/transformer_heads/constants.py#L20&#34;&gt;model_type_map&lt;/a&gt; with the name of the attribute and the class of the base model. You can either do that by importing from &lt;a href=&#34;https://raw.githubusercontent.com/center-for-humans-and-machines/transformer-heads/main/transformer_heads/constants.py&#34;&gt;constants.py&lt;/a&gt; or by adding it directly and creating a pull request.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>chenzomi12/AISystem</title>
    <updated>2024-03-29T01:31:28Z</updated>
    <id>tag:github.com,2024-03-29:/chenzomi12/AISystem</id>
    <link href="https://github.com/chenzomi12/AISystem" rel="alternate"></link>
    <summary type="html">&lt;p&gt;AISystem 主要是指AI系统，包括AI芯片、AI编译器、AI推理和训练框架等AI全栈底层技术&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deep Learning System &amp;amp; AI System&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/d2l-ai/d2l-en/actions/workflows/ci.yml&#34;&gt;&lt;img src=&#34;https://github.com/d2l-ai/d2l-en/actions/workflows/ci.yml/badge.svg?sanitize=true&#34; alt=&#34;Continuous Integration&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/d2l-ai/d2l-en/actions/workflows/build-docker.yml&#34;&gt;&lt;img src=&#34;https://github.com/d2l-ai/d2l-en/actions/workflows/build-docker.yml/badge.svg?sanitize=true&#34; alt=&#34;Build Docker Image&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;文字课程内容正在一节节补充更新，尽可能抽空继续更新正在 &lt;a href=&#34;https://chenzomi12.github.io/&#34;&gt;AISys&lt;/a&gt; ，希望您多多鼓励和参与进来！！！&lt;/p&gt; &#xA;&lt;p&gt;文字课程开源在 &lt;a href=&#34;https://chenzomi12.github.io/&#34;&gt;AISys&lt;/a&gt;，系列视频托管&lt;a href=&#34;https://space.bilibili.com/517221395&#34;&gt;B站&lt;/a&gt;和&lt;a href=&#34;https://www.youtube.com/@zomi6222/videos&#34;&gt;油管&lt;/a&gt;，PPT开源在&lt;a href=&#34;https://github.com/chenzomi12/DeepLearningSystem&#34;&gt;github&lt;/a&gt;，欢迎取用！！！&lt;/p&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;非常希望您也参与到这个开源项目中，B站给ZOMI留言哦！&lt;/p&gt; &#xA; &lt;p&gt;欢迎大家使用的过程中发现bug或者勘误直接提交代码PR到开源社区哦！&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;h2&gt;项目背景&lt;/h2&gt; &#xA;&lt;p&gt;这个开源项目英文名字叫做 &lt;strong&gt;Deep Learning System&lt;/strong&gt; 或者 &lt;strong&gt;AI System(AISys)&lt;/strong&gt;，中文名字叫做 &lt;strong&gt;深度学习系统&lt;/strong&gt; 或者 &lt;strong&gt;AI系统&lt;/strong&gt;。&lt;/p&gt; &#xA;&lt;p&gt;本开源项目主要是跟大家一起探讨和学习人工智能、深度学习的系统设计，而整个系统是围绕着 ZOMI 在工作当中所积累、梳理、构建 AI 系统全栈的内容。希望跟所有关注 AI 开源项目的好朋友一起探讨研究，共同促进学习讨论。&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/images/ai_system02.png&#34; alt=&#34;AI系统全栈&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;课程内容大纲&lt;/h2&gt; &#xA;&lt;p&gt;课程主要包括以下六大模块：&lt;/p&gt; &#xA;&lt;p&gt;第一部分，AI基础知识和AI系统的全栈概述的&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/01Introduction/&#34;&gt;&lt;u&gt;&lt;strong&gt;AI系统概述&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，以及深度学习系统的系统性设计和方法论，主要是整体了解AI训练和推理全栈的体系结构内容。&lt;/p&gt; &#xA;&lt;p&gt;第二部分，硬核篇介绍&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/&#34;&gt;&lt;u&gt;&lt;strong&gt;AI芯片概况&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，这里就很硬核了，从芯片基础到AI芯片的范围都会涉及，芯片设计需要考虑上面AI框架的前端、后端编译，而不是停留在天天喊着吊打英伟达，被现实打趴。&lt;/p&gt; &#xA;&lt;p&gt;第三部分，进阶篇介绍&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/&#34;&gt;&lt;u&gt;&lt;strong&gt;AI编译器原理&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，将站在系统设计的角度，思考在设计现代机器学习系统中需要考虑的编译器问题，特别是中间表达乃至后端优化。&lt;/p&gt; &#xA;&lt;p&gt;第四部分，实际应用&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/&#34;&gt;&lt;u&gt;&lt;strong&gt;推理系统与引擎&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，讲了太多原理身体太虚容易消化不良，还是得回归到业务本质，让行业、企业能够真正应用起来，而推理系统涉及一些核心算法和注意的事情也分享下。&lt;/p&gt; &#xA;&lt;p&gt;第五部分，介绍&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/05Framework/&#34;&gt;&lt;u&gt;&lt;strong&gt;AI框架核心技术&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，首先介绍任何一个AI框架都离不开的自动微分，通过自动微分功能后就会产生表示神经网络的图和算子，然后介绍AI框架前端的优化，还有最近很火的大模型分布式训练在AI框架中的关键技术。&lt;/p&gt; &#xA;&lt;p&gt;第六部分，汇总篇介绍&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/&#34;&gt;&lt;u&gt;&lt;strong&gt;大模型与AI系统&lt;/strong&gt;&lt;/u&gt;&lt;/a&gt;，大模型是基于AI集群的全栈软硬件性能优化，通过最小的每一块AI芯片组成的AI集群，编译器使能到上层的AI框架，训练过程需要分布式并行、集群通信等算法支持，而且在大模型领域最近持续演进如智能体等新技术。&lt;/p&gt; &#xA;&lt;h2&gt;课程设立目的&lt;/h2&gt; &#xA;&lt;p&gt;本课程主要为本科生高年级、硕博研究生、AI系统从业者设计，帮助大家：&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;完整了解AI的计算机系统架构，并通过实际问题和案例，来了解AI完整生命周期下的系统设计。&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;介绍前沿系统架构和AI相结合的研究工作，了解主流框架、平台和工具来了解AI系统。&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;strong&gt;先修课程:&lt;/strong&gt;&amp;nbsp;C++/Python，计算机体系结构，人工智能基础&lt;/p&gt; &#xA;&lt;h2&gt;课程部分&lt;/h2&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/01Introduction/&#34;&gt;一. AI系统概述&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/01Introduction/&#34;&gt;AI 系统&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;算法、框架、体系结构的结合，形成AI系统&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/&#34;&gt;二. AI芯片体系结构&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/01Foundation/&#34;&gt;AI 计算体系&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;神经网络等AI技术的计算模式和计算体系架构&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/02ChipBase/&#34;&gt;AI 芯片基础&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;CPU、GPU、NPU等芯片体系架构基础原理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/03GPUBase/&#34;&gt;图形处理器 GPU&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;GPU的基本原理，英伟达GPU的架构发展&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/04NVIDIA/&#34;&gt;英伟达 GPU 详解&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;英伟达GPU的TensorCore、NVLink深度剖析&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/05Abroad/&#34;&gt;国外 AI 处理器&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;谷歌、特斯拉等专用AI处理器核心原理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/06Domestic/&#34;&gt;国内 AI 处理器&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;寒武纪、燧原科技等专用AI处理器核心原理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/02Hardware/07Thought/&#34;&gt;AI 芯片黄金10年&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;对 AI 芯片的编程模式和发展进行总结&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/&#34;&gt;三. AI编译原理&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/01Tradition/&#34;&gt;传统编译器&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;传统编译器GCC与LLVM，LLVM详细架构&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/02AICompiler/&#34;&gt;AI 编译器&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI编译器发展与架构定义，未来挑战与思考&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/03Frontend/&#34;&gt;前端优化&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI编译器的前端优化(算子融合、内存优化等)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/04Backend/&#34;&gt;后端优化&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI编译器的后端优化(Kernel优化、AutoTuning)&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;多面体&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;待更ing...&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/03Compiler/06PyTorch/&#34;&gt;PyTorch2.0&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;PyTorch2.0最重要的新特性：编译技术栈&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/&#34;&gt;四. AI推理系统&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/01Inference/&#34;&gt;推理系统&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;推理系统整体介绍，推理引擎架构梳理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/02Mobilenet/&#34;&gt;轻量网络&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;轻量化主干网络，MobileNet等SOTA模型介绍&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/03Slim/&#34;&gt;模型压缩&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;模型压缩4件套，量化、蒸馏、剪枝和二值化&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/04Converter/&#34;&gt;转换&amp;amp;优化&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI框架训练后模型进行转换，并对计算图优化&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/04Inference/05Kernel/&#34;&gt;Kernel优化&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;Kernel层、算子层优化，对算子、内存、调度优化&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/05Framework/&#34;&gt;五. AI框架核心技术&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/05Framework/01Foundation/&#34;&gt;AI框架基础&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI框架的作用、发展、编程范式&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/05Framework/02AutoDiff/&#34;&gt;自动微分&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;自动微分的实现方式和原理&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/05Framework/03DataFlow/&#34;&gt;计算图&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;计算图的概念，图优化、图执行、控制流表达&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;&lt;strong&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/&#34;&gt;六. 大模型训练&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;编号&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;名称&lt;/th&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;具体内容&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;1&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/01Introduce/&#34;&gt;大模型全流程&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;大模型整体架构和大模型全流程介绍&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;2&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/02AICluster/&#34;&gt;AI 集群简介&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI集群服务器整体组成相关技术初体验&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;3&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/03Storage/&#34;&gt;AI 集群存储&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;数据存储在AI集群中，具体的存储优化方案&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;4&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/04Network/&#34;&gt;AI 集群通信&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;5&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/05Dataset/&#34;&gt;数据处理&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;6&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/06Algorithm/&#34;&gt;大模型算法&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;7&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/07Train/&#34;&gt;大模型训练&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;8&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/08Parallel/&#34;&gt;分布式并行&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;9&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/09Finetune/&#34;&gt;大模型微调&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;10&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/10Evaluate/&#34;&gt;大模型验证&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;11&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/11Inference/&#34;&gt;大模型推理&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;更新中&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;12&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/06Foundation/12Agent/&#34;&gt;AI Agent&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;AI Agent 智能体，通过大模型走向GAI&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;知识清单&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/chenzomi12/AISystem/main/images/knowledge_list.png&#34; alt=&#34;知识清单&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;贡献者&lt;/h2&gt; &#xA;&lt;!-- readme: collaborators,contributors -start --&gt; &#xA;&lt;a href=&#34;https://github.com/chenzomi12/DeepLearningSystem/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=chenzomi12/DeepLearningSystem&#34;&gt; &lt;/a&gt; &#xA;&lt;!-- readme: collaborators,contributors -end --&gt; &#xA;&lt;h2&gt;备注&lt;/h2&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;这个仓已经到达疯狂的10G啦（ZOMI把所有制作过程、高清图片都原封不动提供），如果你要git clone会非常的慢，因此建议优先到 &lt;a href=&#34;https://github.com/chenzomi12/DeepLearningSystem/releases&#34;&gt;Releases · chenzomi12/DeepLearningSystem&lt;/a&gt; 来下载你需要的内容。&lt;/p&gt; &#xA;&lt;/blockquote&gt;</summary>
  </entry>
  <entry>
    <title>practical-nlp/practical-nlp-code</title>
    <updated>2024-03-29T01:31:28Z</updated>
    <id>tag:github.com,2024-03-29:/practical-nlp/practical-nlp-code</id>
    <link href="https://github.com/practical-nlp/practical-nlp-code" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Official Repository for Code associated with &#39;Practical Natural Language Processing&#39; book by O&#39;Reilly Media&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Practical Natural Language Processing&lt;/h1&gt; &#xA;&lt;h2&gt;A Comprehensive Guide to Building Real-World NLP Systems&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/sowmya-vajjala-2a38734/&#34;&gt;Sowmya Vajjala&lt;/a&gt;, &lt;a href=&#34;http://www.majumderb.com/&#34;&gt;Bodhisattwa P. Majumder&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/anujgupta-82/&#34;&gt;Anuj Gupta&lt;/a&gt;, &lt;a href=&#34;http://harshitsurana.com/&#34;&gt;Harshit Surana&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Endorsed by:&lt;/strong&gt; &lt;a href=&#34;http://zacklipton.com/&#34;&gt;Zachary Lipton&lt;/a&gt;, &lt;a href=&#34;https://ruder.io/&#34;&gt;Sebastian Ruder&lt;/a&gt;, &lt;a href=&#34;http://marc.najork.org/&#34;&gt;Marc Najork&lt;/a&gt;, &lt;a href=&#34;https://www.microsoft.com/en-us/research/people/monojitc/&#34;&gt;Monojit Choudhury&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/vinayakh/&#34;&gt;Vinayak Hegde&lt;/a&gt;, &lt;a href=&#34;https://mengtingwan.github.io/&#34;&gt;Mengting Wan&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/siddharth-sharma-31140210/&#34;&gt;Siddharth Sharma&lt;/a&gt;, &amp;amp; &lt;a href=&#34;https://www.linkedin.com/in/e10is/&#34;&gt;Ed Harris&lt;/a&gt; &lt;strong&gt;Foreword by:&lt;/strong&gt; &lt;a href=&#34;https://cseweb.ucsd.edu/~jmcauley/&#34;&gt;Julian McAuley&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Homepage: &lt;a href=&#34;http://www.practicalnlp.ai&#34;&gt;www.practicalnlp.ai&lt;/a&gt; Published by &lt;a href=&#34;http://shop.oreilly.com/product/0636920262329.do&#34;&gt;O&#39;Reilly Media, 2020&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;Book Structure&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/practical-nlp/practical-nlp-figures/raw/master/figures/P-1.png&#34; alt=&#34;figure&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;Please note that the code repository is still under development and review.&#xA;&#xA;All the notebooks will be crystalized in the coming months. &#xA;&#xA;The notebooks have been tested on an ubuntu machine running python 3.6. &#xA;&#xA;Currently, we are using TF1.x. We will migrate to TF2.x in the coming months.  &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;&lt;span&gt;✨&lt;/span&gt; A newer version compatible with Ubuntu 23 is being added in &lt;a href=&#34;https://github.com/practical-nlp/practical-nlp-code/tree/pnlp-refactor-ubuntu23&#34;&gt;pnlp-refactor-ubuntu23&lt;/a&gt;.&lt;/h3&gt; &#xA;&lt;p&gt;We thank everyone, especially the educators &amp;amp; universities, for their feedback in pointing out the issues &amp;amp; improving the accessibility of the notebooks.&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;🚩 Details of the repository roadmap could be found &lt;a href=&#34;https://raw.githubusercontent.com/practical-nlp/practical-nlp-code/master/roadmap.md&#34;&gt;here&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;!-- ![](http://check-server.in/book/images/book.png =250x250)](http://practicalnlp.ai) --&gt; &#xA;&lt;h3&gt;Open the repository in Google Colab: &lt;a href=&#34;https://colab.research.google.com/github/practical-nlp/practical-nlp/blob/master&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Open the repository in Jupyter nbviewer: &lt;a href=&#34;https://nbviewer.jupyter.org/github/practical-nlp/practical-nlp/tree/master/&#34;&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/2791223/29387450-e5654c72-8294-11e7-95e4-090419520edb.png&#34; alt=&#34;Open in nbviewer&#34;&gt;&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;h3&gt;Chapterwise folders:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch1&#34;&gt;Chapter 1: NLP: A Primer&lt;/a&gt; (only figures &amp;amp; outline)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch2&#34;&gt;Chapter 2: NLP Pipeline&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch3&#34;&gt;Chapter 3: Text Representation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch4&#34;&gt;Chapter 4: Text Classification&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch5&#34;&gt;Chapter 5: Information Extraction&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch6&#34;&gt;Chapter 6: ChatBots&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch7&#34;&gt;Chapter 7: Topics in Brief&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch8&#34;&gt;Chapter 8: Social Media&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch9&#34;&gt;Chapter 9: E-commerce and Retail &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch10&#34;&gt;Chapter 10: Healthcare, Finance and Law&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/tree/master/Ch11&#34;&gt;Chapter 11: End-to-End NLP Process&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Contributors to Codebase:&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/varunp2k/&#34;&gt;Varun Purushotham&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/kartikay-bagla-60638a167/&#34;&gt;Kartikay Bagla&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/jitinkapila/&#34;&gt;Jitin Kapila&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/vishalg8897/&#34;&gt;Vishal Gupta&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/taranjeet7114/&#34;&gt;Taranjeet Singh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/shreyans-dhankhar-501b88118/&#34;&gt;Shreyans Dhankhar&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/kumarjitpathak/&#34;&gt;Kumarjit Pathak&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/ernest-s-kirubakaran/&#34;&gt;Ernest Kirubakaran Selvaraj&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/ayushdatta/&#34;&gt;Ayush Datta&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/rui-shu/&#34;&gt;Rui Shu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/nachiketh-suresh-a4955411/&#34;&gt;Nachiketh Suresh&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/jatin-papreja-71982bb9/&#34;&gt;Jatin Papreja&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/kumar-apurva-000b38197/&#34;&gt;Kumar Apurva&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sukeeratsg&#34;&gt;Sukeerat Goindi&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/Ethan0456&#34;&gt;Abhijeetsingh Meena&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Found a Bug?&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;If the bug is in book text, please enter a errata here: &lt;a href=&#34;https://www.oreilly.com/catalog/errata.csp?isbn=0636920262329&#34;&gt;https://www.oreilly.com/catalog/errata.csp?isbn=0636920262329&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If the bug is in the codebase: Great! Please read &lt;a href=&#34;https://github.com/practical-nlp/practical-nlp/edit/master/Contributing.md&#34;&gt;this&lt;/a&gt; how can you help us improve the codebase&lt;/p&gt;</summary>
  </entry>
</feed>