<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-26T01:37:45Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>rohitgandikota/sliders</title>
    <updated>2023-11-26T01:37:45Z</updated>
    <id>tag:github.com,2023-11-26:/rohitgandikota/sliders</id>
    <link href="https://github.com/rohitgandikota/sliders" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Concept Sliders for Precise Control of Diffusion Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Concept Sliders&lt;/h1&gt; &#xA;&lt;h3&gt;&lt;a href=&#34;https://sliders.baulab.info&#34;&gt;Project Website&lt;/a&gt; | &lt;a href=&#34;https://arxiv.org/pdf/2311.12092.pdf&#34;&gt;Arxiv Preprint&lt;/a&gt; | &lt;a href=&#34;https://sliders.baulab.info/weights/xl_sliders/&#34;&gt;Trained Sliders&lt;/a&gt;&lt;br&gt;&lt;/h3&gt; &#xA;&lt;p&gt;Official code implementation of &#34;Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models&#34;&lt;/p&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img src=&#34;https://raw.githubusercontent.com/rohitgandikota/sliders/main/images/main_figure.png&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;Colab Demo&lt;/h2&gt; &#xA;&lt;p&gt;Try out our colab demo here &lt;a href=&#34;https://colab.research.google.com/github/rohitgandikota/sliders/blob/main/demo_concept_sliders.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;p&gt;To set up your python environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;conda create -n sliders python=3.9&#xA;conda activate sliders&#xA;&#xA;git  clone https://github.com/rohitgandikota/sliders.git&#xA;cd sliders&#xA;pip install -r requirements.txt&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Textual Concept Sliders&lt;/h2&gt; &#xA;&lt;h3&gt;Training SD-1.x and SD-2.x LoRa&lt;/h3&gt; &#xA;&lt;p&gt;To train an age slider - go to &lt;code&gt;train-scripts/textsliders/data/prompts.yaml&lt;/code&gt; and edit the &lt;code&gt;target=person&lt;/code&gt; and &lt;code&gt;positive=old person&lt;/code&gt; and &lt;code&gt;unconditional=young person&lt;/code&gt; (opposite of positive) and &lt;code&gt;neutral=person&lt;/code&gt; and &lt;code&gt;action=enhance&lt;/code&gt; with &lt;code&gt;guidance=4&lt;/code&gt;. &lt;br&gt; If you do not want your edit to be targetted to person replace it with any target you want (eg. dog) or if you need it global replace &lt;code&gt;person&lt;/code&gt; with &lt;code&gt;&#34;&#34;&lt;/code&gt; &lt;br&gt; Finally, run the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python trainscripts/textsliders/train_lora.py --attributes &#39;male, female&#39; --name &#39;ageslider&#39; --rank 4 --alpha 1 --config_file &#39;trainscripts/textsliders/data/config.yaml&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;code&gt;--attributes&lt;/code&gt; argument is used to disentangle concepts from the slider. For instance age slider makes all old people male (so instead add the &lt;code&gt;&#34;female, male&#34;&lt;/code&gt; attributes to allow disentanglement)&lt;/p&gt; &#xA;&lt;h4&gt;Evaluate&lt;/h4&gt; &#xA;&lt;p&gt;To evaluate your trained models use the notebook &lt;code&gt;SD1-sliders-inference.ipynb&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Training SD-XL&lt;/h3&gt; &#xA;&lt;p&gt;To train sliders for SD-XL, use the script &lt;code&gt;train_lora_xl.py&lt;/code&gt;. The setup is same as SDv1.4&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python trainscripts/textsliders/train_lora_xl.py --attributes &#39;male, female&#39; --name &#39;agesliderXL&#39; --rank 4 --alpha 1 --config_file &#39;trainscripts/textsliders/data/config-xl.yaml&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h4&gt;Evaluate&lt;/h4&gt; &#xA;&lt;p&gt;To evaluate your trained models use the notebook &lt;code&gt;XL-sliders-inference.ipynb&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Visual Concept Sliders&lt;/h2&gt; &#xA;&lt;h3&gt;Training SD-1.x and SD-2.x LoRa&lt;/h3&gt; &#xA;&lt;p&gt;To train image based sliders, you need to create a ~4-6 pairs of image dataset (before/after edit for desired concept). Save the before images and after images separately. You can also create a dataset with varied intensity effect and save them differently.&lt;/p&gt; &#xA;&lt;p&gt;To train an image slider for eye size - go to &lt;code&gt;train-scripts/imagesliders/data/config.yaml&lt;/code&gt; and edit the &lt;code&gt;target=eye&lt;/code&gt; and &lt;code&gt;itive=&#39;eye&#39;&lt;/code&gt; and &lt;code&gt;unconditional=&#39;&#39;&lt;/code&gt; and &lt;code&gt;neutral=eye&lt;/code&gt; and &lt;code&gt;action=enhance&lt;/code&gt; with &lt;code&gt;guidance=4&lt;/code&gt;. &lt;br&gt; If you want the diffusion model to figure out the edit concept - leave &lt;code&gt;target, positive, unconditional, neutral&lt;/code&gt; as &lt;code&gt;&#39;&#39;&lt;/code&gt;&lt;br&gt; Finally, run the command:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python trainscripts/imagesliders/train_lora-scale.py --name &#39;eyeslider&#39; --rank 4 --alpha 1 --config_file &#39;trainscripts/imagesliders/data/config.yaml&#39; --folder_main &#39;datasets/eyesize/&#39; --folders &#39;bigsize, smallsize&#39; --scales &#39;1, -1&#39; &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For this to work - you need to store your before images in &lt;code&gt;smallsize&lt;/code&gt; and after images in &lt;code&gt;bigsize&lt;/code&gt;. The corresponding paired files in both the folders should have same names. Both these subfolders should be under &lt;code&gt;datasets/eyesize&lt;/code&gt;. Feel free to make your own datasets in your own named conventions.&lt;/p&gt; &#xA;&lt;h3&gt;Training SD-XL&lt;/h3&gt; &#xA;&lt;p&gt;To train image sliders for SD-XL, use the script &lt;code&gt;train-lora-scale-xl.py&lt;/code&gt;. The setup is same as SDv1.4&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python trainscripts/imagesliders/train_lora-scale-xl.py --name &#39;eyesliderXL&#39; --rank 4 --alpha 1 --config_file &#39;trainscripts/imagesliders/data/config-xl.yaml&#39; --folder_main &#39;/share/u/rohit/imageXLdataset/eyesize_data/&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citing our work&lt;/h2&gt; &#xA;&lt;p&gt;The preprint can be cited as follows&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{gandikota2023sliders,&#xA;  title={Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models},&#xA;  author={Rohit Gandikota and Joanna Materzy\&#39;nska and Tingrui Zhou and Antonio Torralba and David Bau},&#xA;  journal={arXiv preprint arXiv:2311.12092},&#xA;  year={2023}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>