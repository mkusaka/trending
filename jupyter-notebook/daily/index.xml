<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-03-03T01:31:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>evo-design/evo</title>
    <updated>2024-03-03T01:31:11Z</updated>
    <id>tag:github.com,2024-03-03:/evo-design/evo</id>
    <link href="https://github.com/evo-design/evo" rel="alternate"></link>
    <summary type="html">&lt;p&gt;DNA foundation modeling from molecular to genome scale&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Evo: DNA foundation modeling from molecular to genome scale&lt;/h1&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/evo-design/evo/main/evo.jpg&#34; alt=&#34;Evo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Evo is a biological foundation model capable of long-context modeling and design. Evo uses the &lt;a href=&#34;https://github.com/togethercomputer/stripedhyena&#34;&gt;StripedHyena architecture&lt;/a&gt; to enable modeling of sequences at a single-nucleotide, byte-level resolution with near-linear scaling of compute and memory relative to context length. Evo has 7 billion parameters and is trained on OpenGenome, a prokaryotic whole-genome dataset containing ~300 billion tokens.&lt;/p&gt; &#xA;&lt;p&gt;We describe Evo in the paper &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2024.02.27.582234v1&#34;&gt;‚ÄúSequence modeling and design from molecular to genome scale with Evo‚Äù&lt;/a&gt; and in the &lt;a href=&#34;https://arcinstitute.org/news/blog/evo&#34;&gt;accompanying blog post&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide the following model checkpoints:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Checkpoint Name&lt;/th&gt; &#xA;   &lt;th&gt;Description&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo-1-8k-base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 8,192 context. We use this model as the base model for molecular-scale finetuning tasks.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;code&gt;evo-1-131k-base&lt;/code&gt;&lt;/td&gt; &#xA;   &lt;td&gt;A model pretrained with 131,072 context using &lt;code&gt;evo-1-8k-base&lt;/code&gt; as the base model. We use this model to reason about and generate sequences at the genome scale.&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#setup&#34;&gt;Setup&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#installation&#34;&gt;Installation&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#usage&#34;&gt;Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#huggingface&#34;&gt;HuggingFace&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#together-api&#34;&gt;Together API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/#citation&#34;&gt;Citation&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Setup&lt;/h2&gt; &#xA;&lt;h3&gt;Requirements&lt;/h3&gt; &#xA;&lt;p&gt;Evo is based on &lt;a href=&#34;https://github.com/togethercomputer/stripedhyena/tree/main&#34;&gt;StripedHyena&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Evo uses &lt;a href=&#34;https://github.com/Dao-AILab/flash-attention&#34;&gt;FlashAttention-2&lt;/a&gt;, which may not work on all GPU architectures. Please consult the &lt;a href=&#34;https://github.com/Dao-AILab/flash-attention#installation-and-features&#34;&gt;FlashAttention GitHub repository&lt;/a&gt; for the current list of supported GPUs.&lt;/p&gt; &#xA;&lt;p&gt;Make sure to install the correct &lt;a href=&#34;https://pytorch.org/&#34;&gt;PyTorch version&lt;/a&gt; on your system.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;p&gt;You can install Evo using &lt;code&gt;pip&lt;/code&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install evo-model&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;or directly from the GitHub source&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/evo-design/evo.git&#xA;cd evo/&#xA;pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We recommend that you install the PyTorch library first, before installing all other dependencies (due to dependency issues of the &lt;code&gt;flash-attn&lt;/code&gt; library; see, e.g., this &lt;a href=&#34;https://github.com/Dao-AILab/flash-attention/issues/246&#34;&gt;issue&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;One of our &lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/scripts/&#34;&gt;example scripts&lt;/a&gt;, demonstrating how to go from generating sequences with Evo to folding proteins (&lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/scripts/generation_to_folding.py&#34;&gt;scripts/generation_to_folding.py&lt;/a&gt;), further requires the installation of &lt;code&gt;prodigal&lt;/code&gt;. We have created an &lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/environment.yml&#34;&gt;environment.yml&lt;/a&gt; file for this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;conda activate evo-design&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;p&gt;Below is an example of how to download Evo and use it locally through the Python API.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from evo import Evo&#xA;import torch&#xA;&#xA;device = &#39;cuda:0&#39;&#xA;&#xA;evo_model = Evo(&#39;evo-1-131k-base&#39;)&#xA;model, tokenizer = evo_model.model, evo_model.tokenizer&#xA;model.to(device)&#xA;model.eval()&#xA;&#xA;sequence = &#39;ACGT&#39;&#xA;input_ids = torch.tensor(&#xA;    tokenizer.tokenize(sequence),&#xA;    dtype=torch.int,&#xA;).to(device).unsqueeze(0)&#xA;logits, _ = model(input_ids) # (batch, length, vocab)&#xA;&#xA;print(&#39;Logits: &#39;, logits)&#xA;print(&#39;Shape (batch, length, vocab): &#39;, logits.shape)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;An example of batched inference can be found in &lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/scripts/example_inference.py&#34;&gt;&lt;code&gt;scripts/example_inference.py&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;We provide an &lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/scripts/generate.py&#34;&gt;example script&lt;/a&gt; for how to prompt the model and sample a set of sequences given the prompt.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m scripts.generate \&#xA;    --model-name &#39;evo-1-131k-base&#39; \&#xA;    --prompt ACGT \&#xA;    --n-samples 10 \&#xA;    --n-tokens 100 \&#xA;    --temperature 1. \&#xA;    --top-k 4 \&#xA;    --device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We also provide an &lt;a href=&#34;https://raw.githubusercontent.com/evo-design/evo/main/scripts/generate.py&#34;&gt;example script&lt;/a&gt; for using the model to score the log-likelihoods of a set of sequences.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m scripts.score \&#xA;    --input-fasta examples/example_seqs.fasta \&#xA;    --output-tsv scores.tsv \&#xA;    --model-name &#39;evo-1-131k-base&#39; \&#xA;    --device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;HuggingFace&lt;/h2&gt; &#xA;&lt;p&gt;Evo is integrated with &lt;a href=&#34;https://huggingface.co/togethercomputer/evo-1-131k-base&#34;&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from transformers import AutoConfig, AutoModelForCausalLM&#xA;&#xA;model_name = &#39;togethercomputer/evo-1-8k-base&#39;&#xA;&#xA;model_config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)&#xA;model_config.use_cache = True&#xA;&#xA;model = AutoModelForCausalLM.from_pretrained(&#xA;    model_name,&#xA;    config=model_config,&#xA;    trust_remote_code=True,&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Together API&lt;/h2&gt; &#xA;&lt;p&gt;Evo will also be soon available via an API by &lt;a href=&#34;https://www.together.ai/&#34;&gt;TogetherAI&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import openai&#xA;import os&#xA;&#xA;# Fill in your API information here.&#xA;client = openai.OpenAI(&#xA;  api_key=TOGETHER_API_KEY,&#xA;  base_url=&#39;https://api.together.xyz&#39;,&#xA;)&#xA;&#xA;chat_completion = client.chat.completions.create(&#xA;  messages=[&#xA;    {&#xA;      &#34;role&#34;: &#34;system&#34;,&#xA;      &#34;content&#34;: &#34;&#34;&#xA;    },&#xA;    {&#xA;      &#34;role&#34;: &#34;user&#34;,&#xA;      &#34;content&#34;: &#34;ACGT&#34;, # Prompt the model with a sequence.&#xA;    }&#xA;  ],&#xA;  model=&#34;togethercomputer/evo-1-131k-base&#34;,&#xA;  max_tokens=128, # Sample some number of new tokens.&#xA;  logprobs=True&#xA;)&#xA;print(&#xA;    chat_completion.choices[0].logprobs.token_logprobs,&#xA;    chat_completion.choices[0].message.content&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Citation&lt;/h2&gt; &#xA;&lt;p&gt;Please cite the following preprint when referencing Evo.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article {nguyen2024sequence,&#xA;&#x9;author = {Eric Nguyen and Michael Poli and Matthew G Durrant and Armin W Thomas and Brian Kang and Jeremy Sullivan and Madelena Y Ng and Ashley Lewis and Aman Patel and Aaron Lou and Stefano Ermon and Stephen A Baccus and Tina Hernandez-Boussard and Christopher R√© and Patrick D Hsu and Brian L Hie},&#xA;&#x9;title = {Sequence modeling and design from molecular to genome scale with Evo},&#xA;&#x9;year = {2024},&#xA;&#x9;doi = {10.1101/2024.02.27.582234},&#xA;&#x9;publisher = {Cold Spring Harbor Laboratory},&#xA;&#x9;URL = {https://www.biorxiv.org/content/early/2024/02/27/2024.02.27.582234},&#xA;&#x9;journal = {bioRxiv}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>lynnlangit/gcp-for-bioinformatics</title>
    <updated>2024-03-03T01:31:11Z</updated>
    <id>tag:github.com,2024-03-03:/lynnlangit/gcp-for-bioinformatics</id>
    <link href="https://github.com/lynnlangit/gcp-for-bioinformatics" rel="alternate"></link>
    <summary type="html">&lt;p&gt;GCP for Bioinformatics Researchers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Google Cloud Platform (GCP) for Bioinformatics&lt;/h1&gt; &#xA;&lt;p&gt;This repository shows how to use Google Cloud Platform (GCP) public cloud services to scale sets of &lt;strong&gt;bioinformatics data analysis&lt;/strong&gt; tasks. This Repo uses cloud best practices for GCP. All examples use &lt;strong&gt;genomic&lt;/strong&gt; sample (input) data, tools and pipelines. Use cases included here as examples are called by any and all of the following terms:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;genomic-scale data workflows or pipelines&lt;/li&gt; &#xA; &lt;li&gt;bioinformatics primary, secondary or tertiary analysis&lt;/li&gt; &#xA; &lt;li&gt;distributed cloud-based batch jobs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;img src=&#34;https://github.com/lynnlangit/gcp-for-bioinformatics/raw/master/images/learn-gcp.png&#34; width=&#34;390&#34; align=&#34;right&#34;&gt; &#xA;&lt;p&gt;This content is intended for researchers - in particular, this guide is for those who are &lt;strong&gt;NEW to working with GCP&lt;/strong&gt;. You have a number of options on how to use the materials provided in this course. A summary is shown below left.&lt;/p&gt; &#xA;&lt;p&gt;This Repo includes content you can read, watch or run:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;üìó &lt;strong&gt;READ&lt;/strong&gt; - one page of this Repo (MD page)&lt;/li&gt; &#xA; &lt;li&gt;üì∫ &lt;strong&gt;WATCH&lt;/strong&gt; - linked YouTube screencasts&lt;/li&gt; &#xA; &lt;li&gt;üìô &lt;strong&gt;RUN&lt;/strong&gt; - Jupyter Notebook example&lt;/li&gt; &#xA; &lt;li&gt;&lt;img alt=&#34;octocat&#34; src=&#34;https://github.githubassets.com/images/icons/emoji/octocat.png?v8&#34;&gt;) &lt;strong&gt;TRY&lt;/strong&gt; - linked GitHub Repos&lt;/li&gt; &#xA; &lt;li&gt;üìò &lt;strong&gt;EXPAND&lt;/strong&gt; - linked (external) resources&lt;/li&gt; &#xA; &lt;li&gt;üîç &lt;strong&gt;SCAN&lt;/strong&gt; - search a list in this Repo&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;üì∫ Click below to WATCH &#39;Lynn&#39;s Welcome Video&#39; (4 min) on YouTube&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=YoFkSVDlN6k&#34; title=&#34;Welcome to GCP for Bioinformatics&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/YoFkSVDlN6k/0.jpg&#34; alt=&#34;Welcome to GCP for Bioinformatics&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Why would I choose to use a public cloud vendor for bioinformatics?&lt;/h3&gt; &#xA;&lt;p&gt;‚≠êÔ∏è &lt;strong&gt;SAVE MONEY&lt;/strong&gt; run (and pay for) scalable analysis jobs only when you need to run them&lt;br&gt; ‚≠êÔ∏è &lt;strong&gt;SAVE TIME&lt;/strong&gt; use vendor-managed infrastructure &amp;amp; best-practice patterns for fast repeatable research&lt;br&gt; üìó &lt;strong&gt;READ&lt;/strong&gt; the &lt;a href=&#34;https://github.com/lynnlangit/gcp-for-bioinformatics/raw/master/1_FAQ.md&#34;&gt;FAQ for GCP bioinformatics&lt;/a&gt; for this Repo&lt;br&gt; üìï &lt;strong&gt;READ&lt;/strong&gt; Nature article: &lt;a href=&#34;https://www.nature.com/articles/nrg.2017.113&#34;&gt;&#34;Cloud computing for genomic data analysis and collaboration&#34;&lt;/a&gt;&lt;br&gt; üìó &lt;strong&gt;READ&lt;/strong&gt; the top 4 most &lt;a href=&#34;https://github.com/lynnlangit/gcp-for-bioinformatics/raw/master/3_USER-STORIES.md&#34;&gt;common use cases&lt;/a&gt; for using the public cloud for bioinformatics researchers&lt;/p&gt; &#xA;&lt;h3&gt;Bioinformatics wanting more advanced GCP content?&lt;/h3&gt; &#xA;&lt;p&gt;If you would like to learn &lt;strong&gt;more advanced concepts&lt;/strong&gt; (including script examples and patterns) about working with Google Cloud Platform, see my Repo &lt;code&gt;gcp-essentials&lt;/code&gt; --&amp;gt; &lt;a href=&#34;https://github.com/lynnlangit/gcp-essentials&#34;&gt;link&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;New to Bioinformatics?&lt;/h3&gt; &#xA;&lt;p&gt;If you are &lt;strong&gt;NEW to bioinformatics&lt;/strong&gt; and have a computational background...&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;img alt=&#34;octocat&#34; src=&#34;https://github.githubassets.com/images/icons/emoji/octocat.png?v8&#34;&gt;) &lt;strong&gt;REVIEW&lt;/strong&gt; my bioinformatics concepts tools and terms &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Designed for experienced cloud practioners who are &lt;strong&gt;NEW to Bioinformatics&lt;/strong&gt;&lt;/li&gt; &#xA;   &lt;li&gt;The &#39;student notes repo&#39; is named &lt;code&gt;Team Teri&lt;/code&gt; - &lt;a href=&#34;https://github.com/lynnlangit/TeamTeri#who-is-teri&#34;&gt;link&lt;/a&gt; to &#39;who is Teri?&#39;&lt;/li&gt; &#xA;   &lt;li&gt;This Repo includes links to explanations of bioinformatics concepts, tools and platforms - &lt;a href=&#34;https://github.com/lynnlangit/TeamTeri&#34;&gt;link&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h3&gt;Contibutions&lt;/h3&gt; &#xA;&lt;p&gt;We love contributions! See this &lt;a href=&#34;https://github.com/lynnlangit/gcp-for-bioinformatics/raw/master/CONTRIBUTING.md&#34;&gt;short style guide&lt;/a&gt; when making pull requests to this repo.&lt;/p&gt; &#xA;&lt;hr&gt;</summary>
  </entry>
</feed>