<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-09-10T01:38:14Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>aangelopoulos/conformal-prediction</title>
    <updated>2022-09-10T01:38:14Z</updated>
    <id>tag:github.com,2022-09-10:/aangelopoulos/conformal-prediction</id>
    <link href="https://github.com/aangelopoulos/conformal-prediction" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Lightweight, useful implementation of conformal prediction on real data.&lt;/p&gt;&lt;hr&gt;&lt;h1 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Conformal Prediction&lt;/h1&gt; &#xA;&lt;h3 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;rigorous uncertainty quantification for any machine learning task&lt;/h3&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://arxiv.org/abs/2107.07511&#34; alt=&#34;arXiv&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/paper-arXiv-red&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://people.eecs.berkeley.edu/%7Eangelopoulos/blog/posts/gentle-intro&#34; alt=&#34;website&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/website-Berkeley-yellow&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34; alt=&#34;package management&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/conda-env-green&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://opensource.org/licenses/MIT&#34; alt=&#34;License&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://www.youtube.com/watch?v=nql000Lu_iE&#34; alt=&#34;arXiv&#34;&gt;&lt;img src=&#34;https://img.shields.io/youtube/views/nql000Lu_iE?style=social&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://twitter.com/ml_angelopoulos?ref_src=twsrc%5Etfw&#34; alt=&#34;package management&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/ml_angelopoulos?style=social&#34;&gt;&lt;/a&gt; &lt;a style=&#34;text-decoration:none !important;&#34; href=&#34;https://twitter.com/stats_stephen&#34; alt=&#34;package management&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/stats_stephen?style=social&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt; This repository is the easiest way to start using conformal prediction on real data. Each of the &lt;code&gt;notebooks&lt;/code&gt; applies conformal prediction to a real prediction problem with a state-of-the-art machine learning model. &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;No need to download the model or data in order to run conformal&lt;/b&gt;&lt;/p&gt; &#xA;&lt;p&gt; Raw model outputs for several large-scale real-world datasets and a small amount of sample data from each dataset are downloaded automatically by the notebooks. You can develop and test conformal prediction methods entirely in this sandbox, without ever needing to run the original model or download the original data. Open a notebook to see the expected output. You can use these notebooks to experiment with existing methods or as templates to develop your own. &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Example notebooks&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/imagenet-smallest-sets.ipynb&#34;&gt;&lt;code&gt;notebooks/imagenet-smallest-sets.ipynb&lt;/code&gt;&lt;/a&gt;: Imagenet classification with a ResNet152 classifier. Prediction sets guaranteed to contain the true class with 90% probability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/meps-cqr.ipynb&#34;&gt;&lt;code&gt;notebooks/meps-cqr.ipynb&lt;/code&gt;&lt;/a&gt;: Medical expenditure regression with a Gradient Boosting Regressor and conformalized quantile regression. Prediction intervals guaranteed to contain the true dollar value with 90% probability.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/multilabel-classification-mscoco.ipynb&#34;&gt;&lt;code&gt;notebooks/multilabel-classification-mscoco.ipynb&lt;/code&gt;&lt;/a&gt;: Multilabel image classification on the Microsoft Common Objects in Context (MS-COCO) dataset. Set-valued prediction is guaranteed to contain 90% of the ground truth classes.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/toxic-text-outlier-detection.ipynb&#34;&gt;&lt;code&gt;notebooks/toxic-text-outlier-detection.ipynb&lt;/code&gt;&lt;/a&gt;: Detecting toxic or hateful online comments via conformal outlier detection. No more than 10% of in-distribution data will get flagged as toxic.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/tumor-segmentation.ipynb&#34;&gt;&lt;code&gt;notebooks/tumor-segmentation.ipynb&lt;/code&gt;&lt;/a&gt;: Segmenting gut polyps from endoscopy images. Segmentation masks contain 90% of the ground truth tumor pixels.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/weather-time-series-distribution-shift.ipynb&#34;&gt;&lt;code&gt;notebooks/weather-time-series-distribution-shift&lt;/code&gt;&lt;/a&gt;: Predicting future temperatures around the world using time-series data and weighted conformal prediction. Prediction intervals contaion 90% of true temperatures.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aangelopoulos/conformal-prediction/raw/main/notebooks/imagenet-selective-classification.ipynb&#34;&gt;&lt;code&gt;notebooks/imagenet-selective-classification.ipynb&lt;/code&gt;&lt;/a&gt;: When the Imagenet classifier is unsure, it will abstain. Otherwise, it will have an accuracy of 90%, even though the base model was only 77% accurate.&lt;/li&gt; &#xA; &lt;li&gt;...and more!&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Notebooks can be run immediately using the provided Google Colab links&lt;/h3&gt; &#xA;&lt;h5 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Colab links are in the top cell of each notebook&lt;/h5&gt; &#xA;&lt;p&gt; To run these notebooks locally, you just need to have the correct dependencies installed and press &lt;code&gt;run all cells&lt;/code&gt;! The notebooks will automatically download all required data and model outputs. You will need 1.5GB of space on your computer in order for the notebook to store the auto-downloaded data. If you want to see how we generated the precomputed model outputs and data subsamples, see the files in &lt;code&gt;generation-scripts&lt;/code&gt;. There is one for each dataset. To create a &lt;code&gt;conda&lt;/code&gt; environment with the correct dependencies, run &lt;code&gt;conda env create -f environment.yml&lt;/code&gt;. If you still get a dependency error, make sure to activate the &lt;code&gt;conformal&lt;/code&gt; environment within the Jupyter notebook. &lt;/p&gt; &#xA;&lt;h3 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Citation&lt;/h3&gt; &#xA;&lt;p&gt; This repository is meant to accompany our paper, the &lt;a href=&#34;https://arxiv.org/abs/2107.07511&#34;&gt;Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification&lt;/a&gt;. In that paper is a detailed explanation of each example and attributions. If you find this repository useful, in addition to the relevant methods and datasets, please cite: &lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@article{angelopoulos2021gentle,&#xA;  title={A gentle introduction to conformal prediction and distribution-free uncertainty quantification},&#xA;  author={Angelopoulos, Anastasios N and Bates, Stephen},&#xA;  journal={arXiv preprint arXiv:2107.07511},&#xA;  year={2021}&#xA;}&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;Videos&lt;/h3&gt; If you&#39;re interested in learning about conformal prediction in video form, watch our videos below! &#xA;&lt;h4 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;A Tutorial on Conformal Prediction&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nql000Lu_iE&#34;&gt; &lt;img width=&#34;350&#34; src=&#34;https://img.youtube.com/vi/nql000Lu_iE/maxresdefault.jpg&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;A Tutorial on Conformal Prediction Part 2: Conditional Coverage&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=TRx4a2u-j7M&#34;&gt; &lt;img width=&#34;350&#34; src=&#34;https://img.youtube.com/vi/TRx4a2u-j7M/maxresdefault.jpg&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4 align=&#34;center&#34; style=&#34;margin-bottom:0px; border-bottom:0px; padding-bottom:0px&#34;&gt;A Tutorial on Conformal Prediction Part 3: Beyond Conformal Prediction&lt;/h4&gt; &#xA;&lt;p align=&#34;center&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=37HKrmA5gJE&#34;&gt; &lt;img width=&#34;350&#34; src=&#34;https://img.youtube.com/vi/37HKrmA5gJE/maxresdefault.jpg&#34;&gt; &lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>rasbt/python-machine-learning-book-2nd-edition</title>
    <updated>2022-09-10T01:38:14Z</updated>
    <id>tag:github.com,2022-09-10:/rasbt/python-machine-learning-book-2nd-edition</id>
    <link href="https://github.com/rasbt/python-machine-learning-book-2nd-edition" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The &#34;Python Machine Learning (2nd edition)&#34; book code repository and info resource&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;Python Machine Learning (2nd Ed.) Code Repository&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://travis-ci.com/rasbt/python-machine-learning-book-2nd-edition&#34;&gt;&lt;img src=&#34;https://travis-ci.com/rasbt/python-machine-learning-book-2nd-edition.svg?token=zvSsJVLJFKzB2yqaeKN1&amp;amp;branch=master&#34; alt=&#34;Build Status&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/badge/Python-3.6-blue.svg?sanitize=true&#34; alt=&#34;Python 3.6&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Code%20License-MIT-blue.svg?sanitize=true&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;Please note that a new edition (3rd edition) is now available as of December 2019. The code repository link for the 3rd edition is &lt;a href=&#34;https://github.com/rasbt/python-machine-learning-book-3rd-edition&#34;&gt;https://github.com/rasbt/python-machine-learning-book-3rd-edition&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Python Machine Learning, 2nd Ed.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;published September 20th, 2017&lt;/p&gt; &#xA;&lt;p&gt;Paperback: 622 pages&lt;br&gt; Publisher: Packt Publishing&lt;br&gt; Language: English&lt;/p&gt; &#xA;&lt;p&gt;ISBN-10: 1787125939&lt;br&gt; ISBN-13: 978-1787125933&lt;br&gt; Kindle ASIN: B0742K7HYF&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/images/cover_1.jpg&#34; width=&#34;348&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939&#34;&gt;Amazon Page&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition&#34;&gt;Packt Page&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Table of Contents and Code Notebooks&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Helpful installation and setup instructions can be found in the &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch01/README.md&#34;&gt;README.md file of Chapter 1&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;To access the code materials for a given chapter, simply click on the &lt;code&gt;open dir&lt;/code&gt; links next to the chapter headlines to navigate to the chapter subdirectories located in the &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/&#34;&gt;code/&lt;/a&gt; subdirectory. You can also click on the &lt;code&gt;ipynb&lt;/code&gt; links below to open and view the Jupyter notebook of each chapter directly on GitHub.&lt;/p&gt; &#xA;&lt;p&gt;In addition, the &lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/&#34;&gt;code/&lt;/a&gt; subdirectories also contain .py script files, which were created from the Jupyter Notebooks. However, I highly recommend working with the Jupyter notebook if possible in your computing environment. Not only do the Jupyter notebooks contain the images and section headings for easier navigation, but they also allow for a stepwise execution of individual code snippets, which -- in my opinion -- provide a better learning experience.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Please note that these are just the code examples accompanying the book, which I uploaded for your convenience; be aware that these notebooks may not be useful without the formulae and descriptive text.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Machine Learning - Giving Computers the Ability to Learn from Data [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch01&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch01/ch01.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Training Machine Learning Algorithms for Classification [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch02&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch02/ch02.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;A Tour of Machine Learning Classifiers Using Scikit-Learn [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch03&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch03/ch03.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Building Good Training Sets – Data Pre-Processing [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch04&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch04/ch04.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Compressing Data via Dimensionality Reduction [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch05&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch05/ch05.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Learning Best Practices for Model Evaluation and Hyperparameter Optimization [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch06&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch06/ch06.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Combining Different Models for Ensemble Learning [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch07&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch07/ch07.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Applying Machine Learning to Sentiment Analysis [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch08&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch08/ch08.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Embedding a Machine Learning Model into a Web Application [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch09&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch09/ch09.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Predicting Continuous Target Variables with Regression Analysis [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch10/ch10.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Working with Unlabeled Data – Clustering Analysis [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch11&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch11/ch11.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Implementing a Multi-layer Artificial Neural Network from Scratch [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch12&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch12/ch12.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Parallelizing Neural Network Training with TensorFlow [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch13&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch13/ch13.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Going Deeper: The Mechanics of TensorFlow [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch14&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch14/ch14.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Classifying Images with Deep Convolutional Neural Networks [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch15&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch15/ch15.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA; &lt;li&gt;Modeling Sequential Data Using Recurrent Neural Networks [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch16&#34;&gt;open dir&lt;/a&gt;] [&lt;a href=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/code/ch16/ch16.ipynb&#34;&gt;ipynb&lt;/a&gt;]&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h3&gt;What’s new in the second edition from the first edition?&lt;/h3&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Oh, there are so many things that we improved or added; where should I start!? The one issue on top of my priority list was to fix all the nasty typos that were introduced during the layout stage or my oversight. I really appreciated all the helpful feedback from readers in this manner! Furthermore, I addressed all the feedback about sections that may have been confusing or a bit unclear, reworded paragraphs, and added additional explanations. Also, special thanks go to the excellent editors of the second edition, who helped a lot along the way!&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Also, the figures and plots became much prettier. While readers liked the graphic content a lot, some people criticized the PowerPoint-esque style and layout. Thus, I decided to overhaul every little figure with a hopefully more pleasing choice of fonts and colors. Also, the data plots look much nicer now, thanks to the matplotlib team who put a lot of work in matplotlib 2.0 and its new styling theme.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;Beyond all these cosmetic fixes, new sections were added here and there. Among these is, for example, is a section on dealing with imbalanced datasets, which several readers were missing in the first edition and short section on Latent Dirichlet Allocation among others.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;As time and the software world moved on after the first edition was released in September 2015, we decided to replace the introduction to deep learning via Theano. No worries, we didn&#39;t remove it but it got a substantial overhaul and is now based on TensorFlow, which has become a major player in my research toolbox since its open source release by Google in November 2015. Along with the new introduction to deep learning using TensorFlow, the biggest additions to this new edition are three brand new chapters focussing on deep learning applications: A more detailed overview of the TensorFlow mechanics, an introduction to convolutional neural networks for image classification, and an introduction to recurrent neural networks for natural language processing. Of course, and in a similar vein as the rest of the book, these new chapters do not only provide readers with practical instructions and examples but also introduce the fundamental mathematics behind those concepts, which are an essential building block for understanding how deep learning works.&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;[ &lt;a href=&#34;https://www.packtpub.com/books/content/machine-learning-useful-every-problem-domain-interview-sebastian-raschka/&#34;&gt;Excerpt from &#34;Machine Learning can be useful in almost every problem domain:&#34; An interview with Sebastian Raschka&lt;/a&gt; ]&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;br&gt; &#xA;&lt;br&gt; &#xA;&lt;p&gt;Raschka, Sebastian, and Vahid Mirjalili. &lt;em&gt;Python Machine Learning, 2nd Ed&lt;/em&gt;. Packt Publishing, 2017.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;@book{RaschkaMirjalili2017,  &#xA;address = {Birmingham, UK},  &#xA;author = {Raschka, Sebastian and Mirjalili, Vahid},  &#xA;edition = {2},  &#xA;isbn = {978-1787125933},  &#xA;keywords = {Clustering,Data Science,Deep Learning,  &#xA;            Machine Learning,Neural Networks,Programming,  &#xA;            Supervised Learning},  &#xA;publisher = {Packt Publishing},  &#xA;title = {{Python Machine Learning, 2nd Ed.}},  &#xA;year = {2017}  &#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Translations&lt;/h1&gt; &#xA;&lt;h3&gt;German&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ISBN-10: 3958457339&lt;/li&gt; &#xA; &lt;li&gt;ISBN-13: 978-3958457331&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.de/Machine-Learning-Python-Scikit-Learn-TensorFlow/dp/3958457339/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;amp;qid=1513601461&amp;amp;sr=8-5&#34;&gt;Amazon.de link&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mitp.de/IT-WEB/Programmierung/Machine-Learning-mit-Python-oxid.html&#34;&gt;Publisher link&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/images/cover-german.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Japanese&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ISBN-10: 4295003379&lt;/li&gt; &#xA; &lt;li&gt;ISBN-13: 978-4295003373&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.amazon.co.jp/Python-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5-impress-gear/dp/4295003379/ref=tmm_pap_swatch_0&#34;&gt;Amazon.co.jp link&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/rasbt/python-machine-learning-book-2nd-edition/master/images/cover-japanese.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>GeeveGeorge/Stable-Craiyon</title>
    <updated>2022-09-10T01:38:14Z</updated>
    <id>tag:github.com,2022-09-10:/GeeveGeorge/Stable-Craiyon</id>
    <link href="https://github.com/GeeveGeorge/Stable-Craiyon" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A colab notebook that combines Stable Diffusion + DALL-E Mini (Craiyon)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable-Craiyon&lt;/h1&gt; &#xA;&lt;p&gt;A colab notebook that combines Stable Diffusion + DALL-E Mini (Craiyon)&lt;/p&gt; &#xA;&lt;h2&gt;IMPORTANT : Read all the instructions inside the Colab Notebook without fail!&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1EIS7mAu4qcLsoEzQqREuxxaAX9Vmwt7H?usp=sharing&#34;&gt;Colab Demo&lt;/a&gt; for Stable Craiyon! &lt;a href=&#34;https://colab.research.google.com/drive/1EIS7mAu4qcLsoEzQqREuxxaAX9Vmwt7H?usp=sharing&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=7dbyqg7XSJ8&#34;&gt;Youtube Video Instruction&lt;/a&gt; for Stable Craiyon Tutorial &lt;a href=&#34;https://www.youtube.com/watch?v=7dbyqg7XSJ8&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white&#34; alt=&#34;google colab logo&#34;&gt;&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://i.ibb.co/VJKtSWj/Be-Funky-collage-1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>