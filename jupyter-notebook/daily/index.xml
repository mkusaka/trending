<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2022-10-06T01:34:18Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>microsoft/foldingdiff</title>
    <updated>2022-10-06T01:34:18Z</updated>
    <id>tag:github.com,2022-10-06:/microsoft/foldingdiff</id>
    <link href="https://github.com/microsoft/foldingdiff" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Diffusion models of protein structure; trigonometry and attention are all you need!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;foldingdiff - Diffusion model for protein backbone generation&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/psf/black&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true&#34; alt=&#34;Code style: black&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;We present a diffusion model for generating novel protein backbone structures. For more details, see our preprint on &lt;a href=&#34;https://arxiv.org/abs/2209.15611&#34;&gt;arXiv&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/microsoft/foldingdiff/main/plots/generated_0.gif&#34; alt=&#34;Animation of diffusion model protein folds over timesteps&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;p&gt;To install, clone this using &lt;code&gt;git clone&lt;/code&gt;. This software is written in Python, notably using PyTorch, PyTorch Lightning, and the HuggingFace transformers library. The required conda environment is defined within the &lt;code&gt;environment.yml&lt;/code&gt; file. To set this up, make sure you have conda (or &lt;a href=&#34;https://mamba.readthedocs.io/en/latest/index.html&#34;&gt;mamba&lt;/a&gt;) installed, clone this repository, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;conda env create -f environment.yml&#xA;conda activate foldingdiff&#xA;pip install -e ./  # make sure ./ is the dir including setup.py&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Downloading data&lt;/h3&gt; &#xA;&lt;p&gt;We require some data files not packaged on Git due to their large size. These are not required for sampling (as long as you are not using the &lt;code&gt;--testcomparison&lt;/code&gt; option, see below); this is required for training your own model. We provide a script in the &lt;code&gt;data&lt;/code&gt; dir to download requisite CATH data.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Download the CATH dataset&#xA;cd data  # Ensure that you are in the data subdirectory within the codebase&#xA;chmod +x download_cath.sh&#xA;./download_cath.sh&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Training models&lt;/h2&gt; &#xA;&lt;p&gt;To train your own model on the CATH dataset, use the script at &lt;code&gt;bin/train.py&lt;/code&gt; in combination with one of the json config files under &lt;code&gt;config_jsons&lt;/code&gt; (or write your own). An example usage of this is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python bin/train.py config_jsons/cath_full_angles_cosine.json --dryrun&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;By default, the training script will calculate the KL divergence at each timestep before starting training, which can be quite computationally expensive with more timesteps. To skip this, append the &lt;code&gt;--dryrun&lt;/code&gt; flag. The output of the model will be in the &lt;code&gt;results&lt;/code&gt; folder with the following major files present:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;results/&#xA;    - config.json           # Contains the config file for the huggingface BERT model itself&#xA;    - logs/                 # Contains the logs from training&#xA;    - models/               # Contains model checkpoints. By default we store the best 5 models by validation loss and the best 5 by training loss&#xA;    - training_args.json    # Full set of arguments, can be used to reproduce run&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Pre-trained models&lt;/h2&gt; &#xA;&lt;p&gt;We provide weights for a model trained on the CATH dataset. These weights are stored on HuggingFace model hub at &lt;a href=&#34;https://huggingface.co/wukevin/foldingdiff_cath&#34;&gt;wukevin/foldingdiff_cath&lt;/a&gt;. The following code snippet shows how to load this model, load data (assuming it&#39;s been downloaded), and perform a forward pass:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from huggingface_hub import snapshot_download&#xA;from torch.utils.data.dataloader import DataLoader&#xA;from foldingdiff import modelling&#xA;from foldingdiff import datasets as dsets&#xA;&#xA;# Load the model (files will be cached for future calls)&#xA;m = modelling.BertForDiffusion.from_dir(snapshot_download(&#34;wukevin/foldingdiff_cath&#34;))&#xA;&#xA;# Load dataset&#xA;# As part of loading, we try to compute internal angles in parallel. This may&#xA;# throw warnings like the following; this is normal.&#xA;# WARNING:root:Illegal values for omega in /home/*/projects/foldingdiff-main/data/cath/dompdb/2ebqA00 -- skipping&#xA;# After computing these once, the results are saved in a .pkl file under the&#xA;# foldingdiff source directory for faster loading in future calls.&#xA;clean_dset = dsets.CathCanonicalAnglesOnlyDataset(pad=128, trim_strategy=&#39;randomcrop&#39;)&#xA;noised_dset = dsets.NoisedAnglesDataset(clean_dset, timesteps=1000, beta_schedule=&#39;cosine&#39;)&#xA;dl = DataLoader(noised_dset, batch_size=32, shuffle=False)&#xA;x = iter(dl).next()&#xA;&#xA;# Forward pass&#xA;predicted_noise = m(x[&#39;corrupted&#39;], x[&#39;t&#39;], x[&#39;attn_mask&#39;])&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Sampling protein backbones&lt;/h2&gt; &#xA;&lt;p&gt;To sample protein backbones, use the script &lt;code&gt;bin/sample.py&lt;/code&gt;. Example commands to do this using the pretrained weights described above are as follows.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# To sample 10 backbones per length ranging from [50, 128) with a batch size of 512 - reproduces results in our manuscript&#xA;python ~/projects/foldingdiff/bin/sample.py -l 50 128 -n 10 -b 512 --device cuda:0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will run the trained model hosted at &lt;a href=&#34;https://huggingface.co/wukevin/foldingdiff_cath&#34;&gt;wukevin/foldingdiff_cath&lt;/a&gt; and generate sequences of varying lengths. If you wish to load the test dataset and include test chains in the generated plots, use the option &lt;code&gt;--testcomparison&lt;/code&gt;; note that this requires downloading the CATH dataset, see above. Running &lt;code&gt;sample.py&lt;/code&gt; will create the following directory structure in the diretory where it is run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;some_dir/&#xA;    - plots/            # Contains plots comparing the distribution of training/generated angles&#xA;    - sampled_angles/   # Contains .csv.gz files with the sampled angles&#xA;    - sampled_pdb/      # Contains .pdb files from converting the sampled angles to cartesian coordinates&#xA;    - model_snapshot/   # Contains a copy of the model used to produce results&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Not specifying a &lt;code&gt;--device&lt;/code&gt; will default to the first device &lt;code&gt;cuda:0&lt;/code&gt;; use &lt;code&gt;--device cpu&lt;/code&gt; to run on CPU (though this will be very slow). See the following table for runtimes from our machines.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;Device&lt;/th&gt; &#xA;   &lt;th&gt;Runtime estimates sampling 512 structures&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;Nvidia RTX 2080Ti&lt;/td&gt; &#xA;   &lt;td&gt;7 minutes&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;i9-9960X (16 physical cores)&lt;/td&gt; &#xA;   &lt;td&gt;2 hours&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;Maximum training similarity TM scores&lt;/h3&gt; &#xA;&lt;p&gt;After generating sequences, we can calculate TM-scores to evaluate the simliarity of the generated sequences and the original sequences. This is done using the script under &lt;code&gt;bin/tmscore_training.py&lt;/code&gt; and requires data to have been downloaded prior (see above).&lt;/p&gt; &#xA;&lt;h3&gt;Visualizing diffusion &#34;folding&#34; process&lt;/h3&gt; &#xA;&lt;p&gt;The above sampling code can also be run with the &lt;code&gt;--fullhistory&lt;/code&gt; flag to write an additional subdirectory &lt;code&gt;sample_history&lt;/code&gt; under each of the &lt;code&gt;sampled_angles&lt;/code&gt; and &lt;code&gt;sampled_pdb&lt;/code&gt; folders that contain pdb/csv files coresponding to each timestep in the sampling process. The pdb files, for example, can then be passed into the script under &lt;code&gt;foldingdiff/pymol_vis.py&lt;/code&gt; to generate a gif of the folding process (as shown above). An example command to do this is:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python ~/projects/foldingdiff/foldingdiff/pymol_vis.py pdb2gif -i sampled_pdb/sample_history/generated_0/*.pdb -o generated_0.gif&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; this script lives separately from other plotting code because it depends on PyMOL; feel free to install/activate your own installation of PyMOL for this.&lt;/p&gt; &#xA;&lt;h2&gt;Evaluating designability of generated backbones&lt;/h2&gt; &#xA;&lt;p&gt;One way to evaluate the quality of generated backbones is via their &#34;designability&#34;. This refers to whether or not we can design an amino acid chain that will fold into the designed backbone. To evaluate this, we use the &lt;a href=&#34;https://github.com/facebookresearch/esm&#34;&gt;ESM inverse folding model&lt;/a&gt; to generate residues that are predicted to fold into our generated backbone, and use &lt;a href=&#34;https://github.com/HeliXonProtein/OmegaFold&#34;&gt;OmegaFold&lt;/a&gt; to check whether that generated sequence actually does fold into a structure comparable to our backbone. (While prior backbone design works have used AlphaFold for their designability evaluations, this was previously done without providing AlphaFold with MSA information; OmegaFold is designed from the ground up to use sequence only, and is therefore better suited for this use case.)&lt;/p&gt; &#xA;&lt;h3&gt;Inverse folding with ESM&lt;/h3&gt; &#xA;&lt;p&gt;We use a different conda environment for this step; see &lt;a href=&#34;https://colab.research.google.com/github/facebookresearch/esm/blob/main/examples/inverse_folding/notebook.ipynb&#34;&gt;https://colab.research.google.com/github/facebookresearch/esm/blob/main/examples/inverse_folding/notebook.ipynb&lt;/a&gt; for setup details. We found that the following command works on our machines:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mamba create -n inverse python=3.9 pytorch cudatoolkit pyg -c pytorch -c conda-forge -c pyg&#xA;conda activate inverse&#xA;mamba install -c conda-forge biotite&#xA;pip install git+https://github.com/facebookresearch/esm.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After this, we &lt;code&gt;cd&lt;/code&gt; into the folder that contains the &lt;code&gt;sampled_pdb&lt;/code&gt; directory created by the prior step, and run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python ~/projects/foldingdiff/bin/pdb_to_residues_esm.py sampled_pdb -o esm_residues&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This creates a new folder, &lt;code&gt;esm_residues&lt;/code&gt; that contains 10 potential residues for each of the pdb files contained in &lt;code&gt;sampled_pdb&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Structural prediction with OmegaFold&lt;/h3&gt; &#xA;&lt;p&gt;We use &lt;a href=&#34;https://github.com/HeliXonProtein/OmegaFold&#34;&gt;OmegaFold&lt;/a&gt; to fold the amino acid sequences produced above. After creating and activating a separate conda environment and following the authors&#39; instructions for installing OmegaFold, we use the following script to split our input amino acid fasta files across GPUs for inference, and subsequently calculate the self-consistency TM (scTM) scores.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Fold each fasta, spreading the work over GPUs 0 and 1, outputs to omegafold_predictions folder&#xA;python ~/projects/foldingdiff/bin/omegafold_across_gpus.py esm_residues/*.fasta -g 0 1&#xA;# Calculate the scTM scores; parallelizes across all CPUs&#xA;python ~/projects/foldingdiff/bin/omegafold_self_tm.py  # Requires no arguments&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;After executing these commands, the final command produces a json file of all scTM scores, as well as various pdf files containing plots and correlations of the scTM score distribution.&lt;/p&gt; &#xA;&lt;h2&gt;Tests&lt;/h2&gt; &#xA;&lt;p&gt;Tests are implemented through a mixture of doctests and unittests. To run unittests, run:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m unittest -v&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;You may see warnings like the following; these are expected.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WARNING:root:Illegal values for omega in protdiff-main/data/cath/dompdb/5a2qw00 -- skipping&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>