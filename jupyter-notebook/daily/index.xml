<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-11-18T01:35:51Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>openchatai/OpenCopilot</title>
    <updated>2023-11-18T01:35:51Z</updated>
    <id>tag:github.com,2023-11-18:/openchatai/OpenCopilot</id>
    <link href="https://github.com/openchatai/OpenCopilot" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ü§ñ üî• AI Copilot for your own SaaS product. Shopify Sidekick alternative.&lt;/p&gt;&lt;hr&gt;&lt;p&gt; &lt;img alt=&#34;GitHub Contributors&#34; src=&#34;https://img.shields.io/github/contributors/openchatai/opencopilot&#34;&gt; &lt;img alt=&#34;GitHub Last Commit&#34; src=&#34;https://img.shields.io/github/last-commit/openchatai/opencopilot&#34;&gt; &lt;img alt=&#34;&#34; src=&#34;https://img.shields.io/github/repo-size/openchatai/opencopilot&#34;&gt; &lt;img alt=&#34;GitHub Issues&#34; src=&#34;https://img.shields.io/github/issues/openchatai/opencopilot&#34;&gt; &lt;img alt=&#34;GitHub Pull Requests&#34; src=&#34;https://img.shields.io/github/issues-pr/openchatai/opencopilot&#34;&gt; &lt;img alt=&#34;Github License&#34; src=&#34;https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true&#34;&gt; &lt;a href=&#34;https://discord.gg/yjEgCgvefr&#34;&gt;&lt;img alt=&#34;Discord&#34; src=&#34;https://img.shields.io/discord/1111357170504699954&#34;&gt;&lt;/a&gt; &lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/openchatai/OpenCopilot/assets/32633162/a0cdc888-d2de-46b7-8c0b-96e876050b6e&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Documentation &lt;a href=&#34;https://docs.opencopilot.so&#34;&gt;available here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h1&gt;üî• OpenCopilot [early beta]&lt;/h1&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;OpenCopilot allows you to have your own product&#39;s AI copilot. It integrates with your underlying APIs and can execute API calls whenever needed. It uses LLMs to determine if the user&#39;s request requires calling an API endpoint. Then, it decides which endpoint to call and passes the appropriate payload based on the given API definition.&lt;/p&gt; &#xA;&lt;h2&gt;How does it work?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Provide your API/backend definition, including your public endpoints and how to call them. Currently, OpenCopilot supports Swagger OpenAPI 3.0. We&#39;re also working on a UI to allow you to dynamically add endpoints.&lt;/li&gt; &#xA; &lt;li&gt;OpenCopilot validates your schema to achieve the best results.&lt;/li&gt; &#xA; &lt;li&gt;We feed the API definition to an LLM.&lt;/li&gt; &#xA; &lt;li&gt;Finally, you can integrate our user-friendly chat bubble into your SaaS app.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openchatai/OpenCopilot/assets/32633162/0d9cfe4d-87f3-437e-b038-cf53c122d1d2&#34;&gt;https://github.com/openchatai/OpenCopilot/assets/32633162/0d9cfe4d-87f3-437e-b038-cf53c122d1d2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;(In this example, the user was able to add a new fish to the store just by text commands)&lt;/p&gt; &#xA;&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Make sure you have docker installed.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To begin, clone this Git repository:&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;git clone git@github.com:openchatai/OpenCopilot.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Update the &lt;code&gt;.env&lt;/code&gt; file located in the &lt;code&gt;llm-server&lt;/code&gt; directory with your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;. You can use the &lt;code&gt;.env.example&lt;/code&gt; file as a reference:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;OPENAI_API_KEY=YOUR_TOKEN_HERE&#xA;MYSQL_URI=mysql+pymysql://dbuser:dbpass@mysql:3306/opencopilot&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;hr&gt; &#xA;&lt;pre&gt;&lt;code&gt;make install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will install the necessary dependencies and set up the environment for the OpenCopilot project.&lt;/p&gt; &#xA;&lt;p&gt;Once the installation is complete, you can access the OpenCopilot console at &lt;a href=&#34;http://localhost:8888&#34;&gt;http://localhost:8888&lt;/a&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;If needed, you can also restart the local setup using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make restart&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Also, you can see the complete list of commands using&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;make help&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Try it out:&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;You can try it out on &lt;a href=&#34;http://opencopilot.so/&#34;&gt;opencopilot.so&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/openchatai/OpenCopilot/assets/32633162/3bf5c24d-572c-4a42-9e45-40f05e5a16b2&#34;&gt;https://github.com/openchatai/OpenCopilot/assets/32633162/3bf5c24d-572c-4a42-9e45-40f05e5a16b2&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=HVvbY7A7lIQ&#34;&gt;Watch this video from Shopify:&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=HVvbY7A7lIQ&#34; title=&#34;Video Title&#34;&gt;&lt;img src=&#34;https://github.com/openchatai/OpenCopilot/assets/32633162/edebbaa6-eba5-4f72-b88d-cf0d690fffa8&#34; alt=&#34;IMAGE ALT TEXT&#34;&gt;&lt;/a&gt; (OpenCopilot is not affiliated with Shopify, and they do not use OpenCopilot, it&#39;s just a demo of what copilots are capable of)&lt;/p&gt; &#xA;&lt;h2&gt;AI Copilot: a growing trend&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=HVvbY7A7lIQ&amp;amp;ab_channel=Shopify&#34;&gt;Shopify is developing &#34;Shopify Sidekick.&#34;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FCfwc-NNo30&amp;amp;ab_channel=MicrosoftDeveloper&#34;&gt;Microsoft is working on &#34;Windows Copilot.&#34;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/features/copilot&#34;&gt;GitHub is in the process of creating &#34;GitHub Copilot.&#34;&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/bing?form=MA13FV&#34;&gt;Microsoft is also developing &#34;Bing Copilot.&#34;&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Our goal is to empower every SaaS product with the ability to have their own AI copilots tailored for their unique products.&lt;/p&gt; &#xA;&lt;h2&gt;üèÅ What OpenCopilot can and can&#39;t do now?&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;It is capable of calling your underlying APIs.&lt;/li&gt; &#xA; &lt;li&gt;It can transform the response into meaningful text.&lt;/li&gt; &#xA; &lt;li&gt;It can automatically populate certain request payload fields based on the context. &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;For instance, you can request actions like: &#34;Initiate a new case about X problem,&#34; and the title field will be automatically filled with the appropriate name.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;It is not suitable for handling large APIs (you will need to write JSON transofrmers to make it work, refer to the docs for more)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üõ£Ô∏è Roadmap:&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Create unlimited copilots.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Embed the copilot on your SaaS product using standard JS calls.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; TypeScript chat bubble.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Provide Swagger definitions for your APIs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Swagger definition validator + recommender.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; UI endpoints editor.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Chat memory.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Vector DB support for large Swagger files.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Plugins system to support different types of authentications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Offline LLMs.&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Ability to ingest text data, PDF files, websites, and extra data sources.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;We love hearing from you! Got any cool ideas or requests? We&#39;re all ears! So, if you have something in mind, give us a shout!&lt;/p&gt; &#xA;&lt;h3&gt;Important links&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://editor.opencopilot.so&#34;&gt;OpenCopilot Flows Editor&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The backend server (API) is reachable via &lt;a href=&#34;http://localhost:8888/backend&#34;&gt;http://localhost:8888/backend&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The dashboard server is reachable via &lt;a href=&#34;http://localhost:8888/&#34;&gt;http://localhost:8888/&lt;/a&gt; or &lt;a href=&#34;http://localhost:8888/dashboard&#34;&gt;http://localhost:8888/dashboard&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;This project follows the &lt;a href=&#34;https://github.com/all-contributors/all-contributors&#34;&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind are welcome!&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>kharitonov-ivan/multi-object-tracking-in-python</title>
    <updated>2023-11-18T01:35:51Z</updated>
    <id>tag:github.com,2023-11-18:/kharitonov-ivan/multi-object-tracking-in-python</id>
    <link href="https://github.com/kharitonov-ivan/multi-object-tracking-in-python" rel="alternate"></link>
    <summary type="html">&lt;p&gt;üì° implementation of multi object tracking algorithms including PMBM (Poisson Multi Bernoulli Mixture filter) in Python üêç&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Multi-Object-Tracking-in-python&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.python.org/downloads/release/python-3100/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.10-blue.svg?sanitize=true&#34; alt=&#34;Python 3.10&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;This repository contains implementation of various multi-object trackers.&lt;/p&gt; &#xA;&lt;p&gt;In addition, it includes is tutorial with goal to demonstrate principles of work this trackers in educational proposes. It is unfluenced by the Multiple Object Tracking course in Chalmers and Edx &lt;a href=&#34;https://www.youtube.com/channel/UCa2-fpj6AV8T6JK1uTRuFpw/featured&#34;&gt;youtube üì∫&lt;/a&gt; and MATLAB open sourced implementations.&lt;/p&gt; &#xA;&lt;p&gt;You can dive into in tutorial notebook (locally or in colab). Or explore code explicitly. &lt;a target=&#34;_blank&#34; href=&#34;https://colab.research.google.com/github/kharitonov-ivan/multi-object-tracking-in-python/blob/main/tutorial-mot.ipynb&#34;&gt; &lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt; &lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Using in virtualenv&lt;/h1&gt; &#xA;&lt;p&gt;Firstly, you need install Eigen3 in your system.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3.10 -m venv .venv&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;source .venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m pip install -e .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Development&lt;/h1&gt; &#xA;&lt;p&gt;As a dependencies package manager this project use PDM.&lt;/p&gt; &#xA;&lt;p&gt;Install pre-commit&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pre-commit install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Single Object tracking&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;pytest tests/SOT/&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kharitonov-ivan/Multi-Object-Tracking-in-python/main/images/scenario-gifs/SOT_PDA.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Tracking with fixed number of objects&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;pytest tests/MOT&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kharitonov-ivan/Multi-Object-Tracking-in-python/main/images/scenario-gifs/NMOT-GNN.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Multi object tracking with Probability Hypothesis Density filter&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;pytest tests/PHD&lt;/code&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Multi object tracking with Poisson Multi Bernoulli Mixture filter&lt;/h1&gt; &#xA;&lt;p&gt;&lt;code&gt;pytest tests/PMBM&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kharitonov-ivan/Multi-Object-Tracking-in-python/main/images/scenario-gifs/MOT-PMBM.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/kharitonov-ivan/Multi-Object-Tracking-in-python/main/tests/PMBM/.images/PMBM-many_objects_linear_motion_delayed-P_S%3D0.99-P_D%3D0.9-lambda_c%3D10.0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>run-llama/llama-hub</title>
    <updated>2023-11-18T01:35:51Z</updated>
    <id>tag:github.com,2023-11-18:/run-llama/llama-hub</id>
    <link href="https://github.com/run-llama/llama-hub" rel="alternate"></link>
    <summary type="html">&lt;p&gt;A library of data loaders for LLMs made by the community -- to be used with GPT Index and/or LangChain&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;LlamaHub ü¶ô&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;Original creator&lt;/strong&gt;: Jesse Zhang (GH: &lt;a href=&#34;https://github.com/emptycrown&#34;&gt;emptycrown&lt;/a&gt;, Twitter: &lt;a href=&#34;https://twitter.com/thejessezhang&#34;&gt;@thejessezhang&lt;/a&gt;), who courteously donated the repo to LlamaIndex!&lt;/p&gt; &#xA;&lt;p&gt;This is a simple library of all the data loaders / readers / tools that have been created by the community. The goal is to make it extremely easy to connect large language models to a large variety of knowledge sources. These are general-purpose utilities that are meant to be used in &lt;a href=&#34;https://github.com/run-llama/llama_index&#34;&gt;LlamaIndex&lt;/a&gt; and &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Loaders and readers allow you to easily ingest data for search and retrieval by a large language model, while tools allow the models to both read and write to third party data services and sources. Ultimately, this allows you to create your own customized data agent to intelligently work with you and your data to unlock the full capability of next level large language models.&lt;/p&gt; &#xA;&lt;p&gt;For a variety of examples of data agents, see the &lt;a href=&#34;https://github.com/emptycrown/llama-hub/tree/main/llama_hub/tools/notebooks&#34;&gt;notebooks directory&lt;/a&gt;. You can find example Jupyter notebooks for creating data agents that can load and parse data from Google Docs, SQL Databases, Notion, and Slack, and also manage your Google Calendar, and Gmail inbox, or read and use OpenAPI specs.&lt;/p&gt; &#xA;&lt;p&gt;For an easier way to browse the integrations available, check out the website here: &lt;a href=&#34;https://llamahub.ai/&#34;&gt;https://llamahub.ai/&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;img width=&#34;1465&#34; alt=&#34;Screenshot 2023-07-17 at 6 12 32 PM&#34; src=&#34;https://github.com/ajhofmann/llama-hub/assets/10040285/5e344de4-4aca-4f6c-9944-46c00baa5eb2&#34;&gt; &#xA;&lt;h2&gt;Usage (Use &lt;code&gt;llama-hub&lt;/code&gt; as PyPI package)&lt;/h2&gt; &#xA;&lt;p&gt;These general-purpose loaders are designed to be used as a way to load data into &lt;a href=&#34;https://github.com/jerryjliu/llama_index&#34;&gt;LlamaIndex&lt;/a&gt; and/or subsequently used in &lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Installation&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install llama-hub&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LlamaIndex&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index import GPTVectorStoreIndex&#xA;from llama_hub.google_docs import GoogleDocsReader&#xA;&#xA;gdoc_ids = [&#39;1wf-y2pd9C878Oh-FmLH7Q_BQkljdm6TQal-c1pUfrec&#39;]&#xA;loader = GoogleDocsReader()&#xA;documents = loader.load_data(document_ids=gdoc_ids)&#xA;index = GPTVectorStoreIndex.from_documents(documents)&#xA;index.query(&#39;Where did the author go to school?&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LlamaIndex Data Agent&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index.agent import OpenAIAgent&#xA;import openai&#xA;openai.api_key = &#39;sk-api-key&#39;&#xA;&#xA;from llama_hub.tools.google_calendar import GoogleCalendarToolSpec&#xA;tool_spec = GoogleCalendarToolSpec()&#xA;&#xA;agent = OpenAIAgent.from_tools(tool_spec.to_tool_list())&#xA;agent.chat(&#39;what is the first thing on my calendar today&#39;)&#xA;agent.chat(&#34;Please create an event for tomorrow at 4pm to review pull requests&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;For a variety of examples of creating and using data agents, see the &lt;a href=&#34;https://github.com/emptycrown/llama-hub/tree/main/llama_hub/tools/notebooks&#34;&gt;notebooks directory&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;LangChain&lt;/h3&gt; &#xA;&lt;p&gt;Note: Make sure you change the description of the &lt;code&gt;Tool&lt;/code&gt; to match your use case.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index import GPTVectorStoreIndex&#xA;from llama_hub.google_docs import GoogleDocsReader&#xA;from langchain.llms import OpenAI&#xA;from langchain.chains.question_answering import load_qa_chain&#xA;&#xA;# load documents&#xA;gdoc_ids = [&#39;1wf-y2pd9C878Oh-FmLH7Q_BQkljdm6TQal-c1pUfrec&#39;]&#xA;loader = GoogleDocsReader()&#xA;documents = loader.load_data(document_ids=gdoc_ids)&#xA;langchain_documents = [d.to_langchain_format() for d in documents]&#xA;&#xA;# initialize sample QA chain&#xA;llm = OpenAI(temperature=0)&#xA;qa_chain = load_qa_chain(llm)&#xA;question=&#34;&amp;lt;query here&amp;gt;&#34;&#xA;answer = qa_chain.run(input_documents=langchain_documents, question=question)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Loader Usage (Use &lt;code&gt;download_loader&lt;/code&gt; from LlamaIndex)&lt;/h2&gt; &#xA;&lt;p&gt;You can also use the loaders with &lt;code&gt;download_loader&lt;/code&gt; from LlamaIndex in a single line of code.&lt;/p&gt; &#xA;&lt;p&gt;For example, see the code snippets below using the Google Docs Loader.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from llama_index import GPTVectorStoreIndex, download_loader&#xA;&#xA;GoogleDocsReader = download_loader(&#39;GoogleDocsReader&#39;)&#xA;&#xA;gdoc_ids = [&#39;1wf-y2pd9C878Oh-FmLH7Q_BQkljdm6TQal-c1pUfrec&#39;]&#xA;loader = GoogleDocsReader()&#xA;documents = loader.load_data(document_ids=gdoc_ids)&#xA;index = GPTVectorStoreIndex.from_documents(documents)&#xA;index.query(&#39;Where did the author go to school?&#39;)&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;How to add a loader or tool&lt;/h2&gt; &#xA;&lt;p&gt;Adding a loader or tool simply requires forking this repo and making a Pull Request. The Llama Hub website will update automatically. However, please keep in mind the following guidelines when making your PR.&lt;/p&gt; &#xA;&lt;h3&gt;Step 0: Setup virtual environment, install Poetry and dependencies&lt;/h3&gt; &#xA;&lt;p&gt;Create a new Python virtual environment. The command below creates an environment in &lt;code&gt;.venv&lt;/code&gt;, and activates it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -m venv .venv&#xA;source .venv/bin/activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;if you are in windows, use the following to activate your virtual environment:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;.venv\scripts\activate&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install poetry:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install poetry&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Install the required dependencies (this will also install &lt;code&gt;llama_index&lt;/code&gt;):&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;poetry install&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will create an editable install of &lt;code&gt;llama-hub&lt;/code&gt; in your venv.&lt;/p&gt; &#xA;&lt;h3&gt;Step 1: Create a new directory&lt;/h3&gt; &#xA;&lt;p&gt;For loaders, create a new directory in &lt;code&gt;llama_hub&lt;/code&gt;, and for tools create a directory in &lt;code&gt;llama_hub/tools&lt;/code&gt; It can be nested within another, but name it something unique because the name of the directory will become the identifier for your loader (e.g. &lt;code&gt;google_docs&lt;/code&gt;). Inside your new directory, create a &lt;code&gt;__init__.py&lt;/code&gt; file specifying the module&#39;s public interface with &lt;code&gt;__all__&lt;/code&gt;, a &lt;code&gt;base.py&lt;/code&gt; file which will contain your loader implementation, and, if needed, a &lt;code&gt;requirements.txt&lt;/code&gt; file to list the package dependencies of your loader. Those packages will automatically be installed when your loader is used, so no need to worry about that anymore!&lt;/p&gt; &#xA;&lt;p&gt;If you&#39;d like, you can create the new directory and files by running the following script in the &lt;code&gt;llama_hub&lt;/code&gt; directory. Just remember to put your dependencies into a &lt;code&gt;requirements.txt&lt;/code&gt; file.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;./add_loader.sh [NAME_OF_NEW_DIRECTORY]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Step 2: Write your README&lt;/h3&gt; &#xA;&lt;p&gt;Inside your new directory, create a &lt;code&gt;README.md&lt;/code&gt; that mirrors that of the existing ones. It should have a summary of what your loader or tool does, its inputs, and how it is used in the context of LlamaIndex and LangChain.&lt;/p&gt; &#xA;&lt;h3&gt;Step 3: Add your loader to the library.json file&lt;/h3&gt; &#xA;&lt;p&gt;Finally, add your loader to the &lt;code&gt;llama_hub/library.json&lt;/code&gt; file (for tools, add them to the &lt;code&gt;llama_hub/tools/library.json&lt;/code&gt;) so that it may be used by others. As is exemplified by the current file, add the class name of your loader or tool, along with its ID, author, etc. This file is referenced by the Llama Hub website and the download function within LlamaIndex.&lt;/p&gt; &#xA;&lt;h3&gt;Step 4: Make a Pull Request!&lt;/h3&gt; &#xA;&lt;p&gt;Create a PR against the main branch. We typically review the PR within a day. To help expedite the process, it may be helpful to provide screenshots (either in the PR or in the README directly) Show your data loader or tool in action!&lt;/p&gt; &#xA;&lt;h2&gt;Running tests&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;python3.9 -m venv .venv&#xA;source .venv/bin/activate &#xA;pip3 install -r test_requirements.txt&#xA;&#xA;poetry run pytest tests &#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Changelog&lt;/h2&gt; &#xA;&lt;p&gt;If you want to track the latest version updates / see which loaders are added to each release, take a look at our &lt;a href=&#34;https://github.com/emptycrown/llama-hub/raw/main/CHANGELOG.md&#34;&gt;full changelog here&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;FAQ&lt;/h2&gt; &#xA;&lt;h3&gt;How do I test my loader before it&#39;s merged?&lt;/h3&gt; &#xA;&lt;p&gt;There is an argument called &lt;code&gt;loader_hub_url&lt;/code&gt; in &lt;a href=&#34;https://github.com/jerryjliu/llama_index/raw/main/llama_index/readers/download.py&#34;&gt;&lt;code&gt;download_loader&lt;/code&gt;&lt;/a&gt; that defaults to the main branch of this repo. You can set it to your branch or fork to test your new loader.&lt;/p&gt; &#xA;&lt;h3&gt;Should I create a PR against LlamaHub or the LlamaIndex repo directly?&lt;/h3&gt; &#xA;&lt;p&gt;If you have a data loader PR, by default let&#39;s try to create it against LlamaHub! We will make exceptions in certain cases (for instance, if we think the data loader should be core to the LlamaIndex repo).&lt;/p&gt; &#xA;&lt;p&gt;For all other PR&#39;s relevant to LlamaIndex, let&#39;s create it directly against the &lt;a href=&#34;https://github.com/jerryjliu/llama_index&#34;&gt;LlamaIndex repo&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Other questions?&lt;/h3&gt; &#xA;&lt;p&gt;Feel free to hop into the &lt;a href=&#34;https://discord.gg/dGcwcsnxhU&#34;&gt;community Discord&lt;/a&gt; or tag the official &lt;a href=&#34;https://twitter.com/llama_index&#34;&gt;Twitter account&lt;/a&gt;!&lt;/p&gt;</summary>
  </entry>
</feed>