<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-03T01:40:49Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>World-of-ML/DL-Simplified</title>
    <updated>2023-06-03T01:40:49Z</updated>
    <id>tag:github.com,2023-06-03:/World-of-ML/DL-Simplified</id>
    <link href="https://github.com/World-of-ML/DL-Simplified" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Deep Learning Simplified is an Open-source repository, containing beginner to advance level deep learning projects for the contributors, who are willing to start their journey in Deep Learning. Devfolio URL, https://devfolio.co/projects/deep-learning-simplified-f013&lt;/p&gt;&lt;hr&gt;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;h1&gt;DEEP LEARNING SIMPLIFIED üíª&lt;span&gt;üß†&lt;/span&gt;&lt;/h1&gt; &#xA; &lt;h3&gt;Website for Deep Learning Simplified Repo: &lt;a href=&#34;https://tinyurl.com/deep-learning-simplified&#34;&gt;Click Here!üéØ&lt;/a&gt;&lt;/h3&gt; &#xA;&lt;/div&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;p&gt;&lt;img src=&#34;https://img.shields.io/github/contributors/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=blue&#34; alt=&#34;GitHub contributors&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-closed-raw/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=brightgreen&#34; alt=&#34;GitHub Closed issues&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-pr/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=aqua&#34; alt=&#34;GitHub PR Open&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/issues-pr-closed-raw/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=blue&#34; alt=&#34;GitHub PR closed&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/languages/count/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=brightgreen&#34; alt=&#34;GitHub language count&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/languages/top/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=aqua&#34; alt=&#34;GitHub top language&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/last-commit/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=blue&#34; alt=&#34;GitHub last commit&#34;&gt; &lt;img src=&#34;https://img.shields.io/badge/Maintained%3F-yes-brightgreen.svg?style=for-the-badge&#34; alt=&#34;GitHub Maintained&#34;&gt; &lt;img src=&#34;https://img.shields.io/github/repo-size/abhisheks008/DL-Simplified?style=for-the-badge&amp;amp;color=aqua&#34; alt=&#34;Github Repo Size&#34;&gt;&lt;/p&gt; &#xA;&lt;/div&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/World-of-ML/DL-Simplified/raw/main/.github/Assets/deep%20learning%20(2).png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;üî¥ Welcome contributors!&lt;/h2&gt; &#xA;&lt;p&gt;Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain‚Äîalbeit far from matching its ability‚Äîallowing it to ‚Äúlearn‚Äù from large amounts of data. Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. The concept of deep learning is not new. It has been around for a couple of years now. It‚Äôs on hype nowadays because earlier we did not have that much processing power and a lot of data. As in the last 20 years, the processing power increases exponentially, deep learning and machine learning came in the picture. &lt;br&gt; &lt;br&gt; &lt;strong&gt;Deep Learning Simplified is an Open-source repository, containing beginner to advance level deep learning projects for the contributors, who are willing to start their journey in Deep Learning.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Structure of the Projects üìù&lt;/h2&gt; &#xA;&lt;p&gt;This repository consists of various machine learning projects, and all of the projects must follow a certain template. I wish the contributors will take care of this while contributing in this repository. &lt;br&gt;&lt;br&gt; &lt;strong&gt;Dataset&lt;/strong&gt; - This folder stores the dataset used in this project. If the Dataset is not being able to uploaded in this folder due to the large size, then put a README.md file inside the Dataset folder and put the link of the collected dataset in it. That&#39;ll work!&lt;br&gt;&lt;br&gt; &lt;strong&gt;Images&lt;/strong&gt; - This folder is used to store the images generated during the data analysis, data visualization, data segmentation of the project.&lt;br&gt;&lt;br&gt; &lt;strong&gt;Model&lt;/strong&gt; - This folder would have your project file (that is .ipynb file) be it analysis or prediction. Other than project file, it should also have a &lt;strong&gt;&#39;README.md&#39;&lt;/strong&gt; using this &lt;a href=&#34;https://github.com/abhisheks008/DL-Simplified/raw/main/.github/readme_template.md&#34;&gt;template&lt;/a&gt; and &lt;strong&gt;&#39;requirements.txt&#39;&lt;/strong&gt; file which would be enclosed with all needed add-ons and libraries that are included in the project.&lt;br&gt;&lt;br&gt; Please follow the &lt;a href=&#34;https://github.com/abhisheks008/DL-Simplified/raw/main/Code_of_conduct.md&#34;&gt;Code of Conduct&lt;/a&gt; and &lt;a href=&#34;https://github.com/abhisheks008/DL-Simplified/raw/main/CONTRIBUTING.md&#34;&gt;Contributing Guidelines&lt;/a&gt; while contributing in this project repository.&lt;/p&gt; &#xA;&lt;h2&gt;üßÆ Workflow&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Go through the project repository and the &lt;a href=&#34;https://github.com/World-of-ML/DL-Simplified/raw/main/README.md&#34;&gt;README&lt;/a&gt; to get an idea about this repository.&lt;/li&gt; &#xA; &lt;li&gt;Check out the existing issues present there in the &lt;a href=&#34;https://github.com/World-of-ML/DL-Simplified/issues&#34;&gt;Issues&lt;/a&gt; section.&lt;/li&gt; &#xA; &lt;li&gt;Comment out in the issue, you wanna work on.&lt;/li&gt; &#xA; &lt;li&gt;Wait for the issue to be assigned to you. Once it&#39;s assigned to you, start working on it.&lt;/li&gt; &#xA; &lt;li&gt;Fork the repository.&lt;/li&gt; &#xA; &lt;li&gt;Clone your forked repository using terminal or gitbash. Also you can simply use the web version of GitHub to add your files.&lt;/li&gt; &#xA; &lt;li&gt;Make changes to the cloned repository.&lt;/li&gt; &#xA; &lt;li&gt;Add, Commit and Push.&lt;/li&gt; &#xA; &lt;li&gt;Then in Github, in your cloned repository find the option to make a pull request.&lt;/li&gt; &#xA; &lt;li&gt;Project admin will evaluate your PR and provide remarks accordingly. If it satisfies all the criterias, your PR will be merged and your contributions will be counted.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;‚ùÑÔ∏èOpen Source Programs!&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://swoc.getsocialnow.co/&#34;&gt;&lt;img src=&#34;https://media-exp1.licdn.com/dms/image/C560BAQGh8hr-FgbrHw/company-logo_200_200/0/1602422883512?e=2159024400&amp;amp;v=beta&amp;amp;t=s8IX2pN1J2v5SRRbgzVNzxnQ2rWeeMq2Xb__BYW60qE&#34; width=&#34;100px&#34; height=&#34;100px&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Social WoC 2023&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://ssoc.getsocialnow.co/#&#34;&gt;&lt;img src=&#34;https://github.com/abhisheks008/DL-Simplified/raw/main/.github/Assets/logo-1.jpg&#34; width=&#34;100px&#34; height=&#34;100px&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Social SoC 2022&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt; &lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt; &lt;a href=&#34;https://hack2skill.com/hack/ssoc&#34;&gt;&lt;img src=&#34;https://github.com/abhisheks008/DL-Simplified/raw/main/.github/Assets/logo-1.jpg&#34; width=&#34;100px&#34; height=&#34;100px&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Social SoC 2023&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;h2&gt;ü§î New to Open Source programs/events!&lt;/h2&gt; &#xA;&lt;p&gt;Here are few articles which will help you to get an idea on how you start contributing in open source projects, You can refer to the following articles on the basics of Git and Github.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/SYtPC9tHYyQ&#34;&gt;Watch this video to get started, if you have no clue about open source&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.github.com/en/github/getting-started-with-github/fork-a-repo&#34;&gt;Forking a Repo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.github.com/en/desktop/contributing-to-projects/creating-a-pull-request&#34;&gt;Cloning a Repo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://opensource.com/article/19/7/create-pull-request-github&#34;&gt;How to create a Pull Request&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/getting-started-with-git-and-github-6fcd0f2d4ac6&#34;&gt;Getting started with Git and GitHub&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;üèÜ Achievements of this Project Repo üéâ&lt;/h2&gt; &#xA;&lt;p&gt;&lt;span&gt;1‚É£&lt;/span&gt; &lt;strong&gt;Recognized as the &#34;ü•á TOP PROJECT ADMIN&#34; for Social Summer of Code, for the year 2022.&lt;/strong&gt; (&lt;strong&gt;39&lt;/strong&gt; brand new Deep Learning projects have been added throughout this journey!) &lt;br&gt; &lt;span&gt;2‚É£&lt;/span&gt; &lt;strong&gt;Recognized as the &#34;ü•á TOP PROJECT ADMIN&#34; for Social Winter of Code, for the year 2023.&lt;/strong&gt; (&lt;strong&gt;23&lt;/strong&gt; brand new Deep Learning projects have been added throughout this journey!)&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;‚úîProject Admin&lt;/h2&gt; &#xA;&lt;table&gt; &#xA; &lt;tbody&gt;&#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://github.com/abhisheks008&#34;&gt;&lt;img src=&#34;https://avatars.githubusercontent.com/u/68724349?v=4&#34; width=&#34;80px;&#34; alt=&#34;&#34;&gt;&lt;br&gt;&lt;sub&gt;&lt;b&gt;Abhishek Sharma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt;&#xA;&lt;/table&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;‚ú®Top Contributors&lt;/h2&gt; &#xA;&lt;p&gt;Thanks goes to these Wonderful People. Contributions of any kind are welcome!üöÄ&lt;/p&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; &#xA;&lt;!-- prettier-ignore-start --&gt; &#xA;&lt;!-- markdownlint-disable --&gt; &#xA;&lt;a href=&#34;https://github.com/abhisheks008/DL-Simplified/graphs/contributors&#34;&gt; &lt;img src=&#34;https://contrib.rocks/image?repo=abhisheks008/DL-Simplified&#34;&gt; &lt;/a&gt; &#xA;&lt;!-- markdownlint-enable --&gt; &#xA;&lt;!-- prettier-ignore-end --&gt; &#xA;&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;‚≠êGive this Project a Star&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/abhisheks008/&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/followers/abhisheks008.svg?label=Follow%20@abhisheks008&amp;amp;style=social&#34; alt=&#34;GitHub followers&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/abhishek_py3&#34;&gt;&lt;img src=&#34;https://img.shields.io/twitter/follow/abhishek_py3?style=social&#34; alt=&#34;Twitter Follow&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;If you liked working on this project, do ‚≠ê and share this repository.&lt;/p&gt; &#xA;&lt;p&gt;üéâ üéä üòÉ Happy Contributing üòÉ üéä üéâ&lt;/p&gt; &#xA;&lt;h2&gt;üì¨ Contact&lt;/h2&gt; &#xA;&lt;p&gt;If you want to contact me, you can reach me through social handles.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/abhishek_py3&#34;&gt;&lt;img src=&#34;https://seeklogo.com/images/T/twitter-icon-circle-blue-logo-0902F48837-seeklogo.com.png&#34; width=&#34;25&#34;&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href=&#34;https://www.linkedin.com/in/abhishek-sharma-aa06a9183/&#34;&gt;&lt;img src=&#34;https://www.felberpr.com/wp-content/uploads/linkedin-logo.png&#34; width=&#34;25&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;¬© 2023 Abhishek Sharma&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://forthebadge.com&#34;&gt;&lt;img src=&#34;https://forthebadge.com/images/badges/built-with-love.svg?sanitize=true&#34; alt=&#34;forthebadge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://forthebadge.com&#34;&gt;&lt;img src=&#34;https://forthebadge.com/images/badges/built-by-developers.svg?sanitize=true&#34; alt=&#34;forthebadge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://forthebadge.com&#34;&gt;&lt;img src=&#34;https://forthebadge.com/images/badges/built-with-swag.svg?sanitize=true&#34; alt=&#34;forthebadge&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>mix1009/sdwebuiapi</title>
    <updated>2023-06-03T01:40:49Z</updated>
    <id>tag:github.com,2023-06-03:/mix1009/sdwebuiapi</id>
    <link href="https://github.com/mix1009/sdwebuiapi" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Python API client for AUTOMATIC1111/stable-diffusion-webui&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;sdwebuiapi&lt;/h1&gt; &#xA;&lt;p&gt;API client for AUTOMATIC1111/stable-diffusion-webui&lt;/p&gt; &#xA;&lt;p&gt;Supports txt2img, img2img, extra-single-image, extra-batch-images API calls.&lt;/p&gt; &#xA;&lt;p&gt;API support have to be enabled from webui. Add --api when running webui. It&#39;s explained &lt;a href=&#34;https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;You can use --api-auth user1:pass1,user2:pass2 option to enable authentication for api access. (Since it&#39;s basic http authentication the password is transmitted in cleartext)&lt;/p&gt; &#xA;&lt;p&gt;API calls are (almost) direct translation from &lt;a href=&#34;http://127.0.0.1:7860/docs&#34;&gt;http://127.0.0.1:7860/docs&lt;/a&gt; as of 2022/11/21.&lt;/p&gt; &#xA;&lt;h1&gt;Install&lt;/h1&gt; &#xA;&lt;pre&gt;&lt;code&gt;pip install webuiapi&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Usage&lt;/h1&gt; &#xA;&lt;p&gt;webuiapi_demo.ipynb contains example code with original images. Images are compressed as jpeg in this document.&lt;/p&gt; &#xA;&lt;h2&gt;create API client&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;import webuiapi&#xA;&#xA;# create API client&#xA;api = webuiapi.WebUIApi()&#xA;&#xA;# create API client with custom host, port&#xA;#api = webuiapi.WebUIApi(host=&#39;127.0.0.1&#39;, port=7860)&#xA;&#xA;# create API client with custom host, port and https&#xA;#api = webuiapi.WebUIApi(host=&#39;webui.example.com&#39;, port=443, use_https=True)&#xA;&#xA;# create API client with default sampler, steps.&#xA;#api = webuiapi.WebUIApi(sampler=&#39;Euler a&#39;, steps=20)&#xA;&#xA;# optionally set username, password when --api-auth=username:password is set on webui.&#xA;# username, password are not protected and can be derived easily if the communication channel is not encrypted.&#xA;# you can also pass username, password to the WebUIApi constructor.&#xA;api.set_auth(&#39;username&#39;, &#39;password&#39;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;txt2img&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;result1 = api.txt2img(prompt=&#34;cute squirrel&#34;,&#xA;                    negative_prompt=&#34;ugly, out of frame&#34;,&#xA;                    seed=1003,&#xA;                    styles=[&#34;anime&#34;],&#xA;                    cfg_scale=7,&#xA;#                      sampler_index=&#39;DDIM&#39;,&#xA;#                      steps=30,&#xA;#                      enable_hr=True,&#xA;#                      hr_scale=2,&#xA;#                      hr_upscaler=webuiapi.HiResUpscaler.Latent,&#xA;#                      hr_second_pass_steps=20,&#xA;#                      hr_resize_x=1536,&#xA;#                      hr_resize_y=1024,&#xA;#                      denoising_strength=0.4,&#xA;&#xA;                    )&#xA;# images contains the returned images (PIL images)&#xA;result1.images&#xA;&#xA;# image is shorthand for images[0]&#xA;result1.image&#xA;&#xA;# info contains text info about the api call&#xA;result1.info&#xA;&#xA;# info contains paramteres of the api call&#xA;result1.parameters&#xA;&#xA;result1.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459205-258d75bb-d2b6-4882-ad22-040bfcf95626.jpg&#34; alt=&#34;txt2img&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;img2img&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;result2 = api.img2img(images=[result1.image], prompt=&#34;cute cat&#34;, seed=5555, cfg_scale=6.5, denoising_strength=0.6)&#xA;result2.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459294-ab1127e5-04e5-47ac-82b2-2bbd0648402a.jpg&#34; alt=&#34;img2img&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;img2img inpainting&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;from PIL import Image, ImageDraw&#xA;&#xA;mask = Image.new(&#39;RGB&#39;, result2.image.size, color = &#39;black&#39;)&#xA;# mask = result2.image.copy()&#xA;draw = ImageDraw.Draw(mask)&#xA;draw.ellipse((210,150,310,250), fill=&#39;white&#39;)&#xA;draw.ellipse((80,120,160,120+80), fill=&#39;white&#39;)&#xA;&#xA;mask&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459372-7850c6b6-27c5-435a-93e2-8710948d316a.jpg&#34; alt=&#34;mask&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;inpainting_result = api.img2img(images=[result2.image],&#xA;                                mask_image=mask,&#xA;                                inpainting_fill=1,&#xA;                                prompt=&#34;cute cat&#34;,&#xA;                                seed=104,&#xA;                                cfg_scale=5.0,&#xA;                                denoising_strength=0.7)&#xA;inpainting_result.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459398-9c1004be-1352-4427-bc00-442721a0e5a1.jpg&#34; alt=&#34;img2img_inpainting&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;extra-single-image&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;result3 = api.extra_single_image(image=result2.image,&#xA;                                 upscaler_1=webuiapi.Upscaler.ESRGAN_4x,&#xA;                                 upscaling_resize=1.5)&#xA;print(result3.image.size)&#xA;result3.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;(768, 768)&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459455-8579d740-3d8f-47f9-8557-cc177b3e99b7.jpg&#34; alt=&#34;extra_single_image&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;extra-batch-images&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;result4 = api.extra_batch_images(images=[result1.image, inpainting_result.image],&#xA;                                 upscaler_1=webuiapi.Upscaler.ESRGAN_4x,&#xA;                                 upscaling_resize=1.5)&#xA;result4.images[0]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459540-b0bd2931-93db-4d03-9cc1-a9f5e5c89745.jpg&#34; alt=&#34;extra_batch_images_1&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;result4.images[1]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/200459542-aa8547a0-f6db-436b-bec1-031a93a7b1d4.jpg&#34; alt=&#34;extra_batch_images_2&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Async API support&lt;/h3&gt; &#xA;&lt;p&gt;txt2img, img2img, extra_single_image, extra_batch_images support async api call with use_async=True parameter. You need asyncio, aiohttp packages installed.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;result = await api.txt2img(prompt=&#34;cute kitten&#34;,&#xA;                    seed=1001,&#xA;                    use_async=True&#xA;                    )&#xA;result.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Scripts support&lt;/h3&gt; &#xA;&lt;p&gt;Scripts from AUTOMATIC1111&#39;s Web UI are supported, but there aren&#39;t official models that define a script&#39;s interface.&lt;/p&gt; &#xA;&lt;p&gt;To find out the list of arguments that are accepted by a particular script look up the associated python file from AUTOMATIC1111&#39;s repo &lt;code&gt;scripts/[script_name].py&lt;/code&gt;. Search for its &lt;code&gt;run(p, **args)&lt;/code&gt; function and the arguments that come after &#39;p&#39; is the list of accepted arguments&lt;/p&gt; &#xA;&lt;h4&gt;Example for X/Y/Z Plot script:&lt;/h4&gt; &#xA;&lt;pre&gt;&lt;code&gt;(scripts/xyz_grid.py file from AUTOMATIC1111&#39;s repo)&#xA;&#xA;    def run(self, p, x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size):&#xA;    ...&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;List of accepted arguments:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;em&gt;x_type&lt;/em&gt;: Index of the axis for X axis. Indexes start from [0: Nothing]&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;x_values&lt;/em&gt;: String of comma-separated values for the X axis&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;y_type&lt;/em&gt;: Index of the axis type for Y axis. As the X axis, indexes start from [0: Nothing]&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;y_values&lt;/em&gt;: String of comma-separated values for the Y axis&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;z_type&lt;/em&gt;: Index of the axis type for Z axis. As the X axis, indexes start from [0: Nothing]&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;z_values&lt;/em&gt;: String of comma-separated values for the Z axis&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;draw_legend&lt;/em&gt;: &#34;True&#34; or &#34;False&#34;. IMPORTANT: It needs to be a string and not a Boolean value&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;include_lone_images&lt;/em&gt;: &#34;True&#34; or &#34;False&#34;. IMPORTANT: It needs to be a string and not a Boolean value&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;include_sub_grids&lt;/em&gt;: &#34;True&#34; or &#34;False&#34;. IMPORTANT: It needs to be a string and not a Boolean value&lt;/li&gt; &#xA; &lt;li&gt;&lt;em&gt;no_fixed_seeds&lt;/em&gt;: &#34;True&#34; or &#34;False&#34;. IMPORTANT: It needs to be a string and not a Boolean value&lt;/li&gt; &#xA; &lt;li&gt;margin_size: int value&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Available Axis options (Different for txt2img and img2img!)&#xA;XYZPlotAvailableTxt2ImgScripts = [&#xA;    &#34;Nothing&#34;,&#xA;    &#34;Seed&#34;,&#xA;    &#34;Var. seed&#34;,&#xA;    &#34;Var. strength&#34;,&#xA;    &#34;Steps&#34;,&#xA;    &#34;Hires steps&#34;,&#xA;    &#34;CFG Scale&#34;,&#xA;    &#34;Prompt S/R&#34;,&#xA;    &#34;Prompt order&#34;,&#xA;    &#34;Sampler&#34;,&#xA;    &#34;Checkpoint name&#34;,&#xA;    &#34;Sigma Churn&#34;,&#xA;    &#34;Sigma min&#34;,&#xA;    &#34;Sigma max&#34;,&#xA;    &#34;Sigma noise&#34;,&#xA;    &#34;Eta&#34;,&#xA;    &#34;Clip skip&#34;,&#xA;    &#34;Denoising&#34;,&#xA;    &#34;Hires upscaler&#34;,&#xA;    &#34;VAE&#34;,&#xA;    &#34;Styles&#34;,&#xA;]&#xA;&#xA;XYZPlotAvailableImg2ImgScripts = [&#xA;    &#34;Nothing&#34;,&#xA;    &#34;Seed&#34;,&#xA;    &#34;Var. seed&#34;,&#xA;    &#34;Var. strength&#34;,&#xA;    &#34;Steps&#34;,&#xA;    &#34;CFG Scale&#34;,&#xA;    &#34;Image CFG Scale&#34;,&#xA;    &#34;Prompt S/R&#34;,&#xA;    &#34;Prompt order&#34;,&#xA;    &#34;Sampler&#34;,&#xA;    &#34;Checkpoint name&#34;,&#xA;    &#34;Sigma Churn&#34;,&#xA;    &#34;Sigma min&#34;,&#xA;    &#34;Sigma max&#34;,&#xA;    &#34;Sigma noise&#34;,&#xA;    &#34;Eta&#34;,&#xA;    &#34;Clip skip&#34;,&#xA;    &#34;Denoising&#34;,&#xA;    &#34;Cond. Image Mask Weight&#34;,&#xA;    &#34;VAE&#34;,&#xA;    &#34;Styles&#34;,&#xA;]&#xA;&#xA;# Example call&#xA;XAxisType = &#34;Steps&#34;&#xA;XAxisValues = &#34;20,30&#34; &#xA;YAxisType = &#34;Sampler&#34;&#xA;YAxisValues = &#34;Euler a, LMS&#34;&#xA;ZAxisType = &#34;Nothing&#34;&#xA;ZAxisValues = &#34;&#34;&#xA;drawLegend = &#34;True&#34;&#xA;includeLoneImages = &#34;False&#34;&#xA;includeSubGrids = &#34;False&#34;&#xA;noFixedSeeds = &#34;False&#34;&#xA;marginSize = 0&#xA;&#xA;&#xA;# x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size&#xA;&#xA;result = api.txt2img(&#xA;                    prompt=&#34;cute girl with short brown hair in black t-shirt in animation style&#34;,&#xA;                    seed=1003,&#xA;                    script_name=&#34;X/Y/Z Plot&#34;,&#xA;                    script_args=[&#xA;                        XYZPlotAvailableTxt2ImgScripts.index(XAxisType),&#xA;                        XAxisValues,&#xA;                        XYZPlotAvailableTxt2ImgScripts.index(YAxisType),&#xA;                        YAxisValues,&#xA;                        XYZPlotAvailableTxt2ImgScripts.index(ZAxisType),&#xA;                        ZAxisValues,&#xA;                        drawLegend,&#xA;                        includeLoneImages,&#xA;                        includeSubGrids,&#xA;                        noFixedSeeds,&#xA;                        marginSize,                        ]&#xA;                    )&#xA;&#xA;result.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222345625-dc2e4090-6786-4a53-8619-700dc2f12412.jpg&#34; alt=&#34;txt2img_grid_xyz&#34;&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Configuration APIs&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# return map of current options&#xA;options = api.get_options()&#xA;&#xA;# change sd model&#xA;options = {}&#xA;options[&#39;sd_model_checkpoint&#39;] = &#39;model.ckpt [7460a6fa]&#39;&#xA;api.set_options(options)&#xA;&#xA;# when calling set_options, do not pass all options returned by get_options().&#xA;# it makes webui unusable (2022/11/21).&#xA;&#xA;# get available sd models&#xA;api.get_sd_models()&#xA;&#xA;# misc get apis&#xA;api.get_samplers()&#xA;api.get_cmd_flags()      &#xA;api.get_hypernetworks()&#xA;api.get_face_restorers()&#xA;api.get_realesrgan_models()&#xA;api.get_prompt_styles()&#xA;api.get_artist_categories() # deprecated ?&#xA;api.get_artists() # deprecated ?&#xA;api.get_progress()&#xA;api.get_embeddings()&#xA;api.get_cmd_flags()&#xA;api.get_scripts()&#xA;api.get_memory()&#xA;&#xA;# misc apis&#xA;api.interrupt()&#xA;api.skip()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Utility methods&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# save current model name&#xA;old_model = api.util_get_current_model()&#xA;&#xA;# get list of available models&#xA;models = api.util_get_model_names()&#xA;&#xA;# set model (use exact name)&#xA;api.util_set_model(models[0])&#xA;&#xA;# set model (find closest match)&#xA;api.util_set_model(&#39;robodiffusion&#39;)&#xA;&#xA;# wait for job complete&#xA;api.util_wait_for_ready()&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;LORA and alwayson_scripts example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;r = api.txt2img(prompt=&#39;photo of a cute girl with green hair &amp;lt;lora:Moxin_10:0.6&amp;gt; shuimobysim __juice__&#39;,&#xA;                seed=1000,&#xA;                save_images=True,&#xA;                alwayson_scripts={&#34;Simple wildcards&#34;:[]} # wildcards extension doesn&#39;t accept more parameters.&#xA;               )&#xA;r.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extension support - Model-Keyword&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# https://github.com/mix1009/model-keyword&#xA;mki = webuiapi.ModelKeywordInterface(api)&#xA;mki.get_keywords()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;ModelKeywordResult(keywords=[&#39;nousr robot&#39;], model=&#39;robo-diffusion-v1.ckpt&#39;, oldhash=&#39;41fef4bd&#39;, match_source=&#39;model-keyword.txt&#39;)&lt;/p&gt; &#xA;&lt;h3&gt;Extension support - Instruct-Pix2Pix&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# Instruct-Pix2Pix extension is now deprecated and is now part of webui.&#xA;# You can use normal img2img with image_cfg_scale when instruct-pix2pix model is loaded.&#xA;r = api.img2img(prompt=&#39;sunset&#39;, images=[pil_img], cfg_scale=7.5, image_cfg_scale=1.5)&#xA;r.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Extension support - ControlNet&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code&gt;# https://github.com/Mikubill/sd-webui-controlnet&#xA;&#xA;api.controlnet_model_list()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&#xA;[&#39;control_v11e_sd15_ip2p [c4bb465c]&#39;,&#xA; &#39;control_v11e_sd15_shuffle [526bfdae]&#39;,&#xA; &#39;control_v11f1p_sd15_depth [cfd03158]&#39;,&#xA; &#39;control_v11p_sd15_canny [d14c016b]&#39;,&#xA; &#39;control_v11p_sd15_inpaint [ebff9138]&#39;,&#xA; &#39;control_v11p_sd15_lineart [43d4be0d]&#39;,&#xA; &#39;control_v11p_sd15_mlsd [aca30ff0]&#39;,&#xA; &#39;control_v11p_sd15_normalbae [316696f1]&#39;,&#xA; &#39;control_v11p_sd15_openpose [cab727d4]&#39;,&#xA; &#39;control_v11p_sd15_scribble [d4ba51ff]&#39;,&#xA; &#39;control_v11p_sd15_seg [e1f51eb9]&#39;,&#xA; &#39;control_v11p_sd15_softedge [a8575a2a]&#39;,&#xA; &#39;control_v11p_sd15s2_lineart_anime [3825e83e]&#39;,&#xA; &#39;control_v11u_sd15_tile [1f041471]&#39;]&#xA; &lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;api.controlnet_version()&#xA;api.controlnet_module_list()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;pre&gt;&lt;code&gt;# normal txt2img&#xA;r = api.txt2img(prompt=&#34;photo of a beautiful girl with blonde hair&#34;, height=512, seed=100)&#xA;img = r.image&#xA;img&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222315754-43c6dc8c-2a62-4a31-b51a-f68523118e0d.png&#34; alt=&#34;cn1&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# txt2img with ControlNet (used 1.0 but also supports 1.1)&#xA;unit1 = webuiapi.ControlNetUnit(input_image=img, module=&#39;canny&#39;, model=&#39;control_canny-fp16 [e3fe7712]&#39;)&#xA;&#xA;r = api.txt2img(prompt=&#34;photo of a beautiful girl&#34;, controlnet_units=[unit1])&#xA;r.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222315791-c6c480eb-2987-4044-b673-5f2cb6135f87.png&#34; alt=&#34;cn2&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;# img2img with multiple ControlNets (used 1.0 but also supports 1.1)&#xA;unit1 = webuiapi.ControlNetUnit(input_image=img, module=&#39;canny&#39;, model=&#39;control_canny-fp16 [e3fe7712]&#39;)&#xA;unit2 = webuiapi.ControlNetUnit(input_image=img, module=&#39;depth&#39;, model=&#39;control_depth-fp16 [400750f6]&#39;, weight=0.5)&#xA;&#xA;r2 = api.img2img(prompt=&#34;girl&#34;,&#xA;            images=[img], &#xA;            width=512,&#xA;            height=512,&#xA;            controlnet_units=[unit1, unit2],&#xA;            sampler_name=&#34;Euler a&#34;,&#xA;            cfg_scale=7,&#xA;           )&#xA;r2.image&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222315816-1155b0c2-570d-4455-a68e-294fc7061b0a.png&#34; alt=&#34;cn3&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;r2.images[1]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222315836-9a26afec-c407-426b-9a08-b2cef2a32ab1.png&#34; alt=&#34;cn4&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;r2.images[2]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1288793/222315859-e6b6286e-854d-40c1-a516-5a08c827c49a.png&#34; alt=&#34;cn5&#34;&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;r = api.controlnet_detect(images=[img], module=&#39;canny&#39;)&#xA;r.image&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>dream80/roop_colab</title>
    <updated>2023-06-03T01:40:49Z</updated>
    <id>tag:github.com,2023-06-03:/dream80/roop_colab</id>
    <link href="https://github.com/dream80/roop_colab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;ÂçïÂõæÔºå‰∏ÄÈîÆÔºåËßÜÈ¢ëÊç¢ËÑ∏ÔºÅ‰ΩøÁî®ColabËÑöÊú¨Ôºå‰∏çÁî®ÁÉßÊòæÂç°Ôºå‰∏çÁî®Ëí∏Ê°ëÊãøÔºÅ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;roop_colab&lt;/h1&gt; &#xA;&lt;p&gt;roop_colab &lt;img src=&#34;https://raw.githubusercontent.com/dream80/roop_colab/main/cmp.gif&#34; alt=&#34;demo&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://www.tonyisstark.com/1240.html&#34;&gt;tutorial&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
</feed>