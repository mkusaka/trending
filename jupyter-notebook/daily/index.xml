<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-01T01:40:55Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>vijishmadhavan/UnpromptedControl</title>
    <updated>2023-05-01T01:40:55Z</updated>
    <id>tag:github.com,2023-05-01:/vijishmadhavan/UnpromptedControl</id>
    <link href="https://github.com/vijishmadhavan/UnpromptedControl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Remove unwanted objects and restore images without prompts, powered by ControlNet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;UnpromptedControl&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;By sponsoring me, you&#39;re not just supporting my work - you&#39;re helping to create a more collaborative, innovative open source community üíñ &lt;a href=&#34;https://github.com/sponsors/vijishmadhavan?o=sd&amp;amp;sc=t&#34;&gt;sponsor&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://twitter.com/Vijish68859437&#34;&gt;Get more updates on Twitter&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;ControlNet is a highly regarded tool for guiding StableDiffusion models, and it has been widely acknowledged for its effectiveness. In this repository, A simple hack that allows for the restoration or removal of objects without requiring user prompts. By leveraging this approach, the workflow can be significantly streamlined, leading to enhanced process efficiency.&lt;/p&gt; &#xA;&lt;h2&gt;No-prompt&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/vijishmadhavan/UnpromptedControl/blob/master/UnpromptedControl.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; align=&#34;center&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/eg2gif.gif&#34; alt=&#34;restore Result&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/objgif.gif&#34; alt=&#34;restore Result&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Image Restoration&lt;/h2&gt; &#xA;&lt;p&gt;In this image restoration is accomplished using the controlnet-canny and stable-diffusion-2-inpainting techniques, with only &#34;&#34; blank input prompts. Additionally, for automatic scratch segmentation, the FT_Epoch_latest.pt model is being used. However, if the segmentation output is not satisfactory, it is possible to manually sketch and refine the mask to achieve better results. As ControlNet model is trained on pairs of images, one of which has missing parts, and it learns to predict the missing parts based on the content of the complete image.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/eg1.jpg&#34; alt=&#34;restore Result&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/eg2.jpg&#34; alt=&#34;restore Result&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Object Removal&lt;/h2&gt; &#xA;&lt;p&gt;Automatically removing objects from images is a challenging task that requires a combination of computer vision and deep learning techniques. This code leverages the power of OpenCV inpainting, deep learning-based image restoration, and blending techniques to achieve this task automatically, without the need for user prompts. The ControlNetModel and StableDiffusionInpaintPipeline models play a crucial role in guiding the inpainting process and restoring the image to a more natural-looking state. Overall, this code provides an efficient and effective way to remove unwanted objects from images and produce natural-looking results that are consistent with the surrounding image content.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;&#34;Surely, it has its limitations and might fail with certain images, especially those of faces, and may require some back and forth. To obtain good results, we need to mask not only the object but also its shadow.&#34;&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/obj2.jpg&#34; alt=&#34;restore Result&#34;&gt; &lt;img src=&#34;https://raw.githubusercontent.com/vijishmadhavan/UnpromptedControl/master/examples/obj1.jpg&#34; alt=&#34;restore Result&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Limitation&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Limited Generalization: The algorithm currently has limitations when it comes to processing images of people&#39;s faces and bodies. It may not work as expected for these types of images, and additional work is needed to improve its performance in these areas.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;When it comes to removing an object from an image, it&#39;s important to consider the surrounding environment and any elements that may be affected by the removal process. In some cases, removing an object may require the removal of a large area surrounding the object, including its shadows.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To obtain good results, we need to mask not only the object but also its shadow.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life&#34;&gt;https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life&lt;/a&gt; (Segmentation)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/thibaud/controlnet-sd21&#34;&gt;https://huggingface.co/thibaud/controlnet-sd21&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;https://github.com/lllyasviel/ControlNet&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>ardha27/AI-Song-Cover-SOVITS</title>
    <updated>2023-05-01T01:40:55Z</updated>
    <id>tag:github.com,2023-05-01:/ardha27/AI-Song-Cover-SOVITS</id>
    <link href="https://github.com/ardha27/AI-Song-Cover-SOVITS" rel="alternate"></link>
    <summary type="html">&lt;p&gt;All in One Version : Youtube WAV Download, Separating Vocal, Splitting Audio, Training, and Inference Using Google Colab&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI-Song-Cover-SOVITS&lt;/h1&gt; &#xA;&lt;p&gt;All in One Version : Youtube WAV Download, Separating Vocal, Splitting Audio, Training, and Inference Using Google Colab.&lt;/p&gt; &#xA;&lt;h2&gt;Leave A Star if This Repo Was Helpful&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/ardha27/AI-Song-Cover-SOVITS/blob/main/AI_Song_Cover_SOVITS.ipynb&#34;&gt;&lt;img src=&#34;https://colab.research.google.com/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open In Colab&#34;&gt;&lt;/a&gt;&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>hollowstrawberry/kohya-colab</title>
    <updated>2023-05-01T01:40:55Z</updated>
    <id>tag:github.com,2023-05-01:/hollowstrawberry/kohya-colab</id>
    <link href="https://github.com/hollowstrawberry/kohya-colab" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Accessible Google Colab notebooks for Stable Diffusion Lora training, based on the work of kohya-ss and Linaqruf&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kohya Colabs&lt;/h1&gt; &#xA;&lt;p&gt;Accessible Google Colab notebooks for Stable Diffusion Lora training, based on the work of &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;kohya-ss&lt;/a&gt; and &lt;a href=&#34;https://github.com/Linaqruf/kohya-trainer&#34;&gt;Linaqruf&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you like my work consider &lt;a href=&#34;https://ko-fi.com/holostrawberry&#34;&gt;leaving me a tip&lt;/a&gt; :)&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th align=&#34;left&#34;&gt;&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;üá¨üáß English&lt;/th&gt; &#xA;   &lt;th align=&#34;center&#34;&gt;üá™üá∏ Spanish&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;üìä &lt;strong&gt;Dataset Maker&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg?sanitize=true&#34; alt=&#34;Abrir en Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;‚≠ê &lt;strong&gt;Lora Trainer&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg?sanitize=true&#34; alt=&#34;Open in Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg?sanitize=true&#34; alt=&#34;Abrir en Colab&#34;&gt;&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Lora making Guide&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://civitai.com/models/22530&#34;&gt;Click Here&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;-&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Stable Diffusion guide&lt;/strong&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#index&#34;&gt;Click Here&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/spanish.md#index&#34;&gt;Click Aqu√≠&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h3&gt;üìä Dataset Maker - Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Able to scrape hundreds of images from the popular anime gallery &lt;a href=&#34;https://gelbooru.com/index.php?page=wiki&amp;amp;s=view&amp;amp;id=18780&#34;&gt;Gelbooru&lt;/a&gt;, that match the conditions set by the user.&lt;/li&gt; &#xA; &lt;li&gt;Finds duplicate images using the &lt;a href=&#34;https://docs.voxel51.com/&#34;&gt;FiftyOne&lt;/a&gt; open-source software.&lt;/li&gt; &#xA; &lt;li&gt;Displays the user&#39;s dataset back to them through the FiftyOne interface so that they may manually curate their images.&lt;/li&gt; &#xA; &lt;li&gt;Able to generate tags for all your anime images using the &lt;a href=&#34;https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2&#34;&gt;Waifu Diffusion 1.4 Tagger&lt;/a&gt; model.&lt;/li&gt; &#xA; &lt;li&gt;Able to generate captions for all your images using the &lt;a href=&#34;https://huggingface.co/spaces/Salesforce/BLIP&#34;&gt;BLIP&lt;/a&gt; model.&lt;/li&gt; &#xA; &lt;li&gt;Gives you the ability to edit hundreds of text files at once, to add/remove/replace tags inside them dynamically.&lt;/li&gt; &#xA; &lt;li&gt;Works inside your Google Drive by default.&lt;/li&gt; &#xA; &lt;li&gt;Connects easily with Lora Trainer.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;‚≠ê Lora Trainer - Features&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Can train LoRA, LoCon and LoHa.&lt;/li&gt; &#xA; &lt;li&gt;New feature: &lt;a href=&#34;https://arxiv.org/abs/2303.09556&#34;&gt;min-snr-gamma&lt;/a&gt;, optimizes loss to improve training efficiency.&lt;/li&gt; &#xA; &lt;li&gt;One click to install and start training.&lt;/li&gt; &#xA; &lt;li&gt;Offers all useful training parameters while keeping it simple and accessible.&lt;/li&gt; &#xA; &lt;li&gt;Helpful parameter descriptions and runtime messages.&lt;/li&gt; &#xA; &lt;li&gt;Can continue training an existing Lora (though not ideal).&lt;/li&gt; &#xA; &lt;li&gt;Advanced features in the form of custom configurations, allowing training with multiple datasets at once and more.&lt;/li&gt; &#xA; &lt;li&gt;Uses the latest technologies to load and train quickly.&lt;/li&gt; &#xA; &lt;li&gt;Utilizes &lt;a href=&#34;https://github.com/kohya-ss/sd-scripts&#34;&gt;kohya-ss scripts&lt;/a&gt; as a backend, an industry standard.&lt;/li&gt; &#xA; &lt;li&gt;Sources code from &lt;a href=&#34;https://github.com/Linaqruf/kohya-trainer&#34;&gt;Linaqruf&lt;/a&gt;&#39;s colabs. Thank you!&lt;/li&gt; &#xA; &lt;li&gt;Works inside your Google Drive by default.&lt;/li&gt; &#xA; &lt;li&gt;Connects easily with Dataset Maker.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/datasetmaker.png&#34; alt=&#34;Dataset Maker screenshot&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>