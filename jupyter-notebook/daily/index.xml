<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-01-14T01:38:22Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>facebookresearch/balance</title>
    <updated>2023-01-14T01:38:22Z</updated>
    <id>tag:github.com,2023-01-14:/facebookresearch/balance</id>
    <link href="https://github.com/facebookresearch/balance" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The balance python package offers a simple workflow and methods for dealing with biased data samples when looking to infer from them to some target population of interest.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://import-balance.org/&#34;&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/balance/main/website/static/img/balance_logo/PNG/Horizontal/balance_Logo_Horizontal_FullColor_RGB.png&#34; alt=&#34;balance_logo_horizontal&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;&lt;em&gt;balance&lt;/em&gt;: a python package for balancing biased data samples&lt;/h1&gt; &#xA;&lt;p&gt;&lt;em&gt;balance&lt;/em&gt; is currently &lt;strong&gt;in beta&lt;/strong&gt; and under active development. Follow us &lt;a href=&#34;https://github.com/facebookresearch/balance&#34;&gt;on github&lt;/a&gt;!&lt;/p&gt; &#xA;&lt;h2&gt;What is &lt;em&gt;balance&lt;/em&gt;?&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://import-balance.org/&#34;&gt;&lt;em&gt;balance&lt;/em&gt;&lt;/a&gt; is a Python package&lt;/strong&gt; offering a simple workflow and methods for &lt;strong&gt;dealing with biased data samples&lt;/strong&gt; when looking to infer from them to some population of interest.&lt;/p&gt; &#xA;&lt;p&gt;Biased samples often occur in &lt;a href=&#34;https://en.wikipedia.org/wiki/Survey_methodology&#34;&gt;survey statistics&lt;/a&gt; when respondents present &lt;a href=&#34;https://en.wikipedia.org/wiki/Participation_bias&#34;&gt;non-response bias&lt;/a&gt; or survey suffers from &lt;a href=&#34;https://en.wikipedia.org/wiki/Sampling_bias&#34;&gt;sampling bias&lt;/a&gt; (that are not &lt;a href=&#34;https://en.wikipedia.org/wiki/Missing_data#Missing_completely_at_random&#34;&gt;missing completely at random&lt;/a&gt;). A similar issue arises in &lt;a href=&#34;https://en.wikipedia.org/wiki/Observational_study&#34;&gt;observational studies&lt;/a&gt; when comparing the treated vs untreated groups, and in any data that suffers from selection bias.&lt;/p&gt; &#xA;&lt;p&gt;Under the missing at random assumption (&lt;a href=&#34;https://en.wikipedia.org/wiki/Missing_data#Missing_at_random&#34;&gt;MAR&lt;/a&gt;), bias in samples could sometimes be (at least partially) mitigated by relying on auxiliary information (a.k.a.: “covariates” or “features”) that is present for all items in the sample, as well as present in a sample of items from the population. For example, if we want to infer from a sample of respondents to some survey, we may wish to adjust for non-response using demographic information such as age, gender, education, etc. This can be done by weighing the sample to the population using auxiliary information.&lt;/p&gt; &#xA;&lt;p&gt;The package is intended for researchers who are interested in balancing biased samples, such as the ones coming from surveys, using a Python package. This need may arise by survey methodologists, demographers, UX researchers, market researchers, and generally data scientists, statisticiains, and machine learners.&lt;/p&gt; &#xA;&lt;h1&gt;Installation&lt;/h1&gt; &#xA;&lt;h2&gt;Requirements&lt;/h2&gt; &#xA;&lt;p&gt;You need Python 3.8 or later to run &lt;em&gt;balance&lt;/em&gt;. &lt;em&gt;balance&lt;/em&gt; can be built and run from OSX, Linux, and Windows&lt;/p&gt; &#xA;&lt;p&gt;The required Python dependencies are:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;REQUIRES = [&#xA;    &#34;numpy&#34;,&#xA;    &#34;pandas&amp;lt;=1.4.3&#34;,&#xA;    &#34;ipython&#34;,&#xA;    &#34;scipy&amp;lt;=1.8.1&#34;,&#xA;    &#34;patsy&#34;,&#xA;    &#34;seaborn&amp;lt;=0.11.1&#34;,&#xA;    &#34;plotly&#34;,&#xA;    &#34;matplotlib&#34;,&#xA;    &#34;statsmodels&#34;,&#xA;    &#34;scikit-learn&#34;,&#xA;    &#34;ipfn&#34;,&#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that glmnet_python must be installed from the &lt;a href=&#34;https://github.com/bbalasub1/glmnet_python&#34;&gt;Github source&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;See &lt;a href=&#34;https://github.com/facebookresearch/balance/raw/main/setup.py&#34;&gt;setup.py&lt;/a&gt; for more details.&lt;/p&gt; &#xA;&lt;h2&gt;Installing &lt;em&gt;balance&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;As a prerequisite, you must install glmnet_python from source:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m pip install git+https://github.com/bbalasub1/glmnet_python.git@1.0&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h3&gt;Installing via PyPi&lt;/h3&gt; &#xA;&lt;p&gt;We recommend installing &lt;em&gt;balance&lt;/em&gt; from PyPi via pip for the latest stable version:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m pip install balance&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Installation will use Python wheels from PyPI, available for &lt;a href=&#34;https://pypi.org/project/balance/#files&#34;&gt;OSX, Linux, and Windows&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h3&gt;Installing from Source/Git&lt;/h3&gt; &#xA;&lt;p&gt;You can install the latest (bleeding edge) version from Git:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;python -m pip install git+https://github.com/facebookresearch/balance.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Alternatively, if you have a local clone of the repo:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;cd balance&#xA;python -m pip install .&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h1&gt;Getting started&lt;/h1&gt; &#xA;&lt;h2&gt;balance’s workflow in high-level&lt;/h2&gt; &#xA;&lt;p&gt;The core workflow in &lt;a href=&#34;https://import-balance.org/&#34;&gt;&lt;em&gt;balance&lt;/em&gt;&lt;/a&gt; deals with fitting and evaluating weights to a sample. For each unit in the sample (such as a respondent to a survey), balance fits a weight that can be (loosely) interpreted as the number of people from the target population that this respondent represents. This aims to help mitigate the coverage and non-response biases, as illustrated in the following figure.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/facebookresearch/balance/main/website/docs/docs/img/total_survey_error_flow_v02.png?token=GHSAT0AAAAAAB25KSTWSBZGTWAJ7LJ3U3G6Y3VG4XA&#34; alt=&#34;total_survey_error_img&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;The weighting of survey data through &lt;em&gt;balance&lt;/em&gt; is done in the following main steps:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Loading data of the respondents of the survey.&lt;/li&gt; &#xA; &lt;li&gt;Loading data about the target population we would like to correct for.&lt;/li&gt; &#xA; &lt;li&gt;Diagnostics of the sample covariates so to evaluate whether weighting is needed.&lt;/li&gt; &#xA; &lt;li&gt;Adjusting the sample to the target.&lt;/li&gt; &#xA; &lt;li&gt;Evaluation of the results.&lt;/li&gt; &#xA; &lt;li&gt;Use the weights for producing population level estimations.&lt;/li&gt; &#xA; &lt;li&gt;Saving the output weights.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;You can see a step-by-step description (with code) of the above steps in the &lt;a href=&#34;https://import-balance.org/docs/docs/general_framework/&#34;&gt;General Framework&lt;/a&gt; page.&lt;/p&gt; &#xA;&lt;h2&gt;Code example of using &lt;em&gt;balance&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;You may run the following code to play with &lt;em&gt;balance&lt;/em&gt;&#39;s basic workflow (these are snippets taken from the &lt;a href=&#34;https://import-balance.org/docs/tutorials/quickstart/&#34;&gt;quickstart tutorial&lt;/a&gt;):&lt;/p&gt; &#xA;&lt;p&gt;We start by loading data, and adjusting it:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from balance import load_data, Sample&#xA;&#xA;# load simulated example data&#xA;target_df, sample_df = load_data()&#xA;&#xA;# Import sample and target data into a Sample object&#xA;sample = Sample.from_frame(sample_df, outcome_columns=[&#34;happiness&#34;])&#xA;target = Sample.from_frame(target_df)&#xA;&#xA;# Set the target to be the target of sample&#xA;sample_with_target = sample.set_target(target)&#xA;&#xA;# Check basic diagnostics of sample vs target before adjusting:&#xA;# sample_with_target.covars().plot()&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;You can read more on evaluation of the pre-adjusted data in the &lt;a href=&#34;https://import-balance.org/docs/docs/general_framework/pre_adjustment_diagnostics/&#34;&gt;Pre-Adjustment Diagnostics&lt;/a&gt; page.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Next, we adjust the sample to the population by fitting balancing survey weights:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Using ipw to fit survey weights&#xA;adjusted = sample_with_target.adjust(max_de=None)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;em&gt;You can read more on adjustment process in the &lt;a href=&#34;https://import-balance.org/docs/docs/general_framework/adjusting_sample_to_population/&#34;&gt;Adjusting Sample to Population&lt;/a&gt; page.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;The above code gets us an &lt;code&gt;adjusted&lt;/code&gt; object with weights. We can evaluate the benefit of the weights to the coveriate balance, for example by running:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(adjusted.summary())&#xA;    # Covar ASMD reduction: 62.3%, design effect: 2.249&#xA;    # Covar ASMD (7 variables):0.335 -&amp;gt; 0.126&#xA;    # Model performance: Model proportion deviance explained: 0.174&#xA;&#xA;adjusted.covars().plot(library = &#34;seaborn&#34;, dist_type = &#34;kde&#34;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;And get:&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://import-balance.org/assets/images/fig_07_seaborn_after-ac7514f6b150f431b36329bb9ebd9d0a.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;We can also check the impact of the weights on the outcome using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# For the outcome:&#xA;print(adjusted.outcomes().summary())&#xA;    # 1 outcomes: [&#39;happiness&#39;]&#xA;    # Mean outcomes:&#xA;    #             happiness&#xA;    # source&#xA;    # self        54.221388&#xA;    # unadjusted  48.392784&#xA;    #&#xA;    # Response rates (relative to number of respondents in sample):&#xA;    #    happiness&#xA;    # n     1000.0&#xA;    # %      100.0&#xA;adjusted.outcomes().plot()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://import-balance.org/assets/images/fig_09_seaborn_outcome_kde_after-26fa9668164349253b2614335961ade9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;You can read more on evaluation of the post-adjusted data in the &lt;a href=&#34;https://import-balance.org/docs/docs/general_framework/evaluation_of_results/&#34;&gt;Evaluating and using the adjustment weights&lt;/a&gt; page.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;p&gt;Finally, the adjusted data can be downloded using:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;adjusted.to_download()  # Or:&#xA;# adjusted.to_csv()&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;To see a more detailed step-by-step code example with code output prints and plots (both static and interactive), please go over to the &lt;a href=&#34;https://import-balance.org/docs/tutorials/quickstart/&#34;&gt;quickstart tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Implemented methods for adjustments&lt;/h2&gt; &#xA;&lt;p&gt;&lt;em&gt;balance&lt;/em&gt; currently implements various adjustment methods. Click the links to learn more about each:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://import-balance.org/docs/docs/statistical_methods/ipw/&#34;&gt;Logistic regression using L1 (LASSO) penalization.&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://import-balance.org/docs/docs/statistical_methods/cbps/&#34;&gt;Covariate Balancing Propensity Score (CBPS).&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://import-balance.org/docs/docs/statistical_methods/poststratify/&#34;&gt;Post-stratification.&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h2&gt;Implemented methods for diagnostics/evaluation&lt;/h2&gt; &#xA;&lt;p&gt;For diagnostics the main tools (comparing before, after applying weights, and the target population) are:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Plots &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;barplots&lt;/li&gt; &#xA;   &lt;li&gt;density plots (for weights and covariances)&lt;/li&gt; &#xA;   &lt;li&gt;qq-plots&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA; &lt;li&gt;Statistical summaries &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;Weights distributions &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Design_effect#Haphazard_weights_with_estimated_ratio-mean_(%7F&#39;%22%60UNIQ--postMath-0000003A-QINU%60%22&#39;%7F)_-_Kish&#39;s_design_effect&#34;&gt;Kish’s design effect&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;Main summaries (mean, median, variances, quantiles)&lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Covariate distributions &#xA;    &lt;ol&gt; &#xA;     &lt;li&gt;Absolute Standardized Mean Difference (ASMD). For continuous variables, it is &lt;a href=&#34;https://en.wikipedia.org/wiki/Effect_size#Cohen&#39;s_d&#34;&gt;Cohen&#39;s d&lt;/a&gt;. Categorical variables are one-hot encoded, Cohen&#39;s d is calculated for each category and ASMD for a categorical variable is defined as Cohen&#39;s d, average across all categories.&lt;/li&gt; &#xA;    &lt;/ol&gt; &lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;&lt;em&gt;You can read more on evaluation of the post-adjusted data in the &lt;a href=&#34;https://import-balance.org/docs/docs/general_framework/evaluation_of_results/&#34;&gt;Evaluating and using the adjustment weights&lt;/a&gt; page.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h1&gt;More details&lt;/h1&gt; &#xA;&lt;h2&gt;Getting help, submitting bug reports and contributing code&lt;/h2&gt; &#xA;&lt;p&gt;You are welcome to:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Learn more in the &lt;a href=&#34;https://import-balance.org/&#34;&gt;&lt;em&gt;balance&lt;/em&gt;&lt;/a&gt; website.&lt;/li&gt; &#xA; &lt;li&gt;Ask for help on: &lt;a href=&#34;https://stats.stackexchange.com/questions/tagged/balance&#34;&gt;https://stats.stackexchange.com/questions/tagged/balance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Submit bug-reports and features&#39; suggestions at: &lt;a href=&#34;https://github.com/facebookresearch/balance/issues&#34;&gt;https://github.com/facebookresearch/balance/issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Send a pull request on: &lt;a href=&#34;https://github.com/facebookresearch/balance&#34;&gt;https://github.com/facebookresearch/balance&lt;/a&gt;. See the &lt;a href=&#34;https://github.com/facebookresearch/balance/raw/main/CONTRIBUTING.md&#34;&gt;CONTRIBUTING&lt;/a&gt; file for how to help out. And our &lt;a href=&#34;https://github.com/facebookresearch/balance/raw/main/LICENSE-DOCUMENTATION&#34;&gt;CODE OF CONDUCT&lt;/a&gt; for our expectations from contributors.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Citing &lt;em&gt;balance&lt;/em&gt;&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;: TBD.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;em&gt;balance&lt;/em&gt; package is licensed under the &lt;a href=&#34;https://github.com/facebookresearch/balance/raw/main/LICENSE&#34;&gt;GPLv2 license&lt;/a&gt;, and all the documentation on the site is under &lt;a href=&#34;https://github.com/facebookresearch/balance/raw/main/LICENSE-DOCUMENTATION&#34;&gt;CC-BY&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;News&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;: TBD.&lt;/p&gt; &#xA;&lt;h2&gt;Acknowledgements / People&lt;/h2&gt; &#xA;&lt;p&gt;The &lt;em&gt;balance&lt;/em&gt; package is actively maintained by people from the &lt;a href=&#34;https://research.facebook.com/teams/core-data-science/&#34;&gt;Core Data Science&lt;/a&gt; team (in Tel Aviv and Boston), by &lt;a href=&#34;https://research.facebook.com/people/sarig-tal/&#34;&gt;Tal Sarig&lt;/a&gt;, &lt;a href=&#34;https://research.facebook.com/people/galili-tal/&#34;&gt;Tal Galili&lt;/a&gt; and &lt;a href=&#34;https://research.facebook.com/people/mandala-steve/&#34;&gt;Steve Mandala&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;em&gt;balance&lt;/em&gt; package was (and is) developed by many people, including: &lt;a href=&#34;https://research.facebook.com/people/eilat-roee/&#34;&gt;Roee Eilat&lt;/a&gt;, &lt;a href=&#34;https://research.facebook.com/people/galili-tal/&#34;&gt;Tal Galili&lt;/a&gt;, &lt;a href=&#34;https://research.facebook.com/people/haimovich-daniel/&#34;&gt;Daniel Haimovich&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/kevinycliou&#34;&gt;Kevin Liou&lt;/a&gt;, &lt;a href=&#34;https://research.facebook.com/people/mandala-steve/&#34;&gt;Steve Mandala&lt;/a&gt;, &lt;a href=&#34;https://adamobeng.com/&#34;&gt;Adam Obeng&lt;/a&gt; (author of the initial internal Meta version), &lt;a href=&#34;https://research.facebook.com/people/sarig-tal/&#34;&gt;Tal Sarig&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/luke-sonnet&#34;&gt;Luke Sonnet&lt;/a&gt;, &lt;a href=&#34;https://seanjtaylor.com&#34;&gt;Sean Taylor&lt;/a&gt;, &lt;a href=&#34;https://www.linkedin.com/in/barak-yair-reif-2154365/&#34;&gt;Barak Yair Reif&lt;/a&gt;, and others. If you worked on balance in the past, please email us to be added to this list.&lt;/p&gt; &#xA;&lt;p&gt;The &lt;em&gt;balance&lt;/em&gt; package was open-sourced by &lt;a href=&#34;https://research.facebook.com/people/sarig-tal/&#34;&gt;Tal Sarig&lt;/a&gt;, &lt;a href=&#34;https://research.facebook.com/people/galili-tal/&#34;&gt;Tal Galili&lt;/a&gt; and &lt;a href=&#34;https://research.facebook.com/people/mandala-steve/&#34;&gt;Steve Mandala&lt;/a&gt; in late 2022.&lt;/p&gt; &#xA;&lt;p&gt;Branding created by &lt;a href=&#34;https://www.danabeaty.com/&#34;&gt;Dana Beaty&lt;/a&gt;, from the Meta AI Design and Marketing Team.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>drshahizan/Python-big-data</title>
    <updated>2023-01-14T01:38:22Z</updated>
    <id>tag:github.com,2023-01-14:/drshahizan/Python-big-data</id>
    <link href="https://github.com/drshahizan/Python-big-data" rel="alternate"></link>
    <summary type="html">&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/drshahizan/Python-big-data&#34; alt=&#34;Stars Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/drshahizan/Python-big-data/network/members&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/drshahizan/Python-big-data&#34; alt=&#34;Forks Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/drshahizan/Python-big-data/pulls&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues-pr/drshahizan/Python-big-data&#34; alt=&#34;Pull Requests Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/drshahizan/Python-big-data/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/drshahizan/Python-big-data&#34; alt=&#34;Issues Badge&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/drshahizan/Python-big-data/graphs/contributors&#34;&gt;&lt;img alt=&#34;GitHub contributors&#34; src=&#34;https://img.shields.io/github/contributors/drshahizan/Python-big-data?color=2b9348&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://visitor-badge.glitch.me/badge?page_id=drshahizan/Python-big-data&#34; alt=&#34;&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Don&#39;t forget to hit the &lt;span&gt;⭐&lt;/span&gt; if you like this repo.&lt;/p&gt; &#xA;&lt;h1&gt;About Us&lt;/h1&gt; &#xA;&lt;p&gt;The information on this Github is part of the materials for the subject High Performance Data Processing (SECP3133). This folder contains general big data information as well as big data case studies using Malaysian datasets. This case study was created by a &lt;a href=&#34;https://comp.utm.my/bachelor-of-computer-science-data-engineering/&#34;&gt;Bachelor of Computer Science (Data Engineering)&lt;/a&gt;, Universiti Teknologi Malaysia student.&lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img src=&#34;https://github.com/drshahizan/Python_EDA/raw/main/lab/hpdp1.jpeg&#34; height=&#34;200&#34;&gt; &lt;/p&gt; &#xA;&lt;h3&gt;Contents:&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/drshahizan/Python-big-data/main/#notes&#34;&gt;Notes&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Big Data: Pandas&lt;/li&gt; &#xA;   &lt;li&gt;Big Data: Alternatives to Pandas for Processing Large Datasets &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;Modin&lt;/li&gt; &#xA;     &lt;li&gt;Dask&lt;/li&gt; &#xA;     &lt;li&gt;Datatable&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;Comparison between libraries&lt;/li&gt; &#xA;   &lt;li&gt;Big Data: Case study&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/drshahizan/Python-big-data/main/#lab&#34;&gt;Lab&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Pandas&lt;/li&gt; &#xA;   &lt;li&gt;Modin&lt;/li&gt; &#xA;   &lt;li&gt;Dask&lt;/li&gt; &#xA;   &lt;li&gt;Comparison between libraries&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;Assignment &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/tree/main/Assignment%201&#34;&gt;Assignment1: Pandas - Data Processing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;[Assignment2: Alternatives to Pandas for Processing Large Datasets] &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/tree/main/Assignment%202a&#34;&gt;Solution 2a&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/tree/main/Assignment%202b&#34;&gt;Solution 2b&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/tree/main/Project&#34;&gt;Project&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Notes&lt;/h2&gt; &#xA;&lt;h3&gt;Big Data: Pandas&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.edureka.co/blog/python-libraries/&#34;&gt;Top 10 Python Libraries Data Scientists should know&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/top-5-python-libraries-for-big-data/&#34;&gt;Top 5 Python Libraries For Big Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.projectpro.io/article/python-pandas-dataframe-tutorials/405&#34;&gt;Python Pandas Dataframe Tutorial for Beginners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.codementor.io/@guidotournois/4-strategies-to-deal-with-large-datasets-using-pandas-qdw3an95k&#34;&gt;4 strategies how to deal with large datasets in Pandas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/docs/user_guide/scale.html&#34;&gt;Scaling to large dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/5-ways-to-deal-with-large-datasets-in-python-9a80786c4182&#34;&gt;3 ways to deal with large datasets in Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pythonspeed.com/articles/pandas-load-less-data/&#34;&gt;Reducing Pandas memory usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pythonsimplified.com/how-to-handle-large-datasets-in-python-with-pandas/&#34;&gt;How To Handle Large Datasets in Python With Pandas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsai.net/p/data-science/efficient-pandas-using-chunksize-for-large-data-sets-c66bf3037f93&#34;&gt;Efficient Pandas: Using Chunksize for Large Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/l34l-90UF7U&#34;&gt;Video: How to work with big data files (5gb+) in Python Pandas!&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/loading-large-datasets-in-pandas-11bdddd36f7b&#34;&gt;Loading large datasets in Panda&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/xKMyk4wDHnQ&#34;&gt;Video: How to Read Very Big Files With SQL and Pandas in Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html&#34;&gt;Scaling to large datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=E7iwJUzm3Jo&amp;amp;t=2s&#34;&gt;Video: How to Handle Very Large Datasets in Python Pandas (Tips &amp;amp; Tricks)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GmG3dXhehJc&amp;amp;t=1s&#34;&gt;Video: 3 Tips to Read Very Large CSV as Pandas Dataframe&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/code/benhamner/competitions-with-largest-datasets&#34;&gt;Kaggle: Largest Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/code/mohamedbakhet/eda-for-amazon-books-reviews/notebook&#34;&gt;EDA for Amazon books reviews&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Big Data: Alternatives to Pandas for Processing Large Datasets&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/8-alternatives-to-pandas-for-processing-large-datasets-928fc927b08c&#34;&gt;8 Alternatives to Pandas for Processing Large Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/competitions/tabular-playground-series-oct-2021/discussion/275712&#34;&gt;Tutorial compilation for handling larger datasets&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Modin&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://modin.readthedocs.io/en/stable/&#34;&gt;Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/modin-project/modin&#34;&gt;Github Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/how-to-speed-up-pandas-with-modin-84aa6a87bcdb&#34;&gt;How to Speed Up Pandas with Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/code/lordozvlad/speed-up-pandas-workflow-with-modin/notebook&#34;&gt;Kaggle: Speed up Pandas Workflow with Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/LEhMQhCv3Kg&#34;&gt;Video: Do these Pandas Alternatives actually work?&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Dask&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Video - Dask: An Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Dask | Scale the Python tools you love&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Dask – How to handle large dataframes in python using parallel computing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Dask (software)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;&#34;&gt;Parallel Computing with Dask: A Step-by-Step Tutorial&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h4&gt;Datatable&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/vopani/datatableton&#34;&gt;DatatableTon&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/code/sudalairajkumar/getting-started-with-python-datatable&#34;&gt;Getting started with Python datatable&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;🎖️ Comparison between libraries&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/faster-pandas-with-parallel-processing-cudf-vs-modin-f2318c594084&#34;&gt;Faster Pandas with parallel processing: cuDF vs. Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtu.be/ycSf1IbBGWk&#34;&gt;Scaling Interactive Data Science with Modin and Ray&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray&#34;&gt;Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and RAPIDS&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Big Data: Case study&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.bernardmarr.com/img/bigdata-case-studybook_final.pdf&#34;&gt;7 Amazing companies that really get big data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://thecleverprogrammer.com/2021/02/19/data-science-case-studies-solved-using-python/&#34;&gt;Data Science Case Studies: Solved using Python&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.projectpro.io/article/data-science-case-studies-projects-with-examples-and-solutions/519&#34;&gt;10 Real World Data Science Case Studies Projects with Example&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.knowledgehut.com/blog/data-science/top-data-science-case-studies&#34;&gt;Top 8 Data Science Case Studies for Data Science Enthusiasts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Lab&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;Pandas&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_1_1_million_Sales_Records.ipynb&#34;&gt;Lab 1: 1,000,000 Sales Records&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_2_3_technique_handle_large_dataset.ipynb&#34;&gt;Lab 2: NYC Yellow Taxi Trip Data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_3_NYC_EDA.ipynb&#34;&gt;Lab 3: NYC Taxi Trip Duration EDA notebook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_4_NYC_Large_Datasets.ipynb&#34;&gt;Lab 4: Strategies to Deal With Large Datasets Using Pandas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_5_Dataset_285_million_users.ipynb&#34;&gt;Lab 5: eCommerce behavior data from multi category store (285 million users)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Modin&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_1.ipynb&#34;&gt;Lab 1: How to use Modin&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_2.ipynb&#34;&gt;Lab 2: Speed improvements&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_3.ipynb&#34;&gt;Lab 3: Not Implemented&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_4.ipynb&#34;&gt;Lab 4: Experimental Features&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_5.ipynb&#34;&gt;Lab 5: Modin for Distributed Pandas&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Dask&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Dask/Lab_1.ipynb&#34;&gt;Lab 1: Introducing Dask&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Dask/Lab_2.ipynb&#34;&gt;Lab 2: Loading Data Into DataFrames&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Dask/Lab_3.ipynb&#34;&gt;Lab 3: Introducing Dask DataFrames&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Dask/Lab_4.ipynb&#34;&gt;Lab 4: Learning Dask With Python Distributed Computing&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Dask/Lab_5.ipynb&#34;&gt;Lab 5: Parallelize code with dask.delayed&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Comparison between libraries&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Modin/lab_6_IntelModin_Vs_Pandas.ipynb&#34;&gt;Lab: Modin vs Pandas&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/drshahizan/Python-big-data/raw/main/Pandas/Lab_6_Pandas_Modin_Dask_Vaex.ipynb&#34;&gt;Lab: Large datasets (100MB to 1TB+) Pandas_Modin_Dask_Vaex&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Contribution 🛠️&lt;/h2&gt; &#xA;&lt;p&gt;Please create an &lt;a href=&#34;https://github.com/drshahizan/Python_EDA/issues&#34;&gt;Issue&lt;/a&gt; for any improvements, suggestions or errors in the content.&lt;/p&gt; &#xA;&lt;p&gt;You can also contact me using &lt;a href=&#34;https://www.linkedin.com/in/drshahizan/&#34;&gt;Linkedin&lt;/a&gt; for any other queries or feedback. &lt;img src=&#34;https://visitor-badge.glitch.me/badge?page_id=drshahizan&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</summary>
  </entry>
</feed>