<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-06-14T01:41:11Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>andrewgcodes/lightspeedGPT</title>
    <updated>2023-06-14T01:41:11Z</updated>
    <id>tag:github.com,2023-06-14:/andrewgcodes/lightspeedGPT</id>
    <link href="https://github.com/andrewgcodes/lightspeedGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Use GPT4 and GPT3.5 on inputs of unlimited size. Uses multithreading to process multiple chunks in parallel. Useful for tasks like Named Entity Recognition, information extraction on large books, datasets, etc.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;lightspeedGPT (multithreading)&lt;/h1&gt; &#xA;&lt;p&gt;&lt;strong&gt;if there&#39;s interest (150 stars), i&#39;ll make Colab notebooks!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;Use GPT4 and GPT3.5 on inputs of unlimited size. Uses multithreading to process multiple chunks in parallel. Useful for tasks like Named Entity Recognition, information extraction on large books, datasets, etc.&lt;/p&gt; &#xA;&lt;p&gt;Use cases:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Translating a large body of text&lt;/li&gt; &#xA; &lt;li&gt;Extracting geographic entities from a book on the history of wars&lt;/li&gt; &#xA; &lt;li&gt;Summarizing a long article, textbook, or other file bit by bit.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;It is designed to handle large files that may exceed OpenAI&#39;s token limits if processed as a whole. The script splits the input file into manageable pieces and sends each chunk to the OpenAI API separately at the same time. The responses are then collected and saved into an output file.&lt;/p&gt; &#xA;&lt;p&gt;If the OpenAI rate limit is reached, the code uses exponential backoff with jitter to keep retrying until success. It is by default set to give up after three failures.&lt;/p&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://cloud-ojq43hax6-hack-club-bot.vercel.app/0screen_shot_2023-06-11_at_8.44.36_pm.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Usage:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py -i INPUT_FILE -o OUTPUT_FILE -l LOG_FILE -m MODEL -c CHUNKSIZE -t TOKENS -v TEMPERATURE -p PROMPT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Skip to bottom for usage instructions.&lt;/p&gt; &#xA;&lt;h2&gt;Installation&lt;/h2&gt; &#xA;&lt;h3&gt;Prerequisites&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Python 3.6 or above&lt;/li&gt; &#xA; &lt;li&gt;OpenAI API key (either set using echo or hard-code into the main.py script)&lt;/li&gt; &#xA; &lt;li&gt;Basic understanding of the command-line interface (Terminal for macOS and Linux, CMD or PowerShell for Windows)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Steps&lt;/h3&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Clone the GitHub repository to your local machine. (OR might just be easier to download the main.py file and use it directly)&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone https://github.com/your_username/openai-text-processor.git&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;2&#34;&gt; &#xA; &lt;li&gt;Change directory to the cloned repository.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd openai-text-processor&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;3&#34;&gt; &#xA; &lt;li&gt;Install the required packages.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;openai&#xA;tiktoken&#xA;tqdm&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;ol start=&#34;4&#34;&gt; &#xA; &lt;li&gt;The script requires an OpenAI API key, which should be set as an environment variable. You can do this in bash by running the following command:&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export OPENAI_KEY=your_openai_key&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Replace &lt;code&gt;your_openai_key&lt;/code&gt; with your actual OpenAI API key.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The way to set environment variables can vary depending on your operating system and shell. Please consult the appropriate documentation if the above method does not apply to your situation.&lt;/p&gt; &#xA;&lt;h2&gt;Usage&lt;/h2&gt; &#xA;&lt;h3&gt;Command-Line Interface&lt;/h3&gt; &#xA;&lt;p&gt;You can use the OpenAI Text Processor through the command-line interface. The usage is as follows:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py -i INPUT_FILE -o OUTPUT_FILE -l LOG_FILE -m MODEL -c CHUNKSIZE -t TOKENS -v TEMPERATURE -p PROMPT&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Where:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;code&gt;INPUT_FILE&lt;/code&gt; is the path to the input file. This argument is required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;OUTPUT_FILE&lt;/code&gt; is the path to the output file. This argument is required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;LOG_FILE&lt;/code&gt; is the path to the log file. This argument is required.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;MODEL&lt;/code&gt; is the OpenAI model to use (default is &#39;gpt-3.5-turbo-0301&#39;). Alternative: gpt-4-0314. Better quality but slower and more expensive.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;CHUNKSIZE&lt;/code&gt; is the maximum number of tokens per chunk (default is 1000). This shouldn&#39;t be too large (&amp;gt;4000) or OpenAI will be overloaded. A safe size is under 3000 tokens. Your prompt length also counts for the OpenAI token limit.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TOKENS&lt;/code&gt; is the maximum tokens per API call (default is 100). shorter will be faster. but could terminate too early.&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt; is the variability (temperature) for OpenAI model (default is 0.0). 0.0 is probably best if you are going for highest accuracy&lt;/li&gt; &#xA; &lt;li&gt;&lt;code&gt;PROMPT&lt;/code&gt; is the prompt for the OpenAI model. This argument is required. Counts towards the 4k token limit for OpenAI API calls.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Example&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py -i input.txt -o output.txt -l log.txt -m &#39;gpt-3.5-turbo&#39; -c 500 -t 200 -v 0.5 -p &#39;Translate English to French:&#39;&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;This will process the file &lt;code&gt;input.txt&lt;/code&gt;, using the model &#39;gpt-3.5-turbo&#39;, a chunk size of 500 tokens, a maximum of 200 tokens per API call, a temperature of 0.5, and the prompt &#39;Translate English to French:&#39;. The results will be saved in &lt;code&gt;output.txt&lt;/code&gt; and the logs in &lt;code&gt;log.txt&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/andrewgcodes/lightspeedGPT/main/LICENSE.md&#34;&gt;MIT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;&#xA;Inspired by https://github.com/emmethalm/infiniteGPT from Emmet Halm.&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
  <entry>
    <title>AI4Finance-Foundation/FinGPT</title>
    <updated>2023-06-14T01:41:11Z</updated>
    <id>tag:github.com,2023-06-14:/AI4Finance-Foundation/FinGPT</id>
    <link href="https://github.com/AI4Finance-Foundation/FinGPT" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Data-Centric FinGPT. Open-source for open finance! Revolutionize ðŸ”¥ We&#39;ll soon release the trained model.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Data-Centric FinGPT: Open-source for Open Finance.&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://pepy.tech/project/fingpt&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/fingpt&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pepy.tech/project/fingpt&#34;&gt;&lt;img src=&#34;https://pepy.tech/badge/fingpt/week&#34; alt=&#34;Downloads&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://www.python.org/downloads/release/python-360/&#34;&gt;&lt;img src=&#34;https://img.shields.io/badge/python-3.6-blue.svg?sanitize=true&#34; alt=&#34;Python 3.8&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://pypi.org/project/fingpt/&#34;&gt;&lt;img src=&#34;https://img.shields.io/pypi/v/fingpt.svg?sanitize=true&#34; alt=&#34;PyPI&#34;&gt;&lt;/a&gt; &lt;img src=&#34;https://img.shields.io/github/license/AI4Finance-Foundation/fingpt.svg?color=brightgreen&#34; alt=&#34;License&#34;&gt;&lt;/p&gt; &#xA;&lt;p&gt;Let us DO NOT expect Wall Street to open-source LLMs nor open APIs.&lt;/p&gt; &#xA;&lt;p&gt;We democratize Internet-scale data for financial large language models (FinLLMs) at &lt;a href=&#34;https://github.com/AI4Finance-Foundation/FinNLP&#34;&gt;FinNLP&lt;/a&gt; and &lt;a href=&#34;https://ai4finance-foundation.github.io/FinNLP/&#34;&gt;FinNLP Website&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.06031&#34;&gt;Blueprint of FinGPT&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Disclaimer: We are sharing codes for academic purpose under the MIT education license. Nothing herein is financial advice, and NOT a recommendation to trade real money. Please use common sense and always first consult a professional before trading or investing.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h1&gt;Why FinGPT?&lt;/h1&gt; &#xA;&lt;p&gt;1). Finance is highly dynamic. &lt;a href=&#34;https://arxiv.org/abs/2303.17564&#34;&gt;BloombergGPT&lt;/a&gt; retrains an LLM using a mixed dataset of finance and general data sources, which is too expensive (1.3M GPU hours, a cost of around &lt;strong&gt;$5M&lt;/strong&gt;). It is costly to retrain an LLM model every month or every week, so lightweight adaptation is highly favorable in finance. Instead of undertaking a costly and time-consuming process of retraining a model from scratch with every significant change in the financial landscape, FinGPT can be fine-tuned swiftly to align with new data (the cost of adaptation falls significantly, estimated at less than &lt;strong&gt;$300 per training&lt;/strong&gt;).&lt;/p&gt; &#xA;&lt;p&gt;2). Democratizing Internet-scale financial data is critical, which should allow timely updates (monthly or weekly updates) using an automatic data curation pipeline. But, BloombergGPT has privileged data access and APIs. FinGPT presents a more accessible alternative. It prioritizes lightweight adaptation, leveraging the strengths of some of the best available open-source LLMs, which are then fed with financial data and fine-tuned for financial language modeling.&lt;/p&gt; &#xA;&lt;p&gt;3). The key technology is &#34;RLHF (Reinforcement learning from human feedback)&#34;, which is missing in BloombergGPT. RLHF enables an LLM model to learn individual preferences (risk-aversion level, investing habits, personalized robo-advisor, etc.), which is the ``secret&#34; ingredient of ChatGPT and GPT4.&lt;/p&gt; &#xA;&lt;h2&gt;FinGPT Demos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&#34;&gt;FinGPT V1&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Let&#39;s train our own FinGPT in Chinese Financial Market with ChatGLM and LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&#34;&gt;FinGPT V2&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;strong&gt;Let&#39;s train our own FinGPT in American Financial Market with LLaMA and LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;News&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://datascience.columbia.edu/news/2023/columbia-perspectives-on-chatgpt/?utm_source=sendinblue&amp;amp;utm_campaign=DSI%20Newsletter%20April%202023&amp;amp;utm_medium=email&#34;&gt;Columbia Perspectives on ChatGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[MIT Technology Review] &lt;a href=&#34;https://www.technologyreview.com/2023/03/25/1070275/chatgpt-revolutionize-economy-decide-what-looks-like/&#34;&gt;ChatGPT is about to revolutionize the economy. We need to decide what that looks like&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[BloombergGPT] &lt;a href=&#34;https://arxiv.org/abs/2303.17564&#34;&gt;BloombergGPT: A Large Language Model for Finance&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[Finextra] &lt;a href=&#34;https://www.finextra.com/newsarticle/41973/chatgpt-and-bing-ai-to-sit-as-panellists-at-fintech-conference&#34;&gt;ChatGPT and Bing AI to sit as panellists at fintech conference&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;What is FinNLP&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;FinNLP provides a playground for all people interested in LLMs and NLP in Finance. Here we provide full pipelines for LLM training and finetuning in the field of finance. The full architecture is shown in the following picture. Detail codes and introductions can be found &lt;a href=&#34;https://github.com/AI4Finance-Foundation/FinNLP&#34;&gt;here&lt;/a&gt;. Or you may refer to the &lt;a href=&#34;https://ai4finance-foundation.github.io/FinNLP/&#34;&gt;wiki&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;div align=&#34;center&#34;&gt; &#xA; &lt;img align=&#34;center&#34; src=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/figs/FinGPT.jpg&#34;&gt; &#xA;&lt;/div&gt; &#xA;&lt;h2&gt;ChatGPT at AI4Finance&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=fhBw3j_O9LE&#34;&gt;I Built a Trading Bot with ChatGPT&lt;/a&gt;, combining ChatGPT and FinRL.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f&#34;&gt;Hey, ChatGPT! Explain FinRL code to me!&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&#34;&gt;ChatGPT Robo Advisor v2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/demos&#34;&gt;ChatGPT Robo Advisor v1&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A demo of using ChatGPT to build a Robo-advisor&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&#34;&gt;ChatGPT Trading Agent V2&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;A FinRL agent that trades as smartly as ChatGPT by using the large language model behind ChatGPT&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/AI4Finance-Foundation/FinGPT/master/fingpt&#34;&gt;ChatGPT Trading Agent V1&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;Trade with the suggestions given by ChatGPT&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;ChatGPT adds technical indicators into FinRL&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Introductory&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.12712&#34;&gt;Sparks of artificial general intelligence: Early experiments with GPT-4&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[GPT-4] &lt;a href=&#34;https://arxiv.org/abs/2303.08774&#34;&gt;GPT-4 Technical Report&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[InstructGPT] &lt;a href=&#34;https://openreview.net/forum?id=TG8KACxEON&#34;&gt;Training language models to follow instructions with human feedback&lt;/a&gt; NeurIPS 2022.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://medium.com/walmartglobaltech/the-journey-of-open-ai-gpt-models-32d95b7b7fb2&#34;&gt;The Journey of Open AI GPT models&lt;/a&gt;. GPT models explained. Open AI&#39;s GPT-1, GPT-2, GPT-3.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[GPT-3] &lt;a href=&#34;https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html&#34;&gt;Language models are few-shot learners&lt;/a&gt; NeurIPS 2020.&lt;/li&gt; &#xA; &lt;li&gt;[GPT-2] &lt;a href=&#34;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&#34;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[GPT-1] &lt;a href=&#34;https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf&#34;&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[Transformer] &lt;a href=&#34;https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html&#34;&gt;Attention is All you Need&lt;/a&gt; NeurIPS 2017.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;(Financial) Big Data&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[BloombergGPT] &lt;a href=&#34;https://arxiv.org/abs/2303.17564&#34;&gt;BloombergGPT: A Large Language Model for Finance&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://lifearchitect.ai/whats-in-my-ai/&#34;&gt;WHATâ€™S IN MY AI?&lt;/a&gt; A Comprehensive Analysis of Datasets Used to Train GPT-1, GPT-2, GPT-3, GPT-NeoX-20B, Megatron-11B, MT-NLG, and Gopher&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/AI4Finance-Foundation/FinRL-Meta&#34;&gt;FinRL-Meta Repo&lt;/a&gt; and paper &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2022/hash/0bf54b80686d2c4dc0808c2e98d430f7-Abstract-Datasets_and_Benchmarks.html&#34;&gt;FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning&lt;/a&gt;. Advances in Neural Information Processing Systems, 2022.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[AI4Finance] &lt;a href=&#34;https://github.com/AI4Finance-Foundation/FinNLP&#34;&gt;FinNLP&lt;/a&gt; Democratizing Internet-scale financial data.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Interesting Demos&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gwern.net/gpt-3#prompts-as-programming&#34;&gt;GPT-3 Creative Fiction&lt;/a&gt; Creative writing by OpenAIâ€™s GPT-3 model, demonstrating poetry, dialogue, puns, literary parodies, and storytelling. Plus advice on effective GPT-3 prompt programming &amp;amp; avoiding common errors.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;ChatGPT for FinTech&lt;/h2&gt; &#xA;&lt;p&gt;&lt;strong&gt;ChatGPT Trading Bot&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=fhBw3j_O9LE&#34;&gt;I Built a Trading Bot with ChatGPT&lt;/a&gt; combining ChatGPT and FinRL.&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=unsa_gXPAJ4&#34;&gt;ChatGPT Trading strategy 20097% returns&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=4SG2884RcDY&#34;&gt;ChatGPT Coding - Make A Profitable Trading Strategy In Five Minutes!&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=dIEZVPVOZPQ&#34;&gt;Easy Automated Live Trading using ChatGPT (+9660.3% hands free)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=YxjvjK5AD2M&#34;&gt;ChatGPT Trading Strategy 893% Returns&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=9VPfd08uU4Q&#34;&gt;ChatGPT 10 Million Trading Strategy&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=LpzeshX6s2w&#34;&gt;ChatGPT: Your Crypto Assistant&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=ekz6ugJE1h0&amp;amp;t=3s&#34;&gt;Generate Insane Trading Returns with ChatGPT and TradingView&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=rCNz6OX6Niw&#34;&gt;This Ai Forex Trading Strategy Will Make you RICH!? (Chat GPT)&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;(Fast and accurate) Sentiment Analysis&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;GPT-3 can help study customer surveys, social media tweets from customers/users.&lt;/p&gt; &#xA;&lt;p&gt;Tweets&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://platform.openai.com/playground/p/default-tweet-classifier?model=text-davinci-003&#34;&gt;Tweet Classifier&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003&#34;&gt;Advanced Tweet Classifier&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Financial News&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/https-towardsdatascience-com-algorithmic-trading-using-sentiment-analysis-on-news-articles-83db77966704&#34;&gt;Algorithmic Trading using Sentiment Analysis on News Articles&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://python.plainenglish.io/access-historical-financial-news-headlines-with-python-be1b8faaea9f&#34;&gt;Accessing Historical Financial News Headlines with Python&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;PromptNet&lt;/strong&gt; Analogy to ImageNet and WordNet, it is critical to build a PromptNet.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision&#34;&gt;Awesome_Prompting_Papers_in_Computer_Vision&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/OpenPrompt&#34;&gt;OpenPrompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bigscience-workshop/promptsource&#34;&gt;promptsource&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Robo-advisor&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;Coding-tutor&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@ai4finance/hey-chatgpt-explain-finrl-code-to-me-6a91d612296f&#34;&gt;Hey, ChatGPT! Explain FinRL code to me!&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Blogs about ChatGPT for FinTech&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ChatGPT APIs&lt;/h2&gt; &#xA;&lt;p&gt;Prompting as a new programming paradigm!&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[Towards Data Science] &lt;a href=&#34;https://towardsdatascience.com/gpt-3-creative-potential-of-nlp-d5ccae16c1ab&#34;&gt;GPT-3: Creative Potential of NLP&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=Nl2Cdbao5Ws&#34;&gt;OpenAI GPT-3 - Prompt Engineering For Financial NLP&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;[YouTube video] &lt;a href=&#34;https://www.youtube.com/watch?v=bBiTR_1sEmI&#34;&gt;Advanced ChatGPT Prompt Engineering&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/models/gpt-3&#34;&gt;OpenAI API for GPT-3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/mmabrouk/chatgpt-wrapper&#34;&gt;ChatGPT-wrapper: python and shell&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://platform.openai.com/examples&#34;&gt;OpenAI Examples Library&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/shreyashankar/gpt3-sandbox&#34;&gt;GPT-3 Sandbox (Github)&lt;/a&gt; Enable users to create cool web demos using OpenAI GPT-3 API.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://levelup.gitconnected.com/exploring-the-capabilities-of-the-chatgpt-api-a-beginners-guide-e9089d49961f&#34;&gt;Exploring the Capabilities of the ChatGPT API: A Beginnerâ€™s Guide&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://github.com/acheong08/ChatGPT&#34;&gt;Reverse engineered ChatGPT API&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;strong&gt;Prompting programming&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;ChatGPT relatives:&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/osanseviero/ml_timeline&#34;&gt;A Release Timeline&lt;/a&gt; of many LLMs.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.02311&#34;&gt;PaLM&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.15556&#34;&gt;Chincella&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Interesting evaluations:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08582&#34;&gt;RLHF for pretraining&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2302.06476.pdf&#34;&gt;Compare ChatGPT with GPT3.5&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2301.08745.pdf&#34;&gt;Is ChatGPT A Good Translator? A Preliminary Study&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2302.04023.pdf&#34;&gt;A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;[YouTube] &lt;a href=&#34;https://www.youtube.com/watch?v=x4dIx9VYQoM&#34;&gt;Physics Solution: ChatGPT vs. Google&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Links&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/RUCAIBox/LLMSurvey&#34;&gt;LLM Survey&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/elyase/awesome-gpt3&#34;&gt;Awesome GPT-3 Examples&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt;</summary>
  </entry>
  <entry>
    <title>katanaml/sparrow</title>
    <updated>2023-06-14T01:41:11Z</updated>
    <id>tag:github.com,2023-06-14:/katanaml/sparrow</id>
    <link href="https://github.com/katanaml/sparrow" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Data extraction from documents with ML&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Sparrow - Data extraction from documents with ML&lt;/h1&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img width=&#34;300&#34; height=&#34;300&#34; src=&#34;https://github.com/katanaml/sparrow/raw/main/sparrow-ui/assets/sparrow_logo_1.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Description&lt;/h2&gt; &#xA;&lt;p&gt;Sparrow helps to extract and process data from scanned documents and pictures. It works with forms, invoices, receipts and other structured data.&lt;/p&gt; &#xA;&lt;p&gt;Research repo - &lt;a href=&#34;https://github.com/katanaml/sparrow-research&#34;&gt;sparrow-research&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;Modules&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/katanaml/sparrow/tree/main/sparrow-data&#34;&gt;sparrow-data&lt;/a&gt;&lt;/strong&gt; - Sparrow Data module&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/katanaml/sparrow/tree/main/sparrow-ml&#34;&gt;sparrow-ml&lt;/a&gt;&lt;/strong&gt; - Sparrow ML module&lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/katanaml/sparrow/tree/main/sparrow-ui&#34;&gt;sparrow-ui&lt;/a&gt;&lt;/strong&gt; - Sparrow UI module&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Inference&lt;/h3&gt; &#xA;&lt;p&gt;&lt;img src=&#34;https://github.com/katanaml/sparrow/raw/main/sparrow-ui/assets/inference_actual.png&#34; alt=&#34;Inference Results&#34;&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Author&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://katanaml.io&#34;&gt;Katana ML&lt;/a&gt;, &lt;a href=&#34;https://github.com/abaranovskis-redsamurai&#34;&gt;Andrej Baranovskij&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;License&lt;/h2&gt; &#xA;&lt;p&gt;Licensed under the Apache License, Version 2.0. Copyright 2020-2023 Katana ML, Andrej Baranovskij. &lt;a href=&#34;https://github.com/katanaml/sparrow/raw/main/LICENSE&#34;&gt;Copy of the license&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
</feed>