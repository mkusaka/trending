<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Jupyter Notebook Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-02-20T01:39:32Z</updated>
  <subtitle>Daily Trending of Jupyter Notebook in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>aurimas13/Machine-Learning-Goodness</title>
    <updated>2023-02-20T01:39:32Z</updated>
    <id>tag:github.com,2023-02-20:/aurimas13/Machine-Learning-Goodness</id>
    <link href="https://github.com/aurimas13/Machine-Learning-Goodness" rel="alternate"></link>
    <summary type="html">&lt;p&gt;The Machine Learning repository contains ML/DL projects, notebooks, cheat codes of ML/DL/AI, useful information on AI/AGI and codes or coding snippets/scripts/tasks.&lt;/p&gt;&lt;hr&gt;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;444px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/ml.png&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt;Machine Learning Goodness &lt;/b&gt; with various &lt;b&gt; notebooks &lt;/b&gt;, ML/DL projects update and &lt;b&gt; AGI/AI &lt;/b&gt; tips/cheats. &lt;/p&gt; &#xA;&lt;br&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/tree/main/Notebooks&#34;&gt; &lt;img alt=&#34;jupyter&#34; src=&#34;https://img.shields.io/badge/language-jupyter-orange.svg?style=social&amp;amp;logo=jupyter&#34; )&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/tree/main/Notebooks&#34;&gt; &lt;img alt=&#34;python&#34; src=&#34;https://img.shields.io/badge/language-python-blue.svg?style=social&amp;amp;logo=python&#34; )&gt;&lt;/a&gt; &lt;a href=&#34;https://twitter.com/anausedas&#34;&gt;&lt;img alt=&#34;twitter&#34; src=&#34;https://img.shields.io/twitter/follow/anausedas?style=social&#34;&gt;&lt;/a&gt; &lt;img height=&#34;20px&#34; title=&#34;profile views&#34; src=&#34;https://img.shields.io/github/stars/aurimas13/Coding-and_Teaching-ML?style=social&#34; alt=&#34;stars&#34;&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;b&gt; Overview &lt;/b&gt; &lt;/p&gt; &#xA;&lt;p align=&#34;left&#34;&gt; With the start of #100DaysOfMLCode challenge this Machine Learning Goodness repository is updated daily with either the completed Jupyter notebooks, Python codes, ML projects, useful ML/DL/NN libraries, cheat codes of ML/DL/NN/AI, useful information such as websites, beneficial learning materials, tips and whatnot not to mention some basic and advanced Python coding. &lt;/p&gt; &#xA;&lt;h1&gt;Table of Contents&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;Table of contents&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;Worthy Books&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;Worthy Tools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;Worthy Repositories&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#notebooks&#34;&gt;Notebooks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#notes&#34;&gt;Notes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#100daysofmlcode&#34;&gt;100DaysOfMLCode&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#public&#34;&gt;Public&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#jupyter-in-browser&#34;&gt;Jupyter in Browser&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#logo&#34;&gt;Logo&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Worthy Books&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Worthy books to hone expertise of ML/DL/NN/AGI, Python Programming, CS fundamentals needed for AI analysis and any useful book for a Developer or ML Engineer.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Number&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Link&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;Grokking Algorithms: An illustrated guide for programmers and other curious people&lt;/td&gt; &#xA;   &lt;td&gt;Visualisation of most popular algorithms used in Machine Learning and programming to solve problems&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://library.lol/main/1a699911f1094229b4d6c5df601a09ad&#34;&gt;Grokking Algorithms&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;Algorithm Design Manual&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to mathematical analysis of a variety of computer algorithms&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/3030542556/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=3030542556&amp;amp;linkCode=as2&amp;amp;tag=algorist-20&amp;amp;linkId=00b8675b374dcd56244e23efeecc80b0&#34;&gt;Algorithm Design Manual&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;Category Theory for Programmers&lt;/td&gt; &#xA;   &lt;td&gt;Book about Category Theory written on posts from Milewski&#39;s programming &lt;a href=&#34;https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/&#34;&gt;cafe&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.scribd.com/document/387084492/Category-Theory-for-Programmers&#34;&gt;Category Theory for Programmers&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;Automated Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;Book includes overviews of the bread-and-butter techniques we need in AutoML, provides in-depth discussions of existing AutoML systems, and evaluates the state of the art in AutoML&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.automl.org/wp-content/uploads/2019/05/AutoML_Book.pdf&#34;&gt;Automated Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;Mathematics for Computer Science&lt;/td&gt; &#xA;   &lt;td&gt;Book by MIT on Mathematics for Computer Science&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://courses.csail.mit.edu/6.042/spring17/mcs.pdf&#34;&gt;Mathematics for Computer Science&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;Mathematics for Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;Book by University of California on Mathematics for Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gwthomas.github.io/docs/math4ml.pdf&#34;&gt;Mathematics for Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;Applied Artificial Intelligence&lt;/td&gt; &#xA;   &lt;td&gt;Book on engineering AI applications&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.researchgate.net/publication/324030716_Applied_Artificial_Intelligence_-_An_Engineering_Approach&#34;&gt;Applied Artificial Intelligence&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;Automating Machine Learning Pipeline&lt;/td&gt; &#xA;   &lt;td&gt;Book-overview of automating ML lifecycle with Databricks Lakehouse platform&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.databricks.com/wp-content/uploads/2022/02/How-to-Automate-Your-Machine-Learning-Pipeline-eBook-v4-012522.pdf&#34;&gt;Automating Machine Learning Pipeline&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning Yearning&lt;/td&gt; &#xA;   &lt;td&gt;The book for AI Engineers win the era of Deep Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://info.deeplearning.ai/hubfs/andrew-ng-machine-learning-yearning-1.pdf?_hsmi=78646066&amp;amp;_hsenc=p2ANqtz--vl5UX2asi1u_1GfOGzNSEhb07iFH0uWdfUY0vWsyKIgzqknfb_4RnO5i64BFYOfTqjaT2zGFZsuOrK3vbace8MOYYkcohiF4xlHDTSDhIk3he-Yc&#34;&gt;Machine Learning Yearning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td&gt;Think Bayes&lt;/td&gt; &#xA;   &lt;td&gt;An introduytion to Bayesian statistics with Python implementation and Jupyter Notebooks&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://twitter.com/TheSequenceAI/status/1541264801074143232?s=20&amp;amp;t=KyB3eXH00O3HlsUEecSH9g&#34;&gt;Think Bayes&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;11&lt;/td&gt; &#xA;   &lt;td&gt;The Ultimate ChatGPT Guide&lt;/td&gt; &#xA;   &lt;td&gt;The book that provides 100 resources to enhance your life with ChatGPT&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://hasantoxr.gumroad.com/l/gpt&#34;&gt;The Ultimate ChatGPT Guide&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts&lt;/td&gt; &#xA;   &lt;td&gt;The book to learn strategies for crafting compelling ChatGPT prompts that drive engaging and informative conversations&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://fka.gumroad.com/l/art-of-chatgpt-prompting&#34;&gt;The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13&lt;/td&gt; &#xA;   &lt;td&gt;10 ChatGPT prompts for Software Engineers&lt;/td&gt; &#xA;   &lt;td&gt;The book to learn how to prompt for software engineering tasks&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;ttps://sergiorocks.gumroad.com/l/chatgpt-prompts-for-software-engineers&#34;&gt;10 ChatGPT prompts for Software Engineers&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Worthy Tools&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Worthy websites and tools that include cheat codes for Python, Machine Learning, Deep Learning, Neural Networks and what not apart from other worthy tools while you are learning or honing your skills can be found here. Updated constantly when a worthy material is found to be shared on the repository.&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Number&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Link&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;Python Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;The Python Cheatsheet based on the book &#34;Automate the Boring Stuff with Python&#34; and many other sources&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/wilfredinni/python-cheatsheet&#34;&gt;Python Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning Algorithms Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;The Machine Learning Cheatsheet explaining various models briefly&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.accel.ai/anthology/2022/1/24/machine-learning-algorithms-cheat-sheet&#34;&gt;ML Algorithms Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;Awesome AI Datasets &amp;amp; Tools&lt;/td&gt; &#xA;   &lt;td&gt;Links to popular open-source and public datasets, data visualizations, data analytics resources, and data lakes&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/05/awesome-list-datasets.html&#34;&gt;Awesome AI Datasets &amp;amp; Tools&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;This Cheatsheet contains many classical equations and diagrams on Machine Learning to quickly recall knowledge and ideas on Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/soulmachine/machine-learning-cheat-sheet&#34;&gt;Machine Learning Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;Universal Intelligence: A Definition of Machine Intelligence&lt;/td&gt; &#xA;   &lt;td&gt;The publication on definitions of intelligence&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/0712.3329.pdf&#34;&gt;Universal Intelligence&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;Logistic Regression&lt;/td&gt; &#xA;   &lt;td&gt;Detailed Overview of Logistic Regression&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc&#34;&gt;Logistic Regression&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;BCI Overview&lt;/td&gt; &#xA;   &lt;td&gt;Simple Overview of Brain-Computer Interface (BCI)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc&#34;&gt;BCI Overview&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;BCI Research&lt;/td&gt; &#xA;   &lt;td&gt;Fascinating research of Brain-Computer Interface (BCI)&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://medium.com/mlearning-ai/the-brain-computer-interfaces-is-here-bb47b7041c0d&#34;&gt;BCI Research&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;AI in Chemical Discovery&lt;/td&gt; &#xA;   &lt;td&gt;How AI is changing Chemical Diccovery?&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://thegradient.pub/how-ai-is-changing-chemical-discovery/&#34;&gt;AI in Chemical Discovery&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning for Chemistry&lt;/td&gt; &#xA;   &lt;td&gt;Best practices in Machine Learning for Chemistry&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.nature.com/articles/s41557-021-00716-z&#34;&gt;Machine Learning for Chemistry&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;11&lt;/td&gt; &#xA;   &lt;td&gt;AI tools for drug discovery&lt;/td&gt; &#xA;   &lt;td&gt;5 cool AI-powered Drug Discovery tools&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://medium.com/geekculture/5-cool-ai-powered-drug-discovery-tools-1d7e976ffc2a&#34;&gt;AI tools for drug discovery&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;12&lt;/td&gt; &#xA;   &lt;td&gt;Quantum Chemistry and Deep Learning&lt;/td&gt; &#xA;   &lt;td&gt;The application of Deep Learning and Neural Networks on Quantum Chemisty&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.works.so/blog/developers/quantum-chemistry-and-deep-learning&#34;&gt;Quantum Chemistry and Deep Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;13&lt;/td&gt; &#xA;   &lt;td&gt;Computing Machinery and Intelligence&lt;/td&gt; &#xA;   &lt;td&gt;First paper on AI by Alan Turing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gordicaleksa.medium.com/turing-for-dummies-ai-part-1-f0f668bcd83d&#34;&gt;Computing Machinery and Intelligence&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;14&lt;/td&gt; &#xA;   &lt;td&gt;The blog on the take of Alan Turing&lt;/td&gt; &#xA;   &lt;td&gt;The analysis of Alan Turing&#39;s paper on AI (13 in the list) and the blog post on the life of him&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gordicaleksa.medium.com/turing-for-dummies-ai-part-1-f0f668bcd83d&#34;&gt;Blog on Alan Turing&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;15&lt;/td&gt; &#xA;   &lt;td&gt;Minds, Brains and Programs&lt;/td&gt; &#xA;   &lt;td&gt;Paper that objects &#39;Turing Test&#39; by John Searle&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.scribd.com/doc/86417990/John-Searle-Minds-Brains-and-Programs&#34;&gt;Minds, Brains and Programs&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;16&lt;/td&gt; &#xA;   &lt;td&gt;The blog on the take Of John Searle &amp;amp; Alan Turing&lt;/td&gt; &#xA;   &lt;td&gt;The blog post on the take Of John Searle paper (15 in the list) and ideas about AI and Alan Turing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://gordicaleksa.medium.com/turing-for-dummies-ai-part-2-848cb87e95ab&#34;&gt;John Searle &amp;amp; Alan Turing&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;17&lt;/td&gt; &#xA;   &lt;td&gt;The Youtube channel on Deep Learning&#39;s Neural Networks&lt;/td&gt; &#xA;   &lt;td&gt;An amazing youtube channel explaining what is Neural Network with simple and easy to follow descriptions&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aircAruvnKk&amp;amp;t=7s&#34;&gt;Deep Learning&#39;s Neural Networks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;18&lt;/td&gt; &#xA;   &lt;td&gt;8 architectures of Neural Networks&lt;/td&gt; &#xA;   &lt;td&gt;8 architectures of Neural Network every ML engineer should know&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2018/02/8-neural-network-architectures-machine-learning-researchers-need-learn.html&#34;&gt;8 architectures&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;19&lt;/td&gt; &#xA;   &lt;td&gt;Neural Networks for the Prediction of Organic Chemistry Reactions&lt;/td&gt; &#xA;   &lt;td&gt;The use of neural networks for predicting reaction types&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acscentsci.6b00219&#34;&gt;NNs for Prediction of Organic Chemistry Reactions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;20&lt;/td&gt; &#xA;   &lt;td&gt;Expert System for Predicting Reaction Conditions: The Michael Reaction Case&lt;/td&gt; &#xA;   &lt;td&gt;Models were built to decide the compatibility of an organic chemistry process with each considered reaction condition option&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pubs.acs.org/doi/10.1021/ci500698a&#34;&gt;Expert System for Predicting Reaction Conditions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;21&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning in Chemical Reaction Space&lt;/td&gt; &#xA;   &lt;td&gt;Looked at reaction spaces of molecules involved in multiple reactions using ML-concepts&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.nature.com/articles/s41467-020-19267-x&#34;&gt;Machine Learning in Chemical Reaction Space&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;22&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning for Chemical Reactions&lt;/td&gt; &#xA;   &lt;td&gt;An overview of the questions that can and have been addressed using machine learning techniques&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acs.chemrev.1c00033&#34;&gt;Machine Learning for Chemical Reactions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;23&lt;/td&gt; &#xA;   &lt;td&gt;ByTorch overview&lt;/td&gt; &#xA;   &lt;td&gt;BoTorch as a framework of PyTorch&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pub.towardsai.net/botorch-is-a-framework-for-bayesian-optimization-in-pytorch-7d0f90c69064&#34;&gt;ByTorch overview&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;24&lt;/td&gt; &#xA;   &lt;td&gt;ByTorch official&lt;/td&gt; &#xA;   &lt;td&gt;Bayesian optimization or simply an official website of BoTorch&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://botorch.org/&#34;&gt;ByTorch official&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;25&lt;/td&gt; &#xA;   &lt;td&gt;VS Code Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;VS Code Shortcut Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://betterprogramming.pub/20-vs-code-shortcuts-for-fast-coding-cheatsheet-10b0e72fd5d&#34;&gt;VS Code Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;26&lt;/td&gt; &#xA;   &lt;td&gt;Simple Machine Learning Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;The Machine Learning Cheatsheet of all fields making it and common used algorithms&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.accel.ai/anthology/2022/1/24/machine-learning-algorithms-cheat-sheet&#34;&gt;Machine Learning Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;27&lt;/td&gt; &#xA;   &lt;td&gt;DeepMind &amp;amp; UCL on Reinforcement Learning&lt;/td&gt; &#xA;   &lt;td&gt;DeepMind &amp;amp; UCL lectures as videos on Reinforcement Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm&#34;&gt;DeepMind &amp;amp; UCL on Reinforcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;28&lt;/td&gt; &#xA;   &lt;td&gt;Stanford Machine Learning Full Course&lt;/td&gt; &#xA;   &lt;td&gt;Full machine Learning course as lecture slides given at Stanford University&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&#34;&gt;Stanford Machine Learning Full Course&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;29&lt;/td&gt; &#xA;   &lt;td&gt;Coursera&#39;s Deep Learning Specialization&lt;/td&gt; &#xA;   &lt;td&gt;DL Specialization given by teh great Andrew Ng and his team at deeplearning.ai&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Coursera&#39;s Deep Learning Specialization&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;30&lt;/td&gt; &#xA;   &lt;td&gt;Simple Clustering Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;Simple Unsupervised Learning Clustering Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/clustering-cheat-sheet-dcf72259abb6&#34;&gt;Clustering Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;31&lt;/td&gt; &#xA;   &lt;td&gt;Cheatsheet on Confusion Matrix&lt;/td&gt; &#xA;   &lt;td&gt;Cheatsheet on accuracy, precision, recall, TPR, FPR, specificity, sensitivity, ROC and all that stuff in Confusion matrix&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;http://numerical.recipes/whp/ConfusionMatrixDefns.pdf&#34;&gt;Cheatsheet on Confusion Matrix&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;32&lt;/td&gt; &#xA;   &lt;td&gt;Cheatsheets for Data Scientists&lt;/td&gt; &#xA;   &lt;td&gt;Various and different cheatsheets for data scientists&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.datacamp.com/cheat-sheet&#34;&gt;Cheatsheets for Data Scientists&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;33&lt;/td&gt; &#xA;   &lt;td&gt;K-Means Clustering visualisation&lt;/td&gt; &#xA;   &lt;td&gt;Simple graphics explaining K-Means Clustering&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://shabal.in/visuals/kmeans/6.html&#34;&gt;K-Means Clustering visualisation &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;34&lt;/td&gt; &#xA;   &lt;td&gt;Youtube channel by 3Blue1Brown&lt;/td&gt; &#xA;   &lt;td&gt;Youtube channel on animated math concepts&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw&#34;&gt;Animated math concepts&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;35&lt;/td&gt; &#xA;   &lt;td&gt;Essence of Linear Algebra&lt;/td&gt; &#xA;   &lt;td&gt;Youtube playlist on Linear Algebra by 3Blue1Brown&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&#34;&gt;Linear Algebra&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;36&lt;/td&gt; &#xA;   &lt;td&gt;The Neuroscience of Reinforcment Learning&lt;/td&gt; &#xA;   &lt;td&gt;The Princeton slides of Neuroscience for Reinforcement Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.princeton.edu/~yael/ICMLTutorial.pdf&#34;&gt;The Neuroscience of Rein forcement Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;37&lt;/td&gt; &#xA;   &lt;td&gt;Reinforcement Learning of Drug Design&lt;/td&gt; &#xA;   &lt;td&gt;Reinforcement Learning implementation of Drug Design&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://httpsmedium.datadriveninvestor.com/drug-design-made-fun-using-reinforcement-learning-212a4f867f33&#34;&gt;Reinforcment Learning of Drug Design&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;38&lt;/td&gt; &#xA;   &lt;td&gt;Brain-Computer Interface with backing&lt;/td&gt; &#xA;   &lt;td&gt;Advanced BCI with a flexible and moldable backing and penetrating microneedles&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://medicalxpress.com/news/2022-03-brain-computer-interface-flexible.html&#34;&gt;Brain-Computer Interface with backing&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;39&lt;/td&gt; &#xA;   &lt;td&gt;Big O Notation&lt;/td&gt; &#xA;   &lt;td&gt;Great and simple explanation on Big O notation&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/&#34;&gt;Big O Notation&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;40&lt;/td&gt; &#xA;   &lt;td&gt;6 Data Science Certificates&lt;/td&gt; &#xA;   &lt;td&gt;6 Data Science Certificates to boost your career&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/02/6-data-science-certificates.html&#34;&gt;6 Data Science Certificates&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;41&lt;/td&gt; &#xA;   &lt;td&gt;On the Measure of Intelligence&lt;/td&gt; &#xA;   &lt;td&gt;The new concept to measure how human-like artificial intelligence is&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/1911.01547.pdf&#34;&gt;On the Measure of Intelligence&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;42&lt;/td&gt; &#xA;   &lt;td&gt;A Collection of Definitions of Intelligence&lt;/td&gt; &#xA;   &lt;td&gt;70-odd definitions of intelligence&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/0706.3639.pdf&#34;&gt;A Collection of Definitions of Intelligence&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;43&lt;/td&gt; &#xA;   &lt;td&gt;Competition-Level Code Generation with AlphaCode&lt;/td&gt; &#xA;   &lt;td&gt;AlphaCode paper&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.07814&#34;&gt;Competition-Level Code Generation with AlphaCode&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;44&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;What is Machine Learning? A well explained introdution&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pub.towardsai.net/what-is-machine-learning-ml-b58162f97ec7&#34;&gt;Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;45&lt;/td&gt; &#xA;   &lt;td&gt;Autoencoders&lt;/td&gt; &#xA;   &lt;td&gt;Introduction to Autoencoders and dive into Undercomplete Autoencoders&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/autoencoders-ae-a-smart-way-to-process-your-data-using-unsupervised-neural-networks-9661f93a8509&#34;&gt;Autoencoders&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;46&lt;/td&gt; &#xA;   &lt;td&gt;ChatGPT Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;A must-have Cheatsheet for anyone that is using ChatGPT a lot&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/publications/sheets/ChatGPT_Cheatsheet_Costa.pdf&#34;&gt;ChatGPT Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;47&lt;/td&gt; &#xA;   &lt;td&gt;Scikit-learn Cheatsheet&lt;/td&gt; &#xA;   &lt;td&gt;Scikit-Learn Cheatsheet fo Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/publications/sheets/Scikit-Learn_Cheatsheet_for_Machine_Learning.pdf&#34;&gt;Scikit-Learn Cheatsheet&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;48&lt;/td&gt; &#xA;   &lt;td&gt;Top 13 Python Deep Learning Libraries&lt;/td&gt; &#xA;   &lt;td&gt;Summary of top libraries in Deep learning using Python&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2018/11/top-python-deep-learning-libraries.html&#34;&gt;Top 13 Python Deep Learning Libraries&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;49&lt;/td&gt; &#xA;   &lt;td&gt;A Simple Guide to Machine Learning Visualisations&lt;/td&gt; &#xA;   &lt;td&gt;Summary of visual inspection on ML models performance&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/a-simple-guide-to-machine-learning-visualisations-6c808ac925dd&#34;&gt;A Simple Guide to Machine Learning Visualisations&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;50&lt;/td&gt; &#xA;   &lt;td&gt;Discovering the systematic errors made by machine learning models&lt;/td&gt; &#xA;   &lt;td&gt;Summary to discover errors on Machine Learning models that achieve high overall accuracy on coherent slices of validation data&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://ai.stanford.edu/blog/domino/&#34;&gt;Discovering the systematic errors made by machine learning models&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;51&lt;/td&gt; &#xA;   &lt;td&gt;Hypothesis Testing Explaine?&lt;/td&gt; &#xA;   &lt;td&gt;Explanation of Hypothesis Testing&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/09/hypothesis-testing-explained.html&#34;&gt;A Simple Guide to Machine Learning Visualisations&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;52&lt;/td&gt; &#xA;   &lt;td&gt;Intro Course to AI&lt;/td&gt; &#xA;   &lt;td&gt;Free introductory AI course for beginner&#39;s given by Microsoft&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2022/08/free-ai-beginners-course.html&#34;&gt;Intro Course to AI&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;53&lt;/td&gt; &#xA;   &lt;td&gt;ChatGPT productivity hacks&lt;/td&gt; &#xA;   &lt;td&gt;ChatGPT productivity hacks: Five ways to use chatbots to make your life easier&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.zdnet.com/article/chatgpt-productivity-hacks-five-ways-to-use-chatbots-to-make-your-life-easier/?taid=63e690b4be05cf0001218da8&#34;&gt;ChatGPT productivity hacks&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;54&lt;/td&gt; &#xA;   &lt;td&gt;Triple Money with Data Science&lt;/td&gt; &#xA;   &lt;td&gt;Article on how a fellow tripled his income with Data Science in 18 Months&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/10/tripled-my-income-data-science-18-months.html&#34;&gt;Triple Money with Data Science&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;55&lt;/td&gt; &#xA;   &lt;td&gt;Predictions on AI for the next 10 years&lt;/td&gt; &#xA;   &lt;td&gt;Andrew Ng&#39;s prediction on AI for the next 10 years&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://venturebeat.com/ai/andrew-ng-predicts-the-next-10-years-in-ai/?sf162890539=1&#34;&gt;Predictions on AI for the next 10 years&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;56&lt;/td&gt; &#xA;   &lt;td&gt;Theory of Mind May Have Spontaneously Emerged in Large Language Models&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://arxiv.org/pdf/2302.02083.pdf&#34;&gt;Theory of Mind May Have Spontaneously Emerged in Large Language Models&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;57&lt;/td&gt; &#xA;   &lt;td&gt;How ChatGPT Helps You To Automate Machine Learning?&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pub.towardsai.net/how-chatgpt-helps-you-to-automate-machine-learning-55520f49db9c&#34;&gt;How ChatGPT Helps You To Automate Machine Learning?&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;58&lt;/td&gt; &#xA;   &lt;td&gt;The ChatGPT Cheat Sheet&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2023/01/chatgpt-cheat-sheet.html&#34;&gt;The ChatGPT Cheat Sheet&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;59&lt;/td&gt; &#xA;   &lt;td&gt;OpenAI Cookbook&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;OpenAI Cookbook&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;60&lt;/td&gt; &#xA;   &lt;td&gt;Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey from Precision to Interpretability&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://deepai.org/publication/knowledge-augmented-graph-machine-learning-for-drug-discovery-a-survey-from-precision-to-interpretability&#34;&gt;Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey from Precision to Interpretability&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;61&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/a-simple-guide-to-machine-learning-visualisations-6c808ac925dd&#34;&gt;A Simple Guide to Machine Learning Visualisations&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;62&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://appsilon.com/visualize-pytorch-neural-networks/&#34;&gt;How to Visualize PyTorch Neural Networks – 3 Examples in Python&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;63&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://pub.towardsai.net/role-of-data-visualization-in-machine-learning-a6dd62ad1082&#34;&gt;Role of Data Visualization in Machine Learning&lt;/a&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;   &lt;td&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Worthy Repositories&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Worthy GitHub repositories related to the ML/DL/NN/AGI courses with all details included can be found here:&lt;/p&gt; &#xA;&lt;table&gt; &#xA; &lt;thead&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Number&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; &#xA;   &lt;th&gt;&lt;strong&gt;Link&lt;/strong&gt;&lt;/th&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/thead&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;1&lt;/td&gt; &#xA;   &lt;td&gt;Advanced AI course&lt;/td&gt; &#xA;   &lt;td&gt;Code Academy Advanced AI course in Lithuania&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/aurimas13/CodeAcademy-AI-Course&#34;&gt;Advanced AI course&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;2&lt;/td&gt; &#xA;   &lt;td&gt;GitHub on Coursera&#39;s Deep Learning Course&lt;/td&gt; &#xA;   &lt;td&gt;GitHub Repo for Coursera&#39;s Deep Learning Specialization by deeplearning.ai&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/aurimas13/Coursera-Deep-Learning-Specialization&#34;&gt;GitHub on Coursera&#39;s DL Course&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;3&lt;/td&gt; &#xA;   &lt;td&gt;Notes on Coursera&#39;s Deep Learning Course&lt;/td&gt; &#xA;   &lt;td&gt;Lecture Notes for Coursera&#39;s Deep Learning Specialization by deeplearning.ai&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://drive.google.com/drive/folders/1X9qp9KsGs6IuVgzZJZvMJvVzgxPjhNKN?usp=share_link&#34;&gt;Notes on Cousera&#39;s DL Course&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;4&lt;/td&gt; &#xA;   &lt;td&gt;Category Theory on Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;Github containing list of publications of Category Theory in various AI fields&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/bgavran/Category_Theory_Machine_Learning&#34;&gt;Category Theory on ML&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;5&lt;/td&gt; &#xA;   &lt;td&gt;Foundations of Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;Understand the Concepts, Techniques and Mathematical Frameworks Used by Experts in Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://bloomberg.github.io/foml/#home&#34;&gt;Foundations of ML&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;6&lt;/td&gt; &#xA;   &lt;td&gt;Awesome RL&lt;/td&gt; &#xA;   &lt;td&gt;Github repository on amazing materials on Reinforcement Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/aikorea/awesome-rl&#34;&gt;Awesome RL&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;7&lt;/td&gt; &#xA;   &lt;td&gt;Optimizing Chemical Reactions&lt;/td&gt; &#xA;   &lt;td&gt;Optimizing Chemical Reactions with Deep Reinforcement Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/lightingghost/chemopt&#34;&gt;Optimizing Chemical Reactions&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;8&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning cheatsheets&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning cheatsheets on Supervised, Unsupervised &amp;amp; Deep Learning as well as Tips and Tricks&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/02/6-data-science-certificates.html&#34;&gt;Machine Learning cheatsheets &lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;9&lt;/td&gt; &#xA;   &lt;td&gt;ML Youtube Courses&lt;/td&gt; &#xA;   &lt;td&gt;Most recent Machine Leaning courses available on Youtube&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-YouTube-Courses&#34;&gt;ML Youtube Course&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA;  &lt;tr&gt; &#xA;   &lt;td&gt;10&lt;/td&gt; &#xA;   &lt;td&gt;Machine Learning Course Notes&lt;/td&gt; &#xA;   &lt;td&gt;Notes on the courses related to Machine Learning&lt;/td&gt; &#xA;   &lt;td&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Course-Notes&#34;&gt;Machine Learning Course Notes&lt;/a&gt;&lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h1&gt;Notebooks&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Done notebooks of various datasets can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/tree/main/Notebooks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;Notes&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Additional notes that we covered through lectures or additional material that I said about can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/tree/main/Notes&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;100DaysOfMLCode&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;em&gt;This is the section of &lt;strong&gt;100DaysOfMLCode&lt;/strong&gt; challenge updated daily by adding what has been done each day.&lt;/em&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Machine Learning Regression Notebook | Day 1&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the Jupyter code for Regression &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_1_Example_with_PyCaret_of_Regression.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Machine Learning Classification Notebook | Day 2&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the Jupyter code for Classification &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_2_Example_with_PyCaret_of_Classification.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Data Preprocessing and Beneficial Website | Day 3&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the code snippet for Data Preprocessing &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_3_Data_PreProcessing.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Added beneficial website as item &lt;strong&gt;3&lt;/strong&gt; of public open-source datasets for AI &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_3_Data_Preprocessing.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Simple Linear Regression Info and Beneficial Websites | Day 4&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the code snippet for Simple Linear Regression &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_4_Simple_Linear_Regression.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Added beneficial websites as items &lt;strong&gt;2&lt;/strong&gt; &amp;amp; &lt;strong&gt;3&lt;/strong&gt; of Deep Learning Course &amp;amp; its lecture notes &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_4_Simple_Linear_Regression.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Multiple Linear Regression and ML Cheatsheet | Day 5&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the code snippet for Multiple Linear Regression &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_5_Multiple_Linear_Regression.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Added a huge Cheatsheet on Machine Learning as item &lt;strong&gt;4&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; via GitHub repo containing classical equations with diagrams that helped recall knowledge and ideas on Machine Learning.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_5_Multiple_Linear_Regression.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Universal Intelligence and K Nearest Neighbours | Day 6&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Added a publication (&lt;strong&gt;5&lt;/strong&gt;) on Universal Intelligence: A Definition of Machine Intelligence &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; that looks into informal definitions of intelligence defined by experts, then mathematically investigates what is intelligence for machines and studies other tests and definitions of intelligence proposed for machines.&lt;/li&gt; &#xA; &lt;li&gt;Learnt about K Nearest Neighbours algorithm and made a graphical summary below as well as &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_6_K_Nearest_Neighbours.jpg&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_6_K_Nearest_Neighbours.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;KNN code, Notebook on TF Tensors, Creativity of ChatGPT &amp;amp; AI Art | Day 7&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wrote about the K Nearest Neighbours algorithm for classification as a code snippet that can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_7_KNN.md&#34;&gt;here&lt;/a&gt; and honed expertise of Deep Learning framework TensorFlow by making a notebook that looked into TensorFlow tensors &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_7_Example_about_Tensors.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Read articles on how to improve creative writing through ChatGPT &lt;a href=&#34;https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f&#34;&gt;here&lt;/a&gt; where I loved the poem about Python after trying it myself that left me certain that ChatGPT could be a good collaborator on creative writing and on the potential of AI in the art &lt;a href=&#34;https://medium.com/mlearning-ai/is-ai-art-really-art-a363073d62d0&#34;&gt;here&lt;/a&gt; that may lead to the future of social activism.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Algorithms, Category Theory in ML &amp;amp; ML experiment tracking | Day 8&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Finished &#39;Grokking Algorithms: An illustrated guide for programmers and other curious people&#39; by Aditya Y. Bhargava that can be found as item &lt;strong&gt;1&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt;. Recommend it highly as algorithms are explained simply through visualisations and some usage of algorithms in ML is visualised as well. Loved it. Also found another technical book of Steven Skiena&#39;s &#39;Algorithm Design Manual&#39; by reading its preface that will help to hone expertise on algorithms further as it can be found as item &lt;strong&gt;2&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; with videos that complement the book &lt;a href=&#34;https://www3.cs.stonybrook.edu/~skiena/373/videos/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Began diving into Category Theory and its usage in Machine Learning. A nice GitHub repository that lists all of the relevant papers which can be found as item &lt;strong&gt;4&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; while to get a good grasp of Category Theory started reading the book of Category Theory for Programmers by Bartosz Milewski &lt;a href=&#34;https://www.scribd.com/document/387084492/Category-Theory-for-Programmers&#34;&gt;here&lt;/a&gt; as also it can be inspected through &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; as item &lt;strong&gt;3&lt;/strong&gt; where a blog on which the book is based is given.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Dived into ML experiment tracking &lt;a href=&#34;https://neptune.ai/blog/ml-experiment-tracking&#34;&gt;here&lt;/a&gt; that in a few words is the process of saving all the experiment related information.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Automated ML, Algorithm Design Manual &amp;amp; Logistic Regression | Day 9&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;To work out how we could automate all aspects of ML and data analysis pipeline found this awesome book as item &lt;strong&gt;4&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt;. I highly recommend it to any machine learning researcher wanting to get started in the field and to any practitioner looking to understand the methods behind all the AutoML tools out there. Do check it out. After finishing with the current technical book that is going to be my the third technical book of the year to go hand in hand with &lt;a href=&#34;https://www.scribd.com/document/387084492/Category-Theory-for-Programmers&#34;&gt;this one&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Started reading &#39;Algorithm Design Manual&#39; to refresh as well as strengthen knowledge on algorithms used in Machine Learning and Computer Science as full book can be found as item &lt;strong&gt;2&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; with videos that complement the book &lt;a href=&#34;https://www3.cs.stonybrook.edu/~skiena/373/videos/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;To clear my insights on Logistic Regression I was searching on the internet for some well documented sources and came across the article as item &lt;strong&gt;6&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt;. It provides a detailed description of Logistic Regression and I recommend to check it out.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Support Vector Machines &amp;amp; Brain-Computer Interface | Day 10&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Strengthened understanding on what Support Vector Machine is, how it is used to solve classification problems and honed expertise about its usage.&lt;/li&gt; &#xA; &lt;li&gt;Made a graphical summary of SVM below as well as &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_10_Support_Vector_Machines.jpg&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Looked at Brain-Computer Interface (BCI) as a good summary is given as item &lt;strong&gt;7&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; and a nice article on research fascinating news as item &lt;strong&gt;8&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_10_Support_Vector_Machines.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Code on SVM &amp;amp; AI in Chemistry| Day 11&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Implemented Support Vector Machine (SVM) on linearly related data while using Scikit-Learn. As in this library we have SVC classifier I used it to solve the task. The code snippet of it can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_11_SVM.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Coming from chemical background made me hyper excited to study about ML influence on Chemistry through diving into it while reading a number of articles of which some highlights could be &lt;strong&gt;9&lt;/strong&gt;, &lt;strong&gt;10&lt;/strong&gt;, &lt;strong&gt;11&lt;/strong&gt; &amp;amp; &lt;strong&gt;12&lt;/strong&gt; as found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Notebooks on PyTorch Tensors &amp;amp; Visualisations | Day 12&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made two Jupyter notebooks. One with simple analysis of PyTorch Tensors as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_12_Example_of_PyTorch_and_Numpy_tensors.ipynb&#34;&gt;here&lt;/a&gt; and the other on visualising Neural Networks through Pytorch &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_12_Example_of_some_PyTorch_visualisations.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Perceptron with PyTorch, Naive Bayes Classifier &amp;amp; Black Box ML | Day 13&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a notebook with a simple overview of Perceptron theory and its usage through PyTorch as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_13_Example_of_PyTorch_with_Perceptron.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Learned about different types of naive bayes classifiers. Also started to hone Machine Learning expertise by studying the lectures given by Bloomberg as found as item &lt;strong&gt;5&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt;. First one in the playlist was Black Box Machine Learning. It gives the whole overview about prediction functions, feature extraction, learning algorithms, performance evaluation, cross-validation, sample bias, nonstationarity, overfitting, and hyperparameter tuning.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Decision Trees &amp;amp; Original first paper on AI with its analysis | Day 14&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a graphical summary of Decision Trees below as well as &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_14_Decision_Tree.jpg&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Read Alan Turing&#39;s original paper on the foundation of AI as found as &lt;strong&gt;13&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://gordicaleksa.medium.com/turing-for-dummies-ai-part-1-f0f668bcd83d&#34;&gt;here&lt;/a&gt; and its analysis as item &lt;strong&gt;14&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://gordicaleksa.medium.com/turing-for-dummies-ai-part-1-f0f668bcd83d&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_14_Decision_Tree.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Code on Decision Trees &amp;amp; Paper contradicting &#39;Turing Test&#39; with its analysis | Day 15&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the code snippet for Decision Trees &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_15_Decision_Tree.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Read John R. Searle&#39;s paper contradicting &#39;Turing Test&#39; as item &lt;strong&gt;15&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; with its analysis as found as &lt;strong&gt;16&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Neural Networks &amp;amp; Its architectures | Day 16&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;An amazing video on Neural Networks by &lt;strong&gt;3Blue1Brown&lt;/strong&gt; youtube channel. This video gives a good understanding of Neural Networks and uses Handwritten digit dataset to explain the concept. Link to the video found as item 17 &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.youtube.com/watch?v=aircAruvnKk&amp;amp;t=7s&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;A great article going though Neural Network 8 architectures that every ML engineer needs to know found as it 18 &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.kdnuggets.com/2018/02/8-neural-network-architectures-machine-learning-researchers-need-learn.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Machine Learning in Chemistry | Day 17&lt;/h1&gt; &#xA;&lt;p&gt;Read about Machine Learning concepts in Chemistry and particularly in automating and predicting chemical reactions as well as other chemical niceties:&lt;/p&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Most cited article is on the reaction predictions for organic chemistry where these reactions were explored by the use of neural networks. This newly developed predictor built a system which predicts the likely products of these reaction. Further details found as item &lt;strong&gt;19&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed though &lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acscentsci.6b00219&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Machine Learning methods (Support Vector Machine, Naive Bayes, and Random Forest) looked at the compatibility of specific chemical processes and the feasability of these predicted reactions. The link as item &lt;strong&gt;20&lt;/strong&gt; found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed though &lt;a href=&#34;https://pubs.acs.org/doi/10.1021/ci500698a&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Machine Learning studied one of the largest reaction space to date by creating a database that contains all possible chemical reactions found as item &lt;strong&gt;21&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed though &lt;a href=&#34;https://www.nature.com/articles/s41467-020-19267-x&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;The review overviewed how important chemical questions that could be answered through using machine learning techniques as found as item &lt;strong&gt;22&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed though &lt;a href=&#34;https://pubs.acs.org/doi/10.1021/acs.chemrev.1c00033&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Image Recognition | Day 18&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a Notebook implementing deep neural networks on image recognition with PyTorch as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_18_Example_of_Image_Recognition_with_PyTorch.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Fuel Efficiency | Day 19&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a Notebook implementing linear regression with deep neural networks to predict Miles Per Gallon (MPG) values on fuel efficiency across the US, Europe and Japan as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_19_Example_with_TensorFlow_of_Regression_Fuel_Efficiency.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;BoTorch &amp;amp; Reinforcement Learning | Day 20&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Studied about BoTorch as a low level framework of PyTorch which introduction can be found as item &lt;strong&gt;23&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://pub.towardsai.net/botorch-is-a-framework-for-bayesian-optimization-in-pytorch-7d0f90c69064&#34;&gt;here&lt;/a&gt; or full Bayesian optimization as it says as found as item &lt;strong&gt;24&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://botorch.org/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found VS code shortcut cheatsheet as found as item &lt;strong&gt;25&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://betterprogramming.pub/20-vs-code-shortcuts-for-fast-coding-cheatsheet-10b0e72fd5d&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Came across an awesome Reinforcement Learning material that includes everything from codes to theory to Lectures, Papers to Applications and other amazing material on RL you can check by visiting item &lt;strong&gt;6&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; that can also be accessed straight from &lt;a href=&#34;https://github.com/aikorea/awesome-rl&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;TensorFlow Eager with Graph Executions &amp;amp; Simple ML Cheatsheet | Day 21&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Wrote a notebook by comparing Eager and Graph executions in TensorFlow &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_21_Example_of_Graph_and_Eager_Execution.ipynb&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Analysed a simple, short and to the point Machine Learning cheatsheet that can be found as item &lt;strong&gt;26&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://www.accel.ai/anthology/2022/1/24/machine-learning-algorithms-cheat-sheet&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;DeepMind/UCL Lectures &amp;amp; ML and DL courses &amp;amp; Simple Clustering Cheatsheet | Day 22&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Honed knowledge of Reinforcment Learning through studying DeepMind and UCL lecture slides on it as item &lt;strong&gt;27&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.youtube.com/playlist?list=PLqYmG7hTraZDVH599EItlEWsUOsJbAodm&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Found a fantastic full course on Machine Learning by the great Andrew Ng as item &lt;strong&gt;28&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&#34;&gt;here&lt;/a&gt; and two years ago did this on as item &lt;strong&gt;29&lt;/strong&gt; found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;here&lt;/a&gt; which I also highly recommend to begin learning about Deep Learning as time from time I revisit it that I did today for example.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Analysed a short cheatsheet on Clustering and added it as item &lt;strong&gt;30&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://towardsdatascience.com/clustering-cheat-sheet-dcf72259abb6&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;333px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_22_DeepMind_UCL_27.png&#34;&gt; &lt;img height=&#34;333px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_22_Stanford_28.png&#34;&gt; &lt;img height=&#34;333px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_22_Clustering_30.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Random Forest &amp;amp; Confusion matrix Cheatsheet | Day 23&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a graphical summary of Random Forest below as well as &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_23_Random_Forest.jpg&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found a fantastic cheatsheet on Confusion Matrix that incorporates accuracy, precision, recall, TPR, FPR, specificity, sensitivity, ROC and added it as item &lt;strong&gt;31&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;http://numerical.recipes/whp/ConfusionMatrixDefns.pdf&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_23_Random_Forest.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h2&gt;Code on Random Forest &amp;amp; Cheatsheets for Data Scientists | Day 24&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Check out the code snippet for Decision Trees &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Code/Day_24_Random_Forest.md&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found various cheatsheets for Data Scientists as item &lt;strong&gt;32&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.datacamp.com/cheat-sheet&#34;&gt;here&lt;/a&gt; as the glimpse given below.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;1111px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_24_Data_Science_Cheat_Sheets.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;K-Means Clustering | Day 25&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Strengthened knowledge about Unsupervised Learning and particularly Clustering by creating a visual on K-Means as shown below and found a wonderful animation that can help to easily understand K-Means Clustering as found as item &lt;strong&gt;33&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://shabal.in/visuals/kmeans/6.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;2222px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_25_K_Means_Clustering.jpg&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Linear Algebra | Day 26&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Found an awesome channel as item &lt;strong&gt;34&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or you can check the channel directly &lt;a href=&#34;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw&#34;&gt;here&lt;/a&gt; by &lt;strong&gt;3Blue1Brown&lt;/strong&gt;. It has a playlist called &lt;code&gt;Essence of Linear Algebra&lt;/code&gt;. Started yesterday and completed full playlist of videos today which gave a complete overview of Vectors, Linear Combinations, Spans, Basis Vectors, Linear Transformations, Matrix Multiplication, 3D Transformations, Determinants, Inverse Matrix, Column Space, Null Space, Non-Square Matrices, Dot Product, Cross Product, Eigenvectors, Eigenvalues and Abstract Vector Spaces.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Link to the playlist of &lt;code&gt;Essence of Linear Algebra&lt;/code&gt; can be found as item &lt;strong&gt;35&lt;/strong&gt; [here] or accessed straight through &lt;a href=&#34;https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Reinforcement Learning | 27&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found an amazing Princeton material as slides on the Neuroscience of Reinforcement Learning as item &lt;strong&gt;36&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://www.princeton.edu/~yael/ICMLTutorial.pdf&#34;&gt;here&lt;/a&gt;. Looked also at overview of Reinforcement Learning implementation for Drug Design as found as item &lt;strong&gt;37&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://httpsmedium.datadriveninvestor.com/drug-design-made-fun-using-reinforcement-learning-212a4f867f33&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Employee Performance with PyCaret | Day 28&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a Notebook implementing regression with Pycaret to look at employee performance &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_28_Example_with_Pycaret_and_PCA_regression_of_employee_performance.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;BCI, Chemical Reactions &amp;amp; Big O | Day 29&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found a great article on Brain-Computer Interface as item &lt;strong&gt;38&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; where it speaks about closed-loop system possibility once penetrating microneedles can conform to the brain or simply about an advanced brain-computer interface with a flexible and moldable penetrating microneedles that gets to the brain&#39;s cortex. It can also be accessed through &lt;a href=&#34;https://medicalxpress.com/news/2022-03-brain-computer-interface-flexible.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Came across a GitHub repository on optimizing chemical reactions through Reinforcement Learning as item &lt;strong&gt;7&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://github.com/lightingghost/chemopt&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Also found a fantastic explanation on Big O notation as item &lt;strong&gt;39&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;DS Certificates, Chemical Reactions &amp;amp; Big O | Day 30&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Came across 6 Data Science certificates in one place that could boost your career as found as item &lt;strong&gt;40&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.kdnuggets.com/2021/02/6-data-science-certificates.html&#34;&gt;here&lt;/a&gt;. Particularly interested in Google Professional Data Engineer Certification &amp;amp; SAS Certified AI &amp;amp; Machine Learning Professional. Take a look youself. Maybe you will find something useful as well.&lt;/li&gt; &#xA; &lt;li&gt;Also found GitHub repo of Machine Learning cheatsheets on Supervised, Unsupervised &amp;amp; Deep Learning as well as Tips and Tricks given by Stanford CS course. Details as item &lt;strong&gt;41&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; or accessesd through &lt;a href=&#34;https://www.kdnuggets.com/2021/02/6-data-science-certificates.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Mathematics for CS and ML | Day 31&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Started reading lecture notes as books of MIT and University Of California on Mathematics for Computer Science and Mathematics for Machine Learning as items &lt;strong&gt;5&lt;/strong&gt; and &lt;strong&gt;6&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://courses.csail.mit.edu/6.042/spring17/mcs.pdf&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://gwthomas.github.io/docs/math4ml.pdf&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Quizzes about TensorFlow &amp;amp; PyTorch | Day 32&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made two quizzes about TensorFlow and PyTorch combining 25 questions each. Quiz on TensorFlow can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Quizzes/Day_32_Quiz_of_TensorFlow.ipynb&#34;&gt;here&lt;/a&gt; while on PyTorch can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Quizzes/Day_32_Quiz_of_PyTorch.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;PyCaret, PyTorch &amp;amp; Applied Artificial Intelligence | Day 33&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Created problems for PyCaret and PyTorch as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Problems/Problem_PyCaret.ipynb&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Problems/Problem_PyTorch.ipynb&#34;&gt;here&lt;/a&gt;. Their solutions could be also found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Problems/Solution_to_Problem_PyCaret.ipynb&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Problems/Solution_to_Problem_PyTorch.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Found an AI book on engineering Artificial Intelligence applications as item &lt;strong&gt;7&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.researchgate.net/publication/324030716_Applied_Artificial_Intelligence_-_An_Engineering_Approach&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;DL with Python, TensorFlow, Keras &amp;amp; Encoding | Day 34&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Watched Youtube videos to replenish knowledge on Deep Learning with Python, TensorFlow and Keras through four recordings:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wQ8BIBpya2k&amp;amp;list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&amp;amp;index=3&amp;amp;t=19s&#34;&gt;Deep Learning with Python, TensorFlow, and Keras tutorial&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=j-3vuBynnOE&amp;amp;list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&amp;amp;index=4&#34;&gt;Loading in your own data&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=WvoLTXIjBYU&amp;amp;list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&amp;amp;index=4&#34;&gt;Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=BqgTU7_cBnk&amp;amp;list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN&amp;amp;index=5&#34;&gt;Analyzing Models with TensorBoard&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Made a notebook looking at Ordinal and One Hot Encodings as found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_34_Example_of_Neural_Networks_for_Tabular_Data_Demonstration_1.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Essential Papers, AlphaCode &amp;amp; ML | Day 35&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read three papers as items &lt;strong&gt;41&lt;/strong&gt;, &lt;strong&gt;42&lt;/strong&gt; and &lt;strong&gt;43&lt;/strong&gt; as found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or summarrised and accessed below:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1911.01547.pdf&#34;&gt;On the Measure of Intelligence&lt;/a&gt; that explained the new concept of how to measure human-like artificial intelligence that enables fair general intelligence comparisons between AI systems and humans. Written by creator of Keras, Francois Chollet.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/0706.3639.pdf&#34;&gt;A Collection of Definitions of Intelligence&lt;/a&gt; that looked at 70-odd definitions of intelligence.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.07814&#34;&gt;Competition-Level Code Generation with AlphaCode&lt;/a&gt; that looked into the AlphaCode, a system for code generation that can create novel solutions to competitive programming problems that require deeper reasoning like knowing many computer science algorithms to implement. Fantastic read.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found an awesome quick explanation about Machine Learning as item &lt;strong&gt;44&lt;/strong&gt; found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://pub.towardsai.net/what-is-machine-learning-ml-b58162f97ec7&#34;&gt;here&lt;/a&gt;. It explained what Machine Learning is, how it works, and its importance in five minutes of reading.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Power of DL &amp;amp; Scientific Discovery with AI | Day 36&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Watched an awesome video from DeepMind on the Power of Deep Learning that can be accessed through &lt;a href=&#34;https://www.youtube.com/watch?v=KvZGaP8qlI8&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Also watched another video from the creator of DeepMind, Demis Hassabis, on the usage of AI to accelerate scientific discovery as found &lt;a href=&#34;https://www.youtube.com/watch?v=XtJVLOe4cfs&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Automate ML pipeline &amp;amp; Autoencoders | Day 37&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read the short book of automating Machine Learning pipeline as item &lt;strong&gt;8&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://www.databricks.com/wp-content/uploads/2022/02/How-to-Automate-Your-Machine-Learning-Pipeline-eBook-v4-012522.pdf&#34;&gt;here&lt;/a&gt;. This short overview looked at the lifecycle using the Databricks Lakehouse Platform.&lt;/li&gt; &#xA; &lt;li&gt;Studied Autoencoders that give a good representation of your data that focuses on the signal rather the noise. Found and article that briefly introduced Autoencoders and dived deeper into an Undercomplete Autoencoder, suitable for dimensionality reduction and feature extraction as item &lt;strong&gt;45&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed through &lt;a href=&#34;https://towardsdatascience.com/autoencoders-ae-a-smart-way-to-process-your-data-using-unsupervised-neural-networks-9661f93a8509&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Machine Learning Yearning | Day 38&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Came across a Machine Learning Yearning book as item &lt;strong&gt;9&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; that is suited for AI Engineers in the era of Deep Learning where it answers such queries as techniques for reducing avoidable bias, deciding whether to include inconsistent data, generalizing from the training set to the dev set, identifying Bias, Variance, and Data Mismatch Errors as well as spotting a flawed ML pipeline to name a few of the questions that the book answers. It can also be accessed straight through &lt;a href=&#34;https://info.deeplearning.ai/hubfs/andrew-ng-machine-learning-yearning-1.pdf?_hsmi=78646066&amp;amp;_hsenc=p2ANqtz--vl5UX2asi1u_1GfOGzNSEhb07iFH0uWdfUY0vWsyKIgzqknfb_4RnO5i64BFYOfTqjaT2zGFZsuOrK3vbace8MOYYkcohiF4xlHDTSDhIk3he-Yc&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ChatGPT &amp;amp; Scikit-learn Cheatsheets | Day 39&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found an awesome Cheatsheet regarding ChatGPT usage. As OpenAI said it&#39;s a must-have for anyone looking to get the most out of ChatGPT or NLP tasks in general. It can be found as item &lt;strong&gt;46&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed directly through &lt;a href=&#34;https://www.kdnuggets.com/publications/sheets/ChatGPT_Cheatsheet_Costa.pdf&#34;&gt;here&lt;/a&gt; with KDnuggets post on it &lt;a href=&#34;https://www.kdnuggets.com/2023/01/chatgpt-cheat-sheet.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Also came across a cheatsheet of Scikit-learn on Machine Learning that can be found as item &lt;strong&gt;47&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight by clicking on &lt;a href=&#34;https://www.kdnuggets.com/publications/sheets/Scikit-Learn_Cheatsheet_for_Machine_Learning.pdf&#34;&gt;here&lt;/a&gt; with KDnuggets post on it &lt;a href=&#34;https://www.kdnuggets.com/2022/12/scikit-learn-machine-learning-cheatsheet.html&#34;&gt;here&lt;/a&gt;. A bit on Scikit-learn: Scikit-learn is an open-source Python library for all kinds of predictive data analysis. You can perform classification, regression, clustering, dimensionality reduction, model tuning, and data preprocessing tasks.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ML Videos, Top 13 &amp;amp; ML Courses | Day 40&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Came across a fantastic GitHub repository that gives useful ML courses on the Youtube videos where you could refresh yor Machine Learning expertise ranging from Deep Learning to Reinforcement Learning to Graph Machine Learning asnd other subcategories through watching them as found as item &lt;strong&gt;9&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://github.com/dair-ai/ML-YouTube-Courses&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Found Top 13 Deep Learning libraries summarised in one article found as item &lt;strong&gt;48&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://www.kdnuggets.com/2018/11/top-python-deep-learning-libraries.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Stumbled across another fantastic GitHub repository on Machine Learning Courses but this time it provides notes on the&lt;br&gt; courses like for Deep Learning Specialization of 2022 or MIT&#39;s Introduction of Deep Learning to name a few. It can be accessed as item &lt;strong&gt;10&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-repositories&#34;&gt;here&lt;/a&gt; or through this &lt;a href=&#34;https://github.com/dair-ai/ML-Course-Notes&#34;&gt;link&lt;/a&gt; directly.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Visualisations, Errors &amp;amp; Testing | Day 41&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Took today a bit easier and spent time reading articles. The ones I found interesting are items &lt;strong&gt;49&lt;/strong&gt;, &lt;strong&gt;50&lt;/strong&gt; and &lt;strong&gt;51&lt;/strong&gt; where a simple guide of vislisations on Machine Learning is given, then a blog post that helps discovering errors in your Machine Learning models and lastly a well explained overview on Hypothesis Tedting. These article coulds be found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed directly through here:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/a-simple-guide-to-machine-learning-visualisations-6c808ac925dd&#34;&gt;A Simple Guide to Machine Learning Visualisations&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://ai.stanford.edu/blog/domino/&#34;&gt;Discovering the systematic errors made by machine learning models&lt;/a&gt;|&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/09/hypothesis-testing-explained.html&#34;&gt;Hypothesis Testing Explained&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;AI Course, ChatGPT hack &amp;amp; Money | Day 42&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Found a well balanced beginners course on AI by Microsoft as item &lt;strong&gt;52&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed directly through &lt;a href=&#34;https://www.kdnuggets.com/2022/08/free-ai-beginners-course.html&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Also spent time reading articles and the two ones I found interesting give ChatGPT productivity hacks and explanation on how to triple your income with Data Science as items &lt;strong&gt;53&lt;/strong&gt; ant &lt;strong&gt;54&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed directly through here:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.zdnet.com/article/chatgpt-productivity-hacks-five-ways-to-use-chatbots-to-make-your-life-easier/?taid=63e690b4be05cf0001218da8&#34;&gt;ChatGPT productivity hacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.kdnuggets.com/2021/10/tripled-my-income-data-science-18-months.html&#34;&gt;Triple Money with Data Science&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;h1&gt;Neural Nets on Tabular Data | Day 43&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Took it easy today. Created two notebooks with some explanations on Neural Nets for Tabular Data there while using TensorFlow and PyTorch. The former uses in-built embeddings and is short and can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_43_Example_of_Neural_Networks_for_Tabular_Data_Demonstration_2.ipynb&#34;&gt;here&lt;/a&gt; while the latter uses Neural Nets for Tabular Data with PyTorch with less explanation and can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_44_Example_of_Neural_Networks_for_Tabular_with_PyTorch_Demonstration.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA; &lt;li&gt;Came across predictions on AI by Andrew Ng for the next 10 years. Great read. Have a look yourself as item &lt;strong&gt;55&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or access straight through &lt;a href=&#34;https://venturebeat.com/ai/andrew-ng-predicts-the-next-10-years-in-ai/?sf162890539=1&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;ChatGPT &amp;amp; Think Bayes | Day 44&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Delved into ChatGPT by reading a paper showing that it performs much better than GPT3 and more like a nine-year-old kid. It can be found as item &lt;strong&gt;56&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://arxiv.org/pdf/2302.02083.pdf&#34;&gt;here&lt;/a&gt; and read a nice article on how ChatGPT helps to automate Machine Learning projects found as item &lt;strong&gt;57&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accesed straight through &lt;a href=&#34;https://pub.towardsai.net/how-chatgpt-helps-you-to-automate-machine-learning-55520f49db9c&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Came across a book on &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;an introduction to Bayesian statistics&lt;/a&gt; as item &lt;strong&gt;10&lt;/strong&gt; there or could be accessed straight &lt;a href=&#34;https://twitter.com/TheSequenceAI/status/1541264801074143232?s=20&amp;amp;t=KyB3eXH00O3HlsUEecSH9g&#34;&gt;here&lt;/a&gt; that uses computational methods relevant to ML practitioners:&lt;/p&gt; &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;This book uses Python code instead of math!&lt;/li&gt; &#xA;   &lt;li&gt;There’s a Jupyter notebook for every chapter&lt;/li&gt; &#xA;   &lt;li&gt;Code is written in NumPy, SciPy, and Pandas&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;555px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_44_ChatGPT_image.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;PyTorch Presentation | Day 45&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Created PyTorch presentation that can be accessed through &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Presentations/Day_45_PyTorch_Presentation.pdf&#34;&gt;here&lt;/a&gt; as a pdf or as a poweproint presentation while clicking &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Presentations/Day_45_PyTorch_Presentation.pptx&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;555px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/Day_45_PyTorch_Presentation_image.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;FastAI with Tabular Data | Day 46&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Created two notebooks looking at Tabular Data with FastAI. The first one is short and an overview of FastAI with tabular data that can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_46_Neural_Networks_for_Tabular_Data_6_L3_Demonstration_1_of_fastai_tabular.ipynb&#34;&gt;here&lt;/a&gt; while the second notebook looked at entity embeddings of tabular data where embeddings could be understood as modified categorical variables where I compared Neural Nets with Random Forest as well as Ensemble machine and is available &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Notebooks/Day_46_Neural_Networks_for_Tabular_Data_6_L3_Demonstration_2_of_entity_embeddings.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Podcasts on AI, ML, CS &amp;amp; Analytics | Day 47&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Created a list of podcasts that I like to listen on Machine Learning, AI and DS from time to time. Here are the 10 most popular of them as such:&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/data-skeptic/id890348705&#34;&gt;Data Skeptic&lt;/a&gt; | Features interviews and discussion of topics related to data science, statistics, machine learning, and artificial intelligence from the perspective of applying critical thinking and the scientific method to evaluate the veracity of claims and efficacy of approaches.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/data-stories/id502854960&#34;&gt;Data Stories&lt;/a&gt; | Discussions on the latest developments in data analytics, visualization, and related topics.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/artificial-intelligence-lex-mit-ai/id1434243584/&#34;&gt;Lex Fridman Podcast&lt;/a&gt; | Conversations at MIT and beyond about the nature of intelligence and AI from the perspectives of deep learning, robotics, AGI, neuroscience, philosophy, psychology, cognitive science, economics, physics, and mathematics.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://soundcloud.com/linear-digressions&#34;&gt;Linear Digressions&lt;/a&gt; | An exploration of machine learning and data science through interesting (and often very unusual) applications.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twimlai.com/&#34;&gt;TWIMLAI&lt;/a&gt; | This Week in Machine Learning &amp;amp; AI caters to a highly targeted audience of machine learning and AI enthusiasts. Covering technologies such as machine learning, artificial intelligence, deep learning, natural language processing, neural networks, analytics, and deep learning.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/super-data-science/id1163599059&#34;&gt;SuperDataScience&lt;/a&gt; | Bringing you the most inspiring Data Scientists and Analysts from around the world to help you build your successful career in Data Science. Data is growing exponentially and so are salaries of those who work in analytics. This podcast can help you learn how to skyrocket your analytics career.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/talking-machines/id955198749&#34;&gt;Talking Machines&lt;/a&gt; | Katherine Gorman and Neil Lawrence bring you clear conversations with experts in the field, insightful discussions of industry news, and useful answers to your questions. Machine learning is changing the questions we can ask of the world around us, here we explore how to ask the best questions and what to do with the answers.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/the-ai-podcast/id1186480811&#34;&gt;The AI Podcast&lt;/a&gt; form NVIDIA | We connect with some of the world’s leading AI experts to explain how it works, how it’s evolving, and how it intersects with every facet of human endeavor. NVIDIA, the AI computing company, produces this podcast.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/the-analytics-power-hour/id955228473&#34;&gt;The Digital Analytics Power Hour&lt;/a&gt; from Michael Helbling, Tim Wilson, and Moe Kiss | Attend any conference, and you will hear people say that the most informative discussions happened in the bar after the show. Read any business magazine, and you will find an article saying something along the lines of &#34;Business Analytics is the hottest job category out there, and there is a significant lack of people, process and best practice.&#34; In this case, the conference was eMetrics, the bar was… multiple, and the attendees were Michael Helbling, Tim Wilson, and Jim Cain (Co-host Emeritus). After a few pints and a few hours of discussion about the cutting edge of digital analytics, they realized they might have something to contribute back to the community. This podcast is one of those contributions. Each episode is a closed topic and an open forum - the goal is for listeners to enjoy listening to Michael, Tim, and Moe share their thoughts and experiences and hopefully take away something to try at work the next day.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/the-ai-in-business-podcast/id670771965&#34;&gt;AI in Business Podcast&lt;/a&gt; with Daniel Faggella | Learn what&#39;s possible - and what&#39;s working - with artificial intelligence in the enterprise through interviews with top AI and machine learning-focused executives and researchers in sectors like Pharma, Banking, Retail, and Defense. Discover trends, learn about what&#39;s working now, and learn how to adapt and thrive in an era of AI disruption.&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Also worth mention are these podcasts: &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/women-in-data-science/id1440076586&#34;&gt;WiDS (Women in Data Science)&lt;/a&gt; | Data science is improving outcomes in a wide range of domains, from healthcare to seismology to human rights and more. Hear from women leaders across the data science profession, as they share their advice, career highlights, and lessons learned along the way.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/data-science-salon-podcast/id1472749960&#34;&gt;Data Science Salon Podcast&lt;/a&gt; | Interviews with top and rising luminaries in data science, machine learning, and AI on the trends and business use cases that are propelling the field forward.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/voices-in-ai/id1291540809&#34;&gt;Voices in AI&lt;/a&gt; from GigaOm| Today&#39;s Leading Minds Talk AI with Host Byron Reese.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/machine-learning-guide/id1204521130&#34;&gt;Machine Learning Guide&lt;/a&gt; | Teaches the high-level fundamentals of machine learning and artificial intelligence including basic intuition, algorithms, and math. With discussions on languages and frameworks and deep learning, each episode offers a high-quality curated resource for learning each episode’s details.&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/freakonomics-radio/id354668519&#34;&gt;Freakonomics Radio&lt;/a&gt; | Discover the hidden side of everything with Stephen J. Dubner, co-author of the Freakonomics books. Each week, Freakonomics Radio tells you things you always thought you knew (but didn’t) and things you never thought you wanted to know (but do) — from the economics of sleep to how to become great at just about anything. Dubner speaks with Nobel laureates and provocateurs, intellectuals and entrepreneurs, and various other underachievers. Special features include series like “The Secret Life of a C.E.O.” as well as a live game show, “Tell Me Something I Don’t Know.”&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://podcasts.apple.com/us/podcast/talk-python-to-me/id979020229&#34;&gt;Talk Python To Me&lt;/a&gt; | Covering a wide array of Python and related topics, our goal is to bring you the human story behind the Python packages and frameworks you know and love.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;277px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/podcasts.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;ChaGPT Cheat Sheets &amp;amp; Books | Day 48&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;ChatGPT Cheat Sheets could be found as items &lt;strong&gt;58&lt;/strong&gt; and &lt;strong&gt;59&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; where you could learn ChatGPT tips and tricks for NLP, Code, Structure and Unstructured output, Media types, and Meta ChatGPT and &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; for understanding OpenAI API and using it to build ChatGPT applications or accessed throuh &lt;a href=&#34;https://www.kdnuggets.com/2023/01/chatgpt-cheat-sheet.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Books on ChatGPR as items &lt;strong&gt;11&lt;/strong&gt;, &lt;strong&gt;12&lt;/strong&gt; and &lt;strong&gt;13&lt;/strong&gt; could be found &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; where it provides 100 resources to enhance your life with ChatGPT, &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; where you could learn strategies for crafting compelling ChatGPT prompts that drive engaging and informative conversations and &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-books&#34;&gt;here&lt;/a&gt; to learn how to prompt for software engineering tasks or accessed through &lt;a href=&#34;https://hasantoxr.gumroad.com/l/gpt&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://fka.gumroad.com/l/art-of-chatgpt-prompting&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://sergiorocks.gumroad.com/l/chatgpt-prompts-for-software-engineers&#34;&gt;here&lt;/a&gt;.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p align=&#34;center&#34;&gt; &lt;img height=&#34;400px&#34; src=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/chatgpt_cheats_print.png&#34;&gt; &lt;/p&gt; &#xA;&lt;h1&gt;Could AI revolutionise Drug Discovery? | Day 49&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Read article on Graph Machine Learning for Drug Discovery. As DL applciations have been on the rise in Drug Discoveryy yet Graph Machine Learning has gained considerable attention for its exceptional ability to model graph-structured biomedical data and investigate their properties and functional relationships. Details are found as item &lt;strong&gt;60&lt;/strong&gt; &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; or accessed straight through &lt;a href=&#34;https://deepai.org/publication/knowledge-augmented-graph-machine-learning-for-drug-discovery-a-survey-from-precision-to-interpretability&#34;&gt;here&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Machine Learning Visualisations | Day 50&lt;/h1&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Studied about Machine Learning Visualisations. Looked at the basics (1&lt;sup&gt;st&lt;/sup&gt; link), then studied the implementation in PyTorch that I use frequently (2&lt;sup&gt;nd&lt;/sup&gt; link) and finished by looking at Visualsiations role in ML (3&lt;sup&gt;rd&lt;/sup&gt; link.) These articels can be accesesed though &lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#worthy-tools&#34;&gt;here&lt;/a&gt; as there they are as items &lt;strong&gt;61&lt;/strong&gt;, &lt;strong&gt;62&lt;/strong&gt; and &lt;strong&gt;63&lt;/strong&gt; or by clicking on a link below: &#xA;  &lt;ol&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/a-simple-guide-to-machine-learning-visualisations-6c808ac925dd&#34;&gt;A Simple Guide to Machine Learning Visualisations&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://appsilon.com/visualize-pytorch-neural-networks/&#34;&gt;How to Visualize PyTorch Neural Networks – 3 Examples in Python&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://pub.towardsai.net/role-of-data-visualization-in-machine-learning-a6dd62ad1082&#34;&gt;Role of Data Visualization in Machine Learning&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ol&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Public&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;Public folder contains two files:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/todolist.txt&#34;&gt;todolist&lt;/a&gt; - the TO DO List.&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/tree/main/Public/Images&#34;&gt;Images&lt;/a&gt; - the Images folder.&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Jupyter in Browser&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;First nice thing is that you could run Jupyter also through browser by doing so going &lt;a href=&#34;https://jupyterlite.github.io/demo/lab/index.html&#34;&gt;here&lt;/a&gt; and reading more about it in this &lt;a href=&#34;https://medium.com/geekculture/run-jupyter-notebooks-on-a-web-browser-using-jupyterlite-18e3bd25bd97&#34;&gt;article&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;If you find difficulty in running Jupyter Notebook through Browser then you could use Google Colab by clicking &lt;a href=&#34;https://colab.research.google.com/notebooks/intro.ipynb&#34;&gt;here&lt;/a&gt;. Functionalities of both machines are similar.&lt;/p&gt; &#xA;&lt;h1&gt;Logo&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The Logo of the repository can be found &lt;a href=&#34;https://github.com/aurimas13/Machine-Learning-Goodness/raw/main/Public/Images/ml.jpg&#34;&gt;here&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;h1&gt;License&lt;/h1&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/aurimas13/Machine-Learning-Goodness/main/#table-of-contents&#34;&gt;(Back to top)&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;The MIT LICENSE can be found &lt;a href=&#34;https://github.com/aurimas13/CodeAcademy-AI-Course/raw/main/LICENSE&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>datawhalechina/leedl-tutorial</title>
    <updated>2023-02-20T01:39:32Z</updated>
    <id>tag:github.com,2023-02-20:/datawhalechina/leedl-tutorial</id>
    <link href="https://github.com/datawhalechina/leedl-tutorial" rel="alternate"></link>
    <summary type="html">&lt;p&gt;《李宏毅深度学习教程》，PDF下载地址：https://github.com/datawhalechina/leedl-tutorial/releases&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/issues&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/issues/datawhalechina/leedl-tutorial&#34; alt=&#34;GitHub issues&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/stargazers&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/stars/datawhalechina/leedl-tutorial&#34; alt=&#34;GitHub stars&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/network&#34;&gt;&lt;img src=&#34;https://img.shields.io/github/forks/datawhalechina/leedl-tutorial&#34; alt=&#34;GitHub forks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://hits.seeyoufarm.com&#34;&gt;&lt;img src=&#34;https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fdatawhalechina%2Fleedl-tutorial%2F&amp;amp;count_bg=%2379C83D&amp;amp;title_bg=%23555555&amp;amp;icon=&amp;amp;icon_color=%23E7E7E7&amp;amp;title=hits&amp;amp;edge_flat=false&#34; alt=&#34;Hits&#34;&gt;&lt;/a&gt; &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;知识共享许可协议&#34; style=&#34;border-width:0&#34; src=&#34;https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;李宏毅深度学习教程LeeDL-Tutorial&lt;/h1&gt; &#xA;&lt;p&gt;李宏毅老师是台湾大学的教授，其&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html&#34;&gt;《机器学习》（2021年春）&lt;/a&gt;是深度学习领域经典的中文视频之一。李老师幽默风趣的授课风格深受大家喜爱，让晦涩难懂的深度学习理论变得轻松易懂，他会通过很多动漫相关的有趣例子来讲解深度学习理论。李老师的课程内容很全面，覆盖了到深度学习必须掌握的常见理论，能让学生对于深度学习的绝大多数领域都有一定了解，从而可以进一步选择想要深入的方向进行学习，对于想入门深度学习又想看中文讲解的同学是非常推荐的&lt;/p&gt; &#xA;&lt;p&gt;本教程主要内容源于&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html&#34;&gt;《机器学习》（2021年春）&lt;/a&gt;，并在其基础上进行了一定的原创。比如，为了尽可能地降低阅读门槛，笔者对这门公开课的精华内容进行选取并优化，对所涉及的公式都给出详细的推导过程，对较难理解的知识点进行了重点讲解和强化，以方便读者较为轻松地入门。此外，为了丰富内容，笔者在教程中选取了&lt;a href=&#34;https://speech.ee.ntu.edu.tw/~hylee/ml/2017-spring.php&#34;&gt;《机器学习》（2017年春）&lt;/a&gt; 的部分内容，并补充了不少除这门公开课之外的深度学习相关知识。&lt;/p&gt; &#xA;&lt;p&gt;注：&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;基于《机器学习》（2017年春）的李宏毅机器学习笔记在线阅读地址：&lt;a href=&#34;https://datawhalechina.github.io/leedl-tutorial/#/&#34;&gt;https://datawhalechina.github.io/leedl-tutorial/#/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;基于《机器学习》（2017年春）的李宏毅机器学习笔记源文件：&lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/tree/pre_master&#34;&gt;https://github.com/datawhalechina/leedl-tutorial/tree/pre_master&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;最新版PDF下载&lt;/h2&gt; &#xA;&lt;p&gt;地址：&lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/releases&#34;&gt;https://github.com/datawhalechina/leedl-tutorial/releases&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;国内地址(推荐国内读者使用)：&lt;a href=&#34;https://pan.baidu.com/s/14vaVeAVZrWsqQcMYIgN9Nw&#34;&gt;https://pan.baidu.com/s/14vaVeAVZrWsqQcMYIgN9Nw&lt;/a&gt; 提取码: ynuf&lt;/p&gt; &#xA;&lt;h2&gt;内容介绍&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;引言&lt;/strong&gt; @王琦&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;深度学习&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 局部最小值与鞍点&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 训练技巧&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 自适应学习率&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 分类问题损失函数&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 归一化&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;卷积神经网络和自注意力机制&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 卷积神经网络&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 自注意力机制&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;循环神经网络&lt;/strong&gt; @王琦&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Transformer&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成模型&lt;/strong&gt; @杨毅远&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 生成对抗网络基础&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 生成对抗网络理论与 Wasserstein 生成对抗网络&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 生成对抗网络的评估与有条件的生成对抗网络&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 循环生成对抗网络&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;自监督学习&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; 芝麻街的模型&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; BERT&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; GPT-3&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;自动编码器概念及其应用&lt;/strong&gt; @江季&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;对抗攻击&lt;/strong&gt; @杨毅远&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 对抗攻击基本概念&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 对抗攻击的攻击与防守&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;可解释人工智能&lt;/strong&gt; @杨毅远&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;迁移学习&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 领域自适应&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 领域对抗训练&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;深度强化学习&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 深度强化学习基础&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 策略梯度&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 演员-评论员算法&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 稀疏奖励&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 模仿学习&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;终身学习&lt;/strong&gt; @杨毅远&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 灾难性遗忘&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 缓解灾难性遗忘&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;网络压缩&lt;/strong&gt; @王琦&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 剪枝与彩票假设&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; 知识蒸馏&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;集成学习&lt;/strong&gt; @王琦&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;strong&gt;元学习&lt;/strong&gt; @杨毅远&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;配套代码&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/datawhalechina/leedl-tutorial/tree/master/Homework&#34;&gt;点击&lt;/a&gt;或者网页点击&lt;code&gt;Homework&lt;/code&gt;文件夹进入配套代码&lt;/p&gt; &#xA;&lt;h2&gt;贡献者&lt;/h2&gt; &#xA;&lt;table border=&#34;0&#34;&gt; &#xA; &lt;tbody&gt; &#xA;  &lt;tr align=&#34;center&#34;&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/qiwang067&#34;&gt;&lt;img width=&#34;70&#34; height=&#34;70&#34; src=&#34;https://github.com/qiwang067.png?s=40&#34; alt=&#34;pic&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/qiwang067&#34;&gt;Qi Wang&lt;/a&gt; &lt;p&gt; 上海交通大学博士生&lt;br&gt;中国科学院大学硕士&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/yyysjz1997&#34;&gt;&lt;img width=&#34;70&#34; height=&#34;70&#34; src=&#34;https://github.com/yyysjz1997.png?s=40&#34; alt=&#34;pic&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/yyysjz1997&#34;&gt;Yiyuan Yang&lt;/a&gt; &lt;p&gt; 牛津大学博士生&lt;br&gt;清华大学硕士&lt;/p&gt; &lt;/td&gt; &#xA;   &lt;td&gt; &lt;a href=&#34;https://github.com/JohnJim0816&#34;&gt;&lt;img width=&#34;70&#34; height=&#34;70&#34; src=&#34;https://github.com/JohnJim0816.png?s=40&#34; alt=&#34;pic&#34;&gt;&lt;/a&gt;&lt;br&gt; &lt;a href=&#34;https://github.com/JohnJim0816&#34;&gt;John Jim&lt;/a&gt; &lt;p&gt;北京大学硕士&lt;/p&gt; &lt;/td&gt; &#xA;  &lt;/tr&gt; &#xA; &lt;/tbody&gt; &#xA;&lt;/table&gt; &#xA;&lt;h2&gt;引用信息&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@misc{wang2023leedltutorial,&#xA;title = {李宏毅深度学习教程},&#xA;year = {2023},&#xA;author = {王琦，杨毅远，江季},&#xA;url = {https://github.com/datawhalechina/leedl-tutorial}&#xA;}&#xA;&#xA;@misc{wang2023leedltutorialen,&#xA;title = {Deep Learning Tutorial by Hung-yi Lee},&#xA;year = {2023},&#xA;author = {Qi Wang，Yiyuan Yang，Ji Jiang},&#xA;url = {https://github.com/datawhalechina/leedl-tutorial}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;致谢&lt;/h2&gt; &#xA;&lt;p&gt;特别感谢 &lt;a href=&#34;https://github.com/Sm1les&#34;&gt;@Sm1les&lt;/a&gt;、&lt;a href=&#34;https://github.com/LSGOMYP&#34;&gt;@LSGOMYP&lt;/a&gt; 对本项目的帮助与支持。&lt;/p&gt; &#xA;&lt;h2&gt;LICENSE&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;知识共享许可协议&#34; style=&#34;border-width:0&#34; src=&#34;https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-lightgrey&#34;&gt;&lt;/a&gt;&lt;br&gt;本作品采用&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议&lt;/a&gt;进行许可。&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>dair-ai/Prompt-Engineering-Guide</title>
    <updated>2023-02-20T01:39:32Z</updated>
    <id>tag:github.com,2023-02-20:/dair-ai/Prompt-Engineering-Guide</id>
    <link href="https://github.com/dair-ai/Prompt-Engineering-Guide" rel="alternate"></link>
    <summary type="html">&lt;p&gt;🐙 Guides, papers, and resources for prompt engineering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Prompt Engineering Guide&lt;/h1&gt; &#xA;&lt;p&gt;This guide contains a set of recent papers, learning guides, and tools related to prompt engineering. The repo is intended as a research and educational reference for practitioners and developers.&lt;/p&gt; &#xA;&lt;p&gt;Announcements:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;🎉 Prompt Engineering Lecture is live &lt;a href=&#34;https://youtu.be/dOxUroR57xs&#34;&gt;here&lt;/a&gt;! It Includes &lt;a href=&#34;https://github.com/dair-ai/Prompt-Engineering-Guide/raw/main/notebooks/pe-lecture.ipynb&#34;&gt;notebook&lt;/a&gt; and &lt;a href=&#34;https://github.com/dair-ai/Prompt-Engineering-Guide/raw/main/lecture/Prompt-Engineering-Lecture-Elvis.pdf&#34;&gt;slides&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;&lt;a href=&#34;https://discord.gg/SKgkVT8BGJ&#34;&gt;Join our Discord&lt;/a&gt; to discuss more about prompt engineering&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#guides&#34;&gt;Guides&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#papers&#34;&gt;Papers&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#tools--libraries&#34;&gt;Tools &amp;amp; Libraries&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#datasets&#34;&gt;Datasets&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/#blog-guides-tutorials-and-other-readings&#34;&gt;Blog, Guides, Tutorials and Other Readings&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h2&gt;Guides 🔮&lt;/h2&gt; &#xA;&lt;p&gt;The following are a set of guides on prompt engineering developed by us. Guides are work in progress.&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-intro.md&#34;&gt;Prompt Engineering - Introduction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-basic-usage.md&#34;&gt;Prompt Engineering - Basic Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompts-advanced-usage.md&#34;&gt;Prompt Engineering - Advanced Usage&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompt-adversarial.md&#34;&gt;Prompt Engineering - Adversarial Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/dair-ai/Prompt-Engineering-Guide/main/guides/prompt-miscellaneous.md&#34;&gt;Prompt Engineering - Miscellaneous Topics&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Papers&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Release Date)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Surveys / Overviews:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07842&#34;&gt;Augmented Language Models: a Survey&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.00234&#34;&gt;A Survey for In-context Learning&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.10403&#34;&gt;Towards Reasoning in Large Language Models: A Survey&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.07682&#34;&gt;Emergent Abilities of Large Language Models&lt;/a&gt; (Jun 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.13988&#34;&gt;A Taxonomy of Prompt Modifiers for Text-To-Image Generation&lt;/a&gt; (Apr 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.13586&#34;&gt;Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing&lt;/a&gt; (Jul 2021)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Approaches/Techniques:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07994&#34;&gt;À-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08043&#34;&gt;GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07459&#34;&gt;The Capacity for Moral Self-Correction in Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.06868&#34;&gt;SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05619&#34;&gt;Evaluating the Robustness of Discrete Prompts&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.05698&#34;&gt;Compositional Exemplars for In-context Learning&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03668&#34;&gt;Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00923&#34;&gt;Multimodal Chain-of-Thought Reasoning in Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00093&#34;&gt;Large Language Models Can Be Easily Distracted by Irrelevant Context&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.00618&#34;&gt;Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12314&#34;&gt;Progressive Prompts: Continual Learning for Language Models&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.08721&#34;&gt;Batch Prompting: Efficient Inference with LLM APIs&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.08061&#34;&gt;On Second Thought, Let&#39;s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.08073&#34;&gt;Constitutional AI: Harmlessness from AI Feedback&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.04092&#34;&gt;Successive Prompting for Decomposing Complex Questions&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.09251&#34;&gt;Discovering Language Model Behaviors with Model-Written Evaluations&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.06713&#34;&gt;Structured Prompting: Scaling In-Context Learning to 1,000 Examples&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.10435&#34;&gt;PAL: Program-aided Language Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.01910&#34;&gt;Large Language Models Are Human-Level Prompt Engineers&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09527&#34;&gt;Ignore Previous Prompt: Attack Techniques For Language Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.07321&#34;&gt;Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.09066&#34;&gt;Teaching Algorithmic Reasoning via In-context Learning&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.11875&#34;&gt;Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for&#34;&gt;Ask Me Anything: A simple strategy for prompting language models&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.03629&#34;&gt;ReAct: Synergizing Reasoning and Acting in Language Models&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.09150&#34;&gt;Prompting GPT-3 To Be Reliable&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.02406&#34;&gt;Decomposed Prompting: A Modular Approach for Solving Complex Tasks&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01240v3&#34;&gt;Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.02128&#34;&gt;Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.11755&#34;&gt;Promptagator: Few-shot Dense Retrieval From 8 Examples&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.02336&#34;&gt;On the Advance of Making Language Models Better Reasoners&lt;/a&gt; (June 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.11916&#34;&gt;Large Language Models are Zero-Shot Reasoners&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.00445&#34;&gt;MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.12390&#34;&gt;Toxicity Detection with Generative Prompt-based Inference&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.03401&#34;&gt;The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning&lt;/a&gt; (May 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2204.13988&#34;&gt;A Taxonomy of Prompt Modifiers for Text-To-Image Generation&lt;/a&gt; (Apr 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.06566&#34;&gt;PromptChainer: Chaining Large Language Model Prompts through Visual Programming&lt;/a&gt; (Mar 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.11171&#34;&gt;Self-Consistency Improves Chain of Thought Reasoning in Language Models&lt;/a&gt; (March 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.12837&#34;&gt;Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?&lt;/a&gt; (Feb 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;Chain of Thought Prompting Elicits Reasoning in Large Language Models&lt;/a&gt; (Jan 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2112.00114&#34;&gt;Show Your Work: Scratchpads for Intermediate Computation with Language Models&lt;/a&gt; (Nov 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2110.08387&#34;&gt;Generated Knowledge Prompting for Commonsense Reasoning&lt;/a&gt; (Oct 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.07830&#34;&gt;Reframing Instructional Prompts to GPTk&#39;s Language&lt;/a&gt; (Sep 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2109.06977&#34;&gt;Design Guidelines for Prompt Engineering Text-to-Image Generative Models&lt;/a&gt; (Sep 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2021.acl-long.295&#34;&gt;Making Pre-trained Language Models Better Few-shot Learners&lt;/a&gt; (Aug 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.08786&#34;&gt;Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2021.eacl-main.316&#34;&gt;BERTese: Learning to Speak to BERT&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.08691&#34;&gt;The Power of Scale for Parameter-Efficient Prompt Tuning&lt;/a&gt; (April 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.07350&#34;&gt;Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm&lt;/a&gt; (Feb 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2102.09690&#34;&gt;Calibrate Before Use: Improving Few-Shot Performance of Language Models&lt;/a&gt; (Feb 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2101.00190&#34;&gt;Prefix-Tuning: Optimizing Continuous Prompts for Generation&lt;/a&gt; (Jan 2021)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.15980&#34;&gt;AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts&lt;/a&gt; (Oct 2020)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.14165&#34;&gt;Language Models are Few-Shot Learners&lt;/a&gt; (May 2020)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know&#34;&gt;How Can We Know What Language Models Know?&lt;/a&gt; (July 2020)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Applications:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08068&#34;&gt;LabelPrompt: Effective Prompt-based Learning for Relation Classification&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.08102&#34;&gt;Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.07459&#34;&gt;The Capacity for Moral Self-Correction in Large Language Models&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.04156&#34;&gt;Prompting for Multimodal Hateful Meme Classification&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03269&#34;&gt;PLACES: Prompting Language Models for Social Conversation Synthesis&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.01441&#34;&gt;Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation&lt;/a&gt; (Feb 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.12810&#34;&gt;Crawling the Internal Knowledge-Base of Language Models&lt;/a&gt; (Jan 2023)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.02199&#34;&gt;Legal Prompt Engineering for Multilingual Legal Judgement Prediction&lt;/a&gt; (Dec 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2211.15462&#34;&gt;Investigating Prompt Engineering in Diffusion Models&lt;/a&gt; (Nov 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.09513v2&#34;&gt;Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering&lt;/a&gt; (Sep 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.15157&#34;&gt;Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.14699&#34;&gt;Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?&lt;/a&gt; (Oct 2022)&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2022.inlg-main.5&#34;&gt;Plot Writing From Scratch Pre-Trained Language Models&lt;/a&gt; (July 2022)&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Collections:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/Timothyxxx/Chain-of-ThoughtsPapers&#34;&gt;Chain-of-ThoughtsPapers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/task/prompt-engineering&#34;&gt;Papers with Code&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/PromptPapers#papers&#34;&gt;Prompt Papers&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Tools &amp;amp; Libraries&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aitestkitchen.withgoogle.com&#34;&gt;AI Test Kitchen&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/krrishdholakia/betterprompt&#34;&gt;betterprompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.dreamstudio.ai&#34;&gt;DreamStudio&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dust.tt&#34;&gt;DUST&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://trydyno.com&#34;&gt;Dyno&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.everyprompt.com&#34;&gt;EveryPrompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/jerryjliu/gpt_index&#34;&gt;GPT Index&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpttools.com/comparisontool&#34;&gt;GPTTools&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/adversarial-prompts&#34;&gt;hwchase17/adversarial-prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/oughtinc/ice&#34;&gt;Interactive Composition Explorer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;LangChain&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.learngpt.com&#34;&gt;LearnGPT&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lexica.art&#34;&gt;Lexica&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/socketteer/loom&#34;&gt;loom&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://metaprompt.vercel.app/?task=gpt&#34;&gt;Metaprompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/playground&#34;&gt;OpenAI Playground&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/thunlp/OpenPrompt&#34;&gt;OpenPrompt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://playgroundai.com&#34;&gt;Playground&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://app.prodia.com/#/&#34;&gt;Prodia&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://promptbase.com&#34;&gt;Prompt Base&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/microsoft/prompt-engine&#34;&gt;Prompt Engine&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://dalle2-prompt-generator.s3-website-us-west-2.amazonaws.com&#34;&gt;Prompt Generator for OpenAI&#39;s DALL-E 2&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://promptable.ai&#34;&gt;Promptable&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/agencyenterprise/PromptInject&#34;&gt;PromptInject&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sevazhidkov/prompts-ai&#34;&gt;Prompts.ai&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/bigscience-workshop/promptsource&#34;&gt;PromptSource&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scale.com/spellbook&#34;&gt;Scale SpellBook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://sharegpt.com&#34;&gt;sharegpt&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/OpenBioLink/ThoughtSource&#34;&gt;ThoughtSource&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://tools.saxifrage.xyz/prompt&#34;&gt;Visual Prompt Builder&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Datasets&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/anthropics/hh-rlhf/tree/master/red-team-attempts&#34;&gt;Anthropic&#39;s Red Team dataset&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2209.07858&#34;&gt;(paper)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/fka/awesome-chatgpt-prompts&#34;&gt;Awesome ChatGPT Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/poloclub/diffusiondb&#34;&gt;DiffusionDB&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/succinctly/midjourney-prompts&#34;&gt;Midjourney Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/bigscience/P3&#34;&gt;P3 - Public Pool of Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://parti.research.google&#34;&gt;PartiPrompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://allenai.org/data/real-toxicity-prompts&#34;&gt;Real Toxicity Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts&#34;&gt;Stable Diffusion Dataset&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/WritingPrompts&#34;&gt;WritingPrompts&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Blog, Guides, Tutorials and Other Readings&lt;/h2&gt; &#xA;&lt;h4&gt;(Sorted by Name)&lt;/h4&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/3-principles-prompt-engineering-gpt-3-ben-whately&#34;&gt;3 Principles for prompt engineering with GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://aitestkitchen.withgoogle.com/how-lamda-works&#34;&gt;A beginner-friendly guide to generative language models - LaMBDA guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.mihaileric.com/posts/a-complete-introduction-to-prompt-engineering&#34;&gt;A Complete Introduction to Prompt Engineering for Large Language Models&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://medium.com/@thorbjoern.heise/a-generic-framework-for-chatgpt-prompt-engineering-7097f6513a0b&#34;&gt;A Generic Framework for ChatGPT Prompt Engineering&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.jonstokes.com/p/ai-content-generation-part-1-machine&#34;&gt;AI Content Generation&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/f/awesome-chatgpt-prompts&#34;&gt;Awesome ChatGPT Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://mpost.io/best-100-stable-diffusion-prompts-the-most-beautiful-ai-text-to-image-prompts&#34;&gt;Best 100+ Stable Diffusion Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api&#34;&gt;Best practices for prompt engineering with OpenAI API&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gpt3demo.com&#34;&gt;ChatGPT, AI and GPT-3 Apps and use cases&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=5ef83Wljm-M&amp;amp;feature=shares&#34;&gt;CMU Advanced NLP 2022: Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://gist.github.com/Curtis-64&#34;&gt;Curtis64&#39;s set of prompt gists&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#&#34;&gt;DALL·E 2 Prompt Engineering Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://dallery.gallery/the-dalle-2-prompt-book&#34;&gt;DALLE Prompt Book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://scale.com/guides/diffusion-models-guide&#34;&gt;Diffusion Models: A Practical Guide&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/goodside/status/1569128808308957185&#34;&gt;Exploiting GPT-3 Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks&#34;&gt;Exploring Prompt Injection Attacks&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://ai.stanford.edu/blog/in-context-learning&#34;&gt;Extrapolating to Unnatural Language Processing with GPT-3&#39;s In-context Learning: The Good, the Bad, and the Mysterious&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://txt.cohere.ai/generative-ai-part-1&#34;&gt;Generative AI with Cohere: Part 1 - Model Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html&#34;&gt;Giving GPT-3 a Turing Test&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://buildspace.so/notes/intro-to-gpt3-prompts&#34;&gt;GPT3 and Prompts: A quick primer&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://andys.page/posts/how-to-draw&#34;&gt;How to Draw Anything&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/StableDiffusion/comments/x41n87/how_to_get_images_that_dont_suck_a&#34;&gt;How to get images that don&#39;t suck&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://andymatuschak.org/prompts&#34;&gt;How to write good prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=OsbUfL8w-mo&amp;amp;feature=shares&#34;&gt;Language Models and Prompt Engineering: Systematic Survey of Prompting Methods in NLP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://learnprompting.org&#34;&gt;Learn Prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://generative.ink/posts/methods-of-prompt-programming&#34;&gt;Methods of prompt programming&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse&#34;&gt;Mysteries of mode collapse&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://heartbeat.comet.ml/nlp-for-text-to-image-generators-prompt-analysis-part-1-5076a44d8365&#34;&gt;NLP for Text-to-Image Generators: Prompt Analysis&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf&#34;&gt;NLP with Deep Learning CS224N/Ling284 - Lecture 11: Promting, Instruction Tuning, and RLHF&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/sw-yx/ai-notes&#34;&gt;Notes for Prompt Engineering by sw-yx&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;OpenAI Cookbook&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://platform.openai.com/examples&#34;&gt;OpenAI Prompt Examples for several applications&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;http://pretrain.nlpedia.ai&#34;&gt;Pretrain, Prompt, Predict - A New Paradigm for NLP&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/prompt-engineering-101-introduction-resources-amatriain&#34;&gt;Prompt Engineering 101 - Introduction and resources&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=v2gD8BHOaX4&amp;amp;feature=shares&#34;&gt;Prompt Engineering 101: Autocomplete, Zero-shot, One-shot, and Few-shot prompting&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://humanloop.com/blog/prompt-engineering-101&#34;&gt;Prompt Engineering 101&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=w102J3_9Bcs&amp;amp;ab_channel=PatrickDebois&#34;&gt;Prompt Engineering - A new profession ?&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.cohere.ai/docs/prompt-engineering&#34;&gt;Prompt Engineering by co:here&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/prompt-engineering&#34;&gt;Prompt Engineering by Microsoft&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.patterns.app/blog/2022/12/21/finetune-llm-tech-support&#34;&gt;Prompt engineering davinci-003 on our own docs for automated support (Part I)&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://richardbatt.co.uk/prompt-engineering-guide-how-to-engineer-the-perfect-prompts&#34;&gt;Prompt Engineering Guide: How to Engineer the Perfect Prompts&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2022/05/prompt-engineering-in-gpt-3&#34;&gt;Prompt Engineering in GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/spreadsheets/d/1-snKDn38-KypoYCk9XLPg799bHcNFSBAVu2HVvFEAkA/edit#gid=0&#34;&gt;Prompt Engineering Template&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://github.com/topics/prompt-engineering&#34;&gt;Prompt Engineering Topic by GitHub&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.saxifrage.xyz/post/prompt-engineering&#34;&gt;Prompt Engineering: From Words to Art&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://youtube.com/watch?v=BP9fi_0XTlw&amp;amp;feature=shares&#34;&gt;Prompt Engineering with OpenAI&#39;s GPT-3 and other LLMs&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://simonwillison.net/2022/Sep/12/prompt-injection&#34;&gt;Prompt injection attacks against GPT-3&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://twitter.com/ludwig_stumpp/status/1619701277419794435?s=20&amp;amp;t=GtoMlmYCSt-UmvjqJVbBSA&#34;&gt;Prompt injection to read out the secret OpenAI API key&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://savasy-22028.medium.com/prompting-in-nlp-prompt-based-zero-shot-learning-3f34bfdb2b72&#34;&gt;Prompting in NLP: Prompt-based zero-shot learning&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://snorkel.ai/prompting-methods-with-language-models-nlp&#34;&gt;Prompting Methods with Language Models and Their Applications to Weak Supervision&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.gwern.net/GPT-3#prompts-as-programming&#34;&gt;Prompts as Programming by Gwern&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://lspace.swyx.io/p/reverse-prompt-eng&#34;&gt;Reverse Prompt Engineering for Fun and (no) Profit&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators&#34;&gt;Simulators&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://beta.openai.com/docs/quickstart/start-with-an-instruction&#34;&gt;Start with an Instruction&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://artifact-research.com/artificial-intelligence/talking-to-machines-prompt-engineering-injection&#34;&gt;Talking to machines: prompt engineering &amp;amp; injection&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://fedhoneypot.notion.site/25fdbdb69e9e44c6877d79e18336fe05?v=1d2bf4143680451986fd2836a04afbf4&#34;&gt;the Book - Fed Honeypot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/17b_ocq-GL5lhV_bYSShzUgxL02mtWDoiw9xEroJ5m3Q/edit#slide=id.gc6f83aa91_0_79&#34;&gt;The ChatGPT Prompt Book&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking&#34;&gt;Using GPT-Eliezer against ChatGPT Jailbreaking&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h1&gt;Lecture + Tutorial&lt;/h1&gt; &#xA;&lt;p&gt;Full tutorial and lecture coming soon!&lt;/p&gt; &#xA;&lt;hr&gt; &#xA;&lt;p&gt;Feel free to open a PR if you think something is missing here. Always welcome feedback and suggestions.&lt;/p&gt;</summary>
  </entry>
</feed>