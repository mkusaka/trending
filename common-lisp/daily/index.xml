<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Common Lisp Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2024-12-13T01:30:21Z</updated>
  <subtitle>Daily Trending of Common Lisp in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>hikettei/Caten</title>
    <updated>2024-12-13T01:30:21Z</updated>
    <id>tag:github.com,2024-12-13:/hikettei/Caten</id>
    <link href="https://github.com/hikettei/Caten" rel="alternate"></link>
    <summary type="html">&lt;p&gt;[wip] Deep Learning Compiler based on Polyhedral Compiler and Light-weight IRs, and Optimizing Pattern Matcher.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Caten&lt;/h1&gt; &#xA;&lt;blockquote&gt; &#xA; &lt;p&gt;&lt;strong&gt;This repository is still in the early stages of development. Additionally, it includes many experimental approaches. Please consider this as a place to experiment with my ideas. Do not use it in a product under any circumstances.&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;/blockquote&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/hikettei/Caten/actions/workflows/tests_on_push.yml&#34;&gt;&lt;img src=&#34;https://github.com/hikettei/Caten/actions/workflows/tests_on_push.yml/badge.svg?sanitize=true&#34; alt=&#34;CI&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hikettei/Caten/actions/workflows/benchmark.yml&#34;&gt;&lt;img src=&#34;https://github.com/hikettei/Caten/actions/workflows/benchmark.yml/badge.svg?sanitize=true&#34; alt=&#34;Benchmarks&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/hikettei/Caten/actions/workflows/pages/pages-build-deployment&#34;&gt;&lt;img src=&#34;https://github.com/hikettei/Caten/actions/workflows/pages/pages-build-deployment/badge.svg?sanitize=true&#34; alt=&#34;pages-build-deployment&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://discord.gg/tNawU7TN3s&#34;&gt;&lt;img src=&#34;https://dcbadge.limes.pink/api/server/tNawU7TN3s?style=flat&#34; alt=&#34;&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;p&gt;&lt;code&gt;Caten = Compile+AbstracTENsor&lt;/code&gt;&lt;/p&gt; &#xA;&lt;p&gt;Caten is an experimental deep learning compiler. Our goal is to implement a compiler that is as simple as tinygrad, and as flexible as TVM.&lt;/p&gt; &#xA;&lt;p&gt;&lt;strong&gt;We&#39;re looking for collaborators! Please join our Discord and let me know if you&#39;d like to contribute!&lt;/strong&gt;&lt;/p&gt; &#xA;&lt;h2&gt;Showcases&lt;/h2&gt; &#xA;&lt;p&gt;Caten is still under development, but it aims to support a wide range of models in the future—from image processing to text generation, and vision language models! Some models are already up and running.&lt;/p&gt; &#xA;&lt;h3&gt;Running LLMs&lt;/h3&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ JIT=1 PARALLEL=8 ./roswell/caten.ros llm-example --model &#34;gpt2&#34; --prompt &#34;Hello&#34; --max-length 100&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Give the GPT2 demo a try! You can pass compilation settings through environment variables.&lt;/p&gt; &#xA;&lt;p&gt;For example, setting &lt;code&gt;JIT=1&lt;/code&gt; enables JIT compilation, while &lt;code&gt;JIT_DEBUG &amp;gt;= 2&lt;/code&gt; allows you to view the schedule and the generated kernels. Setting &lt;code&gt;PARALLEL=8&lt;/code&gt; divides the ScheduleGraph and compiles it in parallel.&lt;/p&gt; &#xA;&lt;p&gt;You may still find the token/ms rate slow, but we&#39;re not yet at the stage of implementing an AutoScheduler to accelerate kernel performance (as well as GPU support). Once our IR matures enough to handle a wide range of deep learning models, we plan to focus on speeding things up!&lt;/p&gt; &#xA;&lt;h2&gt;Getting Started&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://github.com/roswell/roswell&#34;&gt;Roswell&lt;/a&gt; and suitable IDE. (If unsure, Emacs or &lt;a href=&#34;https://github.com/lem-project/lem&#34;&gt;Lem&lt;/a&gt; is recommended)&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://github.com/Meinersbur/isl&#34;&gt;ISL (Integer Set Library)&lt;/a&gt; for the fast kernel generation.&lt;/li&gt; &#xA; &lt;li&gt;Install &lt;a href=&#34;https://github.com/fukamachi/qlot&#34;&gt;Qlot&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Check out &lt;a href=&#34;https://raw.githubusercontent.com/hikettei/Caten/main/docs/getting-started.lisp&#34;&gt;getting-started.lisp&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone git@github.com:hikettei/Caten.git&#xA;$ cd Caten&#xA;$ qlot install&#xA;$ qlot exec ros run&#xA;&amp;gt; (ql:quickload :caten)&#xA;&amp;gt; (in-package :caten-user)&#xA;&amp;gt; (proceed (!randn `(3 3)))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Get Involved&lt;/h2&gt; &#xA;&lt;ol&gt; &#xA; &lt;li&gt; &lt;p&gt;Join our &lt;a href=&#34;https://discord.gg/tNawU7TN3s&#34;&gt;Discord Server&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Check out our &lt;a href=&#34;https://github.com/users/hikettei/projects/2&#34;&gt;roadmap&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Create a PR&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ol&gt; &#xA;&lt;p&gt;Caten is a project that started only a few months ago. We are currently in the stage of building a solid foundational library. Here’s what we’re looking for:&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;Feature additions with tests (e.g., new activations, unimplemented matrix operations)&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Bug reports and additional tests.&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Refactoring of the core compiler components&lt;/p&gt; &lt;/li&gt; &#xA; &lt;li&gt; &lt;p&gt;Improving the documentation&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;etc...&lt;/p&gt; &#xA;&lt;p&gt;Before contributing, please note that there is no linter here. Make an effort to adhere to &lt;a href=&#34;https://google.github.io/styleguide/lispguide.xml&#34;&gt;Google Common Lisp Style Guide&lt;/a&gt;. Changes that do not follow this should be rejected by the review.&lt;/p&gt; &#xA;&lt;h2&gt;Roadmap&lt;/h2&gt; &#xA;&lt;h3&gt;Supported Models&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;strong&gt;Transformer&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; GPT2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Llama3 8B&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; TinyLLAMA&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Classification&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; MobileNetV2&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; MobileNetV3&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ResNet18/ResNet34/ResNet50&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; VIT_B_16&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Segmentation&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; CenterNet&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;strong&gt;Detection&lt;/strong&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; YoLOv3&lt;/li&gt; &#xA;   &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; YoLOv7&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Supported Formats&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Common Lisp Frontend (caten/apis)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; ONNX (caten/onnx)&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; GGUF (caten/gguf)&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Quantization&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Support Dequantization from GGUF&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support QOPs&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Training&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; Autodiff&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Fast Autodiff&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Support Training&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Distributed Training&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h3&gt;Accelerators&lt;/h3&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; LISP VM&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; checked disabled&gt; CLANG JIT&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; CLANG with Auto Scheduler&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; METAL&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; CUDA&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Vulkan&lt;/li&gt; &#xA; &lt;li&gt;&lt;input type=&#34;checkbox&#34; disabled&gt; Auto Scheduler&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h2&gt;Running tests&lt;/h2&gt; &#xA;&lt;p&gt;You should install python, numpy, pytorch before running the test-suite by using &lt;code&gt;make install_extra&lt;/code&gt;. If not specified, install the latest one.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ make install_extra # extra dependencies for running tests&#xA;$ make test&#xA;&lt;/code&gt;&lt;/pre&gt;</summary>
  </entry>
</feed>