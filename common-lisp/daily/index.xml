<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom">
  <title>GitHub Common Lisp Daily Trending</title>
  <id>http://mshibanami.github.io/GitHubTrendingRSS</id>
  <updated>2023-05-17T01:32:29Z</updated>
  <subtitle>Daily Trending of Common Lisp in GitHub</subtitle>
  <link href="http://mshibanami.github.io/GitHubTrendingRSS"></link>
  <entry>
    <title>nightfly19/cl-arrows</title>
    <updated>2023-05-17T01:32:29Z</updated>
    <id>tag:github.com,2023-05-17:/nightfly19/cl-arrows</id>
    <link href="https://github.com/nightfly19/cl-arrows" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Common Lisp implementation of Clojure&#39;s threading macros&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CL-Arrows&lt;/h1&gt; &#xA;&lt;p&gt;Implements the &lt;code&gt;-&amp;gt;&lt;/code&gt; and &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; threading macros in Clojure, as well as &lt;code&gt;-&amp;lt;&amp;gt;&lt;/code&gt; and &lt;code&gt;-&amp;lt;&amp;gt;&amp;gt;&lt;/code&gt; from the &lt;a href=&#34;https://github.com/rplevy/swiss-arrows&#34;&gt;swiss-arrows&lt;/a&gt; library.&lt;/p&gt; &#xA;&lt;p&gt;This is an ASDF system providing the package &lt;code&gt;cl-arrows&lt;/code&gt;.&lt;/p&gt; &#xA;&lt;h2&gt;Documentation&lt;/h2&gt; &#xA;&lt;p&gt;[macro]&lt;br&gt; &lt;code&gt;-&amp;gt;&lt;/code&gt; initial-form &lt;em&gt;&amp;amp;rest&lt;/em&gt; forms =&amp;gt; results&lt;/p&gt; &#xA;&lt;p&gt;Inserts INITIAL-FORM as first argument into the first of FORMS, the result into the next, etc., before evaluation. FORMS are treated as list designators.&lt;/p&gt; &#xA;&lt;p&gt;[macro]&lt;br&gt; &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt; initial-form &lt;em&gt;&amp;amp;rest&lt;/em&gt; forms =&amp;gt; results&lt;/p&gt; &#xA;&lt;p&gt;Like &lt;code&gt;-&amp;gt;&lt;/code&gt;, but the forms are inserted as last argument instead of first.&lt;/p&gt; &#xA;&lt;p&gt;[macro]&lt;br&gt; &lt;code&gt;-&amp;lt;&amp;gt;&lt;/code&gt; initial-form &lt;em&gt;&amp;amp;rest&lt;/em&gt; forms =&amp;gt; results&lt;/p&gt; &#xA;&lt;p&gt;Like &lt;code&gt;-&amp;gt;&lt;/code&gt;, but if a form in FORMS has one or more symbols named &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; as top-level element, each such symbol is substituted by the primary result of the form accumulated so far, instead of it being inserted as first argument. Also known as diamond wand.&lt;/p&gt; &#xA;&lt;p&gt;[macro]&lt;br&gt; &lt;code&gt;-&amp;lt;&amp;gt;&amp;gt;&lt;/code&gt; initial-form &lt;em&gt;&amp;amp;rest&lt;/em&gt; forms =&amp;gt; results&lt;/p&gt; &#xA;&lt;p&gt;Like &lt;code&gt;-&amp;lt;&amp;gt;&lt;/code&gt;, but if a form in FORMS has no symbols named &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt; as top-level element, insertion is done like in &lt;code&gt;-&amp;gt;&amp;gt;&lt;/code&gt;. Also known as diamond spear.&lt;/p&gt; &#xA;&lt;h2&gt;Examples&lt;/h2&gt; &#xA;&lt;pre&gt;&lt;code&gt;(-&amp;gt; 3&#xA;    /)  ; insert into designated list (/)&#xA;=&amp;gt; 1/3&#xA;&#xA;(-&amp;gt; 3&#xA;    (expt 2))  ; insert as first argument&#xA;=&amp;gt; 9&#xA;&#xA;(-&amp;gt;&amp;gt; 3&#xA;     (expt 2))  ; insert as last argument&#xA;=&amp;gt; 8&#xA;&#xA;(-&amp;lt;&amp;gt;&amp;gt; (list 1 2 3)&#xA;      (remove-if #&#39;oddp &amp;lt;&amp;gt; :count 1 :from-end t) ; substitute &amp;lt;&amp;gt;&#xA;      (reduce #&#39;+)                               ; insert last&#xA;      /)                                         ; list designator&#xA;=&amp;gt; 1/3&#xA;&#xA;(let ((x 3))&#xA;  (-&amp;lt;&amp;gt; (incf x)     ; (let ((r (incf x)))&#xA;       (+ &amp;lt;&amp;gt; &amp;lt;&amp;gt;)))  ;   (+ r r))&#xA;=&amp;gt; 8&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;h2&gt;Todo&lt;/h2&gt; &#xA;&lt;p&gt;Future versions &lt;em&gt;might&lt;/em&gt; include further ideas from rplevy&#39;s &lt;a href=&#34;https://github.com/rplevy/swiss-arrows&#34;&gt;swiss-arrows&lt;/a&gt;.&lt;/p&gt;</summary>
  </entry>
  <entry>
    <title>melisgl/mgl</title>
    <updated>2023-05-17T01:32:29Z</updated>
    <id>tag:github.com,2023-05-17:/melisgl/mgl</id>
    <link href="https://github.com/melisgl/mgl" rel="alternate"></link>
    <summary type="html">&lt;p&gt;Common Lisp machine learning library.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h1&gt;MGL Manual&lt;/h1&gt; &#xA;&lt;h2&gt;Table of Contents&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29&#34; title=&#34;&amp;quot;mgl&amp;quot; ASDF/SYSTEM:SYSTEM&#34;&gt;1 &lt;code&gt;MGL&lt;/code&gt; ASDF System&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-INTRODUCTION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Introduction&#34;&gt;2 Introduction&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29&#34; title=&#34;Overview&#34;&gt;2.1 Overview&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-LINKS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Links&#34;&gt;2.2 Links&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Dependencies&#34;&gt;2.3 Dependencies&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Code Organization&#34;&gt;2.4 Code Organization&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29&#34; title=&#34;Glossary&#34;&gt;2.5 Glossary&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29&#34; title=&#34;Datasets&#34;&gt;3 Datasets&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Samplers&#34;&gt;3.1 Samplers&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Function Sampler&#34;&gt;3.1.1 Function Sampler&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Resampling&#34;&gt;4 Resampling&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Partitions&#34;&gt;4.1 Partitions&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Cross-validation&#34;&gt;4.2 Cross-validation&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Bagging&#34;&gt;4.3 Bagging&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29&#34; title=&#34;CV Bagging&#34;&gt;4.4 CV Bagging&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29&#34; title=&#34;Miscellaneous Operations&#34;&gt;4.5 Miscellaneous Operations&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CORE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Core&#34;&gt;5 Core&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-PERSISTENCE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Persistence&#34;&gt;5.1 Persistence&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Batch Processing&#34;&gt;5.2 Batch Processing&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Executors&#34;&gt;5.3 Executors&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Parameterized Executor Cache&#34;&gt;5.3.1 Parameterized Executor Cache&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Monitoring&#34;&gt;6 Monitoring&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Monitors&#34;&gt;6.1 Monitors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Measurers&#34;&gt;6.2 Measurers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Counters&#34;&gt;6.3 Counters&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Attributes&#34;&gt;6.3.1 Attributes&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Counter classes&#34;&gt;6.3.2 Counter classes&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification&#34;&gt;7 Classification&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Monitors&#34;&gt;7.1 Classification Monitors&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Measurers&#34;&gt;7.2 Classification Measurers&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Counters&#34;&gt;7.3 Classification Counters&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29&#34; title=&#34;Confusion Matrices&#34;&gt;7.3.1 Confusion Matrices&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-FEATURES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Features&#34;&gt;8 Features&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-FEATURE-SELECTION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Feature Selection&#34;&gt;8.1 Feature Selection&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-FEATURE-ENCODING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Feature Encoding&#34;&gt;8.2 Feature Encoding&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Based Optimization&#34;&gt;9 Gradient Based Optimization&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Iterative Optimizer&#34;&gt;9.1 Iterative Optimizer&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29&#34; title=&#34;Cost Function&#34;&gt;9.2 Cost Function&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;9.3 Gradient Descent&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Batch Based Optimizers&#34;&gt;9.3.1 Batch Based Optimizers&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Segmented GD Optimizer&#34;&gt;9.3.2 Segmented GD Optimizer&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Per-weight Optimization&#34;&gt;9.3.3 Per-weight Optimization&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Utilities&#34;&gt;9.3.4 Utilities&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34; title=&#34;Conjugate Gradient&#34;&gt;9.4 Conjugate Gradient&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29&#34; title=&#34;Extension API&#34;&gt;9.5 Extension API&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Implementing Optimizers&#34;&gt;9.5.1 Implementing Optimizers&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Implementing Gradient Sources&#34;&gt;9.5.2 Implementing Gradient Sources&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29&#34; title=&#34;Implementing Gradient Sinks&#34;&gt;9.5.3 Implementing Gradient Sinks&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29&#34; title=&#34;Differentiable Functions&#34;&gt;10 Differentiable Functions&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Backpropagation Neural Networks&#34;&gt;11 Backpropagation Neural Networks&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29&#34; title=&#34;Backprop Overview&#34;&gt;11.1 Backprop Overview&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29&#34; title=&#34;Clump API&#34;&gt;11.2 Clump API&lt;/a&gt;&lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29&#34; title=&#34;`BPN`s&#34;&gt;11.3 &lt;code&gt;BPN&lt;/code&gt;s&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Training&#34;&gt;11.3.1 Training&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Monitoring&#34;&gt;11.3.2 Monitoring&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29&#34; title=&#34;Feed-Forward Nets&#34;&gt;11.3.3 Feed-Forward Nets&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29&#34; title=&#34;Recurrent Neural Nets&#34;&gt;11.3.4 Recurrent Neural Nets&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Lumps&#34;&gt;11.4 Lumps&lt;/a&gt; &#xA;    &lt;ul&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Lump Base Class&#34;&gt;11.4.1 Lump Base Class&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Inputs&#34;&gt;11.4.2 Inputs&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Weight Lump&#34;&gt;11.4.3 Weight Lump&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-ACTIVATIONS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Activations&#34;&gt;11.4.4 Activations&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Activation Functions&#34;&gt;11.4.5 Activation Functions&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Losses&#34;&gt;11.4.6 Losses&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29&#34; title=&#34;Stochasticity&#34;&gt;11.4.7 Stochasticity&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29&#34; title=&#34;Arithmetic&#34;&gt;11.4.8 Arithmetic&lt;/a&gt;&lt;/li&gt; &#xA;     &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Operations for `RNN`s&#34;&gt;11.4.9 Operations for &lt;code&gt;RNN&lt;/code&gt;s&lt;/a&gt;&lt;/li&gt; &#xA;    &lt;/ul&gt; &lt;/li&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29&#34; title=&#34;Utilities&#34;&gt;11.5 Utilities&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29&#34; title=&#34;Boltzmann Machines&#34;&gt;12 Boltzmann Machines&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gaussian Processes&#34;&gt;13 Gaussian Processes&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Natural Language Processing&#34;&gt;14 Natural Language Processing&lt;/a&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3A-40MGL-NLP-BAG-OF-WORDS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Bag of Words&#34;&gt;14.1 Bag of Words&lt;/a&gt;&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;h6&gt;[in package MGL]&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;1 &lt;code&gt;MGL&lt;/code&gt; ASDF System&lt;/h2&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;Version: 0.1.0&lt;/li&gt; &#xA; &lt;li&gt;Description: &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29&#34; title=&#34;&amp;quot;mgl&amp;quot; ASDF/SYSTEM:SYSTEM&#34;&gt;&lt;code&gt;MGL&lt;/code&gt;&lt;/a&gt; is a machine learning library for backpropagation neural networks, boltzmann machines, gaussian processes and more.&lt;/li&gt; &#xA; &lt;li&gt;Licence: MIT, see COPYING.&lt;/li&gt; &#xA; &lt;li&gt;Author: Gábor Melis &lt;a href=&#34;mailto:mega@retes.hu&#34;&gt;mega@retes.hu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Mailto: &lt;a href=&#34;mailto:mega@retes.hu&#34;&gt;mega@retes.hu&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Homepage: &lt;a href=&#34;http://melisgl.github.io/mgl&#34;&gt;http://melisgl.github.io/mgl&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Bug tracker: &lt;a href=&#34;https://github.com/melisgl/mgl/issues&#34;&gt;https://github.com/melisgl/mgl/issues&lt;/a&gt;&lt;/li&gt; &#xA; &lt;li&gt;Source control: &lt;a href=&#34;https://github.com/melisgl/mgl.git&#34;&gt;GIT&lt;/a&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-INTRODUCTION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;2 Introduction&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.1 Overview&lt;/h3&gt; &#xA;&lt;p&gt;MGL is a Common Lisp machine learning library by &lt;a href=&#34;http://quotenil.com&#34;&gt;Gábor Melis&lt;/a&gt; with some parts originally contributed by Ravenpack International. It mainly concentrates on various forms of neural networks (boltzmann machines, feed-forward and recurrent backprop nets). Most of MGL is built on top of MGL-MAT so it has BLAS and CUDA support.&lt;/p&gt; &#xA;&lt;p&gt;In general, the focus is on power and performance not on ease of use. Perhaps one day there will be a cookie cutter interface with restricted functionality if a reasonable compromise is found between power and utility.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-LINKS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.2 Links&lt;/h3&gt; &#xA;&lt;p&gt;Here is the &lt;a href=&#34;https://github.com/melisgl/mgl&#34;&gt;official repository&lt;/a&gt; and the &lt;a href=&#34;http://melisgl.github.io/mgl-pax-world/mgl-manual.html&#34;&gt;HTML documentation&lt;/a&gt; for the latest version.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.3 Dependencies&lt;/h3&gt; &#xA;&lt;p&gt;MGL used to rely on &lt;a href=&#34;https://github.com/tpapp/lla&#34;&gt;LLA&lt;/a&gt; to interface to BLAS and LAPACK. That&#39;s mostly history by now, but configuration of foreign libraries is still done via LLA. See the README in LLA on how to set things up. Note that these days OpenBLAS is easier to set up and just as fast as ATLAS.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/takagi/cl-cuda&#34;&gt;CL-CUDA&lt;/a&gt; and &lt;a href=&#34;https://github.com/melisgl/mgl&#34;&gt;MGL-MAT&lt;/a&gt; are the two main dependencies and also the ones not yet in quicklisp, so just drop them into &lt;code&gt;quicklisp/local-projects/&lt;/code&gt;. If there is no suitable GPU on the system or the CUDA SDK is not installed, MGL will simply fall back on using BLAS and Lisp code. Wrapping code in &lt;code&gt;MGL-MAT:WITH-CUDA*&lt;/code&gt; is basically all that&#39;s needed to run on the GPU, and with &lt;code&gt;MGL-MAT:CUDA-AVAILABLE-P&lt;/code&gt; one can check whether the GPU is really being used.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.4 Code Organization&lt;/h3&gt; &#xA;&lt;p&gt;MGL consists of several packages dedicated to different tasks. For example, package &lt;code&gt;MGL-RESAMPLE&lt;/code&gt; is about &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Resampling&#34;&gt;Resampling&lt;/a&gt; and &lt;code&gt;MGL-GD&lt;/code&gt; is about &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;Gradient Descent&lt;/a&gt; and so on. On one hand, having many packages makes it easier to cleanly separate API and implementation and also to explore into a specific task. At other times, they can be a hassle, so the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29&#34; title=&#34;&amp;quot;mgl&amp;quot; ASDF/SYSTEM:SYSTEM&#34;&gt;&lt;code&gt;MGL&lt;/code&gt;&lt;/a&gt; package itself reexports every external symbol found in all the other packages that make up MGL and MGL-MAT (see &lt;code&gt;MGL-MAT::@MAT-MANUAL&lt;/code&gt;) on which it heavily relies.&lt;/p&gt; &#xA;&lt;p&gt;One exception to this rule is the bundled, but independent MGL-GNUPLOT library.&lt;/p&gt; &#xA;&lt;p&gt;The built in tests can be run with:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(ASDF:OOS &#39;ASDF:TEST-OP &#39;#:MGL)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note, that most of the tests are rather stochastic and can fail once in a while.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;2.5 Glossary&lt;/h3&gt; &#xA;&lt;p&gt;Ultimately machine learning is about creating &lt;strong&gt;models&lt;/strong&gt; of some domain. The observations in the modelled domain are called &lt;strong&gt;instances&lt;/strong&gt; (also known as examples or samples). Sets of instances are called &lt;strong&gt;datasets&lt;/strong&gt;. Datasets are used when fitting a model or when making &lt;strong&gt;predictions&lt;/strong&gt;. Sometimes the word predictions is too specific, and the results obtained from applying a model to some instances are simply called &lt;strong&gt;results&lt;/strong&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;3 Datasets&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-DATASET]&lt;/h6&gt; &#xA;&lt;p&gt;An instance can often be any kind of object of the user&#39;s choice. It is typically represented by a set of numbers which is called a feature vector or by a structure holding the feature vector, the label, etc. A dataset is a &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_seq.htm&#34; title=&#34;SEQUENCE TYPE&#34;&gt;&lt;code&gt;SEQUENCE&lt;/code&gt;&lt;/a&gt; of such instances or a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Samplers&#34;&gt;Samplers&lt;/a&gt; object that produces instances.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AMAP-DATASET-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAP-DATASET&lt;/strong&gt; &lt;em&gt;FN DATASET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with each instance in &lt;code&gt;DATASET&lt;/code&gt;. This is basically equivalent to iterating over the elements of a sequence or a sampler (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Samplers&#34;&gt;Samplers&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AMAP-DATASETS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAP-DATASETS&lt;/strong&gt; &lt;em&gt;FN DATASETS &amp;amp;KEY (IMPUTE NIL IMPUTEP)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with a list of instances, one from each dataset in &lt;code&gt;DATASETS&lt;/code&gt;. Return nothing. If &lt;code&gt;IMPUTE&lt;/code&gt; is specified then iterate until the largest dataset is consumed imputing &lt;code&gt;IMPUTE&lt;/code&gt; for missing values. If &lt;code&gt;IMPUTE&lt;/code&gt; is not specified then iterate until the smallest dataset runs out.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(map-datasets #&#39;prin1 &#39;((0 1 2) (:a :b)))&#xA;.. (0 :A)(1 :B)&#xA;&#xA;(map-datasets #&#39;prin1 &#39;((0 1 2) (:a :b)) :impute nil)&#xA;.. (0 :A)(1 :B)(2 NIL)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is of course allowed to mix sequences with samplers:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(map-datasets #&#39;prin1&#xA;              (list &#39;(0 1 2)&#xA;                    (make-sequence-sampler &#39;(:a :b) :max-n-samples 2)))&#xA;.. (0 :A)(1 :B)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;3.1 Samplers&lt;/h3&gt; &#xA;&lt;p&gt;Some algorithms do not need random access to the entire dataset and can work with a stream observations. Samplers are simple generators providing two functions: &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-DATASET:SAMPLE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SAMPLE&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-DATASET:FINISHEDP GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FINISHEDP&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SAMPLE&lt;/strong&gt; &lt;em&gt;SAMPLER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If &lt;code&gt;SAMPLER&lt;/code&gt; has not run out of data (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-DATASET:FINISHEDP GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FINISHEDP&lt;/code&gt;&lt;/a&gt;) &lt;code&gt;SAMPLE&lt;/code&gt; returns an object that represents a sample from the world to be experienced or, in other words, simply something the can be used as input for training or prediction. It is not allowed to call &lt;code&gt;SAMPLE&lt;/code&gt; if &lt;code&gt;SAMPLER&lt;/code&gt; is &lt;code&gt;FINISHEDP&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;FINISHEDP&lt;/strong&gt; &lt;em&gt;SAMPLER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;See if &lt;code&gt;SAMPLER&lt;/code&gt; has run out of examples.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3ALIST-SAMPLES-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;LIST-SAMPLES&lt;/strong&gt; &lt;em&gt;SAMPLER MAX-SIZE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of samples of length at most &lt;code&gt;MAX-SIZE&lt;/code&gt; or less if &lt;code&gt;SAMPLER&lt;/code&gt; runs out.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AMAKE-SEQUENCE-SAMPLER-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-SEQUENCE-SAMPLER&lt;/strong&gt; &lt;em&gt;SEQ &amp;amp;KEY MAX-N-SAMPLES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create a sampler that returns elements of &lt;code&gt;SEQ&lt;/code&gt; in their original order. If &lt;code&gt;MAX-N-SAMPLES&lt;/code&gt; is non-nil, then at most &lt;code&gt;MAX-N-SAMPLES&lt;/code&gt; are sampled.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AMAKE-RANDOM-SAMPLER-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-RANDOM-SAMPLER&lt;/strong&gt; &lt;em&gt;SEQ &amp;amp;KEY MAX-N-SAMPLES (REORDER #&#39;MGL-RESAMPLE:SHUFFLE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create a sampler that returns elements of &lt;code&gt;SEQ&lt;/code&gt; in random order. If &lt;code&gt;MAX-N-SAMPLES&lt;/code&gt; is non-nil, then at most &lt;code&gt;MAX-N-SAMPLES&lt;/code&gt; are sampled. The first pass over a shuffled copy of &lt;code&gt;SEQ&lt;/code&gt;, and this copy is reshuffled whenever the sampler reaches the end of it. Shuffling is performed by calling the &lt;code&gt;REORDER&lt;/code&gt; function.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3A-2AINFINITELY-EMPTY-DATASET-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*INFINITELY-EMPTY-DATASET*&lt;/strong&gt; &lt;em&gt;#&amp;lt;FUNCTION-SAMPLER &#34;infinitely empty&#34; &amp;gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is the default dataset for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MGL-OPT:MINIMIZE&lt;/code&gt;&lt;/a&gt;. It&#39;s an infinite stream of &lt;code&gt;NIL&lt;/code&gt;s.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;3.1.1 Function Sampler&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AFUNCTION-SAMPLER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;FUNCTION-SAMPLER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A sampler with a function in its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AGENERATOR-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34; title=&#34;MGL-DATASET:GENERATOR (MGL-PAX:READER MGL-DATASET:FUNCTION-SAMPLER)&#34;&gt;&lt;code&gt;GENERATOR&lt;/code&gt;&lt;/a&gt; that produces a stream of samples which may or may not be finite depending on &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AMAX-N-SAMPLES-20-28MGL-PAX-3AACCESSOR-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34; title=&#34;MGL-DATASET:MAX-N-SAMPLES (MGL-PAX:ACCESSOR MGL-DATASET:FUNCTION-SAMPLER)&#34;&gt;&lt;code&gt;MAX-N-SAMPLES&lt;/code&gt;&lt;/a&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-DATASET:FINISHEDP GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FINISHEDP&lt;/code&gt;&lt;/a&gt; returns &lt;code&gt;T&lt;/code&gt; iff &lt;code&gt;MAX-N-SAMPLES&lt;/code&gt; is non-nil, and it&#39;s not greater than the number of samples generated (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AN-SAMPLES-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34; title=&#34;MGL-DATASET:N-SAMPLES (MGL-PAX:READER MGL-DATASET:FUNCTION-SAMPLER)&#34;&gt;&lt;code&gt;N-SAMPLES&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (list-samples (make-instance &#39;function-sampler&#xA;                               :generator (lambda ()&#xA;                                            (random 10))&#xA;                               :max-n-samples 5)&#xA;                10)&#xA;  =&amp;gt; (3 5 2 3 3)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AGENERATOR-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;GENERATOR&lt;/strong&gt; &lt;em&gt;FUNCTION-SAMPLER (:GENERATOR)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A generator function of no arguments that returns the next sample.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AMAX-N-SAMPLES-20-28MGL-PAX-3AACCESSOR-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[accessor] &lt;strong&gt;MAX-N-SAMPLES&lt;/strong&gt; &lt;em&gt;FUNCTION-SAMPLER (:MAX-N-SAMPLES = NIL)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ANAME-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;NAME&lt;/strong&gt; &lt;em&gt;FUNCTION-SAMPLER (:NAME = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An arbitrary object naming the sampler. Only used for printing the sampler object.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DATASET-3AN-SAMPLES-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;N-SAMPLES&lt;/strong&gt; &lt;em&gt;FUNCTION-SAMPLER (:N-SAMPLES = 0)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;4 Resampling&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-RESAMPLE]&lt;/h6&gt; &#xA;&lt;p&gt;The focus of this package is on resampling methods such as cross-validation and bagging which can be used for model evaluation, model selection, and also as a simple form of ensembling. Data partitioning and sampling functions are also provided because they tend to be used together with resampling.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4.1 Partitions&lt;/h3&gt; &#xA;&lt;p&gt;The following functions partition a dataset (currently only &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_seq.htm&#34; title=&#34;SEQUENCE TYPE&#34;&gt;&lt;code&gt;SEQUENCE&lt;/code&gt;&lt;/a&gt;s are supported) into a number of partitions. For each element in the original dataset there is exactly one partition that contains it.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3AFRACTURE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;FRACTURE&lt;/strong&gt; &lt;em&gt;FRACTIONS SEQ &amp;amp;KEY WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Partition &lt;code&gt;SEQ&lt;/code&gt; into a number of subsequences. &lt;code&gt;FRACTIONS&lt;/code&gt; is either a positive integer or a list of non-negative real numbers. &lt;code&gt;WEIGHT&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt; or a function that returns a non-negative real number when called with an element from &lt;code&gt;SEQ&lt;/code&gt;. If &lt;code&gt;FRACTIONS&lt;/code&gt; is a positive integer then return a list of that many subsequences with equal sum of weights bar rounding errors, else partition &lt;code&gt;SEQ&lt;/code&gt; into subsequences, where the sum of weights of subsequence I is proportional to element I of &lt;code&gt;FRACTIONS&lt;/code&gt;. If &lt;code&gt;WEIGHT&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then it&#39;s element is assumed to have the same weight.&lt;/p&gt; &lt;p&gt;To split into 5 sequences:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(fracture 5 &#39;(0 1 2 3 4 5 6 7 8 9))&#xA;=&amp;gt; ((0 1) (2 3) (4 5) (6 7) (8 9))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To split into two sequences whose lengths are proportional to 2 and 3:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(fracture &#39;(2 3) &#39;(0 1 2 3 4 5 6 7 8 9))&#xA;=&amp;gt; ((0 1 2 3) (4 5 6 7 8 9))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;STRATIFY&lt;/strong&gt; &lt;em&gt;SEQ &amp;amp;KEY (KEY #&#39;IDENTITY) (TEST #&#39;EQL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the list of strata of &lt;code&gt;SEQ&lt;/code&gt;. &lt;code&gt;SEQ&lt;/code&gt; is a sequence of elements for which the function &lt;code&gt;KEY&lt;/code&gt; returns the class they belong to. Such classes are opaque objects compared for equality with &lt;code&gt;TEST&lt;/code&gt;. A stratum is a sequence of elements with the same (under &lt;code&gt;TEST&lt;/code&gt;) &lt;code&gt;KEY&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(stratify &#39;(0 1 2 3 4 5 6 7 8 9) :key #&#39;evenp)&#xA;=&amp;gt; ((0 2 4 6 8) (1 3 5 7 9))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3AFRACTURE-STRATIFIED-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;FRACTURE-STRATIFIED&lt;/strong&gt; &lt;em&gt;FRACTIONS SEQ &amp;amp;KEY (KEY #&#39;IDENTITY) (TEST #&#39;EQL) WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Similar to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3AFRACTURE-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:FRACTURE FUNCTION&#34;&gt;&lt;code&gt;FRACTURE&lt;/code&gt;&lt;/a&gt;, but also makes sure that keys are evenly distributed among the partitions (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:STRATIFY FUNCTION&#34;&gt;&lt;code&gt;STRATIFY&lt;/code&gt;&lt;/a&gt;). It can be useful for classification tasks to partition the data set while keeping the distribution of classes the same.&lt;/p&gt; &lt;p&gt;Note that the sets returned are not in random order. In fact, they are sorted internally by &lt;code&gt;KEY&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For example, to make two splits with approximately the same number of even and odd numbers:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(fracture-stratified 2 &#39;(0 1 2 3 4 5 6 7 8 9) :key #&#39;evenp)&#xA;=&amp;gt; ((0 2 1 3) (4 6 8 5 7 9))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4.2 Cross-validation&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CROSS-VALIDATE&lt;/strong&gt; &lt;em&gt;DATA FN &amp;amp;KEY (N-FOLDS 5) (FOLDS (ALEXANDRIA:IOTA N-FOLDS)) (SPLIT-FN #&#39;SPLIT-FOLD/MOD) PASS-FOLD&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Map &lt;code&gt;FN&lt;/code&gt; over the &lt;code&gt;FOLDS&lt;/code&gt; of &lt;code&gt;DATA&lt;/code&gt; split with &lt;code&gt;SPLIT-FN&lt;/code&gt; and collect the results in a list. The simplest demonstration is:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(cross-validate &#39;(0 1 2 3 4)&#xA;                (lambda (test training)&#xA;                 (list test training))&#xA;                :n-folds 5)&#xA;=&amp;gt; (((0) (1 2 3 4))&#xA;    ((1) (0 2 3 4))&#xA;    ((2) (0 1 3 4))&#xA;    ((3) (0 1 2 4))&#xA;    ((4) (0 1 2 3)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Of course, in practice one would typically train a model and return the trained model and/or its score on &lt;code&gt;TEST&lt;/code&gt;. Also, sometimes one may want to do only some of the folds and remember which ones they were:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(cross-validate &#39;(0 1 2 3 4)&#xA;                (lambda (fold test training)&#xA;                 (list :fold fold test training))&#xA;                :folds &#39;(2 3)&#xA;                :pass-fold t)&#xA;=&amp;gt; ((:fold 2 (2) (0 1 3 4))&#xA;    (:fold 3 (3) (0 1 2 4)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Finally, the way the data is split can be customized. By default &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FMOD-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SPLIT-FOLD/MOD FUNCTION&#34;&gt;&lt;code&gt;SPLIT-FOLD/MOD&lt;/code&gt;&lt;/a&gt; is called with the arguments &lt;code&gt;DATA&lt;/code&gt;, the fold (from among &lt;code&gt;FOLDS&lt;/code&gt;) and &lt;code&gt;N-FOLDS&lt;/code&gt;. &lt;code&gt;SPLIT-FOLD/MOD&lt;/code&gt; returns two values which are then passed on to &lt;code&gt;FN&lt;/code&gt;. One can use &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FCONT-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SPLIT-FOLD/CONT FUNCTION&#34;&gt;&lt;code&gt;SPLIT-FOLD/CONT&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASPLIT-STRATIFIED-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SPLIT-STRATIFIED FUNCTION&#34;&gt;&lt;code&gt;SPLIT-STRATIFIED&lt;/code&gt;&lt;/a&gt; or any other function that works with these arguments. The only real constraint is that &lt;code&gt;FN&lt;/code&gt; has to take as many arguments (plus the fold argument if &lt;code&gt;PASS-FOLD&lt;/code&gt;) as &lt;code&gt;SPLIT-FN&lt;/code&gt; returns.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FMOD-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SPLIT-FOLD/MOD&lt;/strong&gt; &lt;em&gt;SEQ FOLD N-FOLDS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Partition &lt;code&gt;SEQ&lt;/code&gt; into two sequences: one with elements of &lt;code&gt;SEQ&lt;/code&gt; with indices whose remainder is &lt;code&gt;FOLD&lt;/code&gt; when divided with &lt;code&gt;N-FOLDS&lt;/code&gt;, and a second one with the rest. The second one is the larger set. The order of elements remains stable. This function is suitable as the &lt;code&gt;SPLIT-FN&lt;/code&gt; argument of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:CROSS-VALIDATE FUNCTION&#34;&gt;&lt;code&gt;CROSS-VALIDATE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FCONT-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SPLIT-FOLD/CONT&lt;/strong&gt; &lt;em&gt;SEQ FOLD N-FOLDS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Imagine dividing &lt;code&gt;SEQ&lt;/code&gt; into &lt;code&gt;N-FOLDS&lt;/code&gt; subsequences of the same size (bar rounding). Return the subsequence of index &lt;code&gt;FOLD&lt;/code&gt; as the first value and the all the other subsequences concatenated into one as the second value. The order of elements remains stable. This function is suitable as the &lt;code&gt;SPLIT-FN&lt;/code&gt; argument of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:CROSS-VALIDATE FUNCTION&#34;&gt;&lt;code&gt;CROSS-VALIDATE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASPLIT-STRATIFIED-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SPLIT-STRATIFIED&lt;/strong&gt; &lt;em&gt;SEQ FOLD N-FOLDS &amp;amp;KEY (KEY #&#39;IDENTITY) (TEST #&#39;EQL) WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Split &lt;code&gt;SEQ&lt;/code&gt; into &lt;code&gt;N-FOLDS&lt;/code&gt; partitions (as in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3AFRACTURE-STRATIFIED-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:FRACTURE-STRATIFIED FUNCTION&#34;&gt;&lt;code&gt;FRACTURE-STRATIFIED&lt;/code&gt;&lt;/a&gt;). Return the partition of index &lt;code&gt;FOLD&lt;/code&gt; as the first value, and the concatenation of the rest as the second value. This function is suitable as the &lt;code&gt;SPLIT-FN&lt;/code&gt; argument of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:CROSS-VALIDATE FUNCTION&#34;&gt;&lt;code&gt;CROSS-VALIDATE&lt;/code&gt;&lt;/a&gt; (mostly likely as a closure with &lt;code&gt;KEY&lt;/code&gt;, &lt;code&gt;TEST&lt;/code&gt;, &lt;code&gt;WEIGHT&lt;/code&gt; bound).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4.3 Bagging&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ABAG-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;BAG&lt;/strong&gt; &lt;em&gt;SEQ FN &amp;amp;KEY (RATIO 1) N WEIGHT (REPLACEMENT T) KEY (TEST #&#39;EQL) (RANDOM-STATE *RANDOM-STATE*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Sample from &lt;code&gt;SEQ&lt;/code&gt; with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SAMPLE-FROM FUNCTION&#34;&gt;&lt;code&gt;SAMPLE-FROM&lt;/code&gt;&lt;/a&gt; (passing &lt;code&gt;RATIO&lt;/code&gt;, &lt;code&gt;WEIGHT&lt;/code&gt;, &lt;code&gt;REPLACEMENT&lt;/code&gt;), or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASAMPLE-STRATIFIED-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SAMPLE-STRATIFIED FUNCTION&#34;&gt;&lt;code&gt;SAMPLE-STRATIFIED&lt;/code&gt;&lt;/a&gt; if &lt;code&gt;KEY&lt;/code&gt; is not &lt;code&gt;NIL&lt;/code&gt;. Call &lt;code&gt;FN&lt;/code&gt; with the sample. If &lt;code&gt;N&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt; then keep repeating this until &lt;code&gt;FN&lt;/code&gt; performs a non-local exit. Else &lt;code&gt;N&lt;/code&gt; must be a non-negative integer, &lt;code&gt;N&lt;/code&gt; iterations will be performed, the primary values returned by &lt;code&gt;FN&lt;/code&gt; collected into a list and returned. See &lt;code&gt;SAMPLE-FROM&lt;/code&gt; and &lt;code&gt;SAMPLE-STRATIFIED&lt;/code&gt; for examples.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SAMPLE-FROM&lt;/strong&gt; &lt;em&gt;RATIO SEQ &amp;amp;KEY WEIGHT REPLACEMENT (RANDOM-STATE *RANDOM-STATE*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a sequence constructed by sampling with or without &lt;code&gt;REPLACEMENT&lt;/code&gt; from &lt;code&gt;SEQ&lt;/code&gt;. The sum of weights in the result sequence will approximately be the sum of weights of &lt;code&gt;SEQ&lt;/code&gt; times &lt;code&gt;RATIO&lt;/code&gt;. If &lt;code&gt;WEIGHT&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt; then elements are assumed to have equal weights, else &lt;code&gt;WEIGHT&lt;/code&gt; should return a non-negative real number when called with an element of &lt;code&gt;SEQ&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To randomly select half of the elements:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(sample-from 1/2 &#39;(0 1 2 3 4 5))&#xA;=&amp;gt; (5 3 2)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To randomly select some elements such that the sum of their weights constitute about half of the sum of weights across the whole sequence:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(sample-from 1/2 &#39;(0 1 2 3 4 5 6 7 8 9) :weight #&#39;identity)&#xA;=&amp;gt; ;; sums to 28 that&#39;s near 45/2&#xA;   (9 4 1 6 8)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To sample with replacement (that is, allowing the element to be sampled multiple times):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(sample-from 1 &#39;(0 1 2 3 4 5) :replacement t)&#xA;=&amp;gt; (1 1 5 1 4 4)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASAMPLE-STRATIFIED-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SAMPLE-STRATIFIED&lt;/strong&gt; &lt;em&gt;RATIO SEQ &amp;amp;KEY WEIGHT REPLACEMENT (KEY #&#39;IDENTITY) (TEST #&#39;EQL) (RANDOM-STATE *RANDOM-STATE*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:SAMPLE-FROM FUNCTION&#34;&gt;&lt;code&gt;SAMPLE-FROM&lt;/code&gt;&lt;/a&gt; but makes sure that the weighted proportion of classes in the result is approximately the same as the proportion in &lt;code&gt;SEQ&lt;/code&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:STRATIFY FUNCTION&#34;&gt;&lt;code&gt;STRATIFY&lt;/code&gt;&lt;/a&gt; for the description of &lt;code&gt;KEY&lt;/code&gt; and &lt;code&gt;TEST&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4.4 CV Bagging&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ABAG-CV-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;BAG-CV&lt;/strong&gt; &lt;em&gt;DATA FN &amp;amp;KEY N (N-FOLDS 5) (FOLDS (ALEXANDRIA:IOTA N-FOLDS)) (SPLIT-FN #&#39;SPLIT-FOLD/MOD) PASS-FOLD (RANDOM-STATE *RANDOM-STATE*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Perform cross-validation on different shuffles of &lt;code&gt;DATA&lt;/code&gt; &lt;code&gt;N&lt;/code&gt; times and collect the results. Since &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:CROSS-VALIDATE FUNCTION&#34;&gt;&lt;code&gt;CROSS-VALIDATE&lt;/code&gt;&lt;/a&gt; collects the return values of &lt;code&gt;FN&lt;/code&gt;, the return value of this function is a list of lists of &lt;code&gt;FN&lt;/code&gt; results. If &lt;code&gt;N&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, don&#39;t collect anything just keep doing repeated CVs until &lt;code&gt;FN&lt;/code&gt; performs a non-local exit.&lt;/p&gt; &lt;p&gt;The following example simply collects the test and training sets for 2-fold CV repeated 3 times with shuffled data:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;;;; This is non-deterministic.&#xA;(bag-cv &#39;(0 1 2 3 4) #&#39;list :n 3 :n-folds 2)&#xA;=&amp;gt; ((((2 3 4) (1 0))&#xA;     ((1 0) (2 3 4)))&#xA;    (((2 1 0) (4 3))&#xA;     ((4 3) (2 1 0)))&#xA;    (((1 0 3) (2 4))&#xA;     ((2 4) (1 0 3))))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;CV bagging is useful when a single CV is not producing stable results. As an ensemble method, CV bagging has the advantage over bagging that each example will occur the same number of times and after the first CV is complete there is a complete but less reliable estimate for each example which gets refined by further CVs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;4.5 Miscellaneous Operations&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3ASPREAD-STRATA-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SPREAD-STRATA&lt;/strong&gt; &lt;em&gt;SEQ &amp;amp;KEY (KEY #&#39;IDENTITY) (TEST #&#39;EQL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a sequence that&#39;s a reordering of &lt;code&gt;SEQ&lt;/code&gt; such that elements belonging to different strata (under &lt;code&gt;KEY&lt;/code&gt; and &lt;code&gt;TEST&lt;/code&gt;, see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29&#34; title=&#34;MGL-RESAMPLE:STRATIFY FUNCTION&#34;&gt;&lt;code&gt;STRATIFY&lt;/code&gt;&lt;/a&gt;) are distributed evenly. The order of elements belonging to the same stratum is unchanged.&lt;/p&gt; &lt;p&gt;For example, to make sure that even and odd numbers are distributed evenly:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(spread-strata &#39;(0 2 4 6 8 1 3 5 7 9) :key #&#39;evenp)&#xA;=&amp;gt; (0 1 2 3 4 5 6 7 8 9)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Same thing with unbalanced classes:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(spread-strata (vector 0 2 3 5 6 1 4)&#xA;               :key (lambda (x)&#xA;                      (if (member x &#39;(1 4))&#xA;                          t&#xA;                          nil)))&#xA;=&amp;gt; #(0 1 2 3 4 5 6)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-RESAMPLE-3AZIP-EVENLY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ZIP-EVENLY&lt;/strong&gt; &lt;em&gt;SEQS &amp;amp;KEY RESULT-TYPE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Make a single sequence out of the sequences in &lt;code&gt;SEQS&lt;/code&gt; so that in the returned sequence indices of elements belonging to the same source sequence are spread evenly across the whole range. The result is a list is &lt;code&gt;RESULT-TYPE&lt;/code&gt; is &lt;code&gt;LIST&lt;/code&gt;(&lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_list_.htm&#34; title=&#34;LIST FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_list.htm&#34; title=&#34;LIST TYPE&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;), it&#39;s a vector if &lt;code&gt;RESULT-TYPE&lt;/code&gt; is &lt;code&gt;VECTOR&lt;/code&gt;(&lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_vector.htm&#34; title=&#34;VECTOR FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_vector.htm&#34; title=&#34;VECTOR TYPE&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;). If &lt;code&gt;RESULT-TYPE&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then it&#39;s determined by the type of the first sequence in &lt;code&gt;SEQS&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(zip-evenly &#39;((0 2 4) (1 3)))&#xA;=&amp;gt; (0 1 2 3 4)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CORE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;5 Core&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-CORE]&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-PERSISTENCE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5.1 Persistence&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALOAD-STATE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;LOAD-STATE&lt;/strong&gt; &lt;em&gt;FILENAME OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Load weights of &lt;code&gt;OBJECT&lt;/code&gt; from &lt;code&gt;FILENAME&lt;/code&gt;. Return &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASAVE-STATE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SAVE-STATE&lt;/strong&gt; &lt;em&gt;FILENAME OBJECT &amp;amp;KEY (IF-EXISTS :ERROR) (ENSURE T)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Save weights of &lt;code&gt;OBJECT&lt;/code&gt; to &lt;code&gt;FILENAME&lt;/code&gt;. If &lt;code&gt;ENSURE&lt;/code&gt;, then &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_ensu_1.htm&#34; title=&#34;ENSURE-DIRECTORIES-EXIST FUNCTION&#34;&gt;&lt;code&gt;ENSURE-DIRECTORIES-EXIST&lt;/code&gt;&lt;/a&gt; is called on &lt;code&gt;FILENAME&lt;/code&gt;. &lt;code&gt;IF-EXISTS&lt;/code&gt; is passed on to &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_open.htm&#34; title=&#34;OPEN FUNCTION&#34;&gt;&lt;code&gt;OPEN&lt;/code&gt;&lt;/a&gt;. Return &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AREAD-STATE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;READ-STATE&lt;/strong&gt; &lt;em&gt;OBJECT STREAM&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Read the weights of &lt;code&gt;OBJECT&lt;/code&gt; from the bivalent &lt;code&gt;STREAM&lt;/code&gt; where weights mean the learnt parameters. There is currently no sanity checking of data which will most certainly change in the future together with the serialization format. Return &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AWRITE-STATE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;WRITE-STATE&lt;/strong&gt; &lt;em&gt;OBJECT STREAM&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Write weight of &lt;code&gt;OBJECT&lt;/code&gt; to the bivalent &lt;code&gt;STREAM&lt;/code&gt;. Return &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AREAD-STATE-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;READ-STATE*&lt;/strong&gt; &lt;em&gt;OBJECT STREAM CONTEXT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is the extension point for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AREAD-STATE-20FUNCTION-29&#34; title=&#34;MGL-CORE:READ-STATE FUNCTION&#34;&gt;&lt;code&gt;READ-STATE&lt;/code&gt;&lt;/a&gt;. It is guaranteed that primary &lt;code&gt;READ-STATE*&lt;/code&gt; methods will be called only once for each &lt;code&gt;OBJECT&lt;/code&gt; (under &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_eq.htm&#34; title=&#34;EQ FUNCTION&#34;&gt;&lt;code&gt;EQ&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;CONTEXT&lt;/code&gt; is an opaque object and must be passed on to any recursive &lt;code&gt;READ-STATE*&lt;/code&gt; calls.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AWRITE-STATE-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;WRITE-STATE*&lt;/strong&gt; &lt;em&gt;OBJECT STREAM CONTEXT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is the extension point for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AWRITE-STATE-20FUNCTION-29&#34; title=&#34;MGL-CORE:WRITE-STATE FUNCTION&#34;&gt;&lt;code&gt;WRITE-STATE&lt;/code&gt;&lt;/a&gt;. It is guaranteed that primary &lt;code&gt;WRITE-STATE*&lt;/code&gt; methods will be called only once for each &lt;code&gt;OBJECT&lt;/code&gt; (under &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_eq.htm&#34; title=&#34;EQ FUNCTION&#34;&gt;&lt;code&gt;EQ&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;CONTEXT&lt;/code&gt; is an opaque object and must be passed on to any recursive &lt;code&gt;WRITE-STATE*&lt;/code&gt; calls.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5.2 Batch Processing&lt;/h3&gt; &#xA;&lt;p&gt;Processing instances one by one during training or prediction can be slow. The models that support batch processing for greater efficiency are said to be &lt;em&gt;striped&lt;/em&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Typically, during or after creating a model, one sets &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; on it a positive integer. When a batch of instances is to be fed to the model it is first broken into subbatches of length that&#39;s at most &lt;code&gt;MAX-N-STRIPES&lt;/code&gt;. For each subbatch, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt; (FIXDOC) is called and a before method takes care of setting &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt; to the actual number of instances in the subbatch. When &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; is set internal data structures may be resized which is an expensive operation. Setting &lt;code&gt;N-STRIPES&lt;/code&gt; is a comparatively cheap operation, often implemented as matrix reshaping.&lt;/p&gt; &#xA;&lt;p&gt;Note that for models made of different parts (for example, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;MGL-BP:BPN&lt;/code&gt;&lt;/a&gt; consists of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;MGL-BP:LUMP&lt;/code&gt;&lt;/a&gt;s) , setting these values affects the constituent parts, but one should never change the number stripes of the parts directly because that would lead to an internal inconsistency in the model.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAX-N-STRIPES&lt;/strong&gt; &lt;em&gt;OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of stripes with which the &lt;code&gt;OBJECT&lt;/code&gt; is capable of dealing simultaneously.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASET-MAX-N-STRIPES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SET-MAX-N-STRIPES&lt;/strong&gt; &lt;em&gt;MAX-N-STRIPES OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Allocate the necessary stuff to allow for &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; number of stripes to be worked with simultaneously in &lt;code&gt;OBJECT&lt;/code&gt;. This is called when &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; is &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/m_setf.htm&#34; title=&#34;SETF MGL-PAX:MACRO&#34;&gt;&lt;code&gt;SETF&lt;/code&gt;&lt;/a&gt;&#39;ed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;N-STRIPES&lt;/strong&gt; &lt;em&gt;OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of stripes currently present in &lt;code&gt;OBJECT&lt;/code&gt;. This is at most &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASET-N-STRIPES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SET-N-STRIPES&lt;/strong&gt; &lt;em&gt;N-STRIPES OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Set the number of stripes (out of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt;) that are in use in &lt;code&gt;OBJECT&lt;/code&gt;. This is called when &lt;code&gt;N-STRIPES&lt;/code&gt; is &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/m_setf.htm&#34; title=&#34;SETF MGL-PAX:MACRO&#34;&gt;&lt;code&gt;SETF&lt;/code&gt;&lt;/a&gt;&#39;ed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AWITH-STRIPES-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;WITH-STRIPES&lt;/strong&gt; &lt;em&gt;SPECS &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Bind start and optionally end indices belonging to stripes in striped objects.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (WITH-STRIPES ((STRIPE1 OBJECT1 START1 END1)&#xA;                 (STRIPE2 OBJECT2 START2)&#xA;                 ...)&#xA;   ...)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is how one&#39;s supposed to find the index range corresponding to the Nth input in an input lump of a bpn:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   (with-stripes ((n input-lump start end))&#xA;     (loop for i upfrom start below end&#xA;           do (setf (mref (nodes input-lump) i) 0d0)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how the input lump is striped, but the matrix into which we are indexing (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt;) is not known to &lt;code&gt;WITH-STRIPES&lt;/code&gt;. In fact, for lumps the same stripe indices work with &lt;code&gt;NODES&lt;/code&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MGL-BP:DERIVATIVES&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASTRIPE-START-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;STRIPE-START&lt;/strong&gt; &lt;em&gt;STRIPE OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the start index of &lt;code&gt;STRIPE&lt;/code&gt; in some array or matrix of &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASTRIPE-END-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;STRIPE-END&lt;/strong&gt; &lt;em&gt;STRIPE OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the end index (exclusive) of &lt;code&gt;STRIPE&lt;/code&gt; in some array or matrix of &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SET-INPUT&lt;/strong&gt; &lt;em&gt;INSTANCES MODEL&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Set &lt;code&gt;INSTANCES&lt;/code&gt; as inputs in &lt;code&gt;MODEL&lt;/code&gt;. &lt;code&gt;INSTANCES&lt;/code&gt; is always a &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_seq.htm&#34; title=&#34;SEQUENCE TYPE&#34;&gt;&lt;code&gt;SEQUENCE&lt;/code&gt;&lt;/a&gt; of instances even for models not capable of batch operation. It sets &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt; to (&lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_length.htm&#34; title=&#34;LENGTH FUNCTION&#34;&gt;&lt;code&gt;LENGTH&lt;/code&gt;&lt;/a&gt; &lt;code&gt;INSTANCES&lt;/code&gt;) in a &lt;code&gt;:BEFORE&lt;/code&gt; method.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAP-BATCHES-FOR-MODEL-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAP-BATCHES-FOR-MODEL&lt;/strong&gt; &lt;em&gt;FN DATASET MODEL&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with batches of instances from &lt;code&gt;DATASET&lt;/code&gt; suitable for &lt;code&gt;MODEL&lt;/code&gt;. The number of instances in a batch is &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;MODEL&lt;/code&gt; or less if there are no more instances left.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;DO-BATCHES-FOR-MODEL&lt;/strong&gt; &lt;em&gt;(BATCH (DATASET MODEL)) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Convenience macro over &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAP-BATCHES-FOR-MODEL-20FUNCTION-29&#34; title=&#34;MGL-CORE:MAP-BATCHES-FOR-MODEL FUNCTION&#34;&gt;&lt;code&gt;MAP-BATCHES-FOR-MODEL&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;5.3 Executors&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAP-OVER-EXECUTORS&lt;/strong&gt; &lt;em&gt;FN INSTANCES PROTOTYPE-EXECUTOR&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Divide &lt;code&gt;INSTANCES&lt;/code&gt; between executors that perform the same function as &lt;code&gt;PROTOTYPE-EXECUTOR&lt;/code&gt; and call &lt;code&gt;FN&lt;/code&gt; with the instances and the executor for which the instances are.&lt;/p&gt; &lt;p&gt;Some objects conflate function and call: the forward pass of a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;MGL-BP:BPN&lt;/code&gt;&lt;/a&gt; computes output from inputs so it is like a function but it also doubles as a function call in the sense that the bpn (function) object changes state during the computation of the output. Hence not even the forward pass of a bpn is thread safe. There is also the restriction that all inputs must be of the same size.&lt;/p&gt; &lt;p&gt;For example, if we have a function that builds bpn a for an input of a certain size, then we can create a factory that creates bpns for a particular call. The factory probably wants to keep the weights the same though. In &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Parameterized Executor Cache&#34;&gt;Parameterized Executor Cache&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-EXECUTOR-WITH-PARAMETERS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAKE-EXECUTOR-WITH-PARAMETERS&lt;/code&gt;&lt;/a&gt; is this factory.&lt;/p&gt; &lt;p&gt;Parallelization of execution is another possibility &lt;code&gt;MAP-OVER-EXECUTORS&lt;/code&gt; allows, but there is no prebuilt solution for it, yet.&lt;/p&gt; &lt;p&gt;The default implementation simply calls &lt;code&gt;FN&lt;/code&gt; with &lt;code&gt;INSTANCES&lt;/code&gt; and &lt;code&gt;PROTOTYPE-EXECUTOR&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ADO-EXECUTORS-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;DO-EXECUTORS&lt;/strong&gt; &lt;em&gt;(INSTANCES OBJECT) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Convenience macro on top of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAP-OVER-EXECUTORS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-OVER-EXECUTORS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;5.3.1 Parameterized Executor Cache&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;PARAMETERIZED-EXECUTOR-CACHE-MIXIN&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Mix this into a model, implement &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AINSTANCE-TO-EXECUTOR-PARAMETERS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:INSTANCE-TO-EXECUTOR-PARAMETERS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;INSTANCE-TO-EXECUTOR-PARAMETERS&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-EXECUTOR-WITH-PARAMETERS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAKE-EXECUTOR-WITH-PARAMETERS&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ADO-EXECUTORS-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-CORE:DO-EXECUTORS MGL-PAX:MACRO&#34;&gt;&lt;code&gt;DO-EXECUTORS&lt;/code&gt;&lt;/a&gt; will be to able build executors suitable for different instances. The canonical example is using a BPN to compute the means and convariances of a gaussian process. Since each instance is made of a variable number of observations, the size of the input is not constant, thus we have a bpn (an executor) for each input dimension (the parameters).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAKE-EXECUTOR-WITH-PARAMETERS&lt;/strong&gt; &lt;em&gt;PARAMETERS CACHE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create a new executor for &lt;code&gt;PARAMETERS&lt;/code&gt;. &lt;code&gt;CACHE&lt;/code&gt; is a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29&#34; title=&#34;MGL-CORE:PARAMETERIZED-EXECUTOR-CACHE-MIXIN CLASS&#34;&gt;&lt;code&gt;PARAMETERIZED-EXECUTOR-CACHE-MIXIN&lt;/code&gt;&lt;/a&gt;. In the BPN gaussian process example, &lt;code&gt;PARAMETERS&lt;/code&gt; would be a list of input dimensions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AINSTANCE-TO-EXECUTOR-PARAMETERS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;INSTANCE-TO-EXECUTOR-PARAMETERS&lt;/strong&gt; &lt;em&gt;INSTANCE CACHE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the parameters for an executor able to handle &lt;code&gt;INSTANCE&lt;/code&gt;. Called by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAP-OVER-EXECUTORS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-OVER-EXECUTORS&lt;/code&gt;&lt;/a&gt; on &lt;code&gt;CACHE&lt;/code&gt; (that&#39;s a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29&#34; title=&#34;MGL-CORE:PARAMETERIZED-EXECUTOR-CACHE-MIXIN CLASS&#34;&gt;&lt;code&gt;PARAMETERIZED-EXECUTOR-CACHE-MIXIN&lt;/code&gt;&lt;/a&gt;). The returned parameters are keys in an &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; parameters-&amp;gt;executor hash table.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;6 Monitoring&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-CORE]&lt;/h6&gt; &#xA;&lt;p&gt;When training or applying a model, one often wants to track various statistics. For example, in the case of training a neural network with cross-entropy loss, these statistics could be the average cross-entropy loss itself, classification accuracy, or even the entire confusion matrix and sparsity levels in hidden layers. Also, there is the question of what to do with the measured values (log and forget, add to some counter or a list).&lt;/p&gt; &#xA;&lt;p&gt;So there may be several phases of operation when we want to keep an eye on. Let&#39;s call these &lt;strong&gt;events&lt;/strong&gt;. There can also be many fairly independent things to do in response to an event. Let&#39;s call these &lt;strong&gt;monitors&lt;/strong&gt;. Some monitors are a composition of two operations: one that extracts some measurements and another that aggregates those measurements. Let&#39;s call these two &lt;strong&gt;measurers&lt;/strong&gt; and &lt;strong&gt;counters&lt;/strong&gt;, respectively.&lt;/p&gt; &#xA;&lt;p&gt;For example, consider training a backpropagation neural network. We want to look at the state of of network just after the backward pass. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABP-LEARNER-20CLASS-29&#34; title=&#34;MGL-BP:BP-LEARNER CLASS&#34;&gt;&lt;code&gt;MGL-BP:BP-LEARNER&lt;/code&gt;&lt;/a&gt; has a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ABP-LEARNER-29-29&#34; title=&#34;MGL-CORE:MONITORS (MGL-PAX:ACCESSOR MGL-BP:BP-LEARNER)&#34;&gt;&lt;code&gt;MONITORS&lt;/code&gt;&lt;/a&gt; event hook corresponding to the moment after backpropagating the gradients. Suppose we are interested in how the training cost evolves:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(push (make-instance &#39;monitor&#xA;                     :measurer (lambda (instances bpn)&#xA;                                 (declare (ignore instances))&#xA;                                 (mgl-bp:cost bpn))&#xA;                     :counter (make-instance &#39;basic-counter))&#xA;      (monitors learner))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;During training, this monitor will track the cost of training examples behind the scenes. If we want to print and reset this monitor periodically we can put another monitor on &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;MGL-OPT:ITERATIVE-OPTIMIZER&lt;/code&gt;&lt;/a&gt;&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;MGL-OPT:ON-N-INSTANCES-CHANGED&lt;/code&gt;&lt;/a&gt; accessor:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(push (lambda (optimizer gradient-source n-instances)&#xA;        (declare (ignore optimizer))&#xA;        (when (zerop (mod n-instances 1000))&#xA;          (format t &#34;n-instances: ~S~%&#34; n-instances)&#xA;          (dolist (monitor (monitors gradient-source))&#xA;            (when (counter monitor)&#xA;              (format t &#34;~A~%&#34; (counter monitor))&#xA;              (reset-counter (counter monitor)))))&#xA;      (mgl-opt:on-n-instances-changed optimizer))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;Note that the monitor we push can be anything as long as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION&#34;&gt;&lt;code&gt;APPLY-MONITOR&lt;/code&gt;&lt;/a&gt; is implemented on it with the appropriate signature. Also note that the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_zerop.htm&#34; title=&#34;ZEROP FUNCTION&#34;&gt;&lt;code&gt;ZEROP&lt;/code&gt;&lt;/a&gt; + &lt;code&gt;MOD&lt;/code&gt;(&lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_mod_r.htm&#34; title=&#34;MOD FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_mod.htm&#34; title=&#34;MOD TYPE&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) logic is fragile, so you will likely want to use &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29&#34; title=&#34;MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY FUNCTION&#34;&gt;&lt;code&gt;MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY&lt;/code&gt;&lt;/a&gt; instead of doing the above.&lt;/p&gt; &#xA;&lt;p&gt;So that&#39;s the general idea. Concrete events are documented where they are signalled. Often there are task specific utilities that create a reasonable set of default monitors (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Monitors&#34;&gt;Classification Monitors&lt;/a&gt;).&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AAPPLY-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;APPLY-MONITORS&lt;/strong&gt; &lt;em&gt;MONITORS &amp;amp;REST ARGUMENTS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION&#34;&gt;&lt;code&gt;APPLY-MONITOR&lt;/code&gt;&lt;/a&gt; on each monitor in &lt;code&gt;MONITORS&lt;/code&gt; and &lt;code&gt;ARGUMENTS&lt;/code&gt;. This is how an event is fired.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;APPLY-MONITOR&lt;/strong&gt; &lt;em&gt;MONITOR &amp;amp;REST ARGUMENTS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Apply &lt;code&gt;MONITOR&lt;/code&gt; to &lt;code&gt;ARGUMENTS&lt;/code&gt;. This sound fairly generic, because it is. &lt;code&gt;MONITOR&lt;/code&gt; can be anything, even a simple function or symbol, in which case this is just &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_apply.htm&#34; title=&#34;APPLY FUNCTION&#34;&gt;&lt;code&gt;CL:APPLY&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Monitors&#34;&gt;Monitors&lt;/a&gt; for more.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACOUNTER-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;COUNTER&lt;/strong&gt; &lt;em&gt;MONITOR&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return an object representing the state of &lt;code&gt;MONITOR&lt;/code&gt; or &lt;code&gt;NIL&lt;/code&gt;, if it doesn&#39;t have any (say because it&#39;s a simple logging function). Most monitors have counters into which they accumulate results until they are printed and reset. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Counters&#34;&gt;Counters&lt;/a&gt; for more.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MONITOR-MODEL-RESULTS&lt;/strong&gt; &lt;em&gt;FN DATASET MODEL MONITORS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with batches of instances from &lt;code&gt;DATASET&lt;/code&gt; until it runs out (as in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-CORE:DO-BATCHES-FOR-MODEL MGL-PAX:MACRO&#34;&gt;&lt;code&gt;DO-BATCHES-FOR-MODEL&lt;/code&gt;&lt;/a&gt;). &lt;code&gt;FN&lt;/code&gt; is supposed to apply &lt;code&gt;MODEL&lt;/code&gt; to the batch and return some kind of result (for neural networks, the result is the model state itself). Apply &lt;code&gt;MONITORS&lt;/code&gt; to each batch and the result returned by &lt;code&gt;FN&lt;/code&gt; for that batch. Finally, return the list of counters of &lt;code&gt;MONITORS&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The purpose of this function is to collect various results and statistics (such as error measures) efficiently by applying the model only once, leaving extraction of quantities of interest from the model&#39;s results to &lt;code&gt;MONITORS&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;See the model specific versions of this functions such as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AMONITOR-BPN-RESULTS-20FUNCTION-29&#34; title=&#34;MGL-BP:MONITOR-BPN-RESULTS FUNCTION&#34;&gt;&lt;code&gt;MGL-BP:MONITOR-BPN-RESULTS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMONITORS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MONITORS&lt;/strong&gt; &lt;em&gt;OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return monitors associated with &lt;code&gt;OBJECT&lt;/code&gt;. See various methods such as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ABP-LEARNER-29-29&#34; title=&#34;MGL-CORE:MONITORS (MGL-PAX:ACCESSOR MGL-BP:BP-LEARNER)&#34;&gt;&lt;code&gt;MONITORS&lt;/code&gt;&lt;/a&gt; for more documentation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;6.1 Monitors&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMONITOR-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;MONITOR&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A monitor that has another monitor called &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34; title=&#34;MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR)&#34;&gt;&lt;code&gt;MEASURER&lt;/code&gt;&lt;/a&gt; embedded in it. When this monitor is applied, it applies the measurer and passes the returned values to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; called on its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACOUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;COUNTER&lt;/code&gt;&lt;/a&gt; slot. One may further specialize &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION&#34;&gt;&lt;code&gt;APPLY-MONITOR&lt;/code&gt;&lt;/a&gt; to change that.&lt;/p&gt; &lt;p&gt;This class is useful when the same event monitor is applied repeatedly over a period and its results must be aggregated such as when training statistics are being tracked or when predictions are begin made. Note that the monitor must be compatible with the event it handles. That is, the embedded &lt;code&gt;MEASURER&lt;/code&gt; must be prepared to take the arguments that are documented to come with the event.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;MEASURER&lt;/strong&gt; &lt;em&gt;MONITOR (:MEASURER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This must be a monitor itself which only means that &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION&#34;&gt;&lt;code&gt;APPLY-MONITOR&lt;/code&gt;&lt;/a&gt; is defined on it (but see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Monitoring&#34;&gt;Monitoring&lt;/a&gt;). The returned values are aggregated by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACOUNTER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34; title=&#34;MGL-CORE:COUNTER (MGL-PAX:READER MGL-CORE:MONITOR)&#34;&gt;&lt;code&gt;COUNTER&lt;/code&gt;&lt;/a&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Measurers&#34;&gt;Measurers&lt;/a&gt; for a library of measurers.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACOUNTER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;COUNTER&lt;/strong&gt; &lt;em&gt;MONITOR (:COUNTER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The &lt;code&gt;COUNTER&lt;/code&gt; of a monitor carries out the aggregation of results returned by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34; title=&#34;MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR)&#34;&gt;&lt;code&gt;MEASURER&lt;/code&gt;&lt;/a&gt;. The See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Counters&#34;&gt;Counters&lt;/a&gt; for a library of counters.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;6.2 Measurers&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29&#34; title=&#34;MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR)&#34;&gt;&lt;code&gt;MEASURER&lt;/code&gt;&lt;/a&gt; is a part of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-20CLASS-29&#34; title=&#34;MGL-CORE:MONITOR CLASS&#34;&gt;&lt;code&gt;MONITOR&lt;/code&gt;&lt;/a&gt; objects, an embedded monitor that computes a specific quantity (e.g. classification accuracy) from the arguments of event it is applied to (e.g. the model results). Measurers are often implemented by combining some kind of model specific extractor with a generic measurer function.&lt;/p&gt; &#xA;&lt;p&gt;All generic measurer functions return their results as multiple values matching the arguments of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; for a counter of a certain type (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Counters&#34;&gt;Counters&lt;/a&gt;) so as to make them easily used in a &lt;code&gt;MONITOR&lt;/code&gt;:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;(multiple-value-call #&#39;add-to-counter &amp;lt;some-counter&amp;gt;&#xA;                     &amp;lt;call-to-some-measurer&amp;gt;)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;The counter class compatible with the measurer this way is noted for each function.&lt;/p&gt; &#xA;&lt;p&gt;For a list of measurer functions see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Measurers&#34;&gt;Classification Measurers&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;6.3 Counters&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;ADD-TO-COUNTER&lt;/strong&gt; &lt;em&gt;COUNTER &amp;amp;REST ARGS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Add &lt;code&gt;ARGS&lt;/code&gt; to &lt;code&gt;COUNTER&lt;/code&gt; in some way. See specialized methods for type specific documentation. The kind of arguments to be supported is the what the measurer functions (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Measurers&#34;&gt;Measurers&lt;/a&gt;) intended to be paired with the counter return as multiple values.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;COUNTER-VALUES&lt;/strong&gt; &lt;em&gt;COUNTER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return any number of values representing the state of &lt;code&gt;COUNTER&lt;/code&gt;. See specialized methods for type specific documentation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACOUNTER-RAW-VALUES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;COUNTER-RAW-VALUES&lt;/strong&gt; &lt;em&gt;COUNTER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return any number of values representing the state of &lt;code&gt;COUNTER&lt;/code&gt; in such a way that passing the returned values as arguments &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; on a fresh instance of the same type recreates the original state.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ARESET-COUNTER-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;RESET-COUNTER&lt;/strong&gt; &lt;em&gt;COUNTER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Restore state of &lt;code&gt;COUNTER&lt;/code&gt; to what it was just after creation.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;6.3.1 Attributes&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AATTRIBUTED-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;ATTRIBUTED&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This is a utility class that all counters subclass. The &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29&#34; title=&#34;MGL-CORE:ATTRIBUTES (MGL-PAX:ACCESSOR MGL-CORE:ATTRIBUTED)&#34;&gt;&lt;code&gt;ATTRIBUTES&lt;/code&gt;&lt;/a&gt; plist can hold basically anything. Currently the attributes are only used when printing and they can be specified by the user. The monitor maker functions such as those in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Monitors&#34;&gt;Classification Monitors&lt;/a&gt; also add attributes of their own to the counters they create.&lt;/p&gt; &lt;p&gt;With the &lt;code&gt;:PREPEND-ATTRIBUTES&lt;/code&gt; initarg when can easily add new attributes without clobbering the those in the &lt;code&gt;:INITFORM&lt;/code&gt;, (&lt;code&gt;:TYPE&lt;/code&gt; &#34;rmse&#34;) in this case.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (princ (make-instance &#39;rmse-counter&#xA;                        :prepend-attributes &#39;(:event &#34;pred.&#34;&#xA;                                              :dataset &#34;test&#34;)))&#xA;  ;; pred. test rmse: 0.000e+0 (0)&#xA;  =&amp;gt; #&amp;lt;RMSE-COUNTER pred. test rmse: 0.000e+0 (0)&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;ATTRIBUTES&lt;/strong&gt; &lt;em&gt;ATTRIBUTED (:ATTRIBUTES = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A plist of attribute keys and values.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ANAME-20-28METHOD-20NIL-20-28MGL-CORE-3AATTRIBUTED-29-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[method] &lt;strong&gt;NAME&lt;/strong&gt; &lt;em&gt;(ATTRIBUTED ATTRIBUTED)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a string assembled from the values of the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29&#34; title=&#34;MGL-CORE:ATTRIBUTES (MGL-PAX:ACCESSOR MGL-CORE:ATTRIBUTED)&#34;&gt;&lt;code&gt;ATTRIBUTES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;ATTRIBUTED&lt;/code&gt;. If there are multiple entries with the same key, then they are printed near together.&lt;/p&gt; &lt;p&gt;Values may be padded according to an enclosing &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AWITH-PADDED-ATTRIBUTE-PRINTING-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-CORE:WITH-PADDED-ATTRIBUTE-PRINTING MGL-PAX:MACRO&#34;&gt;&lt;code&gt;WITH-PADDED-ATTRIBUTE-PRINTING&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AWITH-PADDED-ATTRIBUTE-PRINTING-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;WITH-PADDED-ATTRIBUTE-PRINTING&lt;/strong&gt; &lt;em&gt;(ATTRIBUTEDS) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Note the width of values for each attribute key which is the number of characters in the value&#39;s &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_wr_to_.htm&#34; title=&#34;PRINC-TO-STRING FUNCTION&#34;&gt;&lt;code&gt;PRINC-TO-STRING&lt;/code&gt;&lt;/a&gt;&#39;ed representation. In &lt;code&gt;BODY&lt;/code&gt;, if attributes with they same key are printed they are forced to be at least this wide. This allows for nice, table-like output:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (let ((attributeds&#xA;          (list (make-instance &#39;basic-counter&#xA;                               :attributes &#39;(:a 1 :b 23 :c 456))&#xA;                (make-instance &#39;basic-counter&#xA;                               :attributes &#39;(:a 123 :b 45 :c 6)))))&#xA;    (with-padded-attribute-printing (attributeds)&#xA;      (map nil (lambda (attributed)&#xA;                 (format t &#34;~A~%&#34; attributed))&#xA;           attributeds)))&#xA;  ;; 1   23 456: 0.000e+0 (0)&#xA;  ;; 123 45 6  : 0.000e+0 (0)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALOG-PADDED-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;LOG-PADDED&lt;/strong&gt; &lt;em&gt;ATTRIBUTEDS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Log (see &lt;code&gt;LOG-MSG&lt;/code&gt;) &lt;code&gt;ATTRIBUTEDS&lt;/code&gt; non-escaped (as in &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_wr_pr.htm&#34; title=&#34;PRINC FUNCTION&#34;&gt;&lt;code&gt;PRINC&lt;/code&gt;&lt;/a&gt; or ~A) with the output being as table-like as possible.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;6.3.2 Counter classes&lt;/h4&gt; &#xA;&lt;p&gt;In addition to the really basic ones here, also see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Counters&#34;&gt;Classification Counters&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;BASIC-COUNTER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AATTRIBUTED-20CLASS-29&#34; title=&#34;MGL-CORE:ATTRIBUTED CLASS&#34;&gt;ATTRIBUTED&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A simple counter whose &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; takes two additional parameters: an increment to the internal sums of called the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_numera.htm&#34; title=&#34;NUMERATOR FUNCTION&#34;&gt;&lt;code&gt;NUMERATOR&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_numera.htm&#34; title=&#34;DENOMINATOR FUNCTION&#34;&gt;&lt;code&gt;DENOMINATOR&lt;/code&gt;&lt;/a&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:COUNTER-VALUES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;COUNTER-VALUES&lt;/code&gt;&lt;/a&gt; returns two values:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;NUMERATOR&lt;/code&gt; divided by &lt;code&gt;DENOMINATOR&lt;/code&gt; (or 0 if &lt;code&gt;DENOMINATOR&lt;/code&gt; is 0) and&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;DENOMINATOR&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;Here is an example the compute the mean of 5 things received in two batches:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   (let ((counter (make-instance &#39;basic-counter)))&#xA;     (add-to-counter counter 6.5 3)&#xA;     (add-to-counter counter 3.5 2)&#xA;     counter)&#xA;   =&amp;gt; #&amp;lt;BASIC-COUNTER 2.00000e+0 (5)&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ARMSE-COUNTER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;RMSE-COUNTER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;BASIC-COUNTER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;&lt;code&gt;BASIC-COUNTER&lt;/code&gt;&lt;/a&gt; with whose nominator accumulates the square of some statistics. It has the attribute &lt;code&gt;:TYPE&lt;/code&gt; &#34;rmse&#34;. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:COUNTER-VALUES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;COUNTER-VALUES&lt;/code&gt;&lt;/a&gt; returns the square root of what &lt;code&gt;BASIC-COUNTER&lt;/code&gt;&#39;s &lt;code&gt;COUNTER-VALUES&lt;/code&gt; would return.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (let ((counter (make-instance &#39;rmse-counter)))&#xA;    (add-to-counter counter (+ (* 3 3) (* 4 4)) 2)&#xA;    counter)&#xA;  =&amp;gt; #&amp;lt;RMSE-COUNTER rmse: 3.53553e+0 (2)&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONCAT-COUNTER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CONCAT-COUNTER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AATTRIBUTED-20CLASS-29&#34; title=&#34;MGL-CORE:ATTRIBUTED CLASS&#34;&gt;ATTRIBUTED&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A counter that simply concatenates sequences.&lt;/p&gt; &lt;p&gt;```cl-transcript (let ((counter (make-instance &#39;concat-counter))) (add-to-counter counter &#39;(1 2 3) #(4 5)) (add-to-counter counter &#39;(6 7)) (counter-values counter)) =&amp;gt; (1 2 3 4 5 6 7) ````&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONCATENATION-TYPE-20-28MGL-PAX-3AREADER-20MGL-CORE-3ACONCAT-COUNTER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;CONCATENATION-TYPE&lt;/strong&gt; &lt;em&gt;CONCAT-COUNTER (:CONCATENATION-TYPE = &#39;LIST)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A type designator suitable as the RESULT-TYPE argument to &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_concat.htm&#34; title=&#34;CONCATENATE FUNCTION&#34;&gt;&lt;code&gt;CONCATENATE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;7 Classification&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-CORE]&lt;/h6&gt; &#xA;&lt;p&gt;To be able to measure classification related quantities, we need to define what the label of an instance is. Customization is possible by implementing a method for a specific type of instance, but these functions only ever appear as defaults that can be overridden.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;LABEL-INDEX&lt;/strong&gt; &lt;em&gt;INSTANCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the label of &lt;code&gt;INSTANCE&lt;/code&gt; as a non-negative integer.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;LABEL-INDEX-DISTRIBUTION&lt;/strong&gt; &lt;em&gt;INSTANCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a one dimensional array of probabilities representing the distribution of labels. The probability of the label with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDEX&lt;/code&gt;&lt;/a&gt; &lt;code&gt;I&lt;/code&gt; is element at index &lt;code&gt;I&lt;/code&gt; of the returned arrray.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The following two functions are basically the same as the previous two, but in batch mode: they return a sequence of label indices or distributions. These are called on results produced by models. Implement these for a model and the monitor maker functions below will automatically work. See FIXDOC: for bpn and boltzmann.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALABEL-INDICES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;LABEL-INDICES&lt;/strong&gt; &lt;em&gt;RESULTS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a sequence of label indices for &lt;code&gt;RESULTS&lt;/code&gt; produced by some model for a batch of instances. This is akin to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDEX&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTIONS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;LABEL-INDEX-DISTRIBUTIONS&lt;/strong&gt; &lt;em&gt;RESULT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a sequence of label index distributions for &lt;code&gt;RESULTS&lt;/code&gt; produced by some model for a batch of instances. This is akin to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX-DISTRIBUTION GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDEX-DISTRIBUTION&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;7.1 Classification Monitors&lt;/h3&gt; &#xA;&lt;p&gt;The following functions return a list monitors. The monitors are for events of signature (&lt;code&gt;INSTANCES&lt;/code&gt; &lt;code&gt;MODEL&lt;/code&gt;) such as those produced by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MONITOR-MODEL-RESULTS FUNCTION&#34;&gt;&lt;code&gt;MONITOR-MODEL-RESULTS&lt;/code&gt;&lt;/a&gt; and its various model specific variations. They are model-agnostic functions, extensible to new classifier types.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-CLASSIFICATION-ACCURACY-MONITORS&lt;/strong&gt; &lt;em&gt;MODEL &amp;amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-FN #&#39;LABEL-INDEX)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-20CLASS-29&#34; title=&#34;MGL-CORE:MONITOR CLASS&#34;&gt;&lt;code&gt;MONITOR&lt;/code&gt;&lt;/a&gt; objects associated with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:CLASSIFICATION-ACCURACY-COUNTER CLASS&#34;&gt;&lt;code&gt;CLASSIFICATION-ACCURACY-COUNTER&lt;/code&gt;&lt;/a&gt;s. &lt;code&gt;LABEL-INDEX-FN&lt;/code&gt; is a function like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDEX&lt;/code&gt;&lt;/a&gt;. See that function for more.&lt;/p&gt; &lt;p&gt;Implemented in terms of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAKE-CLASSIFICATION-ACCURACY-MONITORS*&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-CROSS-ENTROPY-MONITORS&lt;/strong&gt; &lt;em&gt;MODEL &amp;amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-DISTRIBUTION-FN #&#39;LABEL-INDEX-DISTRIBUTION)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-20CLASS-29&#34; title=&#34;MGL-CORE:MONITOR CLASS&#34;&gt;&lt;code&gt;MONITOR&lt;/code&gt;&lt;/a&gt; objects associated with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:CROSS-ENTROPY-COUNTER CLASS&#34;&gt;&lt;code&gt;CROSS-ENTROPY-COUNTER&lt;/code&gt;&lt;/a&gt;s. &lt;code&gt;LABEL-INDEX-DISTRIBUTION-FN&lt;/code&gt; is a function like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX-DISTRIBUTION GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDEX-DISTRIBUTION&lt;/code&gt;&lt;/a&gt;. See that function for more.&lt;/p&gt; &lt;p&gt;Implemented in terms of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAKE-CROSS-ENTROPY-MONITORS*&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-LABEL-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-LABEL-MONITORS&lt;/strong&gt; &lt;em&gt;MODEL &amp;amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-FN #&#39;LABEL-INDEX) (LABEL-INDEX-DISTRIBUTION-FN #&#39;LABEL-INDEX-DISTRIBUTION)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return classification accuracy and cross-entropy monitors. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS FUNCTION&#34;&gt;&lt;code&gt;MAKE-CLASSIFICATION-ACCURACY-MONITORS&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS FUNCTION&#34;&gt;&lt;code&gt;MAKE-CROSS-ENTROPY-MONITORS&lt;/code&gt;&lt;/a&gt; for a description of paramters.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The monitor makers above can be extended to support new classifier types via the following generic functions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAKE-CLASSIFICATION-ACCURACY-MONITORS*&lt;/strong&gt; &lt;em&gt;MODEL OPERATION-MODE LABEL-INDEX-FN ATTRIBUTES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Identical to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS FUNCTION&#34;&gt;&lt;code&gt;MAKE-CLASSIFICATION-ACCURACY-MONITORS&lt;/code&gt;&lt;/a&gt; bar the keywords arguments. Specialize this to add to support for new model types. The default implementation also allows for some extensibility: if &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDICES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDICES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;LABEL-INDICES&lt;/code&gt;&lt;/a&gt; is defined on &lt;code&gt;MODEL&lt;/code&gt;, then it will be used to extract label indices from model results.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAKE-CROSS-ENTROPY-MONITORS*&lt;/strong&gt; &lt;em&gt;MODEL OPERATION-MODE LABEL-INDEX-DISTRIBUTION-FN ATTRIBUTES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Identical to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS FUNCTION&#34;&gt;&lt;code&gt;MAKE-CROSS-ENTROPY-MONITORS&lt;/code&gt;&lt;/a&gt; bar the keywords arguments. Specialize this to add to support for new model types. The default implementation also allows for some extensibility: if &lt;code&gt;LABEL-INDEX-DISTRIBUTIONS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTIONS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX-DISTRIBUTIONS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:LABEL-INDEX-DISTRIBUTION GENERIC-FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) is defined on &lt;code&gt;MODEL&lt;/code&gt;, then it will be used to extract label distributions from model results.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;7.2 Classification Measurers&lt;/h3&gt; &#xA;&lt;p&gt;The functions here compare some known good solution (also known as &lt;em&gt;ground truth&lt;/em&gt; or &lt;em&gt;target&lt;/em&gt;) to a prediction or approximation and return some measure of their [dis]similarity. They are model independent, hence one has to extract the ground truths and predictions first. Rarely used directly, they are mostly hidden behind &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29&#34; title=&#34;Classification Monitors&#34;&gt;Classification Monitors&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMEASURE-CLASSIFICATION-ACCURACY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MEASURE-CLASSIFICATION-ACCURACY&lt;/strong&gt; &lt;em&gt;TRUTHS PREDICTIONS &amp;amp;KEY (TEST #&#39;EQL) TRUTH-KEY PREDICTION-KEY WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the number of correct classifications and as the second value the number of instances (equal to length of &lt;code&gt;TRUTHS&lt;/code&gt; in the non-weighted case). &lt;code&gt;TRUTHS&lt;/code&gt; (keyed by &lt;code&gt;TRUTH-KEY&lt;/code&gt;) is a sequence of opaque class labels compared with &lt;code&gt;TEST&lt;/code&gt; to another sequence of classes labels in &lt;code&gt;PREDICTIONS&lt;/code&gt; (keyed by &lt;code&gt;PREDICTION-KEY&lt;/code&gt;). If &lt;code&gt;WEIGHT&lt;/code&gt; is non-nil, then it is a function that returns the weight of an element of &lt;code&gt;TRUTHS&lt;/code&gt;. Weighted cases add their weight to both counts (returned as the first and second values) instead of 1 as in the non-weighted case.&lt;/p&gt; &lt;p&gt;Note how the returned values are suitable for &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/s_multip.htm&#34; title=&#34;MULTIPLE-VALUE-CALL MGL-PAX:MACRO&#34;&gt;&lt;code&gt;MULTIPLE-VALUE-CALL&lt;/code&gt;&lt;/a&gt; with #&#39;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:CLASSIFICATION-ACCURACY-COUNTER CLASS&#34;&gt;&lt;code&gt;CLASSIFICATION-ACCURACY-COUNTER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMEASURE-CROSS-ENTROPY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MEASURE-CROSS-ENTROPY&lt;/strong&gt; &lt;em&gt;TRUTHS PREDICTIONS &amp;amp;KEY TRUTH-KEY PREDICTION-KEY (MIN-PREDICTION-PR 1.0d-15)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the sum of the cross-entropy between pairs of elements with the same index of &lt;code&gt;TRUTHS&lt;/code&gt; and &lt;code&gt;PREDICTIONS&lt;/code&gt;. &lt;code&gt;TRUTH-KEY&lt;/code&gt; is a function that&#39;s when applied to an element of &lt;code&gt;TRUTHS&lt;/code&gt; returns a sequence representing some kind of discrete target distribution (P in the definition below). &lt;code&gt;TRUTH-KEY&lt;/code&gt; may be &lt;code&gt;NIL&lt;/code&gt; which is equivalent to the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_identi.htm&#34; title=&#34;IDENTITY FUNCTION&#34;&gt;&lt;code&gt;IDENTITY&lt;/code&gt;&lt;/a&gt; function. &lt;code&gt;PREDICTION-KEY&lt;/code&gt; is the same kind of key for &lt;code&gt;PREDICTIONS&lt;/code&gt;, but the sequence it returns represents a distribution that approximates (Q below) the true one.&lt;/p&gt; &lt;p&gt;Cross-entropy of the true and approximating distributions is defined as:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  cross-entropy(p,q) = - sum_i p(i) * log(q(i))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;of which this function returns the sum over the pairs of elements of &lt;code&gt;TRUTHS&lt;/code&gt; and &lt;code&gt;PREDICTIONS&lt;/code&gt; keyed by &lt;code&gt;TRUTH-KEY&lt;/code&gt; and &lt;code&gt;PREDICTION-KEY&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Due to the logarithm, if q(i) is close to zero, we run into numerical problems. To prevent this, all q(i) that are less than &lt;code&gt;MIN-PREDICTION-PR&lt;/code&gt; are treated as if they were &lt;code&gt;MIN-PREDICTION-PR&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The second value returned is the sum of p(i) over all &lt;code&gt;TRUTHS&lt;/code&gt; and all &lt;code&gt;I&lt;/code&gt;. This is normally equal to &lt;code&gt;(LENGTH TRUTHS)&lt;/code&gt;, since elements of &lt;code&gt;TRUTHS&lt;/code&gt; represent a probability distribution, but this is not enforced which allows relative importance of elements to be controlled.&lt;/p&gt; &lt;p&gt;The third value returned is a plist that maps each index occurring in the distribution sequences to a list of two elements:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;   sum_j p_j(i) * log(q_j(i))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  sum_j p_j(i)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;where &lt;code&gt;J&lt;/code&gt; indexes into &lt;code&gt;TRUTHS&lt;/code&gt; and &lt;code&gt;PREDICTIONS&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (measure-cross-entropy &#39;((0 1 0)) &#39;((0.1 0.7 0.2)))&#xA;  =&amp;gt; 0.35667497&#xA;     1&#xA;     (2 (0.0 0)&#xA;      1 (0.35667497 1)&#xA;      0 (0.0 0))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how the returned values are suitable for &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/s_multip.htm&#34; title=&#34;MULTIPLE-VALUE-CALL MGL-PAX:MACRO&#34;&gt;&lt;code&gt;MULTIPLE-VALUE-CALL&lt;/code&gt;&lt;/a&gt; with #&#39;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:CROSS-ENTROPY-COUNTER CLASS&#34;&gt;&lt;code&gt;CROSS-ENTROPY-COUNTER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMEASURE-ROC-AUC-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MEASURE-ROC-AUC&lt;/strong&gt; &lt;em&gt;PREDICTIONS PRED &amp;amp;KEY (KEY #&#39;IDENTITY) WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the area under the ROC curve for &lt;code&gt;PREDICTIONS&lt;/code&gt; representing predictions for a binary classification problem. &lt;code&gt;PRED&lt;/code&gt; is a predicate function for deciding whether a prediction belongs to the so called positive class. &lt;code&gt;KEY&lt;/code&gt; returns a number for each element which is the predictor&#39;s idea of how much that element is likely to belong to the class, although it&#39;s not necessarily a probability.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;WEIGHT&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then all elements of &lt;code&gt;PREDICTIONS&lt;/code&gt; count as 1 towards the unnormalized sum within AUC. Else &lt;code&gt;WEIGHT&lt;/code&gt; must be a function like &lt;code&gt;KEY&lt;/code&gt;, but it should return the importance (a positive real number) of elements. If the weight of an prediction is 2 then it&#39;s as if there were another identical copy of that prediction in &lt;code&gt;PREDICTIONS&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The algorithm is based on algorithm 2 in the paper &#39;An introduction to ROC analysis&#39; by Tom Fawcett.&lt;/p&gt; &lt;p&gt;ROC AUC is equal to the probability of a randomly chosen positive having higher &lt;code&gt;KEY&lt;/code&gt; (score) than a randomly chosen negative element. With equal scores in mind, a more precise version is: AUC is the expectation of the above probability over all possible sequences sorted by scores.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMEASURE-CONFUSION-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MEASURE-CONFUSION&lt;/strong&gt; &lt;em&gt;TRUTHS PREDICTIONS &amp;amp;KEY (TEST #&#39;EQL) TRUTH-KEY PREDICTION-KEY WEIGHT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ACONFUSION-MATRIX-20CLASS-29&#34; title=&#34;MGL-CORE:CONFUSION-MATRIX CLASS&#34;&gt;&lt;code&gt;CONFUSION-MATRIX&lt;/code&gt;&lt;/a&gt; from &lt;code&gt;TRUTHS&lt;/code&gt; and &lt;code&gt;PREDICTIONS&lt;/code&gt;. &lt;code&gt;TRUTHS&lt;/code&gt; (keyed by &lt;code&gt;TRUTH-KEY&lt;/code&gt;) is a sequence of class labels compared with &lt;code&gt;TEST&lt;/code&gt; to another sequence of class labels in &lt;code&gt;PREDICTIONS&lt;/code&gt; (keyed by &lt;code&gt;PREDICTION-KEY&lt;/code&gt;). If &lt;code&gt;WEIGHT&lt;/code&gt; is non-nil, then it is a function that returns the weight of an element of &lt;code&gt;TRUTHS&lt;/code&gt;. Weighted cases add their weight to both counts (returned as the first and second values).&lt;/p&gt; &lt;p&gt;Note how the returned confusion matrix can be added to another with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ADD-TO-COUNTER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;7.3 Classification Counters&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CLASSIFICATION-ACCURACY-COUNTER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;BASIC-COUNTER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;&lt;code&gt;BASIC-COUNTER&lt;/code&gt;&lt;/a&gt; with &#34;acc.&#34; as its &lt;code&gt;:TYPE&lt;/code&gt; attribute and a &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_pr_obj.htm&#34; title=&#34;PRINT-OBJECT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;PRINT-OBJECT&lt;/code&gt;&lt;/a&gt; method that prints percentages.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CROSS-ENTROPY-COUNTER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;BASIC-COUNTER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;&lt;code&gt;BASIC-COUNTER&lt;/code&gt;&lt;/a&gt; with &#34;xent&#34; as its &lt;code&gt;:TYPE&lt;/code&gt; attribute.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;7.3.1 Confusion Matrices&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-MATRIX-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CONFUSION-MATRIX&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A confusion matrix keeps count of classification results. The correct class is called &lt;code&gt;target&#39; and the output of the classifier is called&lt;/code&gt;prediction&#39;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-CONFUSION-MATRIX-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-CONFUSION-MATRIX&lt;/strong&gt; &lt;em&gt;&amp;amp;KEY (TEST #&#39;EQL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Classes are compared with &lt;code&gt;TEST&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASORT-CONFUSION-CLASSES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SORT-CONFUSION-CLASSES&lt;/strong&gt; &lt;em&gt;MATRIX CLASSES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of &lt;code&gt;CLASSES&lt;/code&gt; sorted for presentation purposes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-CLASS-NAME-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;CONFUSION-CLASS-NAME&lt;/strong&gt; &lt;em&gt;MATRIX CLASS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Name of &lt;code&gt;CLASS&lt;/code&gt; for presentation purposes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-COUNT-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[generic-function] &lt;strong&gt;CONFUSION-COUNT&lt;/strong&gt; &lt;em&gt;MATRIX TARGET PREDICTION&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAP-CONFUSION-MATRIX-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAP-CONFUSION-MATRIX&lt;/strong&gt; &lt;em&gt;FN MATRIX&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with &lt;code&gt;TARGET&lt;/code&gt;, &lt;code&gt;PREDICTION&lt;/code&gt;, &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_countc.htm&#34; title=&#34;COUNT FUNCTION&#34;&gt;&lt;code&gt;COUNT&lt;/code&gt;&lt;/a&gt; paramaters for each cell in the confusion matrix. Cells with a zero count may be ommitted.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-MATRIX-CLASSES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;CONFUSION-MATRIX-CLASSES&lt;/strong&gt; &lt;em&gt;MATRIX&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A list of all classes. The default is to collect classes from the counts. This can be overridden if, for instance, some classes are not present in the results.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-MATRIX-ACCURACY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CONFUSION-MATRIX-ACCURACY&lt;/strong&gt; &lt;em&gt;MATRIX &amp;amp;KEY FILTER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the overall accuracy of the results in &lt;code&gt;MATRIX&lt;/code&gt;. It&#39;s computed as the number of correctly classified cases (hits) divided by the name of cases. Return the number of hits and the number of cases as the second and third value. If &lt;code&gt;FILTER&lt;/code&gt; function is given, then call it with the target and the prediction of the cell. Disregard cell for which &lt;code&gt;FILTER&lt;/code&gt; returns &lt;code&gt;NIL&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Precision and recall can be easily computed by giving the right filter, although those are provided in separate convenience functions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-MATRIX-PRECISION-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CONFUSION-MATRIX-PRECISION&lt;/strong&gt; &lt;em&gt;MATRIX PREDICTION&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the accuracy over the cases when the classifier said &lt;code&gt;PREDICTION&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACONFUSION-MATRIX-RECALL-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CONFUSION-MATRIX-RECALL&lt;/strong&gt; &lt;em&gt;MATRIX TARGET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the accuracy over the cases when the correct class is &lt;code&gt;TARGET&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AADD-CONFUSION-MATRIX-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ADD-CONFUSION-MATRIX&lt;/strong&gt; &lt;em&gt;MATRIX RESULT-MATRIX&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Add &lt;code&gt;MATRIX&lt;/code&gt; into &lt;code&gt;RESULT-MATRIX&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-FEATURES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;8 Features&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-CORE]&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-FEATURE-SELECTION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;8.1 Feature Selection&lt;/h3&gt; &#xA;&lt;p&gt;The following &lt;em&gt;scoring functions&lt;/em&gt; all return an &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; hash table that maps features to scores.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ACOUNT-FEATURES-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;COUNT-FEATURES&lt;/strong&gt; &lt;em&gt;DOCUMENTS MAPPER &amp;amp;KEY (KEY #&#39;IDENTITY)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return scored features as an &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; hash table whose keys are features of &lt;code&gt;DOCUMENTS&lt;/code&gt; and values are counts of occurrences of features. &lt;code&gt;MAPPER&lt;/code&gt; takes a function and a document and calls function with features of the document.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(sort (alexandria:hash-table-alist&#xA;       (count-features &#39;((&#34;hello&#34; &#34;world&#34;)&#xA;                         (&#34;this&#34; &#34;is&#34; &#34;our&#34; &#34;world&#34;))&#xA;                       (lambda (fn document)&#xA;                         (map nil fn document))))&#xA;      #&#39;string&amp;lt; :key #&#39;car)&#xA;=&amp;gt; ((&#34;hello&#34; . 1) (&#34;is&#34; . 1) (&#34;our&#34; . 1) (&#34;this&#34; . 1) (&#34;world&#34; . 2))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AFEATURE-LLRS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;FEATURE-LLRS&lt;/strong&gt; &lt;em&gt;DOCUMENTS MAPPER CLASS-FN &amp;amp;KEY (CLASSES (ALL-DOCUMENT-CLASSES DOCUMENTS CLASS-FN))&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return scored features as an &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; hash table whose keys are features of &lt;code&gt;DOCUMENTS&lt;/code&gt; and values are their log likelihood ratios. &lt;code&gt;MAPPER&lt;/code&gt; takes a function and a document and calls function with features of the document.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(sort (alexandria:hash-table-alist&#xA;       (feature-llrs &#39;((:a &#34;hello&#34; &#34;world&#34;)&#xA;                       (:b &#34;this&#34; &#34;is&#34; &#34;our&#34; &#34;world&#34;))&#xA;                     (lambda (fn document)&#xA;                       (map nil fn (rest document)))&#xA;                     #&#39;first))&#xA;      #&#39;string&amp;lt; :key #&#39;car)&#xA;=&amp;gt; ((&#34;hello&#34; . 2.6032386) (&#34;is&#34; . 2.6032386) (&#34;our&#34; . 2.6032386)&#xA;    (&#34;this&#34; . 2.6032386) (&#34;world&#34; . 4.8428774e-8))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AFEATURE-DISAMBIGUITIES-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;FEATURE-DISAMBIGUITIES&lt;/strong&gt; &lt;em&gt;DOCUMENTS MAPPER CLASS-FN &amp;amp;KEY (CLASSES (ALL-DOCUMENT-CLASSES DOCUMENTS CLASS-FN))&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return scored features as an &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; hash table whose keys are features of &lt;code&gt;DOCUMENTS&lt;/code&gt; and values are their &lt;em&gt;disambiguities&lt;/em&gt;. &lt;code&gt;MAPPER&lt;/code&gt; takes a function and a document and calls function with features of the document.&lt;/p&gt; &lt;p&gt;From the paper &#39;Using Ambiguity Measure Feature Selection Algorithm for Support Vector Machine Classifier&#39;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3A-40MGL-FEATURE-ENCODING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;8.2 Feature Encoding&lt;/h3&gt; &#xA;&lt;p&gt;Features can rarely be fed directly to algorithms as is, they need to be transformed in some way. Suppose we have a simple language model that takes a single word as input and predicts the next word. However, both input and output is to be encoded as float vectors of length 1000. What we do is find the top 1000 words by some measure (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-FEATURE-SELECTION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Feature Selection&#34;&gt;Feature Selection&lt;/a&gt;) and associate these words with the integers in [0..999] (this is &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AENCODE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ENCODE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ENCODE&lt;/code&gt;&lt;/a&gt;ing). By using for example &lt;a href=&#34;http://en.wikipedia.org/wiki/One-hot&#34;&gt;one-hot&lt;/a&gt; encoding, we translate a word into a float vector when passing in the input. When the model outputs the probability distribution of the next word, we find the index of the max and find the word associated with it (this is &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ADECODE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:DECODE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DECODE&lt;/code&gt;&lt;/a&gt;ing)&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AENCODE-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;ENCODE&lt;/strong&gt; &lt;em&gt;ENCODER DECODED&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Encode &lt;code&gt;DECODED&lt;/code&gt; with &lt;code&gt;ENCODER&lt;/code&gt;. This interface is generic enough to be almost meaningless. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AENCODER-2FDECODER-20CLASS-29&#34; title=&#34;MGL-CORE:ENCODER/DECODER CLASS&#34;&gt;&lt;code&gt;ENCODER/DECODER&lt;/code&gt;&lt;/a&gt; for a simple, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3ABAG-OF-WORDS-ENCODER-20CLASS-29&#34; title=&#34;MGL-NLP:BAG-OF-WORDS-ENCODER CLASS&#34;&gt;&lt;code&gt;MGL-NLP:BAG-OF-WORDS-ENCODER&lt;/code&gt;&lt;/a&gt; for a slightly more involved example.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;ENCODER&lt;/code&gt; is a function designator, then it&#39;s simply &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_funcal.htm&#34; title=&#34;FUNCALL FUNCTION&#34;&gt;&lt;code&gt;FUNCALL&lt;/code&gt;&lt;/a&gt;ed with &lt;code&gt;DECODED&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ADECODE-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;DECODE&lt;/strong&gt; &lt;em&gt;DECODER ENCODED&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Decode &lt;code&gt;ENCODED&lt;/code&gt; with &lt;code&gt;ENCODER&lt;/code&gt;. For an &lt;code&gt;DECODER&lt;/code&gt; / &lt;code&gt;ENCODER&lt;/code&gt; pair, &lt;code&gt;(DECODE DECODER (ENCODE ENCODER OBJECT))&lt;/code&gt; must be equal in some sense to &lt;code&gt;OBJECT&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;DECODER&lt;/code&gt; is a function designator, then it&#39;s simply &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_funcal.htm&#34; title=&#34;FUNCALL FUNCTION&#34;&gt;&lt;code&gt;FUNCALL&lt;/code&gt;&lt;/a&gt;ed with &lt;code&gt;ENCODED&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AENCODER-2FDECODER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;ENCODER/DECODER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Implements O(1) &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AENCODE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ENCODE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ENCODE&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ADECODE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:DECODE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DECODE&lt;/code&gt;&lt;/a&gt; by having an internal decoded-to-encoded and an encoded-to-decoded &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt; hash table. &lt;code&gt;ENCODER/DECODER&lt;/code&gt; objects can be saved and loaded (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-PERSISTENCE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Persistence&#34;&gt;Persistence&lt;/a&gt;) as long as the elements in the hash tables have read/write consitency.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(let ((indexer&#xA;        (make-indexer&#xA;         (alexandria:alist-hash-table &#39;((&#34;I&#34; . 3) (&#34;me&#34; . 2) (&#34;mine&#34; . 1)))&#xA;         2)))&#xA;  (values (encode indexer &#34;I&#34;)&#xA;          (encode indexer &#34;me&#34;)&#xA;          (encode indexer &#34;mine&#34;)&#xA;          (decode indexer 0)&#xA;          (decode indexer 1)&#xA;          (decode indexer 2)))&#xA;=&amp;gt; 0&#xA;=&amp;gt; 1&#xA;=&amp;gt; NIL&#xA;=&amp;gt; &#34;I&#34;&#xA;=&amp;gt; &#34;me&#34;&#xA;=&amp;gt; NIL&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAKE-INDEXER-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-INDEXER&lt;/strong&gt; &lt;em&gt;SCORED-FEATURES N &amp;amp;KEY (START 0) (CLASS &#39;ENCODER/DECODER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Take the top &lt;code&gt;N&lt;/code&gt; features from &lt;code&gt;SCORED-FEATURES&lt;/code&gt; (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3A-40MGL-FEATURE-SELECTION-20MGL-PAX-3ASECTION-29&#34; title=&#34;Feature Selection&#34;&gt;Feature Selection&lt;/a&gt;), assign indices to them starting from &lt;code&gt;START&lt;/code&gt;. Return an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AENCODER-2FDECODER-20CLASS-29&#34; title=&#34;MGL-CORE:ENCODER/DECODER CLASS&#34;&gt;&lt;code&gt;ENCODER/DECODER&lt;/code&gt;&lt;/a&gt; (or another &lt;code&gt;CLASS&lt;/code&gt;) that converts between objects and indices.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Also see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3A-40MGL-NLP-BAG-OF-WORDS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Bag of Words&#34;&gt;Bag of Words&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;9 Gradient Based Optimization&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-OPT]&lt;/h6&gt; &#xA;&lt;p&gt;We have a real valued, differentiable function F and the task is to find the parameters that minimize its value. Optimization starts from a single point in the parameter space of F, and this single point is updated iteratively based on the gradient and value of F at or around the current point.&lt;/p&gt; &#xA;&lt;p&gt;Note that while the stated problem is that of global optimization, for non-convex functions, most algorithms will tend to converge to a local optimum.&lt;/p&gt; &#xA;&lt;p&gt;Currently, there are two optimization algorithms: &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;Gradient Descent&lt;/a&gt; (with several variants) and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34; title=&#34;Conjugate Gradient&#34;&gt;Conjugate Gradient&lt;/a&gt; both of which are first order methods (they do not need second order gradients) but more can be added with the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29&#34; title=&#34;Extension API&#34;&gt;Extension API&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MINIMIZE&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE &amp;amp;KEY (WEIGHTS (LIST-SEGMENTS GRADIENT-SOURCE)) (DATASET *INFINITELY-EMPTY-DATASET*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Minimize the value of the real valued function represented by &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; by updating some of its parameters in &lt;code&gt;WEIGHTS&lt;/code&gt; (a &lt;code&gt;MAT&lt;/code&gt; or a sequence of &lt;code&gt;MAT&lt;/code&gt;s). Return &lt;code&gt;WEIGHTS&lt;/code&gt;. &lt;code&gt;DATASET&lt;/code&gt; (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29&#34; title=&#34;Datasets&#34;&gt;Datasets&lt;/a&gt;) is a set of unoptimized parameters of the same function. For example, &lt;code&gt;WEIGHTS&lt;/code&gt; may be the weights of a neural network while &lt;code&gt;DATASET&lt;/code&gt; is the training set consisting of inputs suitable for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;. The default &lt;code&gt;DATASET&lt;/code&gt;, (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-2AINFINITELY-EMPTY-DATASET-2A-20VARIABLE-29&#34; title=&#34;MGL-DATASET:*INFINITELY-EMPTY-DATASET* VARIABLE&#34;&gt;&lt;code&gt;*INFINITELY-EMPTY-DATASET*&lt;/code&gt;&lt;/a&gt;) is suitable for when all parameters are optimized, so there is nothing left to come from the environment.&lt;/p&gt; &lt;p&gt;Optimization terminates if &lt;code&gt;DATASET&lt;/code&gt; is a sampler and it runs out or when some other condition met (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:TERMINATION (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;TERMINATION&lt;/code&gt;&lt;/a&gt;, for example). If &lt;code&gt;DATASET&lt;/code&gt; is a &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/t_seq.htm&#34; title=&#34;SEQUENCE TYPE&#34;&gt;&lt;code&gt;SEQUENCE&lt;/code&gt;&lt;/a&gt;, then it is reused over and over again.&lt;/p&gt; &lt;p&gt;Examples for various optimizers are provided in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;Gradient Descent&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34; title=&#34;Conjugate Gradient&#34;&gt;Conjugate Gradient&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;9.1 Iterative Optimizer&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;ITERATIVE-OPTIMIZER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;An abstract base class of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;Gradient Descent&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34; title=&#34;Conjugate Gradient&#34;&gt;Conjugate Gradient&lt;/a&gt; based optimizers that iterate over instances until a termination condition is met.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;N-INSTANCES&lt;/strong&gt; &lt;em&gt;ITERATIVE-OPTIMIZER (:N-INSTANCES = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of instances this optimizer has seen so far. Incremented automatically during optimization.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;TERMINATION&lt;/strong&gt; &lt;em&gt;ITERATIVE-OPTIMIZER (:TERMINATION = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If a number, it&#39;s the number of instances to train on in the sense of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;N-INSTANCES&lt;/code&gt;&lt;/a&gt;. If &lt;code&gt;N-INSTANCES&lt;/code&gt; is equal or greater than this value optimization stops. If &lt;code&gt;TERMINATION&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then optimization will continue. If it is &lt;code&gt;T&lt;/code&gt;, then optimization will stop. If it is a function of no arguments, then its return value is processed as if it was returned by &lt;code&gt;TERMINATION&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;ON-OPTIMIZATION-STARTED&lt;/strong&gt; &lt;em&gt;ITERATIVE-OPTIMIZER (:ON-OPTIMIZATION-STARTED = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An event hook with parameters &lt;code&gt;(OPTIMIZER GRADIENT-SOURCE N-INSTANCES)&lt;/code&gt;. Called after initializations are performed (INITIALIZE-OPTIMIZER*, INITIALIZE-GRADIENT-SOURCE*) but before optimization is started.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AON-OPTIMIZATION-FINISHED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;ON-OPTIMIZATION-FINISHED&lt;/strong&gt; &lt;em&gt;ITERATIVE-OPTIMIZER (:ON-OPTIMIZATION-FINISHED = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An event hook with parameters &lt;code&gt;(OPTIMIZER GRADIENT-SOURCE N-INSTANCES)&lt;/code&gt;. Called when optimization has finished.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;ON-N-INSTANCES-CHANGED&lt;/strong&gt; &lt;em&gt;ITERATIVE-OPTIMIZER (:ON-N-INSTANCES-CHANGED = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An event hook with parameters &lt;code&gt;(OPTIMIZER GRADIENT-SOURCE N-INSTANCES)&lt;/code&gt;. Called when optimization of a batch of instances is done and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;N-INSTANCES&lt;/code&gt;&lt;/a&gt; is incremented.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;Now let&#39;s discuss a few handy utilities.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MONITOR-OPTIMIZATION-PERIODICALLY&lt;/strong&gt; &lt;em&gt;OPTIMIZER PERIODIC-FNS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;For each periodic function in the list of &lt;code&gt;PERIODIC-FNS&lt;/code&gt;, add a monitor to &lt;code&gt;OPTIMIZER&lt;/code&gt;&#39;s &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-OPTIMIZATION-STARTED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-OPTIMIZATION-STARTED&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-OPTIMIZATION-FINISHED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-OPTIMIZATION-FINISHED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-OPTIMIZATION-FINISHED&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-N-INSTANCES-CHANGED&lt;/code&gt;&lt;/a&gt; hooks. The monitors are simple functions that just call each periodic function with the event parameters (&lt;code&gt;OPTIMIZER&lt;/code&gt; &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;N-INSTANCES&lt;/code&gt;&lt;/a&gt;). Return &lt;code&gt;OPTIMIZER&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To log and reset the monitors of the gradient source after every 1000 instances seen by &lt;code&gt;OPTIMIZER&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (monitor-optimization-periodically optimizer&#xA;                                     &#39;((:fn log-my-test-error&#xA;                                        :period 2000)&#xA;                                       (:fn reset-optimization-monitors&#xA;                                        :period 1000&#xA;                                        :last-eval 0)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how we don&#39;t pass it&#39;s allowed to just pass the initargs for a &lt;code&gt;PERIODIC-FN&lt;/code&gt; instead of &lt;code&gt;PERIODIC-FN&lt;/code&gt; itself. The &lt;code&gt;:LAST-EVAL&lt;/code&gt; 0 bit prevents &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:RESET-OPTIMIZATION-MONITORS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;RESET-OPTIMIZATION-MONITORS&lt;/code&gt;&lt;/a&gt; from being called at the start of the optimization when the monitors are empty anyway.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;RESET-OPTIMIZATION-MONITORS&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Report the state of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITORS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MONITORS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MONITORS&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;OPTIMIZER&lt;/code&gt; and &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; and reset their counters. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29&#34; title=&#34;MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY FUNCTION&#34;&gt;&lt;code&gt;MONITOR-OPTIMIZATION-PERIODICALLY&lt;/code&gt;&lt;/a&gt; for an example of how this is used.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20-28METHOD-20NIL-20-28MGL-OPT-3AITERATIVE-OPTIMIZER-20T-29-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[method] &lt;strong&gt;RESET-OPTIMIZATION-MONITORS&lt;/strong&gt; &lt;em&gt;(OPTIMIZER ITERATIVE-OPTIMIZER) GRADIENT-SOURCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Log the counters of the monitors of &lt;code&gt;OPTIMIZER&lt;/code&gt; and &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; and reset them.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AREPORT-OPTIMIZATION-PARAMETERS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;REPORT-OPTIMIZATION-PARAMETERS&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A utility that&#39;s often called at the start of optimization (from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-OPTIMIZATION-STARTED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-OPTIMIZATION-STARTED&lt;/code&gt;&lt;/a&gt;). The default implementation logs the description of &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; (as in &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_descri.htm&#34; title=&#34;DESCRIBE FUNCTION&#34;&gt;&lt;code&gt;DESCRIBE&lt;/code&gt;&lt;/a&gt;) and &lt;code&gt;OPTIMIZER&lt;/code&gt; and calls &lt;code&gt;LOG-MAT-ROOM&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;9.2 Cost Function&lt;/h3&gt; &#xA;&lt;p&gt;The function being minimized is often called the &lt;em&gt;cost&lt;/em&gt; or the &lt;em&gt;loss&lt;/em&gt; function.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ACOST-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;COST&lt;/strong&gt; &lt;em&gt;MODEL&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the value of the cost function being minimized. Calling this only makes sense in the context of an ongoing optimization (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt;). The cost is that of a batch of instances.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMAKE-COST-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-COST-MONITORS&lt;/strong&gt; &lt;em&gt;MODEL &amp;amp;KEY OPERATION-MODE ATTRIBUTES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-20CLASS-29&#34; title=&#34;MGL-CORE:MONITOR CLASS&#34;&gt;&lt;code&gt;MONITOR&lt;/code&gt;&lt;/a&gt; objects, each associated with one &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29&#34; title=&#34;MGL-CORE:BASIC-COUNTER CLASS&#34;&gt;&lt;code&gt;BASIC-COUNTER&lt;/code&gt;&lt;/a&gt; with attribute &lt;code&gt;:TYPE&lt;/code&gt; &#34;cost&#34;. Implemented in terms of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAKE-COST-MONITORS-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MAKE-COST-MONITORS* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAKE-COST-MONITORS*&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMAKE-COST-MONITORS-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAKE-COST-MONITORS*&lt;/strong&gt; &lt;em&gt;MODEL OPERATION-MODE ATTRIBUTES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Identical to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAKE-COST-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-OPT:MAKE-COST-MONITORS FUNCTION&#34;&gt;&lt;code&gt;MAKE-COST-MONITORS&lt;/code&gt;&lt;/a&gt; bar the keywords arguments. Specialize this to add to support for new model types.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;9.3 Gradient Descent&lt;/h3&gt; &#xA;&lt;h6&gt;[in package MGL-GD]&lt;/h6&gt; &#xA;&lt;p&gt;Gradient descent is a first-order optimization algorithm. Relying completely on first derivatives, it does not even evaluate the function to be minimized. Let&#39;s see how to minimize a numerical lisp function with respect to some of its parameters.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ASGD-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmelisgl-2Fown-2Fmgl-2Fexample-2Fsgd-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(cl:defpackage :mgl-example-sgd&#xA;  (:use #:common-lisp #:mgl))&#xA;&#xA;(in-package :mgl-example-sgd)&#xA;&#xA;;;; Create an object representing the sine function.&#xA;(defparameter *diff-fn-1*&#xA;  (make-instance &#39;mgl-diffun:diffun&#xA;                 :fn #&#39;sin&#xA;                 ;; We are going to optimize its only parameter.&#xA;                 :weight-indices &#39;(0)))&#xA;&#xA;;;; Minimize SIN. Note that there is no dataset involved because all&#xA;;;; parameters are being optimized.&#xA;(minimize (make-instance &#39;sgd-optimizer :termination 1000)&#xA;          *diff-fn-1*&#xA;          :weights (make-mat 1))&#xA;;;; =&amp;gt; A MAT with a single value of about -pi/2.&#xA;&#xA;;;; Create a differentiable function for f(x,y)=(x-y)^2. X is a&#xA;;;; parameter whose values come from the DATASET argument passed to&#xA;;;; MINIMIZE. Y is a parameter to be optimized (a &#39;weight&#39;).&#xA;(defparameter *diff-fn-2*&#xA;  (make-instance &#39;mgl-diffun:diffun&#xA;                 :fn (lambda (x y)&#xA;                       (expt (- x y) 2))&#xA;                 :parameter-indices &#39;(0)&#xA;                 :weight-indices &#39;(1)))&#xA;&#xA;;;; Find the Y that minimizes the distance from the instances&#xA;;;; generated by the sampler.&#xA;(minimize (make-instance &#39;sgd-optimizer :batch-size 10)&#xA;          *diff-fn-2*&#xA;          :weights (make-mat 1)&#xA;          :dataset (make-instance &#39;function-sampler&#xA;                                  :generator (lambda ()&#xA;                                               (list (+ 10&#xA;                                                        (gaussian-random-1))))&#xA;                                  :max-n-samples 1000))&#xA;;;; =&amp;gt; A MAT with a single value of about 10, the expected value of&#xA;;;; the instances in the dataset.&#xA;&#xA;;;; The dataset can be a SEQUENCE in which case we&#39;d better set&#xA;;;; TERMINATION else optimization would never finish.&#xA;(minimize (make-instance &#39;sgd-optimizer :termination 1000)&#xA;          *diff-fn-2*&#xA;          :weights (make-mat 1)&#xA;          :dataset &#39;((0) (1) (2) (3) (4) (5)))&#xA;;;; =&amp;gt; A MAT with a single value of about 2.5.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;We are going to see a number of accessors for optimizer paramaters. In general, it&#39;s allowed to &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/m_setf.htm&#34; title=&#34;SETF MGL-PAX:MACRO&#34;&gt;&lt;code&gt;SETF&lt;/code&gt;&lt;/a&gt; real slot accessors (as opposed to readers and writers) at any time during optimization and so is defining a method on an optimizer subclass that computes the value in any way. For example, to decay the learning rate on a per mini-batch basis:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(defmethod learning-rate ((optimizer my-sgd-optimizer))&#xA;  (* (slot-value optimizer &#39;learning-rate)&#xA;     (expt 0.998&#xA;           (/ (n-instances optimizer) 60000))))&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.3.1 Batch Based Optimizers&lt;/h4&gt; &#xA;&lt;p&gt;First let&#39;s see everything common to all batch based optimizers, then discuss &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-SGD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;SGD Optimizer&#34;&gt;SGD Optimizer&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Adam Optimizer&#34;&gt;Adam Optimizer&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-NORMALIZED-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Normalized Batch Optimizer&#34;&gt;Normalized Batch Optimizer&lt;/a&gt;. All batch based optimizers are &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;ITERATIVE-OPTIMIZER&lt;/code&gt;&lt;/a&gt;s, so see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Iterative Optimizer&#34;&gt;Iterative Optimizer&lt;/a&gt; too.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;BATCH-GD-OPTIMIZER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Another abstract base class for gradient based optimizers tath updates all weights simultaneously after chewing through &lt;code&gt;BATCH-SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;2&lt;/code&gt;&lt;/a&gt;) inputs. See subclasses &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ASGD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:SGD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;SGD-OPTIMIZER&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AADAM-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:ADAM-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;ADAM-OPTIMIZER&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:NORMALIZED-BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;NORMALIZED-BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;PER-WEIGHT-BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt; may be a better choice when some weights can go unused for instance due to missing input values.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;BATCH-SIZE&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:BATCH-SIZE = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;After having gone through &lt;code&gt;BATCH-SIZE&lt;/code&gt; number of inputs, weights are updated. With &lt;code&gt;BATCH-SIZE&lt;/code&gt; 1, one gets Stochastics Gradient Descent. With &lt;code&gt;BATCH-SIZE&lt;/code&gt; equal to the number of instances in the dataset, one gets standard, &#39;batch&#39; gradient descent. With &lt;code&gt;BATCH-SIZE&lt;/code&gt; between these two extremes, one gets the most practical &#39;mini-batch&#39; compromise.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;LEARNING-RATE&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:LEARNING-RATE = 0.1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is the step size along the gradient. Decrease it if optimization diverges, increase it if it doesn&#39;t make progress.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AMOMENTUM-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;MOMENTUM&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:MOMENTUM = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A value in the [0, 1) interval. &lt;code&gt;MOMENTUM&lt;/code&gt; times the previous weight change is added to the gradient. 0 means no momentum.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AMOMENTUM-TYPE-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;MOMENTUM-TYPE&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:MOMENTUM-TYPE = :NORMAL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;One of &lt;code&gt;:NORMAL&lt;/code&gt;, &lt;code&gt;:NESTEROV&lt;/code&gt; or &lt;code&gt;:NONE&lt;/code&gt;. For pure optimization Nesterov&#39;s momentum may be better, but it may also increases chances of overfitting. Using &lt;code&gt;:NONE&lt;/code&gt; is equivalent to 0 momentum, but it also uses less memory. Note that with &lt;code&gt;:NONE&lt;/code&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AMOMENTUM-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:MOMENTUM (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;MOMENTUM&lt;/code&gt;&lt;/a&gt; is ignored even it it is non-zero.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AWEIGHT-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;WEIGHT-DECAY&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:WEIGHT-DECAY = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An L2 penalty. It discourages large weights, much like a zero mean gaussian prior. &lt;code&gt;WEIGHT-DECAY&lt;/code&gt; * WEIGHT is added to the gradient to penalize large weights. It&#39;s as if the function whose minimum is sought had WEIGHT-DECAY*sum_i{0.5 * WEIGHT_i^2} added to it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AWEIGHT-PENALTY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;WEIGHT-PENALTY&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:WEIGHT-PENALTY = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An L1 penalty. It encourages sparsity. &lt;code&gt;SIGN&lt;/code&gt;(WEIGHT) * &lt;code&gt;WEIGHT-PENALTY&lt;/code&gt; is added to the gradient pushing the weight towards negative infinity. It&#39;s as if the function whose minima is sought had WEIGHT-PENALTY*sum_i{abs(WEIGHT_i)} added to it. Putting it on feature biases consitutes a sparsity constraint on the features.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AUSE-SEGMENT-DERIVATIVES-P-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;USE-SEGMENT-DERIVATIVES-P&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:USE-SEGMENT-DERIVATIVES-P = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Save memory if both the gradient source (the model being optimized) and the optimizer support this feature. It works like this: the accumulator into which the gradient source is asked to place the derivatives of a segment will be &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ASEGMENT-DERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:SEGMENT-DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SEGMENT-DERIVATIVES&lt;/code&gt;&lt;/a&gt; of the segment. This allows the optimizer not to allocate an accumulator matrix into which the derivatives are summed.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;AFTER-UPDATE-HOOK&lt;/strong&gt; &lt;em&gt;GD-OPTIMIZER (:AFTER-UPDATE-HOOK = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A list of functions with no arguments called after each weight update.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ABEFORE-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3ABATCH-GD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;BEFORE-UPDATE-HOOK&lt;/strong&gt; &lt;em&gt;BATCH-GD-OPTIMIZER (:BEFORE-UPDATE-HOOK = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A list of functions of no parameters. Each function is called just before a weight update takes place (after accumulated gradients have been divided the length of the batch). Convenient to hang some additional gradient accumulating code on.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-SGD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;SGD Optimizer&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ASGD-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;SGD-OPTIMIZER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:BATCH-GD-OPTIMIZER CLASS&#34;&gt;BATCH-GD-OPTIMIZER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;With &lt;code&gt;BATCH-SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;2&lt;/code&gt;&lt;/a&gt;) 1 this is Stochastic Gradient Descent. With higher batch sizes, one gets mini-batch and Batch Gradient Descent.&lt;/p&gt; &lt;p&gt;Assuming that &lt;code&gt;ACCUMULATOR&lt;/code&gt; has the sum of gradients for a mini-batch, the weight update looks like this:&lt;/p&gt; &lt;p&gt;$$ \Delta_w^{t+1} = momentum * \Delta_w^t + \frac{accumulator}{batchsize} + l_2 w + l_1 sign(w) $$&lt;/p&gt; &lt;p&gt;$$ w^{t+1} = w^{t} - learningrate * \Delta_w, $$&lt;/p&gt; &lt;p&gt;which is the same as the more traditional formulation:&lt;/p&gt; &lt;p&gt;$$ \Delta_w^{t+1} = momentum * \Delta_w^{t} + learningrate * \left(\frac{\frac{df}{dw}}{batchsize} + l_2 w + l_1 sign(w)\right) $$&lt;/p&gt; &lt;p&gt;$$ w^{t+1} = w^{t} - \Delta_w, $$&lt;/p&gt; &lt;p&gt;but the former works better when batch size, momentum or learning rate change during the course of optimization. The above is with normal momentum, Nesterov&#39;s momentum (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AMOMENTUM-TYPE-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:MOMENTUM-TYPE (MGL-PAX:READER MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;MOMENTUM-TYPE&lt;/code&gt;&lt;/a&gt;) momentum is also available.&lt;/p&gt; &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Batch Based Optimizers&#34;&gt;Batch Based Optimizers&lt;/a&gt; for the description of the various options common to all batch based optimizers.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Adam Optimizer&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AADAM-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;ADAM-OPTIMIZER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:BATCH-GD-OPTIMIZER CLASS&#34;&gt;BATCH-GD-OPTIMIZER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Adam is a first-order stochasistic gradient descent optimizer. It maintains an internal estimation for the mean and raw variance of each derivative as exponential moving averages. The step it takes is basically &lt;code&gt;M/(sqrt(V)+E)&lt;/code&gt; where &lt;code&gt;M&lt;/code&gt; is the estimated mean, &lt;code&gt;V&lt;/code&gt; is the estimated variance, and &lt;code&gt;E&lt;/code&gt; is a small adjustment factor to prevent the gradient from blowing up. See version 5 of the &lt;a href=&#34;http://arxiv.org/abs/1412.6980&#34;&gt;paper&lt;/a&gt; for more.&lt;/p&gt; &lt;p&gt;Note that using momentum is not supported with Adam. In fact, an error is signalled if it&#39;s not &lt;code&gt;:NONE&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Batch Based Optimizers&#34;&gt;Batch Based Optimizers&lt;/a&gt; for the description of the various options common to all batch based optimizers.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;LEARNING-RATE&lt;/strong&gt; &lt;em&gt;ADAM-OPTIMIZER (= 2.0e-4)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Same thing as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:LEARNING-RATE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;LEARNING-RATE&lt;/code&gt;&lt;/a&gt; but with the default suggested by the Adam paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AMEAN-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;MEAN-DECAY&lt;/strong&gt; &lt;em&gt;ADAM-OPTIMIZER (:MEAN-DECAY = 0.9)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A number between 0 and 1 that determines how fast the estimated mean of derivatives is updated. 0 basically gives you &lt;code&gt;RMSPROP&lt;/code&gt; (if &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AVARIANCE-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:VARIANCE-DECAY (MGL-PAX:ACCESSOR MGL-GD:ADAM-OPTIMIZER)&#34;&gt;&lt;code&gt;VARIANCE-DECAY&lt;/code&gt;&lt;/a&gt; is not too large) or AdaGrad (if &lt;code&gt;VARIANCE-DECAY&lt;/code&gt; is close to 1 and the learning rate is annealed. This is $\beta_1$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AMEAN-DECAY-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;MEAN-DECAY-DECAY&lt;/strong&gt; &lt;em&gt;ADAM-OPTIMIZER (:MEAN-DECAY-DECAY = (- 1 1.0d-7))&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A value that should be close to 1. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AMEAN-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:MEAN-DECAY (MGL-PAX:ACCESSOR MGL-GD:ADAM-OPTIMIZER)&#34;&gt;&lt;code&gt;MEAN-DECAY&lt;/code&gt;&lt;/a&gt; is multiplied by this value after each update. This is $\lambda$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AVARIANCE-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;VARIANCE-DECAY&lt;/strong&gt; &lt;em&gt;ADAM-OPTIMIZER (:VARIANCE-DECAY = 0.999)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A number between 0 and 1 that determines how fast the estimated variance of derivatives is updated. This is $\beta_2$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AVARIANCE-ADJUSTMENT-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;VARIANCE-ADJUSTMENT&lt;/strong&gt; &lt;em&gt;ADAM-OPTIMIZER (:VARIANCE-ADJUSTMENT = 1.0d-7)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Within the bowels of adam, the estimated mean is divided by the square root of the estimated variance (per weight) which can lead to numerical problems if the denominator is near zero. To avoid this, &lt;code&gt;VARIANCE-ADJUSTMENT&lt;/code&gt;, which should be a small positive number, is added to the denominator. This is &lt;code&gt;epsilon&lt;/code&gt; in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-NORMALIZED-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Normalized Batch Optimizer&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;NORMALIZED-BATCH-GD-OPTIMIZER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:BATCH-GD-OPTIMIZER CLASS&#34;&gt;BATCH-GD-OPTIMIZER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt; but keeps count of how many times each weight was used in the batch and divides the accumulated gradient by this count instead of dividing by &lt;code&gt;N-INSTANCES-IN-BATCH&lt;/code&gt;. This only makes a difference if there are missing values in the learner that&#39;s being trained. The main feature that distuinguishes this class from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;PER-WEIGHT-BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt; is that batches end at same time for all weights.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AN-WEIGHT-USES-IN-BATCH-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;N-WEIGHT-USES-IN-BATCH&lt;/strong&gt; &lt;em&gt;NORMALIZED-BATCH-GD-OPTIMIZER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Number of uses of the weight in its current batch.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.3.2 Segmented GD Optimizer&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ASEGMENTED-GD-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;SEGMENTED-GD-OPTIMIZER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;An optimizer that delegates training of segments to other optimizers. Useful to delegate training of different segments to different optimizers (capable of working with segmentables) or simply to not train all segments.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ASEGMENTER-20-28MGL-PAX-3AREADER-20MGL-GD-3ASEGMENTED-GD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SEGMENTER&lt;/strong&gt; &lt;em&gt;SEGMENTED-GD-OPTIMIZER (:SEGMENTER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;When this optimizer is initialized it loops over the segment of the learner with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MAP-SEGMENTS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-SEGMENTS&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;SEGMENTER&lt;/code&gt; is a function that is called with each segment and returns an optimizer or &lt;code&gt;NIL&lt;/code&gt;. Several segments may be mapped to the same optimizer. After the segment-&amp;gt;optimizer mappings are collected, each optimizer is initialized by INITIALIZE-OPTIMIZER with the list of segments mapped to it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENTS-20-28MGL-PAX-3AREADER-20MGL-GD-3ASEGMENTED-GD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;SEGMENTS&lt;/strong&gt; &lt;em&gt;SEGMENTED-GD-OPTIMIZER&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ASEGMENTED-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:SEGMENTED-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;SEGMENTED-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt; inherits from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;ITERATIVE-OPTIMIZER&lt;/code&gt;&lt;/a&gt;, so see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Iterative Optimizer&#34;&gt;Iterative Optimizer&lt;/a&gt; too.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.3.3 Per-weight Optimization&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;PER-WEIGHT-BATCH-GD-OPTIMIZER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This is much like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34; title=&#34;Batch Based Optimizers&#34;&gt;Batch Based Optimizers&lt;/a&gt; but it is more clever about when to update weights. Basically every weight has its own batch independent from the batches of others. This has desirable properties. One can for example put two neural networks together without adding any connections between them and the learning will produce results equivalent to the separated case. Also, adding inputs with only missing values does not change anything.&lt;/p&gt; &lt;p&gt;Due to its very non-batch nature, there is no CUDA implementation of this optimizer.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AN-WEIGHT-USES-IN-BATCH-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;N-WEIGHT-USES-IN-BATCH&lt;/strong&gt; &lt;em&gt;PER-WEIGHT-BATCH-GD-OPTIMIZER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Number of uses of the weight in its current batch.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.3.4 Utilities&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3ACLIP-L2-NORM-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CLIP-L2-NORM&lt;/strong&gt; &lt;em&gt;MATS L2-UPPER-BOUND &amp;amp;KEY CALLBACK&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Scale &lt;code&gt;MATS&lt;/code&gt; so that their $L_2$ norm does not exceed &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Compute the norm of of &lt;code&gt;MATS&lt;/code&gt; as if they were a single vector. If the norm is greater than &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt;, then scale each matrix destructively by the norm divided by &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt; and if non-NIL call the function &lt;code&gt;CALLBACK&lt;/code&gt; with the scaling factor.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AARRANGE-FOR-CLIPPING-GRADIENTS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ARRANGE-FOR-CLIPPING-GRADIENTS&lt;/strong&gt; &lt;em&gt;BATCH-GD-OPTIMIZER L2-UPPER-BOUND &amp;amp;KEY CALLBACK&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Make it so that the norm of the batch normalized gradients accumulated by &lt;code&gt;BATCH-GD-OPTIMIZER&lt;/code&gt; is clipped to &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt; before every update. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ACLIP-L2-NORM-20FUNCTION-29&#34; title=&#34;MGL-GD:CLIP-L2-NORM FUNCTION&#34;&gt;&lt;code&gt;CLIP-L2-NORM&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;9.4 Conjugate Gradient&lt;/h3&gt; &#xA;&lt;h6&gt;[in package MGL-CG]&lt;/h6&gt; &#xA;&lt;p&gt;Conjugate gradient is a first-order optimization algorithm. It&#39;s more advanced than gradient descent as it does line searches which unfortunately also makes it unsuitable for non-deterministic functions. Let&#39;s see how to minimize a numerical lisp function with respect to some of its parameters.&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code&gt;;;; Create an object representing the sine function.&#xA;(defparameter *diff-fn-1*&#xA;  (make-instance &#39;mgl-diffun:diffun&#xA;                 :fn #&#39;sin&#xA;                 ;; We are going to optimize its only parameter.&#xA;                 :weight-indices &#39;(0)))&#xA;&#xA;;;; Minimize SIN. Note that there is no dataset involved because all&#xA;;;; parameters are being optimized.&#xA;(minimize (make-instance &#39;cg-optimizer&#xA;                         :batch-size 1&#xA;                         :termination 1)&#xA;          *diff-fn-1*&#xA;          :weights (make-mat 1))&#xA;;;; =&amp;gt; A MAT with a single value of about -pi/2.&#xA;&#xA;;;; Create a differentiable function for f(x,y)=(x-y)^2. X is a&#xA;;;; parameter whose values come from the DATASET argument passed to&#xA;;;; MINIMIZE. Y is a parameter to be optimized (a &#39;weight&#39;).&#xA;(defparameter *diff-fn-2*&#xA;  (make-instance &#39;mgl-diffun:diffun&#xA;                 :fn (lambda (x y)&#xA;                       (expt (- x y) 2))&#xA;                 :parameter-indices &#39;(0)&#xA;                 :weight-indices &#39;(1)))&#xA;&#xA;;;; Find the Y that minimizes the distance from the instances&#xA;;;; generated by the sampler.&#xA;(minimize (make-instance &#39;cg-optimizer :batch-size 10)&#xA;          *diff-fn-2*&#xA;          :weights (make-mat 1)&#xA;          :dataset (make-instance &#39;function-sampler&#xA;                                  :generator (lambda ()&#xA;                                               (list (+ 10&#xA;                                                        (gaussian-random-1))))&#xA;                                  :max-n-samples 1000))&#xA;;;; =&amp;gt; A MAT with a single value of about 10, the expected value of&#xA;;;; the instances in the dataset.&#xA;&#xA;;;; The dataset can be a SEQUENCE in which case we&#39;d better set&#xA;;;; TERMINATION else optimization would never finish. Note how a&#xA;;;; single epoch suffices.&#xA;(minimize (make-instance &#39;cg-optimizer :termination 6)&#xA;          *diff-fn-2*&#xA;          :weights (make-mat 1)&#xA;          :dataset &#39;((0) (1) (2) (3) (4) (5)))&#xA;;;; =&amp;gt; A MAT with a single value of about 2.5.&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3ACG-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;CG&lt;/strong&gt; &lt;em&gt;FN W &amp;amp;KEY (MAX-N-LINE-SEARCHES *DEFAULT-MAX-N-LINE-SEARCHES*) (MAX-N-EVALUATIONS-PER-LINE-SEARCH *DEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH*) (MAX-N-EVALUATIONS *DEFAULT-MAX-N-EVALUATIONS*) (SIG *DEFAULT-SIG*) (RHO *DEFAULT-RHO*) (INT *DEFAULT-INT*) (EXT *DEFAULT-EXT*) (RATIO *DEFAULT-RATIO*) SPARE-VECTORS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3ACG-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-CG:CG-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;CG-OPTIMIZER&lt;/code&gt;&lt;/a&gt; passes each batch of data to this function with its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3ACG-ARGS-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-CG:CG-ARGS (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;CG-ARGS&lt;/code&gt;&lt;/a&gt; passed on.&lt;/p&gt; &lt;p&gt;Minimize a differentiable multivariate function with conjugate gradient. The Polak-Ribiere flavour of conjugate gradients is used to compute search directions, and a line search using quadratic and cubic polynomial approximations and the Wolfe-Powell stopping criteria is used together with the slope ratio method for guessing initial step sizes. Additionally a bunch of checks are made to make sure that exploration is taking place and that extrapolation will not be unboundedly large.&lt;/p&gt; &lt;p&gt;&lt;code&gt;FN&lt;/code&gt; is a function of two parameters: &lt;code&gt;WEIGHTS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) and &lt;code&gt;DERIVATIVES&lt;/code&gt;. &lt;code&gt;WEIGHTS&lt;/code&gt; is a &lt;code&gt;MAT&lt;/code&gt; of the same size as &lt;code&gt;W&lt;/code&gt; that is where the search start from. &lt;code&gt;DERIVATIVES&lt;/code&gt; is also a &lt;code&gt;MAT&lt;/code&gt; of that size and it is where &lt;code&gt;FN&lt;/code&gt; shall place the partial derivatives. &lt;code&gt;FN&lt;/code&gt; returns the value of the function that is being minimized.&lt;/p&gt; &lt;p&gt;&lt;code&gt;CG&lt;/code&gt; performs a number of line searches and invokes &lt;code&gt;FN&lt;/code&gt; at each step. A line search invokes &lt;code&gt;FN&lt;/code&gt; at most &lt;code&gt;MAX-N-EVALUATIONS-PER-LINE-SEARCH&lt;/code&gt; number of times and can succeed in improving the minimum by the sufficient margin or it can fail. Note, the even a failed line search may improve further and hence change the weights it&#39;s just that the improvement was deemed too small. &lt;code&gt;CG&lt;/code&gt; stops when either:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;two line searches fail in a row&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;MAX-N-LINE-SEARCHES&lt;/code&gt; is reached&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;&lt;code&gt;MAX-N-EVALUATIONS&lt;/code&gt; is reached&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;p&gt;&lt;code&gt;CG&lt;/code&gt; returns a &lt;code&gt;MAT&lt;/code&gt; that contains the best weights, the minimum, the number of line searches performed, the number of succesful line searches and the number of evaluations.&lt;/p&gt; &lt;p&gt;When using &lt;code&gt;MAX-N-EVALUATIONS&lt;/code&gt; remember that there is an extra evaluation of &lt;code&gt;FN&lt;/code&gt; before the first line search.&lt;/p&gt; &lt;p&gt;&lt;code&gt;SPARE-VECTORS&lt;/code&gt; is a list of preallocated &lt;code&gt;MAT&lt;/code&gt;s of the same size as &lt;code&gt;W&lt;/code&gt;. Passing 6 of them covers the current need of the algorithm and it will not cons up vectors of size &lt;code&gt;W&lt;/code&gt; at all.&lt;/p&gt; &lt;p&gt;NOTE: If the function terminates within a few iterations, it could be an indication that the function values and derivatives are not consistent (ie, there may be a bug in the implementation of &lt;code&gt;FN&lt;/code&gt; function).&lt;/p&gt; &lt;p&gt;&lt;code&gt;SIG&lt;/code&gt; and &lt;code&gt;RHO&lt;/code&gt; are the constants controlling the Wolfe-Powell conditions. &lt;code&gt;SIG&lt;/code&gt; is the maximum allowed absolute ratio between previous and new slopes (derivatives in the search direction), thus setting &lt;code&gt;SIG&lt;/code&gt; to low (positive) values forces higher precision in the line-searches. &lt;code&gt;RHO&lt;/code&gt; is the minimum allowed fraction of the expected (from the slope at the initial point in the linesearch). Constants must satisfy 0 &amp;lt; &lt;code&gt;RHO&lt;/code&gt; &amp;lt; &lt;code&gt;SIG&lt;/code&gt; &amp;lt; 1. Tuning of &lt;code&gt;SIG&lt;/code&gt; (depending on the nature of the function to be optimized) may speed up the minimization; it is probably not worth playing much with &lt;code&gt;RHO&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-INT-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*DEFAULT-INT*&lt;/strong&gt; &lt;em&gt;0.1&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Don&#39;t reevaluate within &lt;code&gt;INT&lt;/code&gt; of the limit of the current bracket.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-EXT-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*DEFAULT-EXT*&lt;/strong&gt; &lt;em&gt;3&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Extrapolate maximum &lt;code&gt;EXT&lt;/code&gt; times the current step-size.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-SIG-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*DEFAULT-SIG*&lt;/strong&gt; &lt;em&gt;0.1&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;SIG&lt;/code&gt; and &lt;code&gt;RHO&lt;/code&gt; are the constants controlling the Wolfe-Powell conditions. &lt;code&gt;SIG&lt;/code&gt; is the maximum allowed absolute ratio between previous and new slopes (derivatives in the search direction), thus setting &lt;code&gt;SIG&lt;/code&gt; to low (positive) values forces higher precision in the line-searches.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-RHO-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*DEFAULT-RHO*&lt;/strong&gt; &lt;em&gt;0.05&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;RHO&lt;/code&gt; is the minimum allowed fraction of the expected (from the slope at the initial point in the linesearch). Constants must satisfy 0 &amp;lt; &lt;code&gt;RHO&lt;/code&gt; &amp;lt; &lt;code&gt;SIG&lt;/code&gt; &amp;lt; 1.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-RATIO-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*DEFAULT-RATIO*&lt;/strong&gt; &lt;em&gt;10&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Maximum allowed slope ratio.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-MAX-N-LINE-SEARCHES-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[variable] &lt;strong&gt;*DEFAULT-MAX-N-LINE-SEARCHES*&lt;/strong&gt; &lt;em&gt;NIL&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[variable] &lt;strong&gt;*DEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH*&lt;/strong&gt; &lt;em&gt;20&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3A-2ADEFAULT-MAX-N-EVALUATIONS-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[variable] &lt;strong&gt;*DEFAULT-MAX-N-EVALUATIONS*&lt;/strong&gt; &lt;em&gt;NIL&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3ACG-OPTIMIZER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CG-OPTIMIZER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;ITERATIVE-OPTIMIZER&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Updates all weights simultaneously after chewing through &lt;code&gt;BATCH-SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;2&lt;/code&gt;&lt;/a&gt;) inputs.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;BATCH-SIZE&lt;/strong&gt; &lt;em&gt;CG-OPTIMIZER (:BATCH-SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;After having gone through &lt;code&gt;BATCH-SIZE&lt;/code&gt; number of instances, weights are updated. Normally, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3ACG-20FUNCTION-29&#34; title=&#34;MGL-CG:CG FUNCTION&#34;&gt;&lt;code&gt;CG&lt;/code&gt;&lt;/a&gt; operates on all available data, but it may be useful to introduce some noise into the optimization to reduce overfitting by using smaller batch sizes. If &lt;code&gt;BATCH-SIZE&lt;/code&gt; is not set, it is initialized to the size of the dataset at the start of optimization.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3ACG-ARGS-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[accessor] &lt;strong&gt;CG-ARGS&lt;/strong&gt; &lt;em&gt;CG-OPTIMIZER (:CG-ARGS = &#39;NIL)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3AON-CG-BATCH-DONE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;ON-CG-BATCH-DONE&lt;/strong&gt; &lt;em&gt;CG-OPTIMIZER (:ON-CG-BATCH-DONE = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An event hook called when processing a conjugate gradient batch is done. The handlers on the hook are called with 8 arguments:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (optimizer gradient-source instances&#xA;   best-w best-f n-line-searches&#xA;   n-succesful-line-searches n-evaluations)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The latter 5 of which are the return values of the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3ACG-20FUNCTION-29&#34; title=&#34;MGL-CG:CG FUNCTION&#34;&gt;&lt;code&gt;CG&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3ALOG-CG-BATCH-DONE-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;LOG-CG-BATCH-DONE&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE INSTANCES BEST-W BEST-F N-LINE-SEARCHES N-SUCCESFUL-LINE-SEARCHES N-EVALUATIONS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is a function can be added to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3AON-CG-BATCH-DONE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-CG:ON-CG-BATCH-DONE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-CG-BATCH-DONE&lt;/code&gt;&lt;/a&gt;. The default implementation simply logs the event arguments.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CG-3ASEGMENT-FILTER-20-28MGL-PAX-3AREADER-20MGL-CG-3ACG-OPTIMIZER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SEGMENT-FILTER&lt;/strong&gt; &lt;em&gt;CG-OPTIMIZER (:SEGMENT-FILTER = (CONSTANTLY T))&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A predicate function on segments that filters out uninteresting segments. Called from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:INITIALIZE-OPTIMIZER* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;INITIALIZE-OPTIMIZER*&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;9.5 Extension API&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.5.1 Implementing Optimizers&lt;/h4&gt; &#xA;&lt;p&gt;The following generic functions must be specialized for new optimizer types.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMINIMIZE-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MINIMIZE*&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Called by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt; after &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:INITIALIZE-OPTIMIZER* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;INITIALIZE-OPTIMIZER*&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:INITIALIZE-GRADIENT-SOURCE* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;INITIALIZE-GRADIENT-SOURCE*&lt;/code&gt;&lt;/a&gt;, this generic function is the main extension point for writing optimizers.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;INITIALIZE-OPTIMIZER*&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Called automatically before training starts, this function sets up &lt;code&gt;OPTIMIZER&lt;/code&gt; to be suitable for optimizing &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt;. It typically creates appropriately sized accumulators for the gradients.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SEGMENTS&lt;/strong&gt; &lt;em&gt;OPTIMIZER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Several weight matrices known as &lt;em&gt;segments&lt;/em&gt; can be optimized by a single optimizer. This function returns them as a list.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;The rest are just useful for utilities for implementing optimizers.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ATERMINATE-OPTIMIZATION-P-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;TERMINATE-OPTIMIZATION-P&lt;/strong&gt; &lt;em&gt;N-INSTANCES TERMINATION&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Utility function for subclasses of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;ITERATIVE-OPTIMIZER&lt;/code&gt;&lt;/a&gt;. It returns whether optimization is to be terminated based on &lt;code&gt;N-INSTANCES&lt;/code&gt; and &lt;code&gt;TERMINATION&lt;/code&gt; that are values of the respective accessors of &lt;code&gt;ITERATIVE-OPTIMIZER&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASET-N-INSTANCES-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SET-N-INSTANCES&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE N-INSTANCES&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Set &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;N-INSTANCES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;OPTIMIZER&lt;/code&gt; and fire &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;ON-N-INSTANCES-CHANGED&lt;/code&gt;&lt;/a&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-OPT:ITERATIVE-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;ITERATIVE-OPTIMIZER&lt;/code&gt;&lt;/a&gt; subclasses must call this to increment &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29&#34; title=&#34;MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER)&#34;&gt;&lt;code&gt;N-INSTANCES&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-SET-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;SEGMENT-SET&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This is a utility class for optimizers that have a list of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:SEGMENTS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SEGMENTS&lt;/code&gt;&lt;/a&gt; and (the weights being optimized) is able to copy back and forth between those segments and a single &lt;code&gt;MAT&lt;/code&gt; (the accumulator).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENTS-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SEGMENTS&lt;/strong&gt; &lt;em&gt;SEGMENT-SET (:SEGMENTS)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A list of weight matrices.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SIZE&lt;/strong&gt; &lt;em&gt;SEGMENT-SET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The sum of the sizes of the weight matrices of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:SEGMENTS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SEGMENTS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ADO-SEGMENT-SET-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;DO-SEGMENT-SET&lt;/strong&gt; &lt;em&gt;(SEGMENT &amp;amp;OPTIONAL START) SEGMENT-SET &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Iterate over &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:SEGMENTS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SEGMENTS&lt;/code&gt;&lt;/a&gt; in &lt;code&gt;SEGMENT-SET&lt;/code&gt;. If &lt;code&gt;START&lt;/code&gt; is specified, the it is bound to the start index of &lt;code&gt;SEGMENT&lt;/code&gt; within &lt;code&gt;SEGMENT-SET&lt;/code&gt;. The start index is the sum of the sizes of previous segments.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-SET-3C-MAT-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SEGMENT-SET&amp;lt;-MAT&lt;/strong&gt; &lt;em&gt;SEGMENT-SET MAT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Copy the values of &lt;code&gt;MAT&lt;/code&gt; to the weight matrices of &lt;code&gt;SEGMENT-SET&lt;/code&gt; as if they were concatenated into a single &lt;code&gt;MAT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-SET--3EMAT-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;SEGMENT-SET-&amp;gt;MAT&lt;/strong&gt; &lt;em&gt;SEGMENT-SET MAT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Copy the values of &lt;code&gt;SEGMENT-SET&lt;/code&gt; to &lt;code&gt;MAT&lt;/code&gt; as if they were concatenated into a single &lt;code&gt;MAT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.5.2 Implementing Gradient Sources&lt;/h4&gt; &#xA;&lt;p&gt;Weights can be stored in a multitude of ways. Optimizers need to update weights, so it is assumed that weights are stored in any number of &lt;code&gt;MAT&lt;/code&gt; objects called segments.&lt;/p&gt; &#xA;&lt;p&gt;The generic functions in this section must all be specialized for new gradient sources except where noted.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAP-SEGMENTS&lt;/strong&gt; &lt;em&gt;FN GRADIENT-SOURCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Apply &lt;code&gt;FN&lt;/code&gt; to each segment of &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMAP-SEGMENT-RUNS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAP-SEGMENT-RUNS&lt;/strong&gt; &lt;em&gt;FN SEGMENT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; with start and end of intervals of consecutive indices that are not missing in &lt;code&gt;SEGMENT&lt;/code&gt;. Called by optimizers that support partial updates. The default implementation assumes that all weights are present. This only needs to be specialized if one plans to use an optimizer that knows how to deal unused/missing weights such as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:NORMALIZED-BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;MGL-GD:NORMALIZED-BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;OPTIMIZER&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29&#34; title=&#34;MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS&#34;&gt;&lt;code&gt;MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-WEIGHTS-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SEGMENT-WEIGHTS&lt;/strong&gt; &lt;em&gt;SEGMENT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the weight matrix of &lt;code&gt;SEGMENT&lt;/code&gt;. A segment doesn&#39;t need to be a &lt;code&gt;MAT&lt;/code&gt; object itself. For example, it may be a &lt;code&gt;MGL-BM:CHUNK&lt;/code&gt; of a &lt;code&gt;MGL-BM:BM&lt;/code&gt; or a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;MGL-BP:LUMP&lt;/code&gt;&lt;/a&gt; of a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;MGL-BP:BPN&lt;/code&gt;&lt;/a&gt; whose &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; slot holds the weights.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-WEIGHTS-20-28METHOD-20NIL-20-28MGL-MAT-3AMAT-29-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[method] &lt;strong&gt;SEGMENT-WEIGHTS&lt;/strong&gt; &lt;em&gt;(MAT MAT)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;When the segment is really a &lt;code&gt;MAT&lt;/code&gt;, then just return it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ASEGMENT-DERIVATIVES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;SEGMENT-DERIVATIVES&lt;/strong&gt; &lt;em&gt;SEGMENT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the derivatives matrix of &lt;code&gt;SEGMENT&lt;/code&gt;. A segment doesn&#39;t need to be a &lt;code&gt;MAT&lt;/code&gt; object itself. For example, it may be a &lt;code&gt;MGL-BM:CHUNK&lt;/code&gt; of a &lt;code&gt;MGL-BM:BM&lt;/code&gt; or a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;MGL-BP:LUMP&lt;/code&gt;&lt;/a&gt; of a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;MGL-BP:BPN&lt;/code&gt;&lt;/a&gt; whose DERIVATIVES slot holds the gradient.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ALIST-SEGMENTS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;LIST-SEGMENTS&lt;/strong&gt; &lt;em&gt;GRADIENT-SOURCE&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A utility function that returns the list of segments from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MAP-SEGMENTS GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-SEGMENTS&lt;/code&gt;&lt;/a&gt; on &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;INITIALIZE-GRADIENT-SOURCE*&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Called automatically before &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE*&lt;/code&gt;&lt;/a&gt; is called, this function may be specialized if &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; needs some kind of setup.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20-28METHOD-20NIL-20-28T-20T-20T-20T-29-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[method] &lt;strong&gt;INITIALIZE-GRADIENT-SOURCE*&lt;/strong&gt; &lt;em&gt;OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The default method does nothing.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AACCUMULATE-GRADIENTS-2A-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;ACCUMULATE-GRADIENTS*&lt;/strong&gt; &lt;em&gt;GRADIENT-SOURCE SINK BATCH MULTIPLIER VALUEP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Add &lt;code&gt;MULTIPLIER&lt;/code&gt; times the sum of first-order gradients to accumulators of &lt;code&gt;SINK&lt;/code&gt; (normally accessed with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ADO-GRADIENT-SINK-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-OPT:DO-GRADIENT-SINK MGL-PAX:MACRO&#34;&gt;&lt;code&gt;DO-GRADIENT-SINK&lt;/code&gt;&lt;/a&gt;) and if &lt;code&gt;VALUEP&lt;/code&gt;, return the sum of values of the function being optimized for a &lt;code&gt;BATCH&lt;/code&gt; of instances. &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; is the object representing the function being optimized, &lt;code&gt;SINK&lt;/code&gt; is gradient sink.&lt;/p&gt; &lt;p&gt;Note the number of instances in &lt;code&gt;BATCH&lt;/code&gt; may be larger than what &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; process in one go (in the sense of say, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt;), so &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-CORE:DO-BATCHES-FOR-MODEL MGL-PAX:MACRO&#34;&gt;&lt;code&gt;DO-BATCHES-FOR-MODEL&lt;/code&gt;&lt;/a&gt; or something like (&lt;code&gt;GROUP&lt;/code&gt; &lt;code&gt;BATCH&lt;/code&gt; &lt;code&gt;MAX-N-STRIPES&lt;/code&gt;) can be handy.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;9.5.3 Implementing Gradient Sinks&lt;/h4&gt; &#xA;&lt;p&gt;Optimizers call &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AACCUMULATE-GRADIENTS-2A-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:ACCUMULATE-GRADIENTS* GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ACCUMULATE-GRADIENTS*&lt;/code&gt;&lt;/a&gt; on gradient sources. One parameter of &lt;code&gt;ACCUMULATE-GRADIENTS*&lt;/code&gt; is the &lt;code&gt;SINK&lt;/code&gt;. A gradient sink knows what accumulator matrix (if any) belongs to a segment. Sinks are defined entirely by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MAP-GRADIENT-SINK GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-GRADIENT-SINK&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAP-GRADIENT-SINK&lt;/strong&gt; &lt;em&gt;FN SINK&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Call &lt;code&gt;FN&lt;/code&gt; of lambda list (&lt;code&gt;SEGMENT&lt;/code&gt; &lt;code&gt;ACCUMULATOR&lt;/code&gt;) on each segment and their corresponding accumulator &lt;code&gt;MAT&lt;/code&gt; in &lt;code&gt;SINK&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-OPT-3ADO-GRADIENT-SINK-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;DO-GRADIENT-SINK&lt;/strong&gt; &lt;em&gt;((SEGMENT ACCUMULATOR) SINK) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A convenience macro on top of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-OPT:MAP-GRADIENT-SINK GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAP-GRADIENT-SINK&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;10 Differentiable Functions&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-DIFFUN]&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DIFFUN-3ADIFFUN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;DIFFUN&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;DIFFUN&lt;/code&gt; dresses a lisp function (in its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AFN-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29&#34; title=&#34;MGL-COMMON:FN (MGL-PAX:READER MGL-DIFFUN:DIFFUN)&#34;&gt;&lt;code&gt;FN&lt;/code&gt;&lt;/a&gt; slot) as a gradient source (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29&#34; title=&#34;Implementing Gradient Sources&#34;&gt;Implementing Gradient Sources&lt;/a&gt;), which allows it to be used in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt;. See the examples in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Descent&#34;&gt;Gradient Descent&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29&#34; title=&#34;Conjugate Gradient&#34;&gt;Conjugate Gradient&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AFN-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;FN&lt;/strong&gt; &lt;em&gt;DIFFUN (:FN)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A real valued lisp function. It may have any number of parameters.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DIFFUN-3APARAMETER-INDICES-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;PARAMETER-INDICES&lt;/strong&gt; &lt;em&gt;DIFFUN (:PARAMETER-INDICES = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The list of indices of parameters that we don&#39;t optimize. Values for these will come from the DATASET argument of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-DIFFUN-3AWEIGHT-INDICES-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;WEIGHT-INDICES&lt;/strong&gt; &lt;em&gt;DIFFUN (:WEIGHT-INDICES = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The list of indices of parameters to be optimized, the values of which will come from the &lt;code&gt;WEIGHTS&lt;/code&gt; argument of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;11 Backpropagation Neural Networks&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-BP]&lt;/h6&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;11.1 Backprop Overview&lt;/h3&gt; &#xA;&lt;p&gt;Backpropagation Neural Networks are just functions with lots of parameters called &lt;em&gt;weights&lt;/em&gt; and a layered structure when presented as a &lt;a href=&#34;http://en.wikipedia.org/wiki/Automatic_differentiation&#34;&gt;computational graph&lt;/a&gt;. The network is trained to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt; some kind of &lt;em&gt;loss function&lt;/em&gt; whose value the network computes.&lt;/p&gt; &#xA;&lt;p&gt;In this implementation, a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; is assembled from several &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;LUMP&lt;/code&gt;&lt;/a&gt;s (roughly corresponding to layers). Both feed-forward and recurrent neural nets are supported (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;, respectively). &lt;code&gt;BPN&lt;/code&gt;s can contain not only &lt;code&gt;LUMP&lt;/code&gt;s but other &lt;code&gt;BPN&lt;/code&gt;s, too. As we see, networks are composite objects and the abstract base class for composite and simple parts is called &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ACLUMP-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;CLUMP&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;A &lt;code&gt;CLUMP&lt;/code&gt; is a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;LUMP&lt;/code&gt;&lt;/a&gt; or a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;. It represents a differentiable function. Arguments of clumps are given during instantiation. Some arguments are clumps themselves so they get permenantly wired together like this:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;v*m (-&amp;gt;input :size 10 :name &#39;input)&#xA;       (-&amp;gt;weight :dimensions &#39;(10 20) :name &#39;weight)&#xA;       :name &#39;activation)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The above creates three clumps: the vector-matrix multiplication clumps called &lt;code&gt;ACTIVATION&lt;/code&gt; which has a reference to its operands: &lt;code&gt;INPUT&lt;/code&gt; and &lt;code&gt;WEIGHT&lt;/code&gt;. Note that the example just defines a function, no actual computation has taken place, yet.&lt;/p&gt; &lt;p&gt;This wiring of &lt;code&gt;CLUMP&lt;/code&gt;s is how one builds feed-forward nets (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt;) or recurrent neural networks (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;) that are &lt;code&gt;CLUMP&lt;/code&gt;s themselves so one can build nets in a hiearchical style if desired. Non-composite &lt;code&gt;CLUMP&lt;/code&gt;s are called &lt;code&gt;LUMP&lt;/code&gt; (note the loss of &lt;code&gt;C&lt;/code&gt; that stands for composite). The various &lt;code&gt;LUMP&lt;/code&gt; subtypes correspond to different layer types (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;SIGMOID CLASS&#34;&gt;&lt;code&gt;-&amp;gt;SIGMOID&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EDROPOUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;DROPOUT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;DROPOUT&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ERELU-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;RELU CLASS&#34;&gt;&lt;code&gt;-&amp;gt;RELU&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ETANH-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;TANH CLASS&#34;&gt;&lt;code&gt;-&amp;gt;TANH&lt;/code&gt;&lt;/a&gt;, etc).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;At this point, you may want to jump ahead to get a feel for how things work by reading the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34; title=&#34;`FNN` Tutorial&#34;&gt;&lt;code&gt;FNN&lt;/code&gt; Tutorial&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;11.2 Clump API&lt;/h3&gt; &#xA;&lt;p&gt;These are mostly for extension purposes. About the only thing needed from here for normal operation is &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; when clamping inputs or extracting predictions.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASTRIPEDP-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;STRIPEDP&lt;/strong&gt; &lt;em&gt;CLUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;For efficiency, forward and backprop phases do their stuff in batch mode: passing a number of instances through the network in batches. Thus clumps must be able to store values of and gradients for each of these instances. However, some clumps produce the same result for each instance in a batch. These clumps are the weights, the parameters of the network. &lt;code&gt;STRIPEDP&lt;/code&gt; returns true iff &lt;code&gt;CLUMP&lt;/code&gt; does not represent weights (i.e. it&#39;s not a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;For striped clumps, their &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DERIVATIVES&lt;/code&gt;&lt;/a&gt; are &lt;code&gt;MAT&lt;/code&gt; objects with a leading dimension (number of rows in the 2d case) equal to the number of instances in the batch. Non-striped clumps have no restriction on their shape apart from what their usage dictates.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;NODES&lt;/strong&gt; &lt;em&gt;OBJECT&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Returns a &lt;code&gt;MAT&lt;/code&gt; object representing the state or result of &lt;code&gt;OBJECT&lt;/code&gt;. The first dimension of the returned matrix is equal to the number of stripes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt;s&#39; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; holds the result computed by the most recent &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:FORWARD GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FORWARD&lt;/code&gt;&lt;/a&gt;. For &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EINPUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;INPUT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;INPUT&lt;/code&gt;&lt;/a&gt; lumps, this is where input values shall be placed (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;). Currently, the matrix is always two dimensional but this restriction may go away in the future.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;DERIVATIVES&lt;/strong&gt; &lt;em&gt;CLUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the &lt;code&gt;MAT&lt;/code&gt; object representing the partial derivatives of the function &lt;code&gt;CLUMP&lt;/code&gt; computes. The returned partial derivatives were accumulated by previous &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:BACKWARD GENERIC-FUNCTION&#34;&gt;&lt;code&gt;BACKWARD&lt;/code&gt;&lt;/a&gt; calls.&lt;/p&gt; &lt;p&gt;This matrix is shaped like the matrix returned by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;FORWARD&lt;/strong&gt; &lt;em&gt;CLUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Compute the values of the function represented by &lt;code&gt;CLUMP&lt;/code&gt; for all stripes and place the results into &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;CLUMP&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;BACKWARD&lt;/strong&gt; &lt;em&gt;CLUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Compute the partial derivatives of the function represented by &lt;code&gt;CLUMP&lt;/code&gt; and add them to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DERIVATIVES&lt;/code&gt;&lt;/a&gt; of the corresponding argument clumps. The &lt;code&gt;DERIVATIVES&lt;/code&gt; of &lt;code&gt;CLUMP&lt;/code&gt; contains the sum of partial derivatives of all clumps by the corresponding output. This function is intended to be called after a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:FORWARD GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FORWARD&lt;/code&gt;&lt;/a&gt; pass.&lt;/p&gt; &lt;p&gt;Take the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;SIGMOID CLASS&#34;&gt;&lt;code&gt;-&amp;gt;SIGMOID&lt;/code&gt;&lt;/a&gt; clump for example when the network is being applied to a batch of two instances &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt;. &lt;code&gt;x1&lt;/code&gt; and &lt;code&gt;x2&lt;/code&gt; are set in the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EINPUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;INPUT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;INPUT&lt;/code&gt;&lt;/a&gt; lump X. The sigmoid computes &lt;code&gt;1/(1+exp(-x))&lt;/code&gt; where &lt;code&gt;X&lt;/code&gt; is its only argument clump.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  f(x) = 1/(1+exp(-x))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When &lt;code&gt;BACKWARD&lt;/code&gt; is called on the sigmoid lump, its &lt;code&gt;DERIVATIVES&lt;/code&gt; is a 2x1 &lt;code&gt;MAT&lt;/code&gt; object that contains the partial derivatives of the loss function:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  dL(x1)/df&#xA;  dL(x2)/df&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now the &lt;code&gt;BACKWARD&lt;/code&gt; method of the sigmoid needs to add &lt;code&gt;dL(x1)/dx1&lt;/code&gt; and &lt;code&gt;dL(x2)/dx2&lt;/code&gt; to &lt;code&gt;DERIVATIVES&lt;/code&gt; of &lt;code&gt;X&lt;/code&gt;. Now, &lt;code&gt;dL(x1)/dx1 = dL(x1)/df * df(x1)/dx1&lt;/code&gt; and the first term is what we have in &lt;code&gt;DERIVATIVES&lt;/code&gt; of the sigmoid so it only needs to calculate the second term.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;In addition to the above, clumps also have to support &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;), &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; (and the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/m_setf.htm&#34; title=&#34;SETF MGL-PAX:MACRO&#34;&gt;&lt;code&gt;SETF&lt;/code&gt;&lt;/a&gt; methods of the latter two) which can be accomplished just by inheriting from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;, or a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;LUMP&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;11.3 &lt;code&gt;BPN&lt;/code&gt;s&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABPN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;BPN&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;CLUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Abstract base class for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AN-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;N-STRIPES&lt;/strong&gt; &lt;em&gt;BPN (:N-STRIPES = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The current number of instances the network has. This is automatically set to the number of instances passed to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;, so it rarely has to be manipulated directly although it can be set. When set &lt;code&gt;N-STRIPES&lt;/code&gt; of all &lt;code&gt;CLUMPS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) get set to the same value.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMAX-N-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;MAX-N-STRIPES&lt;/strong&gt; &lt;em&gt;BPN (:MAX-N-STRIPES = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The maximum number of instances the network can operate on in parallel. Within &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-FNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-FNN&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-RNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-RNN&lt;/code&gt;&lt;/a&gt;, it defaults to &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; of that parent network, else it defaults to 1. When set &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; of all &lt;code&gt;CLUMPS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) get set to the same value.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;CLUMPS&lt;/strong&gt; &lt;em&gt;BPN (:CLUMPS = (MAKE-ARRAY 0 :ELEMENT-TYPE &#39;CLUMP :ADJUSTABLE T :FILL-POINTER T))&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A topological sorted adjustable array with a fill pointer that holds the clumps that make up the network. Clumps are added to it by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AADD-CLUMP-20FUNCTION-29&#34; title=&#34;MGL-BP:ADD-CLUMP FUNCTION&#34;&gt;&lt;code&gt;ADD-CLUMP&lt;/code&gt;&lt;/a&gt; or, more often, automatically when within a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-FNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-FNN&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-RNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-RNN&lt;/code&gt;&lt;/a&gt;. Rarely needed, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFIND-CLUMP-20FUNCTION-29&#34; title=&#34;MGL-BP:FIND-CLUMP FUNCTION&#34;&gt;&lt;code&gt;FIND-CLUMP&lt;/code&gt;&lt;/a&gt; takes care of most uses.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AFIND-CLUMP-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;FIND-CLUMP&lt;/strong&gt; &lt;em&gt;NAME BPN &amp;amp;KEY (ERRORP T)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Find the clump with &lt;code&gt;NAME&lt;/code&gt; among &lt;code&gt;CLUMPS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of &lt;code&gt;BPN&lt;/code&gt;. As always, names are compared with &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt;. If not found, then return &lt;code&gt;NIL&lt;/code&gt; or signal and error depending on &lt;code&gt;ERRORP&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AADD-CLUMP-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ADD-CLUMP&lt;/strong&gt; &lt;em&gt;CLUMP BPN&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Add &lt;code&gt;CLUMP&lt;/code&gt; to &lt;code&gt;BPN&lt;/code&gt;. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;CLUMP&lt;/code&gt; gets set to that of &lt;code&gt;BPN&lt;/code&gt;. It is an error to add a clump with a name already used by one of the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;CLUMPS&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;BPN&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.3.1 Training&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;s are trained to minimize the loss function they compute. Before a &lt;code&gt;BPN&lt;/code&gt; is passed to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29&#34; title=&#34;MGL-OPT:MINIMIZE FUNCTION&#34;&gt;&lt;code&gt;MINIMIZE&lt;/code&gt;&lt;/a&gt; (as its &lt;code&gt;GRADIENT-SOURCE&lt;/code&gt; argument), it must be wrapped in a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABP-LEARNER-20CLASS-29&#34; title=&#34;MGL-BP:BP-LEARNER CLASS&#34;&gt;&lt;code&gt;BP-LEARNER&lt;/code&gt;&lt;/a&gt; object. &lt;code&gt;BP-LEARNER&lt;/code&gt; has &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ABP-LEARNER-29-29&#34; title=&#34;MGL-CORE:MONITORS (MGL-PAX:ACCESSOR MGL-BP:BP-LEARNER)&#34;&gt;&lt;code&gt;MONITORS&lt;/code&gt;&lt;/a&gt; slot which is used for example by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20-28METHOD-20NIL-20-28MGL-OPT-3AITERATIVE-OPTIMIZER-20T-29-29-29&#34; title=&#34;MGL-OPT:RESET-OPTIMIZATION-MONITORS (METHOD NIL (MGL-OPT:ITERATIVE-OPTIMIZER T))&#34;&gt;&lt;code&gt;RESET-OPTIMIZATION-MONITORS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;Without the bells an whistles, the basic shape of training is this:&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(minimize optimizer (make-instance &#39;bp-learner :bpn bpn)&#xA;          :dataset dataset)&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABP-LEARNER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[class] &lt;strong&gt;BP-LEARNER&lt;/strong&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABPN-20-28MGL-PAX-3AREADER-20MGL-BP-3ABP-LEARNER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;BPN&lt;/strong&gt; &lt;em&gt;BP-LEARNER (:BPN)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The &lt;code&gt;BPN&lt;/code&gt; for which this &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABP-LEARNER-20CLASS-29&#34; title=&#34;MGL-BP:BP-LEARNER CLASS&#34;&gt;&lt;code&gt;BP-LEARNER&lt;/code&gt;&lt;/a&gt; provides the gradients.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3AMONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ABP-LEARNER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;MONITORS&lt;/strong&gt; &lt;em&gt;BP-LEARNER (:MONITORS = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A list of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-20CLASS-29&#34; title=&#34;MGL-CORE:MONITOR CLASS&#34;&gt;&lt;code&gt;MONITOR&lt;/code&gt;&lt;/a&gt;s.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.3.2 Monitoring&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AMONITOR-BPN-RESULTS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MONITOR-BPN-RESULTS&lt;/strong&gt; &lt;em&gt;DATASET BPN MONITORS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;For every batch (of size &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;BPN&lt;/code&gt;) of instances in &lt;code&gt;DATASET&lt;/code&gt;, set the batch as the next input with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;, perform a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:FORWARD GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FORWARD&lt;/code&gt;&lt;/a&gt; pass and apply &lt;code&gt;MONITORS&lt;/code&gt; to the &lt;code&gt;BPN&lt;/code&gt; (with &lt;code&gt;APPLY-MONITORS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITORS-20FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITORS FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;)). Finally, return the counters of &lt;code&gt;MONITORS&lt;/code&gt;. This is built on top of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29&#34; title=&#34;MGL-CORE:MONITOR-MODEL-RESULTS FUNCTION&#34;&gt;&lt;code&gt;MONITOR-MODEL-RESULTS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AMAKE-STEP-MONITOR-MONITORS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-STEP-MONITOR-MONITORS&lt;/strong&gt; &lt;em&gt;RNN &amp;amp;KEY (COUNTER-VALUES-FN #&#39;COUNTER-RAW-VALUES) (MAKE-COUNTER #&#39;MAKE-STEP-MONITOR-MONITOR-COUNTER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a list of monitors, one for every monitor in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ASTEP-MONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:STEP-MONITORS (MGL-PAX:ACCESSOR MGL-BP:RNN)&#34;&gt;&lt;code&gt;STEP-MONITORS&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;RNN&lt;/code&gt;. These monitors extract the results from their warp counterpairs with &lt;code&gt;COUNTER-VALUES-FN&lt;/code&gt; and add them to their own counter that&#39;s created by &lt;code&gt;MAKE-COUNTER&lt;/code&gt;. Wow. Ew. The idea is that one does something like this do monitor warped prediction:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(let ((*warp-time* t))&#xA;  (setf (step-monitors rnn)&#xA;        (make-cost-monitors rnn :attributes &#39;(:event &#34;warped pred.&#34;)))&#xA;  (monitor-bpn-results dataset rnn&#xA;                       ;; Just collect and reset the warp&#xA;                       ;; monitors after each batch of&#xA;                       ;; instances.&#xA;                       (make-step-monitor-monitors rnn)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AMAKE-STEP-MONITOR-MONITOR-COUNTER-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;MAKE-STEP-MONITOR-MONITOR-COUNTER&lt;/strong&gt; &lt;em&gt;STEP-COUNTER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;, &lt;code&gt;STEP-COUNTER&lt;/code&gt; aggregates results of all the time steps during the processing of instances in the current batch. Return a new counter into which results from &lt;code&gt;STEP-COUNTER&lt;/code&gt; can be accumulated when the processing of the batch is finished. The default implementation creates a copy of &lt;code&gt;STEP-COUNTER&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.3.3 Feed-Forward Nets&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt; have a lot in common (see their common superclass, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;). There is very limited functionality that&#39;s specific to &lt;code&gt;FNN&lt;/code&gt;s so let&#39;s get them out of they way before we study a full example.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AFNN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;FNN&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;BPN&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A feed-forward neural net (as opposed to a recurrent one, see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;BUILD-FNN&lt;/strong&gt; &lt;em&gt;(&amp;amp;KEY FNN (CLASS &#39;&#39;FNN) INITARGS MAX-N-STRIPES NAME) &amp;amp;BODY CLUMPS&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Syntactic sugar to assemble &lt;code&gt;FNN&lt;/code&gt;s from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt;s. Like &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm&#34; title=&#34;LET* MGL-PAX:MACRO&#34;&gt;&lt;code&gt;LET*&lt;/code&gt;&lt;/a&gt;, it is a sequence of bindings (of symbols to &lt;code&gt;CLUMP&lt;/code&gt;s). The names of the clumps created default to the symbol of the binding. In case a clump is not bound to a symbol (because it was created in a nested expression), the local function &lt;code&gt;CLUMP&lt;/code&gt; can be used to find the clump with the given name in the fnn being built. Example:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (build-fnn ()&#xA;    (features (-&amp;gt;input :size n-features))&#xA;    (biases (-&amp;gt;weight :size n-features))&#xA;    (weights (-&amp;gt;weight :size (* n-hiddens n-features)))&#xA;    (activations0 (-&amp;gt;v*m :weights weights :x (clump &#39;features)))&#xA;    (activations (-&amp;gt;+ :args (list biases activations0)))&#xA;    (output (-&amp;gt;sigmoid :x activations)))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;&lt;code&gt;FNN&lt;/code&gt; Tutorial&lt;/h5&gt; &#xA;&lt;p&gt;Hopefully this example from &lt;code&gt;example/digit-fnn.lisp&lt;/code&gt; illustrates the concepts involved. If it&#39;s too dense despite the comments, then read up on &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29&#34; title=&#34;Datasets&#34;&gt;Datasets&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29&#34; title=&#34;Gradient Based Optimization&#34;&gt;Gradient Based Optimization&lt;/a&gt; and come back.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADIGIT-FNN-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmelisgl-2Fown-2Fmgl-2Fexample-2Fdigit-fnn-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(cl:defpackage :mgl-example-digit-fnn&#xA;  (:use #:common-lisp #:mgl))&#xA;&#xA;(in-package :mgl-example-digit-fnn)&#xA;&#xA;;;; There are 10 possible digits used as inputs ...&#xA;(defparameter *n-inputs* 10)&#xA;;;; and we want to learn the rule that maps the input digit D to (MOD&#xA;;;; (1+ D) 3).&#xA;(defparameter *n-outputs* 3)&#xA;&#xA;;;; We define a feed-forward net to be able to specialize how inputs&#xA;;;; are translated by adding a SET-INPUT method later.&#xA;(defclass digit-fnn (fnn)&#xA;  ())&#xA;&#xA;;;; Build a DIGIT-FNN with a single hidden layer of rectified linear&#xA;;;; units and a softmax output.&#xA;(defun make-digit-fnn (&amp;amp;key (n-hiddens 5))&#xA;  (build-fnn (:class &#39;digit-fnn)&#xA;    (input (-&amp;gt;input :size *n-inputs*))&#xA;    (hidden-activation (-&amp;gt;activation input :size n-hiddens))&#xA;    (hidden (-&amp;gt;relu hidden-activation))&#xA;    (output-activation (-&amp;gt;activation hidden :size *n-outputs*))&#xA;    (output (-&amp;gt;softmax-xe-loss output-activation))))&#xA;&#xA;;;; This method is called with batches of &#39;instances&#39; (input digits in&#xA;;;; this case) by MINIMIZE and also by MONITOR-BPN-RESULTS before&#xA;;;; performing a forward pass (i.e. computing the value of the&#xA;;;; function represented by the network). Its job is to encode the&#xA;;;; inputs by populating rows of the NODES matrix of the INPUT clump.&#xA;;;;&#xA;;;; Each input is encoded as a row of zeros with a single 1 at index&#xA;;;; determined by the input digit. This is called one-hot encoding.&#xA;;;; The TARGET could be encoded the same way, but instead we use the&#xA;;;; sparse option supported by TARGET of -&amp;gt;SOFTMAX-XE-LOSS.&#xA;(defmethod set-input (digits (fnn digit-fnn))&#xA;  (let* ((input (nodes (find-clump &#39;input fnn)))&#xA;         (output-lump (find-clump &#39;output fnn)))&#xA;    (fill! 0 input)&#xA;    (loop for i upfrom 0&#xA;          for digit in digits&#xA;          do (setf (mref input i digit) 1))&#xA;    (setf (target output-lump)&#xA;          (mapcar (lambda (digit)&#xA;                    (mod (1+ digit) *n-outputs*))&#xA;                  digits))))&#xA;&#xA;;;; Train the network by minimizing the loss (cross-entropy here) with&#xA;;;; stochastic gradient descent.&#xA;(defun train-digit-fnn ()&#xA;  (let ((optimizer&#xA;          ;; First create the optimizer for MINIMIZE.&#xA;          (make-instance &#39;segmented-gd-optimizer&#xA;                         :segmenter&#xA;                         ;; We train each weight lump with the same&#xA;                         ;; parameters and, in fact, the same&#xA;                         ;; optimizer. But it need not be so, in&#xA;                         ;; general.&#xA;                         (constantly&#xA;                          (make-instance &#39;sgd-optimizer&#xA;                                         :learning-rate 1&#xA;                                         :momentum 0.9&#xA;                                         :batch-size 100))))&#xA;        (fnn (make-digit-fnn)))&#xA;    ;; The number of instances the FNN can work with in parallel. It&#39;s&#xA;    ;; usually equal to the batch size or is a its divisor.&#xA;    (setf (max-n-stripes fnn) 50)&#xA;    ;; Initialize all weights randomly.&#xA;    (map-segments (lambda (weights)&#xA;                    (gaussian-random! (nodes weights) :stddev 0.01))&#xA;                  fnn)&#xA;    ;; Arrange for training and test error to be logged.&#xA;    (monitor-optimization-periodically&#xA;     optimizer &#39;((:fn log-test-error :period 10000)&#xA;                 (:fn reset-optimization-monitors :period 1000)))&#xA;    ;; Finally, start the optimization.&#xA;    (minimize optimizer&#xA;              ;; Dress FNN in a BP-LEARNER and attach monitors for the&#xA;              ;; cost to it. These monitors are going to be logged and&#xA;              ;; reset after every 100 training instance by&#xA;              ;; RESET-OPTIMIZATION-MONITORS above.&#xA;              (make-instance &#39;bp-learner&#xA;                             :bpn fnn&#xA;                             :monitors (make-cost-monitors&#xA;                                        fnn :attributes `(:event &#34;train&#34;)))&#xA;              ;; Training stops when the sampler runs out (after 10000&#xA;              ;; instances).&#xA;              :dataset (make-sampler 10000))))&#xA;&#xA;;;; Return a sampler object that produces MAX-N-SAMPLES number of&#xA;;;; random inputs (numbers between 0 and 9).&#xA;(defun make-sampler (max-n-samples)&#xA;  (make-instance &#39;function-sampler :max-n-samples max-n-samples&#xA;                 :generator (lambda () (random *n-inputs*))))&#xA;&#xA;;;; Log the test error. Also, describe the optimizer and the bpn at&#xA;;;; the beginning of training. Called periodically during training&#xA;;;; (see above).&#xA;(defun log-test-error (optimizer learner)&#xA;  (when (zerop (n-instances optimizer))&#xA;    (describe optimizer)&#xA;    (describe (bpn learner)))&#xA;  (log-padded&#xA;   (monitor-bpn-results (make-sampler 1000) (bpn learner)&#xA;                        (make-cost-monitors&#xA;                         (bpn learner) :attributes `(:event &#34;pred.&#34;)))))&#xA;&#xA;#|&#xA;&#xA;;;; Transcript follows:&#xA;(repeatably ()&#xA;  (let ((*log-time* nil))&#xA;    (train-digit-fnn)))&#xA;.. training at n-instances: 0&#xA;.. train cost: 0.000e+0 (0)&#xA;.. #&amp;lt;SEGMENTED-GD-OPTIMIZER {100E112E93}&amp;gt;&#xA;..  SEGMENTED-GD-OPTIMIZER description:&#xA;..    N-INSTANCES = 0&#xA;..    OPTIMIZERS = (#&amp;lt;SGD-OPTIMIZER&#xA;..                    #&amp;lt;SEGMENT-SET&#xA;..                      (#&amp;lt;-&amp;gt;WEIGHT # :SIZE 15 1/1 :NORM 0.04473&amp;gt;&#xA;..                       #&amp;lt;-&amp;gt;WEIGHT # :SIZE 3 1/1 :NORM 0.01850&amp;gt;&#xA;..                       #&amp;lt;-&amp;gt;WEIGHT # :SIZE 50 1/1 :NORM 0.07159&amp;gt;&#xA;..                       #&amp;lt;-&amp;gt;WEIGHT # :SIZE 5 1/1 :NORM 0.03056&amp;gt;)&#xA;..                      {100E335B73}&amp;gt;&#xA;..                    {100E06DF83}&amp;gt;)&#xA;..    SEGMENTS = (#&amp;lt;-&amp;gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE&#xA;..                  15 1/1 :NORM 0.04473&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE&#xA;..                  3 1/1 :NORM 0.01850&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE&#xA;..                  50 1/1 :NORM 0.07159&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE&#xA;..                  5 1/1 :NORM 0.03056&amp;gt;)&#xA;..  &#xA;.. #&amp;lt;SGD-OPTIMIZER {100E06DF83}&amp;gt;&#xA;..  GD-OPTIMIZER description:&#xA;..    N-INSTANCES = 0&#xA;..    SEGMENT-SET = #&amp;lt;SEGMENT-SET&#xA;..                    (#&amp;lt;-&amp;gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE&#xA;..                       15 1/1 :NORM 0.04473&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE&#xA;..                       3 1/1 :NORM 0.01850&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE&#xA;..                       50 1/1 :NORM 0.07159&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE&#xA;..                       5 1/1 :NORM 0.03056&amp;gt;)&#xA;..                    {100E335B73}&amp;gt;&#xA;..    LEARNING-RATE = 1.00000e+0&#xA;..    MOMENTUM = 9.00000e-1&#xA;..    MOMENTUM-TYPE = :NORMAL&#xA;..    WEIGHT-DECAY = 0.00000e+0&#xA;..    WEIGHT-PENALTY = 0.00000e+0&#xA;..    N-AFTER-UPATE-HOOK = 0&#xA;..    BATCH-SIZE = 100&#xA;..  &#xA;..  BATCH-GD-OPTIMIZER description:&#xA;..    N-BEFORE-UPATE-HOOK = 0&#xA;..  #&amp;lt;DIGIT-FNN {100E11A423}&amp;gt;&#xA;..   BPN description:&#xA;..     CLUMPS = #(#&amp;lt;-&amp;gt;INPUT INPUT :SIZE 10 1/50 :NORM 0.00000&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;ACTIVATION&#xA;..                  (HIDDEN-ACTIVATION :ACTIVATION) :STRIPES 1/50&#xA;..                  :CLUMPS 4&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;RELU HIDDEN :SIZE 5 1/50 :NORM 0.00000&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;ACTIVATION&#xA;..                  (OUTPUT-ACTIVATION :ACTIVATION) :STRIPES 1/50&#xA;..                  :CLUMPS 4&amp;gt;&#xA;..                #&amp;lt;-&amp;gt;SOFTMAX-XE-LOSS OUTPUT :SIZE 3 1/50 :NORM 0.00000&amp;gt;)&#xA;..     N-STRIPES = 1&#xA;..     MAX-N-STRIPES = 50&#xA;..   pred. cost: 1.100d+0 (1000.00)&#xA;.. training at n-instances: 1000&#xA;.. train cost: 1.093d+0 (1000.00)&#xA;.. training at n-instances: 2000&#xA;.. train cost: 5.886d-1 (1000.00)&#xA;.. training at n-instances: 3000&#xA;.. train cost: 3.574d-3 (1000.00)&#xA;.. training at n-instances: 4000&#xA;.. train cost: 1.601d-7 (1000.00)&#xA;.. training at n-instances: 5000&#xA;.. train cost: 1.973d-9 (1000.00)&#xA;.. training at n-instances: 6000&#xA;.. train cost: 4.882d-10 (1000.00)&#xA;.. training at n-instances: 7000&#xA;.. train cost: 2.771d-10 (1000.00)&#xA;.. training at n-instances: 8000&#xA;.. train cost: 2.283d-10 (1000.00)&#xA;.. training at n-instances: 9000&#xA;.. train cost: 2.123d-10 (1000.00)&#xA;.. training at n-instances: 10000&#xA;.. train cost: 2.263d-10 (1000.00)&#xA;.. pred. cost: 2.210d-10 (1000.00)&#xA;..&#xA;==&amp;gt; (#&amp;lt;-&amp;gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE 5 1/1 :NORM 2.94294&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE 50 1/1 :NORM 11.48995&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE 3 1/1 :NORM 3.39103&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE 15 1/1 :NORM 11.39339&amp;gt;)&#xA;&#xA;|#&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.3.4 Recurrent Neural Nets&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;&lt;code&gt;RNN&lt;/code&gt; Tutorial&lt;/h5&gt; &#xA;&lt;p&gt;Hopefully this example from &lt;code&gt;example/sum-sign-fnn.lisp&lt;/code&gt; illustrates the concepts involved. Make sure you are comfortable with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34; title=&#34;`FNN` Tutorial&#34;&gt;&lt;code&gt;FNN&lt;/code&gt; Tutorial&lt;/a&gt; before reading this.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASUM-SIG-RNN-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmelisgl-2Fown-2Fmgl-2Fexample-2Fsum-sign-rnn-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(cl:defpackage :mgl-example-sum-sign-rnn&#xA;  (:use #:common-lisp #:mgl))&#xA;&#xA;(in-package :mgl-example-sum-sign-rnn)&#xA;&#xA;;;; There is a single input at each time step...&#xA;(defparameter *n-inputs* 1)&#xA;;;; and we want to learn the rule that outputs the sign of the sum of&#xA;;;; inputs so far in the sequence.&#xA;(defparameter *n-outputs* 3)&#xA;&#xA;;;; Generate a training example that&#39;s a sequence of random length&#xA;;;; between 1 and LENGTH. Elements of the sequence are lists of two&#xA;;;; elements:&#xA;;;;&#xA;;;; 1. The input for the network (a single random number).&#xA;;;;&#xA;;;; 2. The sign of the sum of inputs so far encoded as 0, 1, 2 (for&#xA;;;;    negative, zero and positive values). To add a twist, the sum is&#xA;;;;    reset whenever a negative input is seen.&#xA;(defun make-sum-sign-instance (&amp;amp;key (length 10))&#xA;  (let ((length (max 1 (random length)))&#xA;        (sum 0))&#xA;    (loop for i below length&#xA;          collect (let ((x (1- (* 2 (random 2)))))&#xA;                    (incf sum x)&#xA;                    (when (&amp;lt; x 0)&#xA;                      (setq sum x))&#xA;                    (list x (cond ((minusp sum) 0)&#xA;                                  ((zerop sum) 1)&#xA;                                  (t 2)))))))&#xA;&#xA;;;; Build an RNN with a single lstm hidden layer and softmax output.&#xA;;;; For each time step, a SUM-SIGN-FNN will be instantiated.&#xA;(defun make-sum-sign-rnn (&amp;amp;key (n-hiddens 1))&#xA;  (build-rnn ()&#xA;    (build-fnn (:class &#39;sum-sign-fnn)&#xA;      (input (-&amp;gt;input :size 1))&#xA;      (h (-&amp;gt;lstm input :name &#39;h :size n-hiddens))&#xA;      (prediction (-&amp;gt;softmax-xe-loss (-&amp;gt;activation h :name &#39;prediction&#xA;                                                   :size *n-outputs*))))))&#xA;&#xA;;;; We define this class to be able to specialize how inputs are&#xA;;;; translated by adding a SET-INPUT method later.&#xA;(defclass sum-sign-fnn (fnn)&#xA;  ())&#xA;&#xA;;;; We have a batch of instances from MAKE-SUM-SIGN-INSTANCE for the&#xA;;;; RNN. This function is invoked with elements of these instances&#xA;;;; belonging to the same time step (i.e. at the same index) and sets&#xA;;;; the input and target up.&#xA;(defmethod set-input (instances (fnn sum-sign-fnn))&#xA;  (let ((input-nodes (nodes (find-clump &#39;input fnn))))&#xA;    (setf (target (find-clump &#39;prediction fnn))&#xA;          (loop for stripe upfrom 0&#xA;                for instance in instances&#xA;                collect&#xA;                ;; Sequences in the batch are not of equal length. The&#xA;                ;; RNN sends a NIL our way if a sequence has run out.&#xA;                (when instance&#xA;                  (destructuring-bind (input target) instance&#xA;                    (setf (mref input-nodes stripe 0) input)&#xA;                    target))))))&#xA;&#xA;;;; Train the network by minimizing the loss (cross-entropy here) with&#xA;;;; the Adam optimizer.&#xA;(defun train-sum-sign-rnn ()&#xA;  (let ((rnn (make-sum-sign-rnn)))&#xA;    (setf (max-n-stripes rnn) 50)&#xA;    ;; Initialize the weights in the usual sqrt(1 / fan-in) style.&#xA;    (map-segments (lambda (weights)&#xA;                    (let* ((fan-in (mat-dimension (nodes weights) 0))&#xA;                           (limit (sqrt (/ 6 fan-in))))&#xA;                      (uniform-random! (nodes weights)&#xA;                                       :limit (* 2 limit))&#xA;                      (.+! (- limit) (nodes weights))))&#xA;                  rnn)&#xA;    (minimize (monitor-optimization-periodically&#xA;               (make-instance &#39;adam-optimizer&#xA;                              :learning-rate 0.2&#xA;                              :mean-decay 0.9&#xA;                              :mean-decay-decay 0.9&#xA;                              :variance-decay 0.9&#xA;                              :batch-size 100)&#xA;               &#39;((:fn log-test-error :period 30000)&#xA;                 (:fn reset-optimization-monitors :period 3000)))&#xA;              (make-instance &#39;bp-learner&#xA;                             :bpn rnn&#xA;                             :monitors (make-cost-monitors rnn))&#xA;              :dataset (make-sampler 30000))))&#xA;&#xA;;;; Return a sampler object that produces MAX-N-SAMPLES number of&#xA;;;; random inputs.&#xA;(defun make-sampler (max-n-samples &amp;amp;key (length 10))&#xA;  (make-instance &#39;function-sampler :max-n-samples max-n-samples&#xA;                 :generator (lambda ()&#xA;                              (make-sum-sign-instance :length length))))&#xA;&#xA;;;; Log the test error. Also, describe the optimizer and the bpn at&#xA;;;; the beginning of training. Called periodically during training&#xA;;;; (see above).&#xA;(defun log-test-error (optimizer learner)&#xA;  (when (zerop (n-instances optimizer))&#xA;    (describe optimizer)&#xA;    (describe (bpn learner)))&#xA;  (let ((rnn (bpn learner)))&#xA;    (log-padded&#xA;     (append&#xA;      (monitor-bpn-results (make-sampler 1000) rnn&#xA;                           (make-cost-monitors&#xA;                            rnn :attributes &#39;(:event &#34;pred.&#34;)))&#xA;      ;; Same result in a different way: monitor predictions for&#xA;      ;; sequences up to length 20, but don&#39;t unfold the RNN&#xA;      ;; unnecessarily to save memory.&#xA;      (let ((*warp-time* t))&#xA;        (monitor-bpn-results (make-sampler 1000 :length 20) rnn&#xA;                             ;; Just collect and reset the warp&#xA;                             ;; monitors after each batch of&#xA;                             ;; instances.&#xA;                             (make-cost-monitors&#xA;                              rnn :attributes &#39;(:event &#34;warped pred.&#34;))))))&#xA;    ;; Verify that no further unfoldings took place.&#xA;    (assert (&amp;lt;= (length (clumps rnn)) 10)))&#xA;  (log-mat-room))&#xA;&#xA;#|&#xA;&#xA;;;; Transcript follows:&#xA;(let (;; Backprop nets do not need double float. Using single floats&#xA;      ;; is faster and needs less memory.&#xA;      (*default-mat-ctype* :float)&#xA;      ;; Enable moving data in and out of GPU memory so that the RNN&#xA;      ;; can work with sequences so long that the unfolded network&#xA;      ;; wouldn&#39;t otherwise fit in the GPU.&#xA;      (*cuda-window-start-time* 1)&#xA;      (*log-time* nil))&#xA;  ;; Seed the random number generators.&#xA;  (repeatably ()&#xA;    ;; Enable CUDA if available.&#xA;    (with-cuda* ()&#xA;      (train-sum-sign-rnn))))&#xA;.. training at n-instances: 0&#xA;.. cost: 0.000e+0 (0)&#xA;.. #&amp;lt;ADAM-OPTIMIZER {1006CD5663}&amp;gt;&#xA;..  GD-OPTIMIZER description:&#xA;..    N-INSTANCES = 0&#xA;..    SEGMENT-SET = #&amp;lt;SEGMENT-SET&#xA;..                    (#&amp;lt;-&amp;gt;WEIGHT (H #) :SIZE 1 1/1 :NORM 1.73685&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (H #) :SIZE 1 1/1 :NORM 0.31893&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (#1=# #2=# :PEEPHOLE) :SIZE&#xA;..                       1 1/1 :NORM 1.81610&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (H #2#) :SIZE 1 1/1 :NORM 0.21965&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (#1# #3=# :PEEPHOLE) :SIZE&#xA;..                       1 1/1 :NORM 1.74939&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (H #3#) :SIZE 1 1/1 :NORM 0.40377&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (H PREDICTION) :SIZE&#xA;..                       3 1/1 :NORM 2.15898&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS PREDICTION) :SIZE&#xA;..                       3 1/1 :NORM 2.94470&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (#1# #4=# :PEEPHOLE) :SIZE&#xA;..                       1 1/1 :NORM 0.97601&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (INPUT #4#) :SIZE 1 1/1 :NORM 0.65261&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS #4#) :SIZE 1 1/1 :NORM 0.37653&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (INPUT #1#) :SIZE 1 1/1 :NORM 0.92334&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS #1#) :SIZE 1 1/1 :NORM 0.01609&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (INPUT #5=#) :SIZE 1 1/1 :NORM 1.09995&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS #5#) :SIZE 1 1/1 :NORM 1.41244&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (INPUT #6=#) :SIZE 1 1/1 :NORM 0.40475&amp;gt;&#xA;..                     #&amp;lt;-&amp;gt;WEIGHT (:BIAS #6#) :SIZE 1 1/1 :NORM 1.75358&amp;gt;)&#xA;..                    {1006CD8753}&amp;gt;&#xA;..    LEARNING-RATE = 2.00000e-1&#xA;..    MOMENTUM = NONE&#xA;..    MOMENTUM-TYPE = :NONE&#xA;..    WEIGHT-DECAY = 0.00000e+0&#xA;..    WEIGHT-PENALTY = 0.00000e+0&#xA;..    N-AFTER-UPATE-HOOK = 0&#xA;..    BATCH-SIZE = 100&#xA;..  &#xA;..  BATCH-GD-OPTIMIZER description:&#xA;..    N-BEFORE-UPATE-HOOK = 0&#xA;..  &#xA;..  ADAM-OPTIMIZER description:&#xA;..    MEAN-DECAY-RATE = 1.00000e-1&#xA;..    MEAN-DECAY-RATE-DECAY = 9.00000e-1&#xA;..    VARIANCE-DECAY-RATE = 1.00000e-1&#xA;..    VARIANCE-ADJUSTMENT = 1.00000d-7&#xA;..  #&amp;lt;RNN {10047C77E3}&amp;gt;&#xA;..   BPN description:&#xA;..     CLUMPS = #(#&amp;lt;SUM-SIGN-FNN :STRIPES 1/50 :CLUMPS 4&amp;gt;&#xA;..                #&amp;lt;SUM-SIGN-FNN :STRIPES 1/50 :CLUMPS 4&amp;gt;)&#xA;..     N-STRIPES = 1&#xA;..     MAX-N-STRIPES = 50&#xA;..   &#xA;..   RNN description:&#xA;..     MAX-LAG = 1&#xA;..   pred.        cost: 1.223e+0 (4455.00)&#xA;.. warped pred. cost: 1.228e+0 (9476.00)&#xA;.. Foreign memory usage:&#xA;.. foreign arrays: 162 (used bytes: 39,600)&#xA;.. CUDA memory usage:&#xA;.. device arrays: 114 (used bytes: 220,892, pooled bytes: 19,200)&#xA;.. host arrays: 162 (used bytes: 39,600)&#xA;.. host-&amp;gt;device copies: 6,164, device-&amp;gt;host copies: 4,490&#xA;.. training at n-instances: 3000&#xA;.. cost: 3.323e-1 (13726.00)&#xA;.. training at n-instances: 6000&#xA;.. cost: 3.735e-2 (13890.00)&#xA;.. training at n-instances: 9000&#xA;.. cost: 1.012e-2 (13872.00)&#xA;.. training at n-instances: 12000&#xA;.. cost: 3.026e-3 (13953.00)&#xA;.. training at n-instances: 15000&#xA;.. cost: 9.267e-4 (13948.00)&#xA;.. training at n-instances: 18000&#xA;.. cost: 2.865e-4 (13849.00)&#xA;.. training at n-instances: 21000&#xA;.. cost: 8.893e-5 (13758.00)&#xA;.. training at n-instances: 24000&#xA;.. cost: 2.770e-5 (13908.00)&#xA;.. training at n-instances: 27000&#xA;.. cost: 8.514e-6 (13570.00)&#xA;.. training at n-instances: 30000&#xA;.. cost: 2.705e-6 (13721.00)&#xA;.. pred.        cost: 1.426e-6 (4593.00)&#xA;.. warped pred. cost: 1.406e-6 (9717.00)&#xA;.. Foreign memory usage:&#xA;.. foreign arrays: 216 (used bytes: 52,800)&#xA;.. CUDA memory usage:&#xA;.. device arrays: 148 (used bytes: 224,428, pooled bytes: 19,200)&#xA;.. host arrays: 216 (used bytes: 52,800)&#xA;.. host-&amp;gt;device copies: 465,818, device-&amp;gt;host copies: 371,990&#xA;..&#xA;==&amp;gt; (#&amp;lt;-&amp;gt;WEIGHT (H (H :OUTPUT)) :SIZE 1 1/1 :NORM 0.10624&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (H (H :CELL)) :SIZE 1 1/1 :NORM 0.94460&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT ((H :CELL) (H :FORGET) :PEEPHOLE) :SIZE 1 1/1 :NORM 0.61312&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (H (H :FORGET)) :SIZE 1 1/1 :NORM 0.38093&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT ((H :CELL) (H :INPUT) :PEEPHOLE) :SIZE 1 1/1 :NORM 1.17956&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (H (H :INPUT)) :SIZE 1 1/1 :NORM 0.88011&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (H PREDICTION) :SIZE 3 1/1 :NORM 49.93808&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS PREDICTION) :SIZE 3 1/1 :NORM 10.98112&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT ((H :CELL) (H :OUTPUT) :PEEPHOLE) :SIZE 1 1/1 :NORM 0.67996&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (INPUT (H :OUTPUT)) :SIZE 1 1/1 :NORM 0.65251&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS (H :OUTPUT)) :SIZE 1 1/1 :NORM 10.23003&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (INPUT (H :CELL)) :SIZE 1 1/1 :NORM 5.98116&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS (H :CELL)) :SIZE 1 1/1 :NORM 0.10681&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (INPUT (H :FORGET)) :SIZE 1 1/1 :NORM 4.46301&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS (H :FORGET)) :SIZE 1 1/1 :NORM 1.57195&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (INPUT (H :INPUT)) :SIZE 1 1/1 :NORM 0.36401&amp;gt;&#xA;--&amp;gt;  #&amp;lt;-&amp;gt;WEIGHT (:BIAS (H :INPUT)) :SIZE 1 1/1 :NORM 8.63833&amp;gt;)&#xA;&#xA;|#&#xA;&lt;/code&gt;&lt;/pre&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ARNN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;RNN&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;BPN&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A recurrent neural net (as opposed to a feed-forward one. It is typically built with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-RNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-RNN&lt;/code&gt;&lt;/a&gt; that&#39;s no more than a shallow convenience macro.&lt;/p&gt; &lt;p&gt;An &lt;code&gt;RNN&lt;/code&gt; takes instances as inputs that are sequences of variable length. At each time step, the next unprocessed elements of these sequences are set as input until all input sequences in the batch run out. To be able to perform backpropagation, all intermediate &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;&lt;code&gt;LUMP&lt;/code&gt;&lt;/a&gt;s must be kept around, so the recursive connections are transformed out by &lt;a href=&#34;http://en.wikipedia.org/wiki/Backpropagation_through_time&#34;&gt;unfolding&lt;/a&gt; the network. Just how many lumps this means depends on the length of the sequences.&lt;/p&gt; &lt;p&gt;When an &lt;code&gt;RNN&lt;/code&gt; is created, &lt;code&gt;MAX-LAG + 1&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;s are instantiated so that all weights are present and one can start training it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;UNFOLDER&lt;/strong&gt; &lt;em&gt;RNN (:UNFOLDER)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The &lt;code&gt;UNFOLDER&lt;/code&gt; of an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt; is function of no arguments that builds and returns a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;. The unfolder is allowed to create networks with arbitrary topology even different ones for different &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29&#34; title=&#34;MGL-BP:TIME-STEP FUNCTION&#34;&gt;&lt;code&gt;TIME-STEP&lt;/code&gt;&lt;/a&gt;s with the help of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALAG-20FUNCTION-29&#34; title=&#34;MGL-BP:LAG FUNCTION&#34;&gt;&lt;code&gt;LAG&lt;/code&gt;&lt;/a&gt;, or nested &lt;code&gt;RNN&lt;/code&gt;s. Weights of the same name are shared between the folds. That is, if a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lump were to be created and a weight lump of the same name already exists, then the existing lump will be added to the &lt;code&gt;BPN&lt;/code&gt; created by &lt;code&gt;UNFOLDER&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AMAX-LAG-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;MAX-LAG&lt;/strong&gt; &lt;em&gt;RNN (:MAX-LAG = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The networks built by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; may contain new weights up to time step &lt;code&gt;MAX-LAG&lt;/code&gt;. Beyond that point, all weight lumps must be reappearances of weight lumps with the same name at previous time steps. Most recurrent networks reference only the state of lumps at the previous time step (with the function &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALAG-20FUNCTION-29&#34; title=&#34;MGL-BP:LAG FUNCTION&#34;&gt;&lt;code&gt;LAG&lt;/code&gt;&lt;/a&gt;), hence the default of 1. But it is possible to have connections to arbitrary time steps. The maximum connection lag must be specified when creating the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;CUDA-WINDOW-START-TIME&lt;/strong&gt; &lt;em&gt;RNN (:CUDA-WINDOW-START-TIME = *CUDA-WINDOW-START-TIME*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Due to unfolding, the memory footprint of an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt; is almost linear in the number of time steps (i.e. the max sequence length). For prediction, this is addressed by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Time Warp&#34;&gt;Time Warp&lt;/a&gt;. For training, we cannot discard results of previous time steps because they are needed for backpropagation, but we can at least move them out of GPU memory if they are not going to be used for a while and copy them back before they are needed. Obviously, this is only relevant if CUDA is being used.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;CUDA-WINDOW-START-TIME&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then this feature is turned off. Else, during training, at &lt;code&gt;CUDA-WINDOW-START-TIME&lt;/code&gt; or later time steps, matrices belonging to non-weight lumps may be forced out of GPU memory and later brought back as neeeded.&lt;/p&gt; &lt;p&gt;This feature is implemented in terms of &lt;code&gt;MGL-MAT:WITH-SYNCING-CUDA-FACETS&lt;/code&gt; that uses CUDA host memory (also known as &lt;em&gt;page-locked&lt;/em&gt; or &lt;em&gt;pinned memory&lt;/em&gt;) to do asynchronous copies concurrently with normal computation. The consequence of this is that it is now main memory usage that&#39;s unbounded which toghether with page-locking makes it a potent weapon to bring a machine to a halt. You were warned.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-2ACUDA-WINDOW-START-TIME-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*CUDA-WINDOW-START-TIME*&lt;/strong&gt; &lt;em&gt;NIL&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The default for &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:CUDA-WINDOW-START-TIME (MGL-PAX:ACCESSOR MGL-BP:RNN)&#34;&gt;&lt;code&gt;CUDA-WINDOW-START-TIME&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;BUILD-RNN&lt;/strong&gt; &lt;em&gt;(&amp;amp;KEY RNN (CLASS &#39;&#39;RNN) NAME INITARGS MAX-N-STRIPES (MAX-LAG 1)) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create an &lt;code&gt;RNN&lt;/code&gt; with &lt;code&gt;MAX-N-STRIPES&lt;/code&gt; and &lt;code&gt;MAX-LAG&lt;/code&gt; whose &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; is &lt;code&gt;BODY&lt;/code&gt; wrapped in a lambda. Bind symbol given as the &lt;code&gt;RNN&lt;/code&gt; argument to the &lt;code&gt;RNN&lt;/code&gt; object so that &lt;code&gt;BODY&lt;/code&gt; can see it.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ALAG-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;LAG&lt;/strong&gt; &lt;em&gt;NAME &amp;amp;KEY (LAG 1) RNN PATH&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In &lt;code&gt;RNN&lt;/code&gt; or if it&#39;s &lt;code&gt;NIL&lt;/code&gt; the &lt;code&gt;RNN&lt;/code&gt; being extended with another &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; (called &lt;em&gt;unfolding&lt;/em&gt;), look up the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;NAME&lt;/code&gt; in the &lt;code&gt;BPN&lt;/code&gt; that&#39;s &lt;code&gt;LAG&lt;/code&gt; number of time steps before the &lt;code&gt;BPN&lt;/code&gt; being added. If this function is called from &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; of an &lt;code&gt;RNN&lt;/code&gt; (which is what happens behind the scene in the body of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-RNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-RNN&lt;/code&gt;&lt;/a&gt;), then it returns an opaque object representing a lagged connection to a clump, else it returns the &lt;code&gt;CLUMP&lt;/code&gt; itself.&lt;/p&gt; &lt;p&gt;FIXDOC: &lt;code&gt;PATH&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ATIME-STEP-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;TIME-STEP&lt;/strong&gt; &lt;em&gt;&amp;amp;KEY (RNN *RNN*)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the time step &lt;code&gt;RNN&lt;/code&gt; is currently executing or being unfolded for. It is 0 when the &lt;code&gt;RNN&lt;/code&gt; is being unfolded for the first time.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-CORE-3ASET-INPUT-20-28METHOD-20NIL-20-28T-20MGL-BP-3ARNN-29-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[method] &lt;strong&gt;SET-INPUT&lt;/strong&gt; &lt;em&gt;INSTANCES (RNN RNN)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;RNN&lt;/code&gt;s operate on batches of instances just like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFNN-20CLASS-29&#34; title=&#34;MGL-BP:FNN CLASS&#34;&gt;&lt;code&gt;FNN&lt;/code&gt;&lt;/a&gt;s. But the instances here are like datasets: sequences or samplers and they are turned into sequences of batches of instances with &lt;code&gt;MAP-DATASETS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AMAP-DATASETS-20FUNCTION-29&#34; title=&#34;MGL-DATASET:MAP-DATASETS FUNCTION&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-DATASET-3AMAP-DATASET-20FUNCTION-29&#34; title=&#34;MGL-DATASET:MAP-DATASET FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) &lt;code&gt;:IMPUTE&lt;/code&gt; &lt;code&gt;NIL&lt;/code&gt;. The batch of instances at index 2 is clamped onto the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; at time step 2 with &lt;code&gt;SET-INPUT&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;When the input sequences in the batch are not of the same length, already exhausted sequences will produce &lt;code&gt;NIL&lt;/code&gt; (due to &lt;code&gt;:IMPUTE&lt;/code&gt; &lt;code&gt;NIL&lt;/code&gt;) above. When such a &lt;code&gt;NIL&lt;/code&gt; is clamped with &lt;code&gt;SET-INPUT&lt;/code&gt; on a &lt;code&gt;BPN&lt;/code&gt; of the &lt;code&gt;RNN&lt;/code&gt;, &lt;code&gt;SET-INPUT&lt;/code&gt; must set the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29&#34; title=&#34;MGL-BP:IMPORTANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;LOSS)&#34;&gt;&lt;code&gt;IMPORTANCE&lt;/code&gt;&lt;/a&gt; of the -&amp;gt;ERROR lumps to 0 else training would operate on the noise left there by previous invocations.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Time Warp&lt;/h5&gt; &#xA;&lt;p&gt;The unbounded memory usage of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;s with one &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; allocated per time step can become a problem. For training, where the gradients often have to be backpropagated from the last time step to the very beginning, this is hard to solve but with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:CUDA-WINDOW-START-TIME (MGL-PAX:ACCESSOR MGL-BP:RNN)&#34;&gt;&lt;code&gt;CUDA-WINDOW-START-TIME&lt;/code&gt;&lt;/a&gt; the limit is no longer GPU memory.&lt;/p&gt; &#xA;&lt;p&gt;For prediction on the other hand, one doesn&#39;t need to keep old steps around indefinitely: they can be discarded when future time steps will never reference them again.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[variable] &lt;strong&gt;*WARP-TIME*&lt;/strong&gt; &lt;em&gt;NIL&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Controls whether warping is enabled (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29&#34; title=&#34;Time Warp&#34;&gt;Time Warp&lt;/a&gt;). Don&#39;t enable it for training, as it would make backprop impossible.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AWARPED-TIME-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;WARPED-TIME&lt;/strong&gt; &lt;em&gt;&amp;amp;KEY (RNN *RNN*) (TIME (TIME-STEP :RNN RNN)) (LAG 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return the index of the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; in &lt;code&gt;CLUMPS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of &lt;code&gt;RNN&lt;/code&gt; whose task it is to execute computation at &lt;code&gt;(- (TIME-STEP RNN) LAG)&lt;/code&gt;. This is normally the same as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29&#34; title=&#34;MGL-BP:TIME-STEP FUNCTION&#34;&gt;&lt;code&gt;TIME-STEP&lt;/code&gt;&lt;/a&gt; (disregarding &lt;code&gt;LAG&lt;/code&gt;). That is, &lt;code&gt;CLUMPS&lt;/code&gt; can be indexed by &lt;code&gt;TIME-STEP&lt;/code&gt; to get the &lt;code&gt;BPN&lt;/code&gt;. However, when &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29&#34; title=&#34;MGL-BP:*WARP-TIME* VARIABLE&#34;&gt;&lt;code&gt;*WARP-TIME*&lt;/code&gt;&lt;/a&gt; is true, execution proceeds in a cycle as the structure of the network allows.&lt;/p&gt; &lt;p&gt;Suppose we have a typical &lt;code&gt;RNN&lt;/code&gt; that only ever references the previous time step so its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AMAX-LAG-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:MAX-LAG (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;MAX-LAG&lt;/code&gt;&lt;/a&gt; is 1. Its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; returns &lt;code&gt;BPN&lt;/code&gt;s of identical structure bar a shift in their time lagged connections except for the very first, so &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AWARP-START-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:WARP-START (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;WARP-START&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:WARP-LENGTH (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;WARP-LENGTH&lt;/code&gt;&lt;/a&gt; are both 1. If &lt;code&gt;*WARP-TIME*&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then the mapping from &lt;code&gt;TIME-STEP&lt;/code&gt; to the &lt;code&gt;BPN&lt;/code&gt; in &lt;code&gt;CLUMPS&lt;/code&gt; is straightforward:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  time:   |  0 |  1 |  2 |  3 |  4 |  5&#xA;  --------+----+----+----+----+----+----&#xA;  warped: |  0 |  1 |  2 |  3 |  4 |  5&#xA;  --------+----+----+----+----+----+----&#xA;  bpn:    | b0 | b1 | b2 | b3 | b4 | b5&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When &lt;code&gt;*WARP-TIME*&lt;/code&gt; is true, we reuse the &lt;code&gt;B1&lt;/code&gt; - &lt;code&gt;B2&lt;/code&gt; bpns in a loop:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  time:   |  0 |  1 |  2 |  3 |  4 |  5&#xA;  --------+----+----+----+----+----+----&#xA;  warped: |  0 |  1 |  2 |  1 |  2 |  1&#xA;  --------+----+----+----+----+----+----&#xA;  bpn:    | b0 | b1 | b2 | b1*| b2 | b1*&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;B1*&lt;/code&gt; is the same &lt;code&gt;BPN&lt;/code&gt; as &lt;code&gt;B1&lt;/code&gt;, but its connections created by &lt;code&gt;LAG&lt;/code&gt; go through warped time and end up referencing &lt;code&gt;B2&lt;/code&gt;. This way, memory consumption is independent of the number time steps needed to process a sequence or make predictions.&lt;/p&gt; &lt;p&gt;To be able to pull this trick off &lt;code&gt;WARP-START&lt;/code&gt; and &lt;code&gt;WARP-LENGTH&lt;/code&gt; must be specified when the &lt;code&gt;RNN&lt;/code&gt; is instantiated. In general, with &lt;code&gt;*WARP-TIME*&lt;/code&gt; &lt;code&gt;(+ WARP-START (MAX 2 WARP-LENGTH))&lt;/code&gt; bpns are needed. The 2 comes from the fact that with cycle length 1 a bpn would need to takes its input from itself which is problematic because it has &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; for only one set of values.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AWARP-START-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;WARP-START&lt;/strong&gt; &lt;em&gt;RNN (:WARP-START = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29&#34; title=&#34;MGL-BP:TIME-STEP FUNCTION&#34;&gt;&lt;code&gt;TIME-STEP&lt;/code&gt;&lt;/a&gt; from which &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; will create &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;s that essentially repeat every &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:WARP-LENGTH (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;WARP-LENGTH&lt;/code&gt;&lt;/a&gt; steps.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;WARP-LENGTH&lt;/strong&gt; &lt;em&gt;RNN (:WARP-LENGTH = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;An integer such that the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29&#34; title=&#34;MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN)&#34;&gt;&lt;code&gt;UNFOLDER&lt;/code&gt;&lt;/a&gt; creates at time step &lt;code&gt;I&lt;/code&gt; (where &lt;code&gt;(&amp;lt;= WARP-START I)&lt;/code&gt;) is identical to the &lt;code&gt;BPN&lt;/code&gt; created at time step &lt;code&gt;(+ WARP-START (MOD (- I WARP-START) WARP-LENGTH))&lt;/code&gt; except for a shift in its time lagged connections.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASTEP-MONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;STEP-MONITORS&lt;/strong&gt; &lt;em&gt;RNN (:STEP-MONITORS = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;During training, unfolded &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt;s corresponding to previous time steps may be expensive to get at because they are no longer in GPU memory. This consideration also applies to making prediction with the additional caveat that with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29&#34; title=&#34;MGL-BP:*WARP-TIME* VARIABLE&#34;&gt;&lt;code&gt;*WARP-TIME*&lt;/code&gt;&lt;/a&gt; true, previous states are discarded so it&#39;s not possible to gather statistics after &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:FORWARD GENERIC-FUNCTION&#34;&gt;&lt;code&gt;FORWARD&lt;/code&gt;&lt;/a&gt; finished.&lt;/p&gt; &lt;p&gt;Add monitor objects to this slot and they will be automatically applied to the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt; after each step when &lt;code&gt;FORWARD&lt;/code&gt;ing the &lt;code&gt;RNN&lt;/code&gt; during training or prediction. To be able to easily switch between sets of monitors, in addition to a list of monitors this can be a symbol or a function, too. If it&#39;s a symbol, then its a designator for its &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_symb_5.htm&#34; title=&#34;SYMBOL-VALUE FUNCTION&#34;&gt;&lt;code&gt;SYMBOL-VALUE&lt;/code&gt;&lt;/a&gt;. If it&#39;s a function, then it must have no arguments and it&#39;s a designator for its return value.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;11.4 Lumps&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.1 Lump Base Class&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ALUMP-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;LUMP&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;CLUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A &lt;code&gt;LUMP&lt;/code&gt; is a simple, layerlike component of a neural network. There are many kinds of lumps, each of which performs a specific operation or just stores inputs and weights. By convention, the names of lumps start with the prefix &lt;code&gt;-&amp;gt;&lt;/code&gt;. Defined as classes, they also have a function of the same name as the class to create them easily. These maker functions typically have keyword arguments corresponding to initargs of the class, with some (mainly the input lumps) turned into normal positional arguments. So instead of having to do&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (make-instance &#39;-&amp;gt;tanh :x some-input :name &#39;my-tanh)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;one can simply write&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (-&amp;gt;tanh some-input :name &#39;my-tanh)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Lumps instantiated in any way within a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-FNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-FNN&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29&#34; title=&#34;MGL-BP:BUILD-RNN MGL-PAX:MACRO&#34;&gt;&lt;code&gt;BUILD-RNN&lt;/code&gt;&lt;/a&gt; are automatically added to the network being built.&lt;/p&gt; &lt;p&gt;A lump has its own &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DERIVATIVES&lt;/code&gt;&lt;/a&gt; matrices allocated for it in which the results of the forward and backward passes are stored. This is in contrast to a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; whose &lt;code&gt;NODES&lt;/code&gt; and &lt;code&gt;DERIVATIVES&lt;/code&gt; are those of its last constituent &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Since lumps almost always live within a &lt;code&gt;BPN&lt;/code&gt;, their &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-CORE:N-STRIPES (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AMAX-N-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29&#34; title=&#34;MGL-CORE:MAX-N-STRIPES (MGL-PAX:READER MGL-BP:BPN)&#34;&gt;&lt;code&gt;MAX-N-STRIPES&lt;/code&gt;&lt;/a&gt; are handled automagically behind the scenes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SIZE&lt;/strong&gt; &lt;em&gt;LUMP (:SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of values in a single stripe.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ADEFAULT-VALUE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;DEFAULT-VALUE&lt;/strong&gt; &lt;em&gt;LUMP (:DEFAULT-VALUE = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Upon creation or resize the lump&#39;s nodes get filled with this value.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADEFAULT-SIZE-20GENERIC-FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[generic-function] &lt;strong&gt;DEFAULT-SIZE&lt;/strong&gt; &lt;em&gt;LUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Return a default for the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;SIZE&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;LUMP&lt;/code&gt; if one is not supplied at instantiation. The value is often computed based on the sizes of the inputs. This function is for implementing new lump types.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ANODES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;NODES&lt;/strong&gt; &lt;em&gt;LUMP (= NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The values computed by the lump in the forward pass are stored here. It is an &lt;code&gt;N-STRIPES * SIZE&lt;/code&gt; matrix that has storage allocated for &lt;code&gt;MAX-N-STRIPES * SIZE&lt;/code&gt; elements for non-weight lumps. &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lumps have no stripes nor restrictions on their shape.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADERIVATIVES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;DERIVATIVES&lt;/strong&gt; &lt;em&gt;LUMP&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The derivatives computed in the backward pass are stored here. This matrix is very much like &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:NODES (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; in shape and size.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.2 Inputs&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-INPUT-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Input Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EINPUT-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;INPUT&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EDROPOUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;DROPOUT CLASS&#34;&gt;-&amp;gt;DROPOUT&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A lump that has no input lumps, does not change its values in the forward pass (except when &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EINPUT-29-29&#34; title=&#34;MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;INPUT)&#34;&gt;&lt;code&gt;DROPOUT&lt;/code&gt;&lt;/a&gt; is non-zero), and does not compute derivatives. &lt;em&gt;Clamp&lt;/em&gt; inputs on &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; of input lumps in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For convenience, &lt;code&gt;-&amp;gt;INPUT&lt;/code&gt; can perform dropout itself although it defaults to no dropout.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;input :size 10 :name &#39;some-input)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;INPUT SOME-INPUT :SIZE 10 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EINPUT-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;DROPOUT&lt;/strong&gt; &lt;em&gt;-&amp;gt;INPUT (= NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29&#34; title=&#34;MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;DROPOUT)&#34;&gt;&lt;code&gt;DROPOUT&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-EMBEDDING-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Embedding Lump&lt;/h5&gt; &#xA;&lt;p&gt;This lump is like an input and a simple activation molded together in the name of efficiency.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EEMBEDDING-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;EMBEDDING&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Select rows of &lt;code&gt;WEIGHTS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;), one row for each index in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-BP:INPUT-ROW-INDICES (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;INPUT-ROW-INDICES&lt;/code&gt;&lt;/a&gt;. This lump is equivalent to adding an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EINPUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;INPUT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;INPUT&lt;/code&gt;&lt;/a&gt; lump with a one hot encoding scheme and a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EV-2AM-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;V*M CLASS&#34;&gt;&lt;code&gt;-&amp;gt;V*M&lt;/code&gt;&lt;/a&gt; lump on top of it, but it is more efficient in execution and in memory usage, because it works with a sparse representation of the input.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the number of columns of &lt;code&gt;WEIGHTS&lt;/code&gt; which is determined automatically.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;embedding :weights (-&amp;gt;weight :name &#39;embedding-weights&#xA;                                :dimensions &#39;(3 5))&#xA;             :name &#39;embeddings)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;EMBEDDING EMBEDDINGS :SIZE 5 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;WEIGHTS&lt;/strong&gt; &lt;em&gt;-&amp;gt;EMBEDDING (:WEIGHTS)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A weight lump whose rows indexed by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-BP:INPUT-ROW-INDICES (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;INPUT-ROW-INDICES&lt;/code&gt;&lt;/a&gt; are copied to the output of this lump.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;INPUT-ROW-INDICES&lt;/strong&gt; &lt;em&gt;-&amp;gt;EMBEDDING (:INPUT-ROW-INDICES)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A sequence of batch size length of row indices. To be set in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.3 Weight Lump&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;WEIGHT&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A set of optimizable parameters of some kind. When a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; is is trained (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29&#34; title=&#34;Training&#34;&gt;Training&lt;/a&gt;) the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; of weight lumps will be changed. Weight lumps perform no computation.&lt;/p&gt; &lt;p&gt;Weights can be created by specifying the total size or the dimensions:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(dimensions (-&amp;gt;weight :size 10 :name &#39;w))&#xA;=&amp;gt; (1 10)&#xA;(dimensions (-&amp;gt;weight :dimensions &#39;(5 10) :name &#39;w))&#xA;=&amp;gt; (5 10)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADIMENSIONS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EWEIGHT-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;DIMENSIONS&lt;/strong&gt; &lt;em&gt;-&amp;gt;WEIGHT (:DIMENSIONS)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DERIVATIVES&lt;/code&gt;&lt;/a&gt; of this lump will be allocated with these dimensions.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AWITH-WEIGHTS-COPIED-20MGL-PAX-3AMACRO-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[macro] &lt;strong&gt;WITH-WEIGHTS-COPIED&lt;/strong&gt; &lt;em&gt;(FROM-BPN) &amp;amp;BODY BODY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In &lt;code&gt;BODY&lt;/code&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; will first look up if a weight lump of the same name exists in &lt;code&gt;FROM-BPN&lt;/code&gt; and return that, or else create a weight lump normally. If &lt;code&gt;FROM-BPN&lt;/code&gt; is &lt;code&gt;NIL&lt;/code&gt;, then no weights are copied.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-ACTIVATIONS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.4 Activations&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Activation Subnet&lt;/h5&gt; &#xA;&lt;p&gt;So we have some inputs. Usually the next step is to multiply the input vector with a weight matrix and add biases. This can be done directly with -&amp;gt;+, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EV-2AM-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;V*M CLASS&#34;&gt;&lt;code&gt;-&amp;gt;V*M&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt;, but it&#39;s more convenient to use activation subnets to reduce the clutter.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EACTIVATION-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;ACTIVATION&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;BPN&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Activation subnetworks are built by the function &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION FUNCTION&#34;&gt;&lt;code&gt;-&amp;gt;ACTIVATION&lt;/code&gt;&lt;/a&gt; and they have a number of lumps hidden inside them. Ultimately, this subnetwork computes a sum like &lt;code&gt;sum_i x_i * W_i + sum_j y_j .* V_j + biases&lt;/code&gt; where &lt;code&gt;x_i&lt;/code&gt; are input lumps, &lt;code&gt;W_i&lt;/code&gt; are dense matrices representing connections, while &lt;code&gt;V_j&lt;/code&gt; are peephole connection vectors that are mulitplied in an elementwise manner with their corresponding input &lt;code&gt;y_j&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;-&amp;gt;ACTIVATION&lt;/strong&gt; &lt;em&gt;INPUTS &amp;amp;KEY (NAME (GENSYM)) SIZE PEEPHOLES (ADD-BIAS-P T)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create a subnetwork of class &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION CLASS&#34;&gt;&lt;code&gt;-&amp;gt;ACTIVATION&lt;/code&gt;&lt;/a&gt; that computes the over activation from dense connection from lumps in &lt;code&gt;INPUTS&lt;/code&gt;, and elementwise connection from lumps in &lt;code&gt;PEEPHOLES&lt;/code&gt;. Create new &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lumps as necessary. &lt;code&gt;INPUTS&lt;/code&gt; and &lt;code&gt;PEEPHOLES&lt;/code&gt; can be a single lump or a list of lumps. Finally, if &lt;code&gt;ADD-BIAS-P&lt;/code&gt;, then add an elementwise bias too. &lt;code&gt;SIZE&lt;/code&gt; must be specified explicitly, because it is not possible to determine it unless there are peephole connections.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;activation (-&amp;gt;input :size 10 :name &#39;input) :name &#39;h1 :size 4)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;ACTIVATION (H1 :ACTIVATION) :STRIPES 1/1 :CLUMPS 4&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is the basic workhorse of neural networks which takes care of the linear transformation whose results and then fed to some non-linearity (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;SIGMOID CLASS&#34;&gt;&lt;code&gt;-&amp;gt;SIGMOID&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ETANH-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;TANH CLASS&#34;&gt;&lt;code&gt;-&amp;gt;TANH&lt;/code&gt;&lt;/a&gt;, etc).&lt;/p&gt; &lt;p&gt;The name of the subnetwork clump is &lt;code&gt;(,NAME :ACTIVATION)&lt;/code&gt;. The bias weight lump (if any) is named &lt;code&gt;(:BIAS ,NAME)&lt;/code&gt;. Dense connection weight lumps are named are named after the input and &lt;code&gt;NAME&lt;/code&gt;: &lt;code&gt;(,(NAME INPUT) ,NAME)&lt;/code&gt;, while peepholes weight lumps are named &lt;code&gt;(,(NAME INPUT) ,NAME :PEEPHOLE)&lt;/code&gt;. This is useful to know if, for example, they are to be initialized differently.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-BATCH-NORMALIZATION-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Batch-Normalization&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EBATCH-NORMALIZED-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;BATCH-NORMALIZED&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is an implementation of v3 of the &lt;a href=&#34;http://arxiv.org/abs/1502.03167&#34;&gt;Batch Normalization paper&lt;/a&gt;. The output of &lt;code&gt;-&amp;gt;BATCH-NORMALIZED&lt;/code&gt; is its input normalized so that for all elements the mean across stripes is zero and the variance is 1. That is, the mean of the batch is subtracted from the inputs and they are rescaled by their sample stddev. Actually, after the normalization step the values are rescaled and shifted (but this time with learnt parameters) in order to keep the representational power of the model the same. The primary purpose of this lump is to speed up learning, but it also acts as a regularizer. See the paper for the details.&lt;/p&gt; &lt;p&gt;To normalize the output of &lt;code&gt;LUMP&lt;/code&gt; without no additional regularizer effect:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;batch-normalized lump :batch-size :use-population)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The above uses an exponential moving average to estimate the mean and variance of batches and these estimations are used at both training and test time. In contrast to this, the published version uses the sample mean and variance of the current batch at training time which injects noise into the process. The noise is higher for lower batch sizes and has a regularizing effect. This is the default behavior (equivalent to &lt;code&gt;:BATCH-SIZE NIL&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;batch-normalized lump)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For performance reasons one may wish to process a higher number of instances in a batch (in the sense of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt;) and get the regularization effect associated with a lower batch size. This is possible by setting &lt;code&gt;:BATCH-SIZE&lt;/code&gt; to a divisor of the the number of stripes. Say, the number of stripes is 128, but we want as much regularization as we would get with 32:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;batch-normalized lump :batch-size 32)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The primary input of &lt;code&gt;-&amp;gt;BATCH-NORMALIZED&lt;/code&gt; is often an &lt;code&gt;-&amp;gt;ACTIVATION&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION CLASS&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) and its output is fed into an activation function (see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29&#34; title=&#34;Activation Functions&#34;&gt;Activation Functions&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ABATCH-NORMALIZATION-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZED-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;BATCH-NORMALIZATION&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZED (:NORMALIZATION)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EBATCH-NORMALIZATION-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;BATCH-NORMALIZATION CLASS&#34;&gt;&lt;code&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/code&gt;&lt;/a&gt; of this lump. May be shared between multiple &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EBATCH-NORMALIZED-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;BATCH-NORMALIZED CLASS&#34;&gt;&lt;code&gt;-&amp;gt;BATCH-NORMALIZED&lt;/code&gt;&lt;/a&gt; lumps.&lt;/p&gt; &lt;p&gt;Batch normalization is special in that it has state apart from the computed results (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt;) and its derivatives (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-BP:DERIVATIVES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;DERIVATIVES&lt;/code&gt;&lt;/a&gt;). This state is the estimated mean and variance of its inputs and they are encapsulated by &lt;code&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;NORMALIZATION&lt;/code&gt; is not given at instantiation, then a new &lt;code&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/code&gt; object will be created automatically, passing &lt;code&gt;:BATCH-SIZE&lt;/code&gt;, &lt;code&gt;:VARIANCE-ADJUSTMENT&lt;/code&gt;, and &lt;code&gt;:POPULATION-DECAY&lt;/code&gt; arguments on to &lt;code&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/code&gt;. See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;BATCH-SIZE&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AVARIANCE-ADJUSTMENT-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-GD:VARIANCE-ADJUSTMENT (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;VARIANCE-ADJUSTMENT&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3APOPULATION-DECAY-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-BP:POPULATION-DECAY (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;POPULATION-DECAY&lt;/code&gt;&lt;/a&gt;. New scale and shift weight lumps will be created with names:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  `(,name :scale)&#xA;  `(,name :shift)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;where &lt;code&gt;NAME&lt;/code&gt; is the &lt;code&gt;NAME&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANAME-20-28METHOD-20NIL-20-28MGL-CORE-3AATTRIBUTED-29-29-29&#34; title=&#34;MGL-COMMON:NAME (METHOD NIL (MGL-CORE:ATTRIBUTED))&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANAME-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29&#34; title=&#34;MGL-COMMON:NAME (MGL-PAX:READER MGL-DATASET:FUNCTION-SAMPLER)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump.&lt;/p&gt; &lt;p&gt;This default behavior covers the use-case where the statistics kept by &lt;code&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/code&gt; are to be shared only between time steps of an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EBATCH-NORMALIZATION-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;BATCH-NORMALIZATION&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;-&amp;gt;WEIGHT&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The primary purpose of this class is to hold the estimated mean and variance of the inputs to be normalized and allow them to be shared between multiple &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EBATCH-NORMALIZED-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;BATCH-NORMALIZED CLASS&#34;&gt;&lt;code&gt;-&amp;gt;BATCH-NORMALIZED&lt;/code&gt;&lt;/a&gt; lumps that carry out the computation. These estimations are saved and loaded by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASAVE-STATE-20FUNCTION-29&#34; title=&#34;MGL-CORE:SAVE-STATE FUNCTION&#34;&gt;&lt;code&gt;SAVE-STATE&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ALOAD-STATE-20FUNCTION-29&#34; title=&#34;MGL-CORE:LOAD-STATE FUNCTION&#34;&gt;&lt;code&gt;LOAD-STATE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;batch-normalization (-&amp;gt;weight :name &#39;(h1 :scale) :size 10)&#xA;                       (-&amp;gt;weight :name &#39;(h1 :shift) :size 10)&#xA;                       :name &#39;(h1 :batch-normalization))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ASCALE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SCALE&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZATION (:SCALE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A weight lump of the same size as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ASHIFT-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-BP:SHIFT (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;SHIFT&lt;/code&gt;&lt;/a&gt;. This is $\gamma$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASHIFT-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SHIFT&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZATION (:SHIFT)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A weight lump of the same size as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASCALE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:SCALE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;SCALE&lt;/code&gt;&lt;/a&gt;. This is $\beta$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;BATCH-SIZE&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZATION (:BATCH-SIZE = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Normally all stripes participate in the batch. Lowering the number of stripes may increase the regularization effect, but it also makes the computation less efficient. By setting &lt;code&gt;BATCH-SIZE&lt;/code&gt; to a divisor of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:N-STRIPES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;N-STRIPES&lt;/code&gt;&lt;/a&gt; one can decouple the concern of efficiency from that of regularization. The default value, &lt;code&gt;NIL&lt;/code&gt;, is equivalent to &lt;code&gt;N-STRIPES&lt;/code&gt;. &lt;code&gt;BATCH-SIZE&lt;/code&gt; only affects training.&lt;/p&gt; &lt;p&gt;With the special value &lt;code&gt;:USE-POPULATION&lt;/code&gt;, instead of the mean and the variance of the current batch, use the population statistics for normalization. This effectively cancels the regularization effect, leaving only the faster learning.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-GD-3AVARIANCE-ADJUSTMENT-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;VARIANCE-ADJUSTMENT&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZATION (:VARIANCE-ADJUSTMENT = 1.0e-4)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A small positive real number that&#39;s added to the sample variance. This is $\epsilon$ in the paper.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3APOPULATION-DECAY-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;POPULATION-DECAY&lt;/strong&gt; &lt;em&gt;-&amp;gt;BATCH-NORMALIZATION (:POPULATION-DECAY = 0.99)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;While training, an exponential moving average of batch means and standard deviances (termed &lt;em&gt;population statistics&lt;/em&gt;) is updated. When making predictions, normalization is performed using these statistics. These population statistics are persisted by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASAVE-STATE-20FUNCTION-29&#34; title=&#34;MGL-CORE:SAVE-STATE FUNCTION&#34;&gt;&lt;code&gt;SAVE-STATE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EBATCH-NORMALIZED-ACTIVATION-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;-&amp;gt;BATCH-NORMALIZED-ACTIVATION&lt;/strong&gt; &lt;em&gt;INPUTS &amp;amp;KEY (NAME (GENSYM)) SIZE PEEPHOLES BATCH-SIZE VARIANCE-ADJUSTMENT POPULATION-DECAY&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A utility functions that creates and wraps an &lt;code&gt;-&amp;gt;ACTIVATION&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION CLASS&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EBATCH-NORMALIZED-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;BATCH-NORMALIZED CLASS&#34;&gt;&lt;code&gt;-&amp;gt;BATCH-NORMALIZED&lt;/code&gt;&lt;/a&gt; and with its &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABATCH-NORMALIZATION-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZED-29-29&#34; title=&#34;MGL-BP:BATCH-NORMALIZATION (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZED)&#34;&gt;&lt;code&gt;BATCH-NORMALIZATION&lt;/code&gt;&lt;/a&gt; the two weight lumps for the scale and shift parameters. &lt;code&gt;(-&amp;gt;BATCH-NORMALIZED-ACTIVATION INPUTS :NAME &#39;H1 :SIZE 10)&lt;/code&gt; is equivalent to:&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-commonlisp&#34;&gt;(-&amp;gt;batch-normalized (-&amp;gt;activation inputs :name &#39;h1 :size 10 :add-bias-p nil)&#xA;                    :name &#39;(h1 :batch-normalized-activation))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how biases are turned off since normalization will cancel them anyway (but a shift is added which amounts to the same effect).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.5 Activation Functions&lt;/h4&gt; &#xA;&lt;p&gt;Now we are moving on to the most important non-linearities to which activations are fed.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SIGMOID-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Sigmoid Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESIGMOID-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SIGMOID&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EDROPOUT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;DROPOUT CLASS&#34;&gt;-&amp;gt;DROPOUT&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Applies the &lt;code&gt;1/(1 + e^{-x})&lt;/code&gt; function elementwise to its inputs. This is one of the classic non-linearities for neural networks.&lt;/p&gt; &lt;p&gt;For convenience, &lt;code&gt;-&amp;gt;SIGMOID&lt;/code&gt; can perform dropout itself although it defaults to no dropout.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;sigmoid (-&amp;gt;activation (-&amp;gt;input :size 10) :size 5) :name &#39;this)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;SIGMOID THIS :SIZE 5 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESIGMOID-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;DROPOUT&lt;/strong&gt; &lt;em&gt;-&amp;gt;SIGMOID (= NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;See &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29&#34; title=&#34;MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;DROPOUT)&#34;&gt;&lt;code&gt;DROPOUT&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-TANH-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Tanh Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ETANH-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;TANH&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Applies the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_sinh_.htm&#34; title=&#34;TANH FUNCTION&#34;&gt;&lt;code&gt;TANH&lt;/code&gt;&lt;/a&gt; function to its input in an elementwise manner. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SCALED-TANH-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Scaled Tanh Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESCALED-TANH-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SCALED-TANH&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Pretty much like &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_sinh_.htm&#34; title=&#34;TANH FUNCTION&#34;&gt;&lt;code&gt;TANH&lt;/code&gt;&lt;/a&gt; but its input and output is scaled in such a way that the variance of its output is close to 1 if the variance of its input is close to 1 which is a nice property to combat vanishing gradients. The actual function is &lt;code&gt;1.7159 * tanh(2/3 * x)&lt;/code&gt;. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-RELU-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Relu Lump&lt;/h5&gt; &#xA;&lt;p&gt;We are somewhere around year 2007 by now.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ERELU-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;RELU&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;max(0,x)&lt;/code&gt; activation function. Be careful, relu units can get stuck in the off state: if they move to far to negative territory it can be very difficult to get out of it. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-MAX-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Max Lump&lt;/h5&gt; &#xA;&lt;p&gt;We are in about year 2011.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EMAX-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;MAX&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is basically maxout without dropout (see &lt;a href=&#34;http://arxiv.org/abs/1302.4389&#34;&gt;http://arxiv.org/abs/1302.4389&lt;/a&gt;). It groups its inputs by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;MAX)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt;, and outputs the maximum of each group. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of the output is automatically calculated, it is the size of the input divided by &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;MAX)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;max (-&amp;gt;input :size 120) :group-size 3 :name &#39;my-max)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;MAX MY-MAX :SIZE 40 1/1 :NORM 0.00000 :GROUP-SIZE 3&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The advantage of &lt;code&gt;-&amp;gt;MAX&lt;/code&gt; over &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ERELU-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;RELU CLASS&#34;&gt;&lt;code&gt;-&amp;gt;RELU&lt;/code&gt;&lt;/a&gt; is that flow gradient is never stopped so there is no problem of units getting stuck in off state.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;GROUP-SIZE&lt;/strong&gt; &lt;em&gt;-&amp;gt;MAX (:GROUP-SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of inputs in each group.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-MIN-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Min Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EMIN-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;MIN&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Same as &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EMAX-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;MAX CLASS&#34;&gt;&lt;code&gt;-&amp;gt;MAX&lt;/code&gt;&lt;/a&gt;, but it computes the &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_max_m.htm&#34; title=&#34;MIN FUNCTION&#34;&gt;&lt;code&gt;MIN&lt;/code&gt;&lt;/a&gt; of groups. Rarely useful.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMIN-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;GROUP-SIZE&lt;/strong&gt; &lt;em&gt;-&amp;gt;MIN (:GROUP-SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of inputs in each group.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-MAX-CHANNEL-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Max-Channel Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EMAX-CHANNEL-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;MAX-CHANNEL&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Called LWTA (Local Winner Take All) or Channel-Out (see &lt;a href=&#34;http://arxiv.org/abs/1312.1909&#34;&gt;http://arxiv.org/abs/1312.1909&lt;/a&gt;) in the literature it is basically &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EMAX-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;MAX CLASS&#34;&gt;&lt;code&gt;-&amp;gt;MAX&lt;/code&gt;&lt;/a&gt;, but instead of producing one output per group, it just produces zeros for all unit but the one with the maximum value in the group. This allows the next layer to get some information about the path along which information flowed. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-CHANNEL-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;GROUP-SIZE&lt;/strong&gt; &lt;em&gt;-&amp;gt;MAX-CHANNEL (:GROUP-SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of inputs in each group.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.6 Losses&lt;/h4&gt; &#xA;&lt;p&gt;Ultimately, we need to tell the network what to learn which means that the loss function to be minimized needs to be constructed as part of the network.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-LOSS-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Loss Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ELOSS-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;LOSS&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ESUM-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;SUM CLASS&#34;&gt;-&amp;gt;SUM&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Calculate the loss for the instances in the batch. The main purpose of this lump is to provide a training signal.&lt;/p&gt; &lt;p&gt;An error lump is usually a leaf in the graph of lumps (i.e. there are no other lumps whose input is this one). The special thing about error lumps is that 1 (but see &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29&#34; title=&#34;MGL-BP:IMPORTANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;LOSS)&#34;&gt;&lt;code&gt;IMPORTANCE&lt;/code&gt;&lt;/a&gt;) is added automatically to their derivatives. Error lumps have exactly one node (per stripe) whose value is computed as the sum of nodes in their input lump.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;IMPORTANCE&lt;/strong&gt; &lt;em&gt;-&amp;gt;LOSS (:IMPORTANCE = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This is to support weighted instances. That is when not all training instances are equally important. If non-NIL, a 1d &lt;code&gt;MAT&lt;/code&gt; with the importances of stripes of the batch. When &lt;code&gt;IMPORTANCE&lt;/code&gt; is given (typically in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;), then instead of adding 1 to the derivatives of all stripes, &lt;code&gt;IMPORTANCE&lt;/code&gt; is added elemtwise.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SQUARED-DIFFERENCE-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Squared Difference Lump&lt;/h5&gt; &#xA;&lt;p&gt;In regression, the squared error loss is most common. The squared error loss can be constructed by combining &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ESQUARED-DIFFERENCE-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;SQUARED-DIFFERENCE CLASS&#34;&gt;&lt;code&gt;-&amp;gt;SQUARED-DIFFERENCE&lt;/code&gt;&lt;/a&gt; with a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ELOSS-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;LOSS CLASS&#34;&gt;&lt;code&gt;-&amp;gt;LOSS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESQUARED-DIFFERENCE-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SQUARED-DIFFERENCE&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This lump takes two input lumps and calculates their squared difference &lt;code&gt;(x - y)^2&lt;/code&gt; in an elementwise manner. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is automatically determined from the size of its inputs. This lump is often fed into &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ELOSS-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;LOSS CLASS&#34;&gt;&lt;code&gt;-&amp;gt;LOSS&lt;/code&gt;&lt;/a&gt; that sums the squared differences and makes it part of the function to be minimized.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;loss (-&amp;gt;squared-difference (-&amp;gt;activation (-&amp;gt;input :size 100)&#xA;                                            :size 10)&#xA;                              (-&amp;gt;input :name &#39;target :size 10))&#xA;        :name &#39;squared-error)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;LOSS SQUARED-ERROR :SIZE 1 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Currently this lump is not CUDAized, but it will copy data from the GPU if it needs to.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SOFTMAX-XE-LOSS-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Softmax Cross-Entropy Loss Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESOFTMAX-XE-LOSS-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SOFTMAX-XE-LOSS&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A specialized lump that computes the softmax of its input in the forward pass and backpropagates a cross-entropy loss. The advantage of doing these together is numerical stability. The total cross-entropy is the sum of cross-entropies per group of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt; elements:&lt;/p&gt; &lt;p&gt;$$ XE(x) = - \sum_{i=1,g} t_i \ln(s_i), $$&lt;/p&gt; &lt;p&gt;where &lt;code&gt;g&lt;/code&gt; is the number of classes (&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt;), &lt;code&gt;t_i&lt;/code&gt; are the targets (i.e. the true probabilities of the class, often all zero but one), &lt;code&gt;s_i&lt;/code&gt; is the output of softmax calculated from input &lt;code&gt;X&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;$$ s_i = {softmax}(x_1, x_2, ..., x_g) = \frac{e^x_i}{\sum_{j=1,g} e^x_j} $$&lt;/p&gt; &lt;p&gt;In other words, in the forward phase this lump takes input &lt;code&gt;X&lt;/code&gt;, computes its elementwise &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_exp_e.htm&#34; title=&#34;EXP FUNCTION&#34;&gt;&lt;code&gt;EXP&lt;/code&gt;&lt;/a&gt;, normalizes each group of &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt; elements to sum to 1 to get the softmax which is the result that goes into &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:NODES GENERIC-FUNCTION&#34;&gt;&lt;code&gt;NODES&lt;/code&gt;&lt;/a&gt;. In the backward phase, there are two sources of gradients: the lumps that use the output of this lump as their input (currently not implemented and would result in an error) and an implicit cross-entropy loss.&lt;/p&gt; &lt;p&gt;One can get the cross-entropy calculated in the most recent forward pass by calling &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ACOST-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-COMMON:COST GENERIC-FUNCTION&#34;&gt;&lt;code&gt;COST&lt;/code&gt;&lt;/a&gt; on this lump.&lt;/p&gt; &lt;p&gt;This is the most common loss function for classification. In fact, it is nearly ubiquitous. See the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34; title=&#34;`FNN` Tutorial&#34;&gt;&lt;code&gt;FNN&lt;/code&gt; Tutorial&lt;/a&gt; and the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29&#34; title=&#34;`RNN` Tutorial&#34;&gt;&lt;code&gt;RNN&lt;/code&gt; Tutorial&lt;/a&gt; for how this loss and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt; work together.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;GROUP-SIZE&lt;/strong&gt; &lt;em&gt;-&amp;gt;SOFTMAX-XE-LOSS (:GROUP-SIZE)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The number of elements in a softmax group. This is the number of classes for classification. Often &lt;code&gt;GROUP-SIZE&lt;/code&gt; is equal to &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) (it is the default), but in general the only constraint is that &lt;code&gt;SIZE&lt;/code&gt; is a multiple of &lt;code&gt;GROUP-SIZE&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3ATARGET-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;TARGET&lt;/strong&gt; &lt;em&gt;-&amp;gt;SOFTMAX-XE-LOSS (:TARGET = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Set in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:SET-INPUT GENERIC-FUNCTION&#34;&gt;&lt;code&gt;SET-INPUT&lt;/code&gt;&lt;/a&gt;, this is either a &lt;code&gt;MAT&lt;/code&gt; of the same size as the input lump &lt;code&gt;X&lt;/code&gt; or if the target is very sparse, this can also be a sequence of batch size length that contains the index value pairs of non-zero entries:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;  (;; first instance in batch has two non-zero targets&#xA;   (;; class 10 has 30% expected probability&#xA;    (10 . 0.3)&#xA;    ;; class 2 has 70% expected probability&#xA;    (2 .  0.7))&#xA;   ;; second instance in batch puts 100% on class 7&#xA;   7&#xA;   ;; more instances in the batch follow&#xA;   ...)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Actually, in the rare case where &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt; is not &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) (i.e. there are several softmax normalization groups for every example), the length of the above target sequence is &lt;code&gt;BATCH-SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EBATCH-NORMALIZATION-29-29&#34; title=&#34;MGL-COMMON:BATCH-SIZE (MGL-PAX:READER MGL-BP:-&gt;BATCH-NORMALIZATION)&#34;&gt;&lt;code&gt;2&lt;/code&gt;&lt;/a&gt;) * N-GROUPS. Indices are always relative to the start of the group.&lt;/p&gt; &lt;p&gt;If &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;GROUP-SIZE&lt;/code&gt;&lt;/a&gt; is large (for example, in neural language models with a huge number of words), using sparse targets can make things go much faster, because calculation of the derivative is no longer quadratic.&lt;/p&gt; &lt;p&gt;Giving different weights to training instances is implicitly supported. While target values in a group should sum to 1, multiplying all target values with a weight &lt;code&gt;W&lt;/code&gt; is equivalent to training that &lt;code&gt;W&lt;/code&gt; times on the same example.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AENSURE-SOFTMAX-TARGET-MATRIX-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ENSURE-SOFTMAX-TARGET-MATRIX&lt;/strong&gt; &lt;em&gt;SOFTMAX-XE-LOSS N&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Set &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ATARGET-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29&#34; title=&#34;MGL-COMMON:TARGET (MGL-PAX:ACCESSOR MGL-BP:-&gt;SOFTMAX-XE-LOSS)&#34;&gt;&lt;code&gt;TARGET&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;SOFTMAX-XE-LOSS&lt;/code&gt; to a &lt;code&gt;MAT&lt;/code&gt; capable of holding the dense target values for &lt;code&gt;N&lt;/code&gt; stripes.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.7 Stochasticity&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-DROPOUT-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Dropout Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EDROPOUT-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;DROPOUT&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The output of this lump is identical to its input, except it randomly zeroes out some of them during training which act as a very strong regularizer. See Geoffrey Hinton&#39;s &#39;Improving neural networks by preventing co-adaptation of feature detectors&#39;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is the size of its input which is determined automatically.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;DROPOUT&lt;/strong&gt; &lt;em&gt;-&amp;gt;DROPOUT (:DROPOUT = 0.5)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If non-NIL, then in the forward pass zero out each node in this chunk with &lt;code&gt;DROPOUT&lt;/code&gt; probability.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-GAUSSIAN-RANDOM-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Gaussian Random Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EGAUSSIAN-RANDOM-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;GAUSSIAN-RANDOM&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;This lump has no input, it produces normally distributed independent random numbers with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AMEAN-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34; title=&#34;MGL-BP:MEAN (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM)&#34;&gt;&lt;code&gt;MEAN&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34; title=&#34;MGL-BP:VARIANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM)&#34;&gt;&lt;code&gt;VARIANCE&lt;/code&gt;&lt;/a&gt; (or &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AVARIANCE-FOR-PREDICTION-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34; title=&#34;MGL-BP:VARIANCE-FOR-PREDICTION (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM)&#34;&gt;&lt;code&gt;VARIANCE-FOR-PREDICTION&lt;/code&gt;&lt;/a&gt;). This is useful building block for noise based regularization methods.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;gaussian-random :size 10 :name &#39;normal :mean 1 :variance 2)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;GAUSSIAN-RANDOM NORMAL :SIZE 10 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AMEAN-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;MEAN&lt;/strong&gt; &lt;em&gt;-&amp;gt;GAUSSIAN-RANDOM (:MEAN = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The mean of the normal distribution.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;VARIANCE&lt;/strong&gt; &lt;em&gt;-&amp;gt;GAUSSIAN-RANDOM (:VARIANCE = 1)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The variance of the normal distribution.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AVARIANCE-FOR-PREDICTION-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;VARIANCE-FOR-PREDICTION&lt;/strong&gt; &lt;em&gt;-&amp;gt;GAUSSIAN-RANDOM (:VARIANCE-FOR-PREDICTION = 0)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If not &lt;code&gt;NIL&lt;/code&gt;, then this value overrides &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29&#34; title=&#34;MGL-BP:VARIANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM)&#34;&gt;&lt;code&gt;VARIANCE&lt;/code&gt;&lt;/a&gt; when not in training (i.e. when making predictions).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SAMPLE-BINARY-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Binary Sampling Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESAMPLE-BINARY-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SAMPLE-BINARY&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Treating values of its input as probabilities, sample independent binomials. Turn true into 1 and false into 0. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is determined automatically from the size of its input.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;sample-binary (-&amp;gt;input :size 10) :name &#39;binarized-input)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;SAMPLE-BINARY BINARIZED-INPUT :SIZE 10 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.8 Arithmetic&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SUM-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Sum Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESUM-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SUM&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Computes the sum of all nodes of its input per stripe. This &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is always 1.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-V-2AM-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Vector-Matrix Multiplication Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EV-2AM-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;V*M&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Perform &lt;code&gt;X * WEIGHTS&lt;/code&gt; where &lt;code&gt;X&lt;/code&gt; (the input) is of size &lt;code&gt;M&lt;/code&gt; and &lt;code&gt;WEIGHTS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) is a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; whose single stripe is taken to be of dimensions &lt;code&gt;M x N&lt;/code&gt; stored in row major order. &lt;code&gt;N&lt;/code&gt; is the size of this lump. If &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ATRANSPOSE-WEIGHTS-P-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34; title=&#34;MGL-BP:TRANSPOSE-WEIGHTS-P (MGL-PAX:READER MGL-BP:-&gt;V*M)&#34;&gt;&lt;code&gt;TRANSPOSE-WEIGHTS-P&lt;/code&gt;&lt;/a&gt; then &lt;code&gt;WEIGHTS&lt;/code&gt; is &lt;code&gt;N x M&lt;/code&gt; and `X&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt;WEIGHTS&#39;` is computed.&lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;WEIGHTS&lt;/strong&gt; &lt;em&gt;-&amp;gt;V*M (:WEIGHTS)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lump.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ATRANSPOSE-WEIGHTS-P-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;TRANSPOSE-WEIGHTS-P&lt;/strong&gt; &lt;em&gt;-&amp;gt;V*M (:TRANSPOSE-WEIGHTS-P = NIL)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Determines whether the input is multiplied by &lt;code&gt;WEIGHTS&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29&#34; title=&#34;MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) or its transpose.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP--2B-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Elementwise Addition Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3E-2B-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;+&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Performs elementwise addition on its input lumps. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is automatically determined from the size of its inputs if there is at least one. If one of the inputs is a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lump, then it is added to every stripe.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;+ (list (-&amp;gt;input :size 10) (-&amp;gt;weight :size 10 :name &#39;bias))&#xA;     :name &#39;plus)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;+ PLUS :SIZE 10 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP--2A-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Elementwise Multiplication Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3E-2A-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;*&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Performs elementwise multiplication on its two input lumps. The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is automatically determined from the size of its inputs. Either input can be a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;WEIGHT CLASS&#34;&gt;&lt;code&gt;-&amp;gt;WEIGHT&lt;/code&gt;&lt;/a&gt; lump.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(-&amp;gt;* (-&amp;gt;input :size 10) (-&amp;gt;weight :size 10 :name &#39;scale)&#xA;     :name &#39;mult)&#xA;==&amp;gt; #&amp;lt;-&amp;gt;* MULT :SIZE 10 1/1 :NORM 0.00000&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-ABS-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Abs Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EABS-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[class] &lt;strong&gt;-&amp;gt;ABS&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-EXP-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Exp Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3EEXP-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[class] &lt;strong&gt;-&amp;gt;EXP&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-NORMALIZED-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Normalized Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ENORMALIZED-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[class] &lt;strong&gt;-&amp;gt;NORMALIZED&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h4&gt;11.4.9 Operations for &lt;code&gt;RNN&lt;/code&gt;s&lt;/h4&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-LSTM-SUBNET-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;LSTM Subnet&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ELSTM-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;LSTM&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;BPN&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Long-Short Term Memory subnetworks are built by the function &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3ELSTM-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;LSTM FUNCTION&#34;&gt;&lt;code&gt;-&amp;gt;LSTM&lt;/code&gt;&lt;/a&gt; and they have many lumps hidden inside them. These lumps are packaged into a subnetwork to reduce clutter.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ELSTM-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;-&amp;gt;LSTM&lt;/strong&gt; &lt;em&gt;INPUTS &amp;amp;KEY NAME CELL-INIT OUTPUT-INIT SIZE (ACTIVATION-FN &#39;-&amp;gt;ACTIVATION) (GATE-FN &#39;-&amp;gt;SIGMOID) (INPUT-FN &#39;-&amp;gt;TANH) (OUTPUT-FN &#39;-&amp;gt;TANH) (PEEPHOLES T)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Create an LSTM layer consisting of input, forget, output gates with which input, cell state and output are scaled. Lots of lumps are created, the final one representing to output of the LSTM has &lt;code&gt;NAME&lt;/code&gt;. The rest of the lumps are named automatically based on &lt;code&gt;NAME&lt;/code&gt;. This function returns only the output lump (&lt;code&gt;m&lt;/code&gt;), but all created lumps are added automatically to the &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ABPN-20CLASS-29&#34; title=&#34;MGL-BP:BPN CLASS&#34;&gt;&lt;code&gt;BPN&lt;/code&gt;&lt;/a&gt; being built.&lt;/p&gt; &lt;p&gt;There are many papers and tutorials on LSTMs. This version is well described in &#34;Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling&#34; (2014, Hasim Sak, Andrew Senior, Francoise Beaufays). Using the notation from that paper:&lt;/p&gt; &lt;p&gt;$$ i_t = s(W_{ix} x_t + W_{im} m_{t-1} + W_{ic} \odot c_{t-1} + b_i) $$&lt;/p&gt; &lt;p&gt;$$ f_t = s(W_{fx} x_t + W_{fm} m_{t-1} + W_{fc} \odot c_{t-1} + b_f) $$&lt;/p&gt; &lt;p&gt;$$ c_t = f_t \odot c_{t-1} + i_t \odot g(W_{cx} x_t + W_{cm} m_{t-1} + b_c) $$&lt;/p&gt; &lt;p&gt;$$ o_t = s(W_{ox} x_t + W_{om} m_{t-1} + W_{oc} \odot c_t + b_o) $$&lt;/p&gt; &lt;p&gt;$$ m_t = o_t \odot h(c_t), $$&lt;/p&gt; &lt;p&gt;where &lt;code&gt;i&lt;/code&gt;, &lt;code&gt;f&lt;/code&gt;, and &lt;code&gt;o&lt;/code&gt; are the input, forget and output gates. &lt;code&gt;c&lt;/code&gt; is the cell state and &lt;code&gt;m&lt;/code&gt; is the actual output.&lt;/p&gt; &lt;p&gt;Weight matrices for connections from &lt;code&gt;c&lt;/code&gt; (&lt;code&gt;W_ic&lt;/code&gt;, &lt;code&gt;W_fc&lt;/code&gt; and &lt;code&gt;W_oc&lt;/code&gt;) are diagonal and represented by just the vector of diagonal values. These connections are only added if &lt;code&gt;PEEPHOLES&lt;/code&gt; is true.&lt;/p&gt; &lt;p&gt;A notable difference from the paper is that in addition to being a single lump, &lt;code&gt;x_t&lt;/code&gt; (&lt;code&gt;INPUTS&lt;/code&gt;) can also be a list of lumps. Whenever some activation is to be calculated based on &lt;code&gt;x_t&lt;/code&gt;, it is going to be the sum of individual activations. For example, &lt;code&gt;W_ix * x_t&lt;/code&gt; is really &lt;code&gt;sum_j W_ijx * inputs_j&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If &lt;code&gt;CELL-INIT&lt;/code&gt; is non-NIL, then it must be a &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ACLUMP-20CLASS-29&#34; title=&#34;MGL-BP:CLUMP CLASS&#34;&gt;&lt;code&gt;CLUMP&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;SIZE&lt;/code&gt; form which stands for the initial state of the value cell (&lt;code&gt;c_{-1}&lt;/code&gt;). &lt;code&gt;CELL-INIT&lt;/code&gt; being &lt;code&gt;NIL&lt;/code&gt; is equivalent to the state of all zeros.&lt;/p&gt; &lt;p&gt;&lt;code&gt;ACTIVATION-FN&lt;/code&gt; defaults to &lt;code&gt;-&amp;gt;ACTIVATION&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20CLASS-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION CLASS&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;ACTIVATION FUNCTION&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;), but it can be for example &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3A--3EBATCH-NORMALIZED-ACTIVATION-20FUNCTION-29&#34; title=&#34;MGL-BP:-&gt;BATCH-NORMALIZED-ACTIVATION FUNCTION&#34;&gt;&lt;code&gt;-&amp;gt;BATCH-NORMALIZED-ACTIVATION&lt;/code&gt;&lt;/a&gt;. In general, functions like the aforementioned two with signature like (&lt;code&gt;INPUTS&lt;/code&gt; &lt;code&gt;&amp;amp;KEY&lt;/code&gt; &lt;code&gt;NAME&lt;/code&gt; &lt;code&gt;SIZE&lt;/code&gt; &lt;code&gt;PEEPHOLES&lt;/code&gt;) can be passed as &lt;code&gt;ACTIVATION-FN&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-SEQ-BARRIER-LUMP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h5&gt;Sequence Barrier Lump&lt;/h5&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A--3ESEQ-BARRIER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;-&amp;gt;SEQ-BARRIER&lt;/strong&gt; &lt;em&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ALUMP-20CLASS-29&#34; title=&#34;MGL-BP:LUMP CLASS&#34;&gt;LUMP&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;p&gt;In an &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARNN-20CLASS-29&#34; title=&#34;MGL-BP:RNN CLASS&#34;&gt;&lt;code&gt;RNN&lt;/code&gt;&lt;/a&gt;, processing of stripes (instances in the batch) may require different number of time step so the final state for stripe 0 is in stripe 0 of some lump L at time step 7, while for stripe 1 it is in stripe 1 of sump lump L at time step 42.&lt;/p&gt; &lt;p&gt;This lump copies the per-stripe states from different lumps into a single lump so that further processing can take place (typically when the &lt;code&gt;RNN&lt;/code&gt; is embedded in another network).&lt;/p&gt; &lt;p&gt;The &lt;code&gt;SIZE&lt;/code&gt;(&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP)&#34;&gt;&lt;code&gt;0&lt;/code&gt;&lt;/a&gt; &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29&#34; title=&#34;MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET)&#34;&gt;&lt;code&gt;1&lt;/code&gt;&lt;/a&gt;) of this lump is automatically set to the size of the lump returned by &lt;code&gt;(FUNCALL SEQ-ELT-FN 0)&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASEQ-ELT-FN-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESEQ-BARRIER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[reader] &lt;strong&gt;SEQ-ELT-FN&lt;/strong&gt; &lt;em&gt;-&amp;gt;SEQ-BARRIER (:SEQ-ELT-FN)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A function of an &lt;code&gt;INDEX&lt;/code&gt; argument that returns the lump with that index in some sequence.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ASEQ-INDICES-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESEQ-BARRIER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[accessor] &lt;strong&gt;SEQ-INDICES&lt;/strong&gt; &lt;em&gt;-&amp;gt;SEQ-BARRIER&lt;/em&gt;&lt;/p&gt; &lt;p&gt;A sequence of length batch size of indices. The element at index &lt;code&gt;I&lt;/code&gt; is the index to be passed to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ASEQ-ELT-FN-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESEQ-BARRIER-29-29&#34; title=&#34;MGL-BP:SEQ-ELT-FN (MGL-PAX:READER MGL-BP:-&gt;SEQ-BARRIER)&#34;&gt;&lt;code&gt;SEQ-ELT-FN&lt;/code&gt;&lt;/a&gt; to find the lump whose stripe &lt;code&gt;I&lt;/code&gt; is copied to stripe &lt;code&gt;I&lt;/code&gt; of this this lump.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;11.5 Utilities&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3ARENORMALIZE-ACTIVATIONS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;RENORMALIZE-ACTIVATIONS&lt;/strong&gt; &lt;em&gt;-&amp;gt;V*M-LUMPS L2-UPPER-BOUND&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If the l2 norm of the incoming weight vector of the a unit is larger than &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt; then renormalize it to &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt;. The list of &lt;code&gt;-&amp;gt;V*M-LUMPS&lt;/code&gt; is assumed to be eventually fed to the same lump.&lt;/p&gt; &lt;p&gt;To use it, group the activation clumps into the same GD-OPTIMIZER and hang this function on &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:AFTER-UPDATE-HOOK (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;AFTER-UPDATE-HOOK&lt;/code&gt;&lt;/a&gt;, that latter of which is done for you &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3AARRANGE-FOR-RENORMALIZING-ACTIVATIONS-20FUNCTION-29&#34; title=&#34;MGL-BP:ARRANGE-FOR-RENORMALIZING-ACTIVATIONS FUNCTION&#34;&gt;&lt;code&gt;ARRANGE-FOR-RENORMALIZING-ACTIVATIONS&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;See &#34;Improving neural networks by preventing co-adaptation of feature detectors (Hinton, 2012)&#34;, &lt;a href=&#34;http://arxiv.org/pdf/1207.0580.pdf&#34;&gt;http://arxiv.org/pdf/1207.0580.pdf&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-BP-3AARRANGE-FOR-RENORMALIZING-ACTIVATIONS-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;ARRANGE-FOR-RENORMALIZING-ACTIVATIONS&lt;/strong&gt; &lt;em&gt;BPN OPTIMIZER L2-UPPER-BOUND&lt;/em&gt;&lt;/p&gt; &lt;p&gt;By pushing a lambda to &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29&#34; title=&#34;MGL-GD:AFTER-UPDATE-HOOK (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER)&#34;&gt;&lt;code&gt;AFTER-UPDATE-HOOK&lt;/code&gt;&lt;/a&gt; of &lt;code&gt;OPTIMIZER&lt;/code&gt; arrange for all weights beings trained by &lt;code&gt;OPTIMIZER&lt;/code&gt; to be renormalized (as in &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-BP-3ARENORMALIZE-ACTIVATIONS-20FUNCTION-29&#34; title=&#34;MGL-BP:RENORMALIZE-ACTIVATIONS FUNCTION&#34;&gt;&lt;code&gt;RENORMALIZE-ACTIVATIONS&lt;/code&gt;&lt;/a&gt; with &lt;code&gt;L2-UPPER-BOUND&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;It is assumed that if the weights either belong to an activation lump or are simply added to the activations (i.e. they are biases).&lt;/p&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;12 Boltzmann Machines&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;13 Gaussian Processes&lt;/h2&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h2&gt;14 Natural Language Processing&lt;/h2&gt; &#xA;&lt;h6&gt;[in package MGL-NLP]&lt;/h6&gt; &#xA;&lt;p&gt;This in nothing more then a couple of utilities for now which may grow into a more serious toolset for NLP eventually.&lt;/p&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3AMAKE-N-GRAM-MAPPEE-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;MAKE-N-GRAM-MAPPEE&lt;/strong&gt; &lt;em&gt;FUNCTION N&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Make a function of a single argument that&#39;s suitable as the function argument to a mapper function. It calls &lt;code&gt;FUNCTION&lt;/code&gt; with every &lt;code&gt;N&lt;/code&gt; element.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(map nil (make-n-gram-mappee #&#39;print 3) &#39;(a b c d e))&#xA;..&#xA;.. (A B C) &#xA;.. (B C D) &#xA;.. (C D E) &#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3ABLEU-20FUNCTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[function] &lt;strong&gt;BLEU&lt;/strong&gt; &lt;em&gt;CANDIDATES REFERENCES &amp;amp;KEY CANDIDATE-KEY REFERENCE-KEY (N 4)&lt;/em&gt;&lt;/p&gt; &lt;p&gt;Compute the &lt;a href=&#34;http://en.wikipedia.org/wiki/BLEU&#34;&gt;BLEU score&lt;/a&gt; for bilingual CORPUS. &lt;code&gt;BLEU&lt;/code&gt; measures how good a translation is compared to human reference translations.&lt;/p&gt; &lt;p&gt;&lt;code&gt;CANDIDATES&lt;/code&gt; (keyed by &lt;code&gt;CANDIDATE-KEY&lt;/code&gt;) and &lt;code&gt;REFERENCES&lt;/code&gt; (keyed by &lt;code&gt;REFERENCE-KEY&lt;/code&gt;) are sequences of sentences. A sentence is a sequence of words. Words are compared with &lt;a href=&#34;http://www.lispworks.com/documentation/HyperSpec/Body/f_equal.htm&#34; title=&#34;EQUAL FUNCTION&#34;&gt;&lt;code&gt;EQUAL&lt;/code&gt;&lt;/a&gt;, and may be any kind of object (not necessarily strings).&lt;/p&gt; &lt;p&gt;Currently there is no support for multiple reference translations. &lt;code&gt;N&lt;/code&gt; determines the largest n-grams to consider.&lt;/p&gt; &lt;p&gt;The first return value is the &lt;code&gt;BLEU&lt;/code&gt; score (between 0 and 1, not as a percentage). The second value is the sum of the lengths of &lt;code&gt;CANDIDATES&lt;/code&gt; divided by the sum of the lengths of &lt;code&gt;REFERENCES&lt;/code&gt; (or &lt;code&gt;NIL&lt;/code&gt;, if the denominator is 0). The third is a list of n-gram precisions (also between 0 and 1 or &lt;code&gt;NIL&lt;/code&gt;), one for each element in [1..&lt;code&gt;N&lt;/code&gt;].&lt;/p&gt; &lt;p&gt;This is basically a reimplementation of &lt;a href=&#34;https://github.com/moses-smt/mosesdecoder/raw/master/scripts/generic/multi-bleu.perl&#34;&gt;multi-bleu.perl&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(bleu &#39;((1 2 3 4) (a b))&#xA;      &#39;((1 2 3 4) (1 2)))&#xA;=&amp;gt; 0.8408964&#xA;=&amp;gt; 1&#xA;=&amp;gt; (;; 1-gram precision: 4/6&#xA;    2/3&#xA;    ;; 2-gram precision: 3/4&#xA;    3/4&#xA;    ;; 3-gram precision: 2/2&#xA;    1&#xA;    ;; 4-gram precision: 1/1&#xA;    1)&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3A-40MGL-NLP-BAG-OF-WORDS-20MGL-PAX-3ASECTION-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;h3&gt;14.1 Bag of Words&lt;/h3&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3ABAG-OF-WORDS-ENCODER-20CLASS-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt; &lt;p&gt;[class] &lt;strong&gt;BAG-OF-WORDS-ENCODER&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-CORE-3AENCODE-20GENERIC-FUNCTION-29&#34; title=&#34;MGL-CORE:ENCODE GENERIC-FUNCTION&#34;&gt;&lt;code&gt;ENCODE&lt;/code&gt;&lt;/a&gt; all features of a document with a sparse vector. Get the features of document from &lt;code&gt;MAPPER&lt;/code&gt;, encode each feature with &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3AFEATURE-ENCODER-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34; title=&#34;MGL-NLP:FEATURE-ENCODER (MGL-PAX:READER MGL-NLP:BAG-OF-WORDS-ENCODER)&#34;&gt;&lt;code&gt;FEATURE-ENCODER&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;FEATURE-ENCODER&lt;/code&gt; may return &lt;code&gt;NIL&lt;/code&gt; if the feature is not used. The result is a vector of encoded-feature/value conses. encoded-features are unique (under &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3AENCODED-FEATURE-TEST-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34; title=&#34;MGL-NLP:ENCODED-FEATURE-TEST (MGL-PAX:READER MGL-NLP:BAG-OF-WORDS-ENCODER)&#34;&gt;&lt;code&gt;ENCODED-FEATURE-TEST&lt;/code&gt;&lt;/a&gt;) within the vector but are in no particular order.&lt;/p&gt; &lt;p&gt;Depending on &lt;code&gt;KIND&lt;/code&gt;, value is calculated in various ways:&lt;/p&gt; &#xA;  &lt;ul&gt; &#xA;   &lt;li&gt; &lt;p&gt;For &lt;code&gt;:FREQUENCY&lt;/code&gt; it is the number of times the corresponding feature was found in &lt;code&gt;DOCUMENT&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;For &lt;code&gt;:BINARY&lt;/code&gt; it is always 1.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;For &lt;code&gt;:NORMALIZED-FREQUENCY&lt;/code&gt; and &lt;code&gt;:NORMALIZED-BINARY&lt;/code&gt; are like the unnormalized counterparts except that as the final step values in the assembled sparse vector are normalized to sum to 1.&lt;/p&gt; &lt;/li&gt; &#xA;   &lt;li&gt; &lt;p&gt;Finally, &lt;code&gt;:COMPACTED-BINARY&lt;/code&gt; is like &lt;code&gt;:BINARY&lt;/code&gt; but the return values is not a vector of conses, but a vector of element-type &lt;a href=&#34;https://raw.githubusercontent.com/melisgl/mgl/master/#x-28MGL-NLP-3AENCODED-FEATURE-TYPE-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34; title=&#34;MGL-NLP:ENCODED-FEATURE-TYPE (MGL-PAX:READER MGL-NLP:BAG-OF-WORDS-ENCODER)&#34;&gt;&lt;code&gt;ENCODED-FEATURE-TYPE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &#xA;  &lt;/ul&gt; &lt;pre&gt;&lt;code class=&#34;language-common-lisp&#34;&gt;(let* ((feature-indexer&#xA;         (make-indexer&#xA;          (alexandria:alist-hash-table &#39;((&#34;I&#34; . 3) (&#34;me&#34; . 2) (&#34;mine&#34; . 1)))&#xA;          2))&#xA;       (bag-of-words-encoder&#xA;         (make-instance &#39;bag-of-words-encoder&#xA;                        :feature-encoder feature-indexer&#xA;                        :feature-mapper (lambda (fn document)&#xA;                                          (map nil fn document))&#xA;                        :kind :frequency)))&#xA;  (encode bag-of-words-encoder &#39;(&#34;All&#34; &#34;through&#34; &#34;day&#34; &#34;I&#34; &#34;me&#34; &#34;mine&#34;&#xA;                                 &#34;I&#34; &#34;me&#34; &#34;mine&#34; &#34;I&#34; &#34;me&#34; &#34;mine&#34;)))&#xA;=&amp;gt; #((0 . 3.0d0) (1 . 3.0d0))&#xA;&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3AFEATURE-ENCODER-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;FEATURE-ENCODER&lt;/strong&gt; &lt;em&gt;BAG-OF-WORDS-ENCODER (:FEATURE-ENCODER)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3AFEATURE-MAPPER-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;FEATURE-MAPPER&lt;/strong&gt; &lt;em&gt;BAG-OF-WORDS-ENCODER (:FEATURE-MAPPER)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3AENCODED-FEATURE-TEST-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;ENCODED-FEATURE-TEST&lt;/strong&gt; &lt;em&gt;BAG-OF-WORDS-ENCODER (:ENCODED-FEATURE-TEST = #&#39;EQL)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3AENCODED-FEATURE-TYPE-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;ENCODED-FEATURE-TYPE&lt;/strong&gt; &lt;em&gt;BAG-OF-WORDS-ENCODER (:ENCODED-FEATURE-TYPE = T)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;p&gt;&lt;a id=&#34;x-28MGL-NLP-3ABAG-OF-WORDS-KIND-20-28MGL-PAX-3AREADER-20MGL-NLP-3ABAG-OF-WORDS-ENCODER-29-29&#34;&gt;&lt;/a&gt;&lt;/p&gt; &#xA;&lt;ul&gt; &#xA; &lt;li&gt;[reader] &lt;strong&gt;BAG-OF-WORDS-KIND&lt;/strong&gt; &lt;em&gt;BAG-OF-WORDS-ENCODER (:KIND = :BINARY)&lt;/em&gt;&lt;/li&gt; &#xA;&lt;/ul&gt; &#xA;&lt;hr&gt; &#xA;&lt;h6&gt;[generated by &lt;a href=&#34;https://github.com/melisgl/mgl-pax&#34;&gt;MGL-PAX&lt;/a&gt;]&lt;/h6&gt;</summary>
  </entry>
</feed>